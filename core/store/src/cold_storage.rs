use crate::columns::DBKeyType;
use crate::{DBCol, Store, StoreUpdate};

use borsh::BorshDeserialize;
use near_primitives::types::BlockHeight;
use std::collections::HashMap;
use std::io;
use strum::IntoEnumIterator;

type StoreKey = Vec<u8>;
type StoreValue = Option<Vec<u8>>;
type StoreCache = HashMap<(DBCol, StoreKey), StoreValue>;

struct StoreWithCache<'a> {
    store: &'a Store,
    cache: StoreCache,
}

impl StoreUpdate {
    fn copy_from_store(
        &mut self,
        store: &mut StoreWithCache,
        col: DBCol,
        key: StoreKey,
    ) -> io::Result<()> {
        let data = store.get(col, &key)?;
        if let Some(value) = data {
            if col.is_insert_only() {
                self.insert(col, &key, &value);
            } else if col.is_rc() {
                self.increment_refcount(col, &key, &value);
            } else {
                self.set(col, &key, &value);
            }
        }
        return Ok(());
    }

    pub fn add_cold_update(&mut self, store: &Store, height: &BlockHeight) -> io::Result<()> {
        let _span = tracing::debug_span!(target: "client", "add cold update", height = height);

        let mut store_with_cache = StoreWithCache { store, cache: StoreCache::new() };

        let key_type_to_keys = get_keys_from_store(&mut store_with_cache, height)?;
        for col in DBCol::iter() {
            if col.is_cold() {
                for key in combine_keys(&key_type_to_keys, &col.key_type()) {
                    self.copy_from_store(&mut store_with_cache, col, key)?;
                }
            }
        }

        Ok(())
    }

    pub fn test_genesis_update(&mut self, store: &Store) -> io::Result<()> {
        let mut store_with_cache = StoreWithCache { store, cache: StoreCache::new() };
        for col in DBCol::iter() {
            if col.is_cold() {
                for (key, _) in store.iter(col).map(Result::unwrap) {
                    self.copy_from_store(&mut store_with_cache, col, key.to_vec())?;
                }
            }
        }
        Ok(())
    }
}

fn get_keys_from_store(
    store: &mut StoreWithCache,
    height: &BlockHeight,
) -> io::Result<HashMap<DBKeyType, Vec<StoreKey>>> {
    let mut key_type_to_keys = HashMap::new();

    let height_key = height.to_le_bytes();
    let block_hash_key = store.get_or_err(DBCol::BlockHeight, &height_key)?.as_slice().to_vec();

    for key_type in DBKeyType::iter() {
        key_type_to_keys.insert(
            key_type,
            match key_type {
                DBKeyType::BlockHash => vec![block_hash_key.clone()],
                _ => {
                    vec![]
                }
            },
        );
    }

    Ok(key_type_to_keys)
}

pub fn combine_keys(
    key_type_to_value: &HashMap<DBKeyType, Vec<StoreKey>>,
    key_types: &Vec<DBKeyType>,
) -> Vec<StoreKey> {
    combine_keys_with_stop(key_type_to_value, key_types, key_types.len())
}

/// Recursive method to create every combination of keys values for given order of key types.
/// stop: usize -- what length of key_types to consider.
/// first generates all the key combination for first stop - 1 key types
/// then adds every key value for the last key type to every key value generated by previous call.
fn combine_keys_with_stop(
    key_type_to_keys: &HashMap<DBKeyType, Vec<StoreKey>>,
    keys_order: &Vec<DBKeyType>,
    stop: usize,
) -> Vec<StoreKey> {
    // if no key types are provided, return one empty key value
    if stop == 0 {
        return vec![StoreKey::new()];
    }
    let last_kt = &keys_order[stop - 1];
    // if one of the key types has no keys, no need to calculate anything, the result is empty
    if key_type_to_keys[last_kt].is_empty() {
        return vec![];
    }
    let all_smaller_keys = combine_keys_with_stop(key_type_to_keys, keys_order, stop - 1);
    let mut result_keys = vec![];
    for prefix_key in &all_smaller_keys {
        for suffix_key in &key_type_to_keys[last_kt] {
            let mut new_key = prefix_key.clone();
            new_key.extend(suffix_key);
            result_keys.push(new_key);
        }
    }
    result_keys
}

fn option_to_not_found<T, F>(res: io::Result<Option<T>>, field_name: F) -> io::Result<T>
where
    F: std::string::ToString,
{
    match res {
        Ok(Some(o)) => Ok(o),
        Ok(None) => Err(io::Error::new(io::ErrorKind::NotFound, field_name.to_string())),
        Err(e) => Err(e),
    }
}

#[allow(dead_code)]
impl StoreWithCache<'_> {
    pub fn get(&mut self, column: DBCol, key: &[u8]) -> io::Result<StoreValue> {
        if !self.cache.contains_key(&(column, key.to_vec())) {
            self.cache.insert(
                (column.clone(), key.to_vec()),
                self.store.get(column, key)?.map(|x| x.as_slice().to_vec()),
            );
        }
        Ok(self.cache[&(column, key.to_vec())].clone())
    }

    pub fn get_ser<T: BorshDeserialize>(
        &mut self,
        column: DBCol,
        key: &[u8],
    ) -> io::Result<Option<T>> {
        match self.get(column, key)? {
            Some(bytes) => Ok(Some(T::try_from_slice(&bytes)?)),
            None => Ok(None),
        }
    }

    pub fn get_or_err(&mut self, column: DBCol, key: &[u8]) -> io::Result<Vec<u8>> {
        option_to_not_found(self.get(column, key), format_args!("{:?}: {:?}", column, key))
    }

    pub fn get_ser_or_err<T: BorshDeserialize>(
        &mut self,
        column: DBCol,
        key: &[u8],
    ) -> io::Result<T> {
        option_to_not_found(self.get_ser(column, key), format_args!("{:?}: {:?}", column, key))
    }
}

#[cfg(test)]
mod test {
    use super::{combine_keys, StoreKey};
    use crate::columns::DBKeyType;
    use std::collections::{HashMap, HashSet};

    #[test]
    fn test_combine_keys() {
        // What DBKeyType s are used here does not matter
        let key_type_to_keys = HashMap::from([
            (DBKeyType::BlockHash, vec![vec![1, 2, 3], vec![2, 3]]),
            (DBKeyType::BlockHeight, vec![vec![0, 1], vec![3, 4, 5]]),
            (DBKeyType::ShardId, vec![]),
        ]);

        assert_eq!(
            HashSet::<StoreKey>::from_iter(combine_keys(
                &key_type_to_keys,
                &vec![DBKeyType::BlockHash, DBKeyType::BlockHeight]
            )),
            HashSet::<StoreKey>::from_iter(vec![
                vec![1, 2, 3, 0, 1],
                vec![1, 2, 3, 3, 4, 5],
                vec![2, 3, 0, 1],
                vec![2, 3, 3, 4, 5]
            ])
        );

        assert_eq!(
            HashSet::<StoreKey>::from_iter(combine_keys(
                &key_type_to_keys,
                &vec![DBKeyType::BlockHeight, DBKeyType::BlockHash, DBKeyType::BlockHeight]
            )),
            HashSet::<StoreKey>::from_iter(vec![
                vec![0, 1, 1, 2, 3, 0, 1],
                vec![0, 1, 1, 2, 3, 3, 4, 5],
                vec![0, 1, 2, 3, 0, 1],
                vec![0, 1, 2, 3, 3, 4, 5],
                vec![3, 4, 5, 1, 2, 3, 0, 1],
                vec![3, 4, 5, 1, 2, 3, 3, 4, 5],
                vec![3, 4, 5, 2, 3, 0, 1],
                vec![3, 4, 5, 2, 3, 3, 4, 5]
            ])
        );

        assert_eq!(
            HashSet::<StoreKey>::from_iter(combine_keys(
                &key_type_to_keys,
                &vec![DBKeyType::ShardId, DBKeyType::BlockHeight]
            )),
            HashSet::<StoreKey>::from_iter(vec![])
        );

        assert_eq!(
            HashSet::<StoreKey>::from_iter(combine_keys(
                &key_type_to_keys,
                &vec![DBKeyType::BlockHash, DBKeyType::ShardId]
            )),
            HashSet::<StoreKey>::from_iter(vec![])
        );

        assert_eq!(
            HashSet::<StoreKey>::from_iter(combine_keys(&key_type_to_keys, &vec![])),
            HashSet::<StoreKey>::from_iter(vec![vec![]])
        );
    }
}
