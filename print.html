<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Guide to Nearcore Development</title>
        <meta name="robots" content="noindex" />
        <!-- Custom HTML head -->
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="index.html">Introduction</a></li><li class="chapter-item expanded affix "><li class="part-title">Protocol Specification</li><li class="chapter-item expanded "><a href="DataStructures/index.html"><strong aria-hidden="true">1.</strong> Data Structures</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="DataStructures/AccessKey.html"><strong aria-hidden="true">1.1.</strong> Access Keys</a></li><li class="chapter-item expanded "><a href="DataStructures/Account.html"><strong aria-hidden="true">1.2.</strong> Accounts</a></li><li class="chapter-item expanded "><a href="DataStructures/Block.html"><strong aria-hidden="true">1.3.</strong> Block and Block Header</a></li><li class="chapter-item expanded "><a href="DataStructures/DataTypes.html"><strong aria-hidden="true">1.4.</strong> Data Types</a></li><li class="chapter-item expanded "><a href="DataStructures/MerkleProof.html"><strong aria-hidden="true">1.5.</strong> Merkle Proofs</a></li><li class="chapter-item expanded "><a href="DataStructures/Transaction.html"><strong aria-hidden="true">1.6.</strong> Transaction</a></li></ol></li><li class="chapter-item expanded "><a href="ChainSpec/index.html"><strong aria-hidden="true">2.</strong> Chain Specification</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ChainSpec/BlockProcessing.html"><strong aria-hidden="true">2.1.</strong> Block Processing</a></li><li class="chapter-item expanded "><a href="ChainSpec/Consensus.html"><strong aria-hidden="true">2.2.</strong> Consensus</a></li><li class="chapter-item expanded "><a href="ChainSpec/LightClient.html"><strong aria-hidden="true">2.3.</strong> Light Client</a></li><li class="chapter-item expanded "><a href="ChainSpec/SelectingBlockProducers.html"><strong aria-hidden="true">2.4.</strong> Selecting Chunk and Block Producers</a></li><li class="chapter-item expanded "><a href="ChainSpec/Transactions.html"><strong aria-hidden="true">2.5.</strong> Transactions in the Blockchain Layer</a></li><li class="chapter-item expanded "><a href="ChainSpec/Upgradability.html"><strong aria-hidden="true">2.6.</strong> Upgradability</a></li><li class="chapter-item expanded "><a href="ChainSpec/EpochAndStaking/index.html"><strong aria-hidden="true">2.7.</strong> Epochs and Staking</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ChainSpec/EpochAndStaking/Epoch.html"><strong aria-hidden="true">2.7.1.</strong> Epoch</a></li><li class="chapter-item expanded "><a href="ChainSpec/EpochAndStaking/EpochManager.html"><strong aria-hidden="true">2.7.2.</strong> EpochManager</a></li><li class="chapter-item expanded "><a href="ChainSpec/EpochAndStaking/Staking.html"><strong aria-hidden="true">2.7.3.</strong> Staking and slashing</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="NetworkSpec/NetworkSpec.html"><strong aria-hidden="true">3.</strong> Network Specification</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="NetworkSpec/Messages.html"><strong aria-hidden="true">3.1.</strong> Messages</a></li><li class="chapter-item expanded "><a href="NetworkSpec/RoutingTableExchangeAlgorithm.html"><strong aria-hidden="true">3.2.</strong> Routing Table Exchange Algorithm</a></li></ol></li><li class="chapter-item expanded "><a href="RuntimeSpec/index.html"><strong aria-hidden="true">4.</strong> Runtime Specification</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="RuntimeSpec/AccountStorage.html"><strong aria-hidden="true">4.1.</strong> Account Receipt Storage</a></li><li class="chapter-item expanded "><a href="RuntimeSpec/Actions.html"><strong aria-hidden="true">4.2.</strong> Actions</a></li><li class="chapter-item expanded "><a href="RuntimeSpec/ApplyingChunk.html"><strong aria-hidden="true">4.3.</strong> Applying chunk</a></li><li class="chapter-item expanded "><a href="RuntimeSpec/Components/Components.html"><strong aria-hidden="true">4.4.</strong> Components</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="RuntimeSpec/Components/RuntimeCrate.html"><strong aria-hidden="true">4.4.1.</strong> Runtime Crate</a></li><li class="chapter-item expanded "><a href="RuntimeSpec/Components/BindingsSpec/BindingsSpec.html"><strong aria-hidden="true">4.4.2.</strong> Bindings Specification</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="RuntimeSpec/Components/BindingsSpec/ContextAPI.html"><strong aria-hidden="true">4.4.2.1.</strong> Context API</a></li><li class="chapter-item expanded "><a href="RuntimeSpec/Components/BindingsSpec/EconomicsAPI.html"><strong aria-hidden="true">4.4.2.2.</strong> Economics API</a></li><li class="chapter-item expanded "><a href="RuntimeSpec/Components/BindingsSpec/MathAPI.html"><strong aria-hidden="true">4.4.2.3.</strong> Math API</a></li><li class="chapter-item expanded "><a href="RuntimeSpec/Components/BindingsSpec/MiscellaneousAPI.html"><strong aria-hidden="true">4.4.2.4.</strong> Miscellaneous API</a></li><li class="chapter-item expanded "><a href="RuntimeSpec/Components/BindingsSpec/PromisesAPI.html"><strong aria-hidden="true">4.4.2.5.</strong> Promises API</a></li><li class="chapter-item expanded "><a href="RuntimeSpec/Components/BindingsSpec/RegistersAPI.html"><strong aria-hidden="true">4.4.2.6.</strong> Registers API</a></li><li class="chapter-item expanded "><a href="RuntimeSpec/Components/BindingsSpec/TrieAPI.html"><strong aria-hidden="true">4.4.2.7.</strong> Trie API</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="RuntimeSpec/Fees/Fees.html"><strong aria-hidden="true">4.5.</strong> Fees</a></li><li class="chapter-item expanded "><a href="RuntimeSpec/FunctionCall.html"><strong aria-hidden="true">4.6.</strong> Function Call</a></li><li class="chapter-item expanded "><a href="RuntimeSpec/Preparation.html"><strong aria-hidden="true">4.7.</strong> Contract Preparation</a></li><li class="chapter-item expanded "><a href="RuntimeSpec/Receipts.html"><strong aria-hidden="true">4.8.</strong> Receipts</a></li><li class="chapter-item expanded "><a href="RuntimeSpec/Refunds.html"><strong aria-hidden="true">4.9.</strong> Refunds</a></li><li class="chapter-item expanded "><a href="RuntimeSpec/Runtime.html"><strong aria-hidden="true">4.10.</strong> Runtime</a></li><li class="chapter-item expanded "><a href="RuntimeSpec/Transactions.html"><strong aria-hidden="true">4.11.</strong> Transactions</a></li><li class="chapter-item expanded "><a href="RuntimeSpec/Scenarios/Scenarios.html"><strong aria-hidden="true">4.12.</strong> Scenarios</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="RuntimeSpec/Scenarios/CrossContractCall.html"><strong aria-hidden="true">4.12.1.</strong> Cross-ContractCall</a></li><li class="chapter-item expanded "><a href="RuntimeSpec/Scenarios/FinancialTransaction.html"><strong aria-hidden="true">4.12.2.</strong> Financial Transaction</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="Economics/Economics.html"><strong aria-hidden="true">5.</strong> Economics</a></li><li class="chapter-item expanded "><a href="GenesisConfig/GenesisConfig.html"><strong aria-hidden="true">6.</strong> GenesisConfig</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="GenesisConfig/ExtCostsConfig.html"><strong aria-hidden="true">6.1.</strong> ExtCostsConfig</a></li><li class="chapter-item expanded "><a href="GenesisConfig/VMConfig.html"><strong aria-hidden="true">6.2.</strong> VMConfig</a></li><li class="chapter-item expanded "><a href="GenesisConfig/StateRecord.html"><strong aria-hidden="true">6.3.</strong> StateRecord</a></li><li class="chapter-item expanded "><a href="GenesisConfig/RuntimeConfig.html"><strong aria-hidden="true">6.4.</strong> RuntimeConfig</a></li><li class="chapter-item expanded "><a href="GenesisConfig/RuntimeFeeConfig.html"><strong aria-hidden="true">6.5.</strong> RuntimeFeeConfig</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="GenesisConfig/RuntimeFeeConfig/AccessKeyCreationConfig.html"><strong aria-hidden="true">6.5.1.</strong> AccessKeyCreationConfig</a></li><li class="chapter-item expanded "><a href="GenesisConfig/RuntimeFeeConfig/ActionCreationConfig.html"><strong aria-hidden="true">6.5.2.</strong> ActionCreationConfig</a></li><li class="chapter-item expanded "><a href="GenesisConfig/RuntimeFeeConfig/DataReceiptCreationConfig.html"><strong aria-hidden="true">6.5.3.</strong> DataReceiptCreationConfig</a></li><li class="chapter-item expanded "><a href="GenesisConfig/RuntimeFeeConfig/Fee.html"><strong aria-hidden="true">6.5.4.</strong> Fee</a></li><li class="chapter-item expanded "><a href="GenesisConfig/RuntimeFeeConfig/Fraction.html"><strong aria-hidden="true">6.5.5.</strong> Fraction</a></li><li class="chapter-item expanded "><a href="GenesisConfig/RuntimeFeeConfig/StorageUsageConfig.html"><strong aria-hidden="true">6.5.6.</strong> StorageUsageConfig</a></li></ol></li></ol></li><li class="chapter-item expanded "><li class="part-title">Architecture</li><li class="chapter-item expanded "><a href="architecture/index.html"><strong aria-hidden="true">7.</strong> Overview</a></li><li class="chapter-item expanded "><a href="architecture/how/index.html"><strong aria-hidden="true">8.</strong> How neard works</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="architecture/how/sync.html"><strong aria-hidden="true">8.1.</strong> How Sync Works</a></li><li class="chapter-item expanded "><a href="architecture/how/gc.html"><strong aria-hidden="true">8.2.</strong> Garbage Collection</a></li><li class="chapter-item expanded "><a href="architecture/how/epoch.html"><strong aria-hidden="true">8.3.</strong> How Epoch Works</a></li><li class="chapter-item expanded "><a href="architecture/how/tx_routing.html"><strong aria-hidden="true">8.4.</strong> Transaction Routing</a></li><li class="chapter-item expanded "><a href="architecture/how/tx_receipts.html"><strong aria-hidden="true">8.5.</strong> Transactions And Receipts</a></li><li class="chapter-item expanded "><a href="architecture/how/cross-shard.html"><strong aria-hidden="true">8.6.</strong> Cross shard transactions - deep dive</a></li><li class="chapter-item expanded "><a href="architecture/how/gas.html"><strong aria-hidden="true">8.7.</strong> Gas</a></li><li class="chapter-item expanded "><a href="architecture/how/receipt-congestion.html"><strong aria-hidden="true">8.8.</strong> Receipt Congestion</a></li><li class="chapter-item expanded "><a href="architecture/how/meta-tx.html"><strong aria-hidden="true">8.9.</strong> Meta transactions</a></li><li class="chapter-item expanded "><a href="architecture/how/serialization.html"><strong aria-hidden="true">8.10.</strong> Serialization: Borsh, Json, ProtoBuf</a></li><li class="chapter-item expanded "><a href="architecture/how/proofs.html"><strong aria-hidden="true">8.11.</strong> Proofs</a></li><li class="chapter-item expanded "><a href="architecture/how/resharding_v2.html"><strong aria-hidden="true">8.12.</strong> Resharding V2</a></li><li class="chapter-item expanded "><a href="architecture/how/optimistic_block.html"><strong aria-hidden="true">8.13.</strong> Optimistic block</a></li></ol></li><li class="chapter-item expanded "><a href="architecture/next/index.html"><strong aria-hidden="true">9.</strong> How neard will work</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="architecture/next/catchup_and_state_sync.html"><strong aria-hidden="true">9.1.</strong> Catchup and state sync improvements</a></li><li class="chapter-item expanded "><a href="architecture/next/malicious_chunk_producer_and_phase2.html"><strong aria-hidden="true">9.2.</strong> Malicious producers and phase 2</a></li></ol></li><li class="chapter-item expanded "><a href="architecture/storage.html"><strong aria-hidden="true">10.</strong> Storage</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="architecture/storage/flow.html"><strong aria-hidden="true">10.1.</strong> Storage Request Flow</a></li><li class="chapter-item expanded "><a href="architecture/storage/trie_storage.html"><strong aria-hidden="true">10.2.</strong> Trie Storage</a></li><li class="chapter-item expanded "><a href="architecture/storage/database.html"><strong aria-hidden="true">10.3.</strong> Database Format</a></li><li class="chapter-item expanded "><a href="architecture/storage/flat_storage.html"><strong aria-hidden="true">10.4.</strong> Flat Storage</a></li></ol></li><li class="chapter-item expanded "><a href="architecture/network.html"><strong aria-hidden="true">11.</strong> Network</a></li><li class="chapter-item expanded "><a href="architecture/gas/index.html"><strong aria-hidden="true">12.</strong> Gas Cost Parameters</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="architecture/gas/parameter_definition.html"><strong aria-hidden="true">12.1.</strong> Parameter Definitions</a></li><li class="chapter-item expanded "><a href="architecture/gas/gas_profile.html"><strong aria-hidden="true">12.2.</strong> Gas Profile</a></li><li class="chapter-item expanded "><a href="architecture/gas/estimator.html"><strong aria-hidden="true">12.3.</strong> Runtime Parameter Estimator</a></li></ol></li><li class="chapter-item expanded "><li class="part-title">Practices</li><li class="chapter-item expanded "><a href="practices/index.html"><strong aria-hidden="true">13.</strong> Overview</a></li><li class="chapter-item expanded "><a href="practices/rust.html"><strong aria-hidden="true">14.</strong> Rust ðŸ¦€</a></li><li class="chapter-item expanded "><a href="practices/workflows/index.html"><strong aria-hidden="true">15.</strong> Workflows</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="practices/workflows/run_a_node.html"><strong aria-hidden="true">15.1.</strong> Run a Node</a></li><li class="chapter-item expanded "><a href="practices/workflows/deploy_a_contract.html"><strong aria-hidden="true">15.2.</strong> Deploy a Contract</a></li><li class="chapter-item expanded "><a href="practices/workflows/gas_estimations.html"><strong aria-hidden="true">15.3.</strong> Run Gas Estimations</a></li><li class="chapter-item expanded "><a href="practices/workflows/localnet_on_many_machines.html"><strong aria-hidden="true">15.4.</strong> Localnet on many machines</a></li><li class="chapter-item expanded "><a href="practices/workflows/io_trace.html"><strong aria-hidden="true">15.5.</strong> IO tracing</a></li><li class="chapter-item expanded "><a href="practices/workflows/profiling.html"><strong aria-hidden="true">15.6.</strong> Profiling</a></li><li class="chapter-item expanded "><a href="practices/workflows/benchmarks.html"><strong aria-hidden="true">15.7.</strong> Benchmarks</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="practices/workflows/benchmarking_synthetic_workloads.html"><strong aria-hidden="true">15.7.1.</strong> Synthetic Workloads</a></li><li class="chapter-item expanded "><a href="practices/workflows/benchmarking_chunk_application_on_native_transfers.html"><strong aria-hidden="true">15.7.2.</strong> Native Transfer Chunk Application</a></li></ol></li><li class="chapter-item expanded "><a href="practices/workflows/otel_traces.html"><strong aria-hidden="true">15.8.</strong> Working with OpenTelemetry Traces</a></li><li class="chapter-item expanded "><a href="practices/workflows/futex_contention.html"><strong aria-hidden="true">15.9.</strong> Futex contention</a></li></ol></li><li class="chapter-item expanded "><a href="practices/style.html"><strong aria-hidden="true">16.</strong> Code Style</a></li><li class="chapter-item expanded "><a href="practices/docs.html"><strong aria-hidden="true">17.</strong> Documentation</a></li><li class="chapter-item expanded "><a href="practices/tracking_issues.html"><strong aria-hidden="true">18.</strong> Tracking Issues</a></li><li class="chapter-item expanded "><a href="practices/security_vulnerabilities.html"><strong aria-hidden="true">19.</strong> Security Vulnerabilities</a></li><li class="chapter-item expanded "><a href="practices/fast_builds.html"><strong aria-hidden="true">20.</strong> Fast Builds</a></li><li class="chapter-item expanded "><a href="practices/testing/index.html"><strong aria-hidden="true">21.</strong> Testing</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="practices/testing/python_tests.html"><strong aria-hidden="true">21.1.</strong> Python Tests</a></li><li class="chapter-item expanded "><a href="practices/testing/test_utils.html"><strong aria-hidden="true">21.2.</strong> Testing Utils</a></li><li class="chapter-item expanded "><a href="practices/testing/coverage.html"><strong aria-hidden="true">21.3.</strong> Test Coverage</a></li></ol></li><li class="chapter-item expanded "><a href="practices/protocol_upgrade.html"><strong aria-hidden="true">22.</strong> Protocol Upgrade</a></li><li class="chapter-item expanded affix "><li class="part-title">Advanced configuration</li><li class="chapter-item expanded "><a href="advanced_configuration/networking.html"><strong aria-hidden="true">23.</strong> Networking</a></li><li class="chapter-item expanded affix "><li class="part-title">Custom test networks</li><li class="chapter-item expanded "><a href="test_networks/mainnet_spoon.html"><strong aria-hidden="true">24.</strong> Starting a network from mainnet state</a></li><li class="chapter-item expanded affix "><li class="part-title">Misc</li><li class="chapter-item expanded "><a href="misc/index.html"><strong aria-hidden="true">25.</strong> Overview</a></li><li class="chapter-item expanded "><a href="misc/state_sync_dump.html"><strong aria-hidden="true">26.</strong> State Sync Dump</a></li><li class="chapter-item expanded "><a href="misc/archival_data_recovery.html"><strong aria-hidden="true">27.</strong> Archival node - recovery of missing data</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Guide to Nearcore Development</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/near/nearcore/tree/master/docs" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<p>Welcome to the nearcore development guide!</p>
<p>The target audience of this guide is developers of nearcore itself. If you are
a user of NEAR (either a contract developer, or validator running a node),
please refer to the user docs at <a href="https://docs.near.org">https://docs.near.org</a>.</p>
<p>This guide is built with <a href="https://rust-lang.github.io/mdBook/">mdBook</a>
from sources in the <a href="https://github.com/near/nearcore/">nearcore repository</a>.
You can edit it by pressing the &quot;edit&quot; icon in the top right corner, we welcome
all contributions. The guide is hosted at <a href="https://near.github.io/nearcore/">https://near.github.io/nearcore/</a>.</p>
<p>The guide is organized as a collection of loosely coupled chapters -- you don't
need to read them in order, feel free to peruse the TOC, and focus on
the interesting bits. The chapters are classified into three parts:</p>
<ul>
<li><a href="./architecture/"><strong>Architecture</strong></a> talks about how the code works.
So, for example, if you are interested in how a transaction flows through the
system, look there!</li>
<li><a href="./practices/"><strong>Practices</strong></a> describe, broadly, how we write code.
For example, if you want to learn about code style, issue tracking, or
debugging performance problems, this is the chapter for you.</li>
<li>Finally, the <a href="./misc/"><strong>Misc</strong></a> part holds various assorted bits
and pieces. We are trying to bias ourselves towards writing more docs, so, if
you want to document something and it doesn't cleanly map to a category above,
just put it in misc!</li>
</ul>
<p>If you are unsure, start with <a href="./architecture/">Architecture Overview</a> and then
read <a href="./practices/workflows/run_a_node.html">Run a Node</a></p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="overview"><a class="header" href="#overview">Overview</a></h1>
<p>This chapter describes various data structures used by NEAR Protocol.</p>
<h3 id="data-structures"><a class="header" href="#data-structures">Data Structures</a></h3>
<ul>
<li><a href="DataStructures/./AccessKey.html">Access Keys</a></li>
<li><a href="DataStructures/./Account.html">Accounts</a></li>
<li><a href="DataStructures/./Block.html">Block and Block Header</a></li>
<li><a href="DataStructures/./DataTypes.html">Data Types</a></li>
<li><a href="DataStructures/./MerkleProof.html">Merkle Proofs</a></li>
<li><a href="DataStructures/./Transaction.html">Transaction</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="access-keys"><a class="header" href="#access-keys">Access Keys</a></h1>
<p>Access key provides an access for a particular account. Each access key belongs to some account and
is identified by a unique (within the account) public key. Access keys are stored as <code>account_id,public_key</code> in a trie state. Account can have from <a href="DataStructures/AccessKey.html#account-without-access-keys">zero</a> to multiple access keys.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct AccessKey {
    /// The nonce for this access key.
    /// NOTE: In some cases the access key needs to be recreated. If the new access key reuses the
    /// same public key, the nonce of the new access key should be equal to the nonce of the old
    /// access key. It's required to avoid replaying old transactions again.
    pub nonce: Nonce,
    /// Defines permissions for this access key.
    pub permission: AccessKeyPermission,
}
<span class="boring">}
</span></code></pre></pre>
<p>There are 2 types of <code>AccessKeyPermission</code> in NEAR currently: <code>FullAccess</code> and <code>FunctionCall</code>. <code>FullAccess</code> grants permissions to issue any action on the account. This includes <a href="DataStructures/../RuntimeSpec/Actions.html#deploycontractaction">DeployContract</a>, <a href="DataStructures/../RuntimeSpec/Actions.html#transferaction">Transfer</a> tokens, call functions <a href="DataStructures/../RuntimeSpec/Actions.html#functioncallaction">FunctionCall</a>, <a href="DataStructures/../RuntimeSpec/Actions.html#stakeaction">Stake</a> and even permission to delete the account <a href="DataStructures/../RuntimeSpec/Actions.html#deleteaccountaction">DeleteAccountAction</a>. <code>FunctionCall</code> on the other hand, <strong>only</strong> grants permission to call any or a specific set of methods on one given contract. It has an allowance of <code>$NEAR</code> that can be spent on <strong>GAS and transaction fees only</strong>. Function call access keys <strong>cannot</strong> be used to transfer <code>$NEAR</code>.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum AccessKeyPermission {
    FunctionCall(FunctionCallPermission),
    FullAccess,
}
<span class="boring">}
</span></code></pre></pre>
<h2 id="accesskeypermissionfunctioncall"><a class="header" href="#accesskeypermissionfunctioncall">AccessKeyPermission::FunctionCall</a></h2>
<p>Grants limited permission to make <a href="DataStructures/../RuntimeSpec/Actions.html#functioncallaction">FunctionCall</a> to a specified <code>receiver_id</code> and methods of a particular contract with a limit of allowed balance to spend.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct FunctionCallPermission {
    /// Allowance is a balance limit to use by this access key to pay for function call gas and
    /// transaction fees. When this access key is used, both account balance and the allowance is
    /// decreased by the same value.
    /// `None` means unlimited allowance.
    /// NOTE: To change or increase the allowance, the old access key needs to be deleted and a new
    /// access key should be created.
    pub allowance: Option&lt;Balance&gt;,

    /// The access key only allows transactions with the given receiver's account id.
    pub receiver_id: AccountId,

    /// A list of method names that can be used. The access key only allows transactions with the
    /// function call of one of the given method names.
    /// Empty list means any method name can be used.
    pub method_names: Vec&lt;String&gt;,
}
<span class="boring">}
</span></code></pre></pre>
<h2 id="account-without-access-keys"><a class="header" href="#account-without-access-keys">Account without access keys</a></h2>
<p>If account has no access keys attached it means that it has no owner who can run transactions from its behalf. However, if such accounts has code it can be invoked by other accounts and contracts.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="accounts"><a class="header" href="#accounts">Accounts</a></h1>
<h2 id="account-id"><a class="header" href="#account-id">Account ID</a></h2>
<p>NEAR Protocol has an account names system. Account ID is similar to a username. Account IDs have to follow the rules.</p>
<h3 id="account-id-rules"><a class="header" href="#account-id-rules">Account ID Rules</a></h3>
<ul>
<li>minimum length is 2</li>
<li>maximum length is 64</li>
<li><strong>Account ID</strong> consists of <strong>Account ID parts</strong> separated by <code>.</code></li>
<li><strong>Account ID part</strong> consists of lowercase alphanumeric symbols separated by either <code>_</code> or <code>-</code>.</li>
<li><strong>Account ID</strong> that is 64 characters long and consists of lowercase hex characters is a specific <strong>NEAR-implicit account ID</strong>.</li>
<li><strong>Account ID</strong> that is <code>0x</code> followed by 40 lowercase hex characters is a specific <strong>ETH-implicit account ID</strong>.</li>
</ul>
<p>Account names are similar to a domain names.
Top level account (TLA) like <code>near</code>, <code>com</code>, <code>eth</code> can only be created by <code>registrar</code> account (see next section for more details).
Only <code>near</code> can create <code>alice.near</code>. And only <code>alice.near</code> can create <code>app.alice.near</code> and so on.
Note, <code>near</code> can NOT create <code>app.alice.near</code> directly.</p>
<p>Additionally, there is an <a href="DataStructures/Account.html#implicit-account-creation">implicit account creation path</a>.</p>
<p>Regex for a full account ID, without checking for length:</p>
<pre><code class="language-regex">^(([a-z\d]+[\-_])*[a-z\d]+\.)*([a-z\d]+[\-_])*[a-z\d]+$
</code></pre>
<h3 id="top-level-accounts"><a class="header" href="#top-level-accounts">Top Level Accounts</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Name</th><th>Value</th></tr></thead><tbody>
<tr><td>REGISTRAR_ACCOUNT_ID</td><td><code>registrar</code></td></tr>
</tbody></table>
</div>
<p>Top level account names (TLAs) are very valuable as they provide root of trust and discoverability for companies, applications and users.
To allow for fair access to them, the top level account names are going to be auctioned off.</p>
<p>Specifically, only <code>REGISTRAR_ACCOUNT_ID</code> account can create new top level accounts (other than <a href="DataStructures/Account.html#implicit-accounts">implicit accounts</a>). <code>REGISTRAR_ACCOUNT_ID</code> implements standard Account Naming (link TODO) interface to allow create new accounts.</p>
<p><em>Note: we are not going to deploy <code>registrar</code> auction at launch, instead allow to deploy it by Foundation after initial launch. The link to details of the auction will be added here in the next spec release post MainNet.</em></p>
<h3 id="examples"><a class="header" href="#examples">Examples</a></h3>
<p>Valid accounts:</p>
<pre><code class="language-c">ok
bowen
ek-2
ek.near
com
google.com
bowen.google.com
near
illia.cheap-accounts.near
max_99.near
100
near2019
over.9000
a.bro
// Valid, but can't be created, because &quot;a&quot; is too short
bro.a
</code></pre>
<p>Invalid accounts:</p>
<pre><code class="language-c">not ok           // Whitespace characters are not allowed
a                // Too short
100-             // Suffix separator
bo__wen          // Two separators in a row
_illia           // Prefix separator
.near            // Prefix dot separator
near.            // Suffix dot separator
a..near          // Two dot separators in a row
$$$              // Non alphanumeric characters are not allowed
WAT              // Non lowercase characters are not allowed
me@google.com    // @ is not allowed (it was allowed in the past)
system           // cannot use the system account, see the section on System account below
// TOO LONG:
abcdefghijklmnopqrstuvwxyz.abcdefghijklmnopqrstuvwxyz.abcdefghijklmnopqrstuvwxyz
</code></pre>
<h2 id="system-account"><a class="header" href="#system-account">System account</a></h2>
<p><code>system</code> is a special account that is only used to identify refund receipts. For refund receipts, we set the predecessor_id to be <code>system</code> to indicate that it is a refund receipt. Users cannot create or access the <code>system</code> account. In fact, this account does not exist as part of the state.</p>
<h2 id="implicit-accounts"><a class="header" href="#implicit-accounts">Implicit accounts</a></h2>
<p>Implicit accounts work similarly to Bitcoin/Ethereum accounts.
You can reserve an account ID before it's created by generating a corresponding (public, private) key pair locally.
The public key maps to the account ID. The corresponding secret key allows you to use the account once it's created on chain.</p>
<h3 id="near-implicit-account-id"><a class="header" href="#near-implicit-account-id">NEAR-implicit account ID</a></h3>
<p>The account ID is a lowercase hex representation of the public key.
An ED25519 public key is 32 bytes long and maps to a 64-character account ID.</p>
<p>Example: a public key in base58 <code>BGCCDDHfysuuVnaNVtEhhqeT4k9Muyem3Kpgq2U1m9HX</code> will map to the account ID <code>98793cd91a3f870fb126f66285808c7e094afcfc4eda8a970f6648cdf0dbd6de</code>.</p>
<h3 id="eth-implicit-account-id"><a class="header" href="#eth-implicit-account-id">ETH-implicit account ID</a></h3>
<p>The account ID is derived from a Secp256K1 public key using the following formula: <code>'0x' + keccak256(public_key)[12:32].hex()</code>.</p>
<p>Example: a public key in base58 <code>2KFsZcvNUMBfmTp5DTMmguyeQyontXZ2CirPsb21GgPG3KMhwrkRuNiFCdMyRU3R4KbopMpSMXTFQfLoMkrg4HsT</code> will map to the account ID <code>0x87b435f1fcb4519306f9b755e274107cc78ac4e3</code>.</p>
<h3 id="implicit-account-creation"><a class="header" href="#implicit-account-creation">Implicit account creation</a></h3>
<p>An account with implicit account ID can only be created by sending a transaction/receipt with a single <code>Transfer</code> action to the implicit account ID receiver:</p>
<ul>
<li>The account will be created with the account ID.</li>
<li>The account balance will have a transfer balance deposited to it.</li>
<li>If this is NEAR-implicit account, it will have a new full access key with the ED25519-curve public key of <code>decode_hex(account_id)</code> and nonce <code>(block_height - 1) * MULTIPLIER</code> (to address an issues discussed <a href="https://gov.near.org/t/issue-with-access-key-nonce/749">here</a>).</li>
<li>If this is ETH-implicit account, it will have the <a href="DataStructures/Account.html#wallet-contract">Wallet Contract</a> deployed, which can only be used by the owner of the Secp256K1 private key where <code>'0x' + keccak256(public_key)[12:32].hex()</code> matches the account ID.</li>
</ul>
<p>Implicit account can not be created using <code>CreateAccount</code> action to avoid being able to hijack the account without having the corresponding private key.</p>
<p>Once a NEAR-implicit account is created it acts as a regular account until it's deleted.</p>
<p>An ETH-implicit account can only be used by calling the methods of the <a href="DataStructures/Account.html#wallet-contract">Wallet Contract</a>. It cannot be deleted, nor can a full access key be added.
The primary purpose of ETH-implicit accounts is to enable seamless integration of existing Ethereum tools (such as wallets) with the NEAR blockchain.</p>
<h3 id="wallet-contract"><a class="header" href="#wallet-contract">Wallet Contract</a></h3>
<p>The Wallet Contract (see <a href="https://github.com/near/NEPs/issues/518">NEP-518</a> for more details) functions as a user account and is designed to receive, validate, and execute Ethereum-compatible transactions on the NEAR blockchain.</p>
<p>Without going into details, an Ethereum-compatible wallet user sends a transaction to an RPC endpoint, which wraps it and passes it to the Wallet Contract (on the target account) as an <code>rlp_execute(target: AccountId, tx_bytes_b64: Vec&lt;u8&gt;)</code> contract call.
Then, the contract parses <code>tx_bytes_b64</code> and verifies it is signed with the private key matching the target <a href="DataStructures/Account.html#eth-implicit-account-id">ETH-implicit account ID</a> on which the contract is hosted.</p>
<p>Under the hood, the transaction encodes a NEAR-native action. Currently supported actions are:</p>
<ul>
<li>Transfer (from ETH-implicit account).</li>
<li>Function call (call another contract).</li>
<li>Add <code>AccessKey</code> with <code>FunctionCallPermission</code>. This allows adding a relayer's public key to an ETH-implicit account, enabling the relayer to pay the gas fee for transactions from this account. Still, each transaction has to be signed by the owner of the account (corresponding Secp256K1 private key).</li>
<li>Delete <code>AccessKey</code>.</li>
</ul>
<h2 id="account"><a class="header" href="#account">Account</a></h2>
<p>Data for a single account is collocated in one shard. The account data consists of the following:</p>
<ul>
<li>Balance</li>
<li>Locked balance (for staking)</li>
<li>Code of the contract</li>
<li>Key-value storage of the contract. Stored in a ordered trie</li>
<li><a href="DataStructures/AccessKey.html">Access Keys</a></li>
<li><a href="DataStructures/../RuntimeSpec/Receipts.html#postponed-actionreceipt">Postponed ActionReceipts</a></li>
<li><a href="DataStructures/../RuntimeSpec/Receipts.html#received-datareceipt">Received DataReceipts</a></li>
</ul>
<h4 id="balances"><a class="header" href="#balances">Balances</a></h4>
<p>Total account balance consists of unlocked balance and locked balance.</p>
<p>Unlocked balance is tokens that the account can use for transaction fees, transfers staking and other operations.</p>
<p>Locked balance is the tokens that are currently in use for staking to be a validator or to become a validator.
Locked balance may become unlocked at the beginning of an epoch. See <a href="DataStructures/../ChainSpec/EpochAndStaking/Staking.html">Staking</a> for details.</p>
<h4 id="contracts"><a class="header" href="#contracts">Contracts</a></h4>
<p>A contract (AKA smart contract) is a program in WebAssembly that belongs to a specific account.
When account is created, it doesn't have a contract (except ETH-implicit accounts).
A contract has to be explicitly deployed, either by the account owner, or during the account creation.
A contract can be executed by anyone who calls a method on your account. A contract has access to the storage on your account.</p>
<h4 id="storage"><a class="header" href="#storage">Storage</a></h4>
<p>Every account has its own storage. It's a persistent key-value trie. Keys are ordered in lexicographical order.
The storage can only be modified by the contract on the account.
Current implementation on Runtime only allows your account's contract to read from the storage, but this might change in the future and other accounts's contracts will be able to read from your storage.</p>
<p>NOTE: Accounts must maintain a minimum amount of value at a rate of 1 NEAR per 100kb of total storage in order to remain responsive.
This includes the storage of the account itself, contract code, contract storage, and all access keys.
Any account with less than this minimum amount will not be able to maintain a responsive contract and will, instead, return an error related to this mismatch in storage vs. minimum account balance.
See <a href="https://docs.near.org/concepts/storage/storage-staking">Storage Staking</a> in the docs.</p>
<h4 id="access-keys-1"><a class="header" href="#access-keys-1">Access Keys</a></h4>
<p>An access key grants an access to a account. Each access key on the account is identified by a unique public key.
This public key is used to validate signature of transactions.
Each access key contains a unique nonce to differentiate or order transactions signed with this access key.</p>
<p>An access key has a permission associated with it. The permission can be one of two types:</p>
<ul>
<li><code>FullAccess</code> permission. It grants full access to the account.</li>
<li><code>FunctionCall</code> permission. It grants access to only issued function call transactions.</li>
</ul>
<p>See <a href="DataStructures/AccessKey.html">Access Keys</a> for more details.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="block-and-block-header"><a class="header" href="#block-and-block-header">Block and Block Header</a></h1>
<p>The data structures for block and block headers are</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct Block {
    /// Block Header
    pub header: BlockHeader,
    /// Headers of chunk in the block
    pub chunks: Vec&lt;ShardChunkHeader&gt;,
    /// Challenges, but they are not used today
    pub challenges: Challenges,

    /// Data to confirm the correctness of randomness beacon output
    pub vrf_value: [u8; 32],
    pub vrf_proof: [u8; 64],
}
<span class="boring">}
</span></code></pre></pre>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct BlockHeader {
    pub prev_hash: CryptoHash,

    /// Inner part of the block header that gets hashed, split into two parts, one that is sent
    ///    to light clients, and the rest
    pub inner_lite: BlockHeaderInnerLite,
    pub inner_rest: BlockHeaderInnerRest,

    /// Signature of the block producer.
    pub signature: Signature,

    /// Cached value of hash for this block.
    pub hash: CryptoHash,
}
<span class="boring">}
</span></code></pre></pre>
<p>where <code>BlockHeaderInnerLite</code> and <code>BlockHeaderInnerRest</code> are</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct BlockHeaderInnerLite {
    /// Height of this block.
    pub height: u64,
    /// Epoch start hash of this block's epoch.
    /// Used for retrieving validator information
    pub epoch_id: EpochId,
    pub next_epoch_id: EpochId,
    /// Root hash of the state at the previous block.
    pub prev_state_root: CryptoHash,
    /// Root of the outcomes of transactions and receipts.
    pub outcome_root: CryptoHash,
    /// Timestamp at which the block was built (number of non-leap-nanoseconds since January 1, 1970 0:00:00 UTC).
    pub timestamp: u64,
    /// Hash of the next epoch block producers set
    pub next_bp_hash: CryptoHash,
    /// Merkle root of block hashes up to the current block.
    pub block_merkle_root: CryptoHash,
}
<span class="boring">}
</span></code></pre></pre>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct BlockHeaderInnerRest {
    /// Root hash of the chunk receipts in the given block.
    pub chunk_receipts_root: CryptoHash,
    /// Root hash of the chunk headers in the given block.
    pub chunk_headers_root: CryptoHash,
    /// Root hash of the chunk transactions in the given block.
    pub chunk_tx_root: CryptoHash,
    /// Root hash of the challenges in the given block.
    pub challenges_root: CryptoHash,
    /// The output of the randomness beacon
    pub random_value: CryptoHash,
    /// Validator proposals.
    pub validator_proposals: Vec&lt;ValidatorStake&gt;,
    /// Mask for new chunks included in the block
    pub chunk_mask: Vec&lt;bool&gt;,
    /// Gas price. Same for all chunks
    pub gas_price: u128,
    /// Total supply of tokens in the system
    pub total_supply: u128,
    /// List of challenges result from previous block.
    pub challenges_result: ChallengesResult,

    /// Last block that has full BFT finality
    pub last_final_block: CryptoHash,
    /// Last block that has doomslug finality
    pub last_ds_final_block: CryptoHash,

    /// The ordinal of the Block on the Canonical Chain
    pub block_ordinal: u64,
    
    /// All the approvals included in this block
    pub approvals: Vec&lt;Option&lt;Signature&gt;&gt;,

    /// Latest protocol version that this block producer has.
    pub latest_protocol_version: u32,
}
<span class="boring">}
</span></code></pre></pre>
<p>Here <code>CryptoHash</code> is a 32-byte hash and <code>EpochId</code> is a 32-byte identifier.</p>
<h2 id="block-hash"><a class="header" href="#block-hash">Block Hash</a></h2>
<p>The hash of a block is computed by</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>sha256(concat(
    sha256(concat(
        sha256(borsh(inner_lite)),
        sha256(borsh(inner_rest))
    )),
    prev_hash
))
<span class="boring">}
</span></code></pre></pre>
<h1 id="chunk-and-chunk-header"><a class="header" href="#chunk-and-chunk-header">Chunk and Chunk Header</a></h1>
<p>The data structures for chunk and chunk header are</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct ShardChunkHeader {
    pub inner: ShardChunkHeaderInner,

    pub height_included: BlockHeight,

    /// Signature of the chunk producer.
    pub signature: Signature,

    pub hash: ChunkHash,
}
<span class="boring">}
</span></code></pre></pre>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct ShardChunk {
    pub chunk_hash: ChunkHash,
    pub header: ShardChunkHeader,
    pub transactions: Vec&lt;SignedTransaction&gt;,
    pub receipts: Vec&lt;Receipt&gt;,
}
<span class="boring">}
</span></code></pre></pre>
<p>where <code>ShardChunkHeaderInner</code> is</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct ShardChunkHeaderInner {
    /// Previous block hash.
    pub prev_block_hash: CryptoHash,
    pub prev_state_root: CryptoHash,
    /// Root of the outcomes from execution transactions and results.
    pub outcome_root: CryptoHash,
    pub encoded_merkle_root: CryptoHash,
    pub encoded_length: u64,
    pub height_created: u64,
    /// Shard index.
    pub shard_id: u64,
    /// Gas used in this chunk.
    pub gas_used: u64,
    /// Gas limit voted by validators.
    pub gas_limit: u64,
    /// Total balance burnt in previous chunk
    pub balance_burnt: u128,
    /// Outgoing receipts merkle root.
    pub outgoing_receipts_root: CryptoHash,
    /// Tx merkle root.
    pub tx_root: CryptoHash,
    /// Validator proposals.
    pub validator_proposals: Vec&lt;ValidatorStake&gt;,
}
<span class="boring">}
</span></code></pre></pre>
<h2 id="chunk-hash"><a class="header" href="#chunk-hash">Chunk Hash</a></h2>
<p>Chunk hash is computed by</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>sha256(
    concat(
        sha256(borsh(inner)),
        encoded_merkle_root
    )
)
<span class="boring">}
</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="data-types"><a class="header" href="#data-types">Data Types</a></h1>
<h2 id="type-cryptohash--u8-32"><a class="header" href="#type-cryptohash--u8-32">type CryptoHash = [u8; 32]</a></h2>
<p>A sha256 or keccak256 hash.</p>
<h2 id="accountid--string"><a class="header" href="#accountid--string">AccountId = String</a></h2>
<p>Account identifier. Provides access to user's state.</p>
<h2 id="type-merklehash--cryptohash"><a class="header" href="#type-merklehash--cryptohash">type MerkleHash = CryptoHash</a></h2>
<p>Hash used by a struct implementing the Merkle tree.</p>
<h2 id="type-validatorid--usize"><a class="header" href="#type-validatorid--usize">type ValidatorId = usize</a></h2>
<p>Validator identifier in current group.</p>
<h2 id="type-validatormask--bool"><a class="header" href="#type-validatormask--bool">type ValidatorMask = [bool]</a></h2>
<p>Mask which validators participated in multi sign.</p>
<h2 id="type-storageusage--u64"><a class="header" href="#type-storageusage--u64">type StorageUsage = u64</a></h2>
<p>StorageUsage is used to count the amount of storage used by a contract.</p>
<h2 id="type-storageusagechange--i64"><a class="header" href="#type-storageusagechange--i64">type StorageUsageChange = i64</a></h2>
<p>StorageUsageChange is used to count the storage usage within a single contract call.</p>
<h2 id="type-nonce--u64"><a class="header" href="#type-nonce--u64">type Nonce = u64</a></h2>
<p>Nonce for transactions.</p>
<h2 id="type-blockindex--u64"><a class="header" href="#type-blockindex--u64">type BlockIndex = u64</a></h2>
<p>Index of the block.</p>
<h2 id="type-shardid--u64"><a class="header" href="#type-shardid--u64">type ShardId = u64</a></h2>
<p>Shard index, from 0 to NUM_SHARDS - 1.</p>
<h2 id="type-balance--u128"><a class="header" href="#type-balance--u128">type Balance = u128</a></h2>
<p>Balance is type for storing amounts of tokens.</p>
<h2 id="gas--u64"><a class="header" href="#gas--u64">Gas = u64</a></h2>
<p>Gas is a type for storing amount of gas.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="merkle-proofs"><a class="header" href="#merkle-proofs">Merkle Proofs</a></h1>
<!-- cspell:ignore CRYPTOHASH elif -->
<p>Many components of NEAR Protocol rely on Merkle root and Merkle proofs. For an array of sha256 hashes, we define its
merkle root as:</p>
<pre><code class="language-python">CRYPTOHASH_DEFAULT = [0] * 32
def combine_hash(hash1, hash2):
    return sha256(hash1 + hash2)

def merkle_root(hashes):
    if len(hashes) == 0:
        return CRYPTOHASH_DEFAULT
    elif len(hashes) == 1:
        return hashes[0]
    else:
        l = hashes.len();
        subtree_len = l.next_power_of_two() // 2;
        left_root = merkle_root(hashes[0:subtree_len])
        right_root = merkle_root(hashes[subtree_len:l])
        return combine_hash(left_root, right_root)
</code></pre>
<p>Generally, for an array of borsh-serializable object, its merkle root is defined as</p>
<pre><code class="language-python">def arr_merkle_root(arr):
    return merkle_root(list(map(lambda x: sha256(borsh(x)), arr)))
</code></pre>
<p>A Merkle proof is defined by:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct MerklePathItem {
    pub hash: MerkleHash,
    pub direction: Direction,
}

pub enum Direction {
    Left,
    Right,
}

pub type MerkleProof = Vec&lt;MerklePathItem&gt;;
<span class="boring">}
</span></code></pre></pre>
<p>The verification of a hash <code>h</code> against a proclaimed merkle root <code>r</code> with proof <code>p</code> is defined by:</p>
<pre><code class="language-python">def compute_root(h, p):
    res = h
    for item in p:
        if item.direction is Left:
            res = combine_hash(item.hash, res)
        else:
            res = combine_hash(res, item.hash)
    return res

assert compute_root(h, p) == r
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="transaction"><a class="header" href="#transaction">Transaction</a></h1>
<p>See <a href="DataStructures/../RuntimeSpec/Transactions.html">Transactions</a> documentation in the <a href="DataStructures/../RuntimeSpec">Runtime Specification</a> section.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="overview-1"><a class="header" href="#overview-1">Overview</a></h1>
<p>This chapter covers the NEAR Protocol chain specification.</p>
<h3 id="chain-specification"><a class="header" href="#chain-specification">Chain Specification</a></h3>
<ul>
<li><a href="ChainSpec/./BlockProcessing.html">Block Processing</a></li>
<li><a href="ChainSpec/./Consensus.html">Consensus</a></li>
<li><a href="ChainSpec/./LightClient.html">Light Client</a></li>
<li><a href="ChainSpec/./SelectingBlockProducers.html">Selecting Chunk and Block Producers</a></li>
<li><a href="ChainSpec/./Transactions.html">Transactions in the Blockchain Layer</a></li>
<li><a href="ChainSpec/./Upgradability.html">Upgradability</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="block-processing"><a class="header" href="#block-processing">Block Processing</a></h1>
<p>This section covers how blocks are processed once they arrive from the network.</p>
<h2 id="data-structures-1"><a class="header" href="#data-structures-1">Data Structures</a></h2>
<p>Please refer to <a href="ChainSpec/../DataStructures/Block.html">this section</a> for details about blocks and chunks.</p>
<h2 id="validity-of-block-header"><a class="header" href="#validity-of-block-header">Validity of Block Header</a></h2>
<p>A block header is invalid if any of the following holds:</p>
<ul>
<li><code>timestamp</code> is invalid due to one of the following:
<ul>
<li>It is more than 120s ahead of the local time of the machine.</li>
<li>It is smaller than the timestamp of the previous block.</li>
</ul>
</li>
<li>Its signature is not valid, i.e, verifying the signature using the public key of the block producer fails</li>
<li><code>epoch_id</code> is invalid, i.e, it does not match the epoch id of the block computed locally.</li>
<li><code>next_bp_hash</code> is invalid. This could mean one of the following:
<ul>
<li><code>epoch_id == prev_block.epoch_id &amp;&amp; next_bp_hash != prev_block.next_bp_hash</code></li>
<li><code>epoch_id != prev_block.epoch_id &amp;&amp; next_bp_hash != compute_bp_hash(next_epoch_id, prev_hash)</code> where <code>compute_bp_hash</code> computes the hash of next epoch's validators.</li>
</ul>
</li>
<li><code>chunk_mask</code> does not match the size of the chunk mask is not the same as the number of shards</li>
<li>Approval or finality information is invalid. See <a href="ChainSpec/Consensus.html">consensus</a> for more details.</li>
</ul>
<h2 id="validity-of-block"><a class="header" href="#validity-of-block">Validity of Block</a></h2>
<p>A block is invalid if any of the following holds:</p>
<ul>
<li>Any of the chunk headers included in the block has an invalid signature.</li>
<li>State root computed from chunk headers does not match <code>state_root</code> in the header.</li>
<li>Receipts root computed from chunk headers does not match <code>chunk_receipts_root</code> in the header.</li>
<li>Chunk headers root computed from chunk headers does not match <code>chunk_headers_root</code> in the header.</li>
<li>Transactions root computed from chunk headers does not match <code>chunk_tx_root</code> in the header.</li>
<li>For some index <code>i</code>, <code>chunk_mask[i]</code> does not match whether a new chunk from shard <code>i</code> is included in the block.</li>
<li>Its vrf output is invalid</li>
<li>Its gas price is invalid, i.e, gas priced computed from previous gas price and gas usage from chunks included in the block according to the formula described in <a href="ChainSpec/../Economics/Economics.html">economics</a> does not match the gas price in the header.</li>
<li>Its <code>validator_proposals</code> is not valid, which means that it does not match the concatenation of validator proposals from the chunk headers included in the block.</li>
</ul>
<h2 id="process-a-new-block"><a class="header" href="#process-a-new-block">Process a new block</a></h2>
<p>When a new block <code>B</code> is received from the network, the node first check whether it is ready to be processed:</p>
<ul>
<li>Its parent has already been processed.</li>
<li>Header and the block itself are valid</li>
<li>All the chunk parts are received. More specifically, this means
<ul>
<li>For any shard that the node tracks, if there is a new chunk from that shard included in <code>B</code>, the node has the entire chunk.</li>
<li>For block producers, they have their chunk parts for shards they do not track to guarantee data availability.</li>
</ul>
</li>
</ul>
<p>Once all the checks are done, the chunks included in <code>B</code> can be applied.</p>
<p>If the chunks are successfully applied, <code>B</code> is saved and if the height of <code>B</code> is higher than the highest known block (head of the chain),
the head is updated.</p>
<h2 id="apply-a-chunk"><a class="header" href="#apply-a-chunk">Apply a chunk</a></h2>
<p>In order to apply a chunk, we first check that the chunk is valid:</p>
<pre><code class="language-python">def validate_chunk(chunk):
    # get the local result of applying the previous chunk (chunk_extra)
    prev_chunk_extra = get_chunk_extra(chunk.prev_block_hash, chunk.shard_id)
    # check that the post state root of applying the previous chunk matches the prev state root in the current chunk
    assert prev_chunk_extra.state_root == chunk.state_root
    # check that the merkle root of execution outcomes match
    assert prev_chunk_extra.outcome_root == chunk.outcome_root
    # check that validator proposals match
    assert prev_chunk_extra.validator_proposals == chunk.validator_proposals
    # check that gas usage matches
    assert prev_chunk_extra.gas_used == chunk.gas_used
    # check that balance burnt matches
    assert prev_chunk_extra.balance_burnt == chunk.balance_burnt
    # check outgoing receipt root matches
    assert prev_chunk_extra.outgoing_receipt_root == chunk.outgoing_receipt_root
</code></pre>
<p>After this we apply transactions and receipts:</p>
<pre><code class="language-python"># get the incoming receipts for this shard
incoming_receipts = get_incoming_receipts(block_hash, shard_id)
# apply transactions and receipts and obtain the result, which includes state changes and execution outcomes
apply_result = apply_transactions(shard_id, state_root, chunk.transactions, incoming_receipts, other_block_info)
# save apply result locally
save_result(apply_result)
</code></pre>
<h2 id="catchup"><a class="header" href="#catchup">Catchup</a></h2>
<p>If a node validates shard <code>X</code> in epoch <code>T</code> and needs to validate shard <code>Y</code> in epoch <code>T+1</code> due to validator rotation, it has to download the state of that shard before epoch <code>T+1</code> starts to be able to do so.
To accomplish this, the node will start downloading the state of shard <code>Y</code> at the beginning of epoch <code>T</code> and, after it has successfully downloaded the state, will apply all the chunks for shard <code>Y</code> in epoch <code>T</code> until the current block.
From there the node will apply chunks for both shard <code>X</code> and shard <code>Y</code> for the rest of the epoch.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="consensus"><a class="header" href="#consensus">Consensus</a></h1>
<h2 id="definitions-and-notation"><a class="header" href="#definitions-and-notation">Definitions and notation</a></h2>
<!-- cspell:ignore operatorname preconfigured -->
<p>For the purpose of maintaining consensus, transactions are grouped into <em>blocks</em>. There is a single preconfigured block <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">G</span></span></span></span> called <em>genesis block</em>. Every block except <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">G</span></span></span></span> has a link pointing to the <em>previous block</em> <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm" style="margin-right:0.01389em;">prev</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mclose">)</span></span></span></span>, where <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> is the block, and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">G</span></span></span></span> is reachable from every block by following those links (that is, there are no cycles).</p>
<p>The links between blocks give rise to a partial order: for blocks <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>, <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> means that <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel"><span class="mrel"><span class="mord vbox"><span class="thinbox"><span class="rlap"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="inner"><span class="mord"><span class="mrel">î€ </span></span></span><span class="fix"></span></span></span></span></span><span class="mrel">=</span></span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> is reachable from <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> by following links to previous blocks, and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8193em;vertical-align:-0.136em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">â‰¤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> means that <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> or <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>. The relations <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mrel">&gt;</span></span></span></span> and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7719em;vertical-align:-0.136em;"></span><span class="mrel">â‰¥</span></span></span></span> are defined as the reflected versions of <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mrel">&lt;</span></span></span></span> and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7719em;vertical-align:-0.136em;"></span><span class="mrel">â‰¤</span></span></span></span>, respectively. Finally, <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">âˆ¼</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> means that either <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>, <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> or <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>, and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel amsrm">â‰</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> means the opposite.</p>
<p>A <em>chain</em> <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">chain</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">)</span></span></span></span> is a set of blocks reachable from block <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span>, which is called its <em>tip</em>. That is, <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">chain</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">âˆ£</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8193em;vertical-align:-0.136em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">â‰¤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">}</span></span></span></span>. For any blocks <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>, there is a chain that both <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> belong to iff <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">âˆ¼</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>. In this case, <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> are said to be <em>on the same chain</em>.</p>
<p>Each block has an integer <em>height</em> <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">h</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mclose">)</span></span></span></span>. It is guaranteed that block heights are monotonic (that is, for any block <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel"><span class="mrel"><span class="mord vbox"><span class="thinbox"><span class="rlap"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="inner"><span class="mord"><span class="mrel">î€ </span></span></span><span class="fix"></span></span></span></span></span><span class="mrel">=</span></span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">G</span></span></span></span>, <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">h</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">h</span></span><span class="mopen">(</span><span class="mop"><span class="mord mathrm" style="margin-right:0.01389em;">prev</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mclose">))</span></span></span></span>), but they need not be consecutive. Also, <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">h</span></span><span class="mopen">(</span><span class="mord mathnormal">G</span><span class="mclose">)</span></span></span></span> may not be zero. Each node keeps track of a valid block with the largest height it knows about, which is called its <em>head</em>.</p>
<p>Blocks are grouped into <em>epochs</em>. In a chain, the set of blocks that belongs to some epoch forms a contiguous range: if blocks <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> such that <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> belong to the same epoch, then every block <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> such that <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> also belongs to that epoch. Epochs can be identified by sequential indices: <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">G</span></span></span></span> belongs to an epoch with index <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span>, and for every other block <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>, the index of its epoch is either the same as that of <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm" style="margin-right:0.01389em;">prev</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mclose">)</span></span></span></span>, or one greater.</p>
<p>Each epoch is associated with a set of block producers that are validating blocks in that epoch, as well as an assignment of block heights to block producers that are responsible for producing a block at that height. A block producer responsible for producing a block at height <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">h</span></span></span></span> is called <em>block proposer at <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">h</span></span></span></span></em>. This information (the set and the assignment) for an epoch with index <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7955em;vertical-align:-0.136em;"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">â‰¥</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">2</span></span></span></span> is determined by the last block of the epoch with index <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7429em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">âˆ’</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">2</span></span></span></span>. For epochs with indices <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span> and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span>, this information is preconfigured. Therefore, if two chains share the last block of some epoch, they will have the same set and the same assignment for the next two epochs, but not necessarily for any epoch after that.</p>
<p>The consensus protocol defines a notion of <em>finality</em>. Informally, if a block <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> is final, any future final blocks may only be built on top of <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>. Therefore, transactions in <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> and preceding blocks are never going to be reversed. Finality is not a function of a block itself, rather, a block may be final or not final in some chain it is a member of. Specifically, <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">final</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">)</span></span></span></span>, where <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8193em;vertical-align:-0.136em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">â‰¤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span>, means that <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> is final in <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">chain</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">)</span></span></span></span>. A block that is final in a chain is final in all of its extensions: specifically, if <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">final</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">)</span></span></span></span> is true, then <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0019em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">final</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">â€²</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> is also true for all <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8879em;vertical-align:-0.136em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">â€²</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">â‰¥</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span>.</p>
<h2 id="data-structures-2"><a class="header" href="#data-structures-2">Data structures</a></h2>
<p>The fields in the Block header relevant to the consensus process are:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct BlockHeader {
    ...
    prev_hash: BlockHash,
    height: BlockHeight,
    epoch_id: EpochId,
    last_final_block_hash: BlockHash,
    approvals: Vec&lt;Option&lt;Signature&gt;&gt;
    ...
}
<span class="boring">}
</span></code></pre></pre>
<p>Block producers in the particular epoch exchange many kinds of messages. The two kinds that are relevant to the consensus are <strong>Blocks</strong> and <strong>Approvals</strong>. The approval contains the following fields:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>enum ApprovalInner {
    Endorsement(BlockHash),
    Skip(BlockHeight),
}

struct Approval {
    inner: ApprovalInner,
    target_height: BlockHeight,
    signature: Signature,
    account_id: AccountId
}
<span class="boring">}
</span></code></pre></pre>
<p>Where the parameter of the <code>Endorsement</code> is the hash of the approved block, the parameter of the <code>Skip</code> is the height of the approved block, <code>target_height</code> is the specific height at which the approval can be used (an approval with a particular <code>target_height</code> can be only included in the <code>approvals</code> of a block that has <code>height = target_height</code>), <code>account_id</code> is the account of the block producer who created the approval, and <code>signature</code> is their signature on the tuple <code>(inner, target_height)</code>.</p>
<h2 id="approvals-requirements"><a class="header" href="#approvals-requirements">Approvals Requirements</a></h2>
<p>Every block <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> except the genesis block must logically contain approvals of a form described in the next paragraph from block producers whose cumulative stake exceeds <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:-0.1667em;"></span><span class="mord"><span class="mord">/</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> of the total stake in the current epoch, and in specific conditions described in section <a href="ChainSpec/Consensus.html#epoch-switches">epoch switches</a> also the approvals of the same form from block producers whose cumulative stake exceeds <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:-0.1667em;"></span><span class="mord"><span class="mord">/</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> of the total stake in the next epoch.</p>
<p>The approvals logically included in the block must be an <code>Endorsement</code> with the hash of <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm" style="margin-right:0.01389em;">prev</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mclose">)</span></span></span></span> if and only if <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">h</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">h</span></span><span class="mopen">(</span><span class="mop"><span class="mord mathrm" style="margin-right:0.01389em;">prev</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mclose">))</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span>, otherwise it must be a <code>Skip</code> with the height of <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm" style="margin-right:0.01389em;">prev</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mclose">)</span></span></span></span>. See <a href="ChainSpec/Consensus.html#approval-condition">this section</a> below for details on why the endorsements must contain the hash of the previous block, and skips must contain the height.</p>
<p>Note that since each approval that is logically stored in the block is the same for each block producer (except for the <code>account_id</code> of the sender and the <code>signature</code>), it is redundant to store the full approvals. Instead physically we only store the signatures of the approvals. The specific way they are stored is the following: we first fetch the ordered set of block producers from the current epoch. If the block is on the epoch boundary and also needs to include approvals from the next epoch (see <a href="ChainSpec/Consensus.html#epoch-switches">epoch switches</a>), we add new accounts from the new epoch</p>
<pre><code class="language-python">def get_accounts_for_block_ordered(h, prev_block):
    cur_epoch = get_next_block_epoch(prev_block)
    next_epoch = get_next_block_next_epoch(prev_block)

    account_ids = get_epoch_block_producers_ordered(cur_epoch)
    if next_block_needs_approvals_from_next_epoch(prev_block):
        for account_id in get_epoch_block_producers_ordered(next_epoch):
            if account_id not in account_ids:
                account_ids.append(account_id)

    return account_ids
</code></pre>
<p>The block then contains a vector of optional signatures of the same or smaller size than the resulting set of <code>account_ids</code>, with each element being <code>None</code> if the approval for such account is absent, or the signature on the approval message if it is present. It's easy to show that the actual approvals that were signed by the block producers can easily be reconstructed from the information available in the block, and thus the signatures can be verified. If the vector of signatures is shorter than the length of <code>account_ids</code>, the remaining signatures are assumed to be <code>None</code>.</p>
<h2 id="messages"><a class="header" href="#messages">Messages</a></h2>
<p>On receipt of the approval message the participant just stores it in the collection of approval messages.</p>
<pre><code class="language-python">def on_approval(self, approval):
    self.approvals.append(approval)
</code></pre>
<p>Whenever a participant receives a block, the operations relevant to the consensus include updating the <code>head</code> and initiating a timer to start sending the approvals on the block to the block producers at the consecutive <code>target_height</code>s. The timer delays depend on the height of the last final block, so that information is also persisted.</p>
<pre><code class="language-python">def on_block(self, block):
    header = block.header

    if header.height &lt;= self.head_height:
        return

    last_final_block = store.get_block(header.last_final_block_hash)

    self.head_height = header.height
    self.head_hash = block.hash()
    self.largest_final_height = last_final_block.height

    self.timer_height = self.head_height + 1
    self.timer_started = time.time()

    self.endorsement_pending = True
</code></pre>
<p>The timer needs to be checked periodically, and contain the following logic:</p>
<pre><code class="language-python">def get_delay(n):
    min(MAX_DELAY, MIN_DELAY + DELAY_STEP * (n-2))

def process_timer(self):
    now = time.time()

    skip_delay = get_delay(self.timer_height - self.largest_final_height)

    if self.endorsement_pending and now &gt; self.timer_started + ENDORSEMENT_DELAY:

        if self.head_height &gt;= self.largest_target_height:
            self.largest_target_height = self.head_height + 1
            self.send_approval(head_height + 1)

        self.endorsement_pending = False

    if now &gt; self.timer_started + skip_delay:
        assert not self.endorsement_pending

        self.largest_target_height = max(self.largest_target_height, self.timer_height + 1)
        self.send_approval(self.timer_height + 1)

        self.timer_started = now
        self.timer_height += 1

def send_approval(self, target_height):
    if target_height == self.head_height + 1:
        inner = Endorsement(self.head_hash)
    else:
        inner = Skip(self.head_height)

    approval = Approval(inner, target_height)
    send(approval, to_whom = get_block_proposer(self.head_hash, target_height))
</code></pre>
<p>Where <code>get_block_proposer</code> returns the next block proposer given the previous block and the height of the next block.</p>
<p>It is also necessary that <code>ENDORSEMENT_DELAY &lt; MIN_DELAY</code>. Moreover, while not necessary for correctness, we require that <code>ENDORSEMENT_DELAY * 2 &lt;= MIN_DELAY</code>.</p>
<h2 id="block-production"><a class="header" href="#block-production">Block Production</a></h2>
<!-- cspell:ignore isinstance -->
<p>We first define a convenience function to fetch approvals that can be included in a block at particular height:</p>
<pre><code class="language-python">def get_approvals(self, target_height):
    return [approval for approval
                     in self.approvals
                     if approval.target_height == target_height and
                        (isinstance(approval.inner, Skip) and approval.prev_height == self.head_height or
                         isinstance(approval.inner, Endorsement) and approval.prev_hash == self.head_hash)]
</code></pre>
<p>A block producer assigned for a particular height produces a block at that height whenever they have <code>get_approvals</code> return approvals from block producers whose stake collectively exceeds 2/3 of the total stake.</p>
<h2 id="finality-condition"><a class="header" href="#finality-condition">Finality condition</a></h2>
<p>A block <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> is final in <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">chain</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">)</span></span></span></span>, where <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8193em;vertical-align:-0.136em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">â‰¥</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>, when either <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">G</span></span></span></span> or there is a block <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8193em;vertical-align:-0.136em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">â‰¤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span> such that <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm" style="margin-right:0.01389em;">prev</span></span><span class="mopen">(</span><span class="mop"><span class="mord mathrm" style="margin-right:0.01389em;">prev</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">))</span></span></span></span> and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">h</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">h</span></span><span class="mopen">(</span><span class="mop"><span class="mord mathrm" style="margin-right:0.01389em;">prev</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">))</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">h</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">2</span></span></span></span>. That is, either <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> is the genesis block, or <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">chain</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">)</span></span></span></span> includes at least two blocks on top of <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>, and these three blocks (<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> and the two following blocks) have consecutive heights.</p>
<h2 id="epoch-switches"><a class="header" href="#epoch-switches">Epoch switches</a></h2>
<p>There's a parameter <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0044em;vertical-align:-0.31em;"></span><span class="mop"><span class="mord mathrm">epoch_length</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">â‰¥</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">3</span></span></span></span> that defines the minimum length of an epoch. Suppose that a particular epoch <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> started at height <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">h</span></span></span></span>, and say the next epoch will be <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>. Say <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">BP</span></span><span class="mopen">(</span><span class="mord mathnormal">e</span><span class="mclose">)</span></span></span></span> is a set of block producers in epoch <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">e</span></span></span></span>. Say <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mop"><span class="mord mathrm">last_final</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">)</span></span></span></span> is the highest final block in <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">chain</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">)</span></span></span></span>. The following are the rules of what blocks contain approvals from what block producers, and belong to what epoch.</p>
<ul>
<li>Any block <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> with <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">h</span></span><span class="mopen">(</span><span class="mop"><span class="mord mathrm" style="margin-right:0.01389em;">prev</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mclose">))</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0044em;vertical-align:-0.31em;"></span><span class="mop"><span class="mord mathrm">epoch_length</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">âˆ’</span><span class="mord">3</span></span></span></span> is in the epoch <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and must have approvals from more than <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:-0.1667em;"></span><span class="mord"><span class="mord">/</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> of <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">BP</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> (stake-weighted).</li>
<li>Any block <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> with <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">h</span></span><span class="mopen">(</span><span class="mop"><span class="mord mathrm" style="margin-right:0.01389em;">prev</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mclose">))</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">â‰¥</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0044em;vertical-align:-0.31em;"></span><span class="mop"><span class="mord mathrm">epoch_length</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">âˆ’</span><span class="mord">3</span></span></span></span> for which <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mop"><span class="mord mathrm">h</span></span><span class="mopen">(</span><span class="mop"><span class="mord mathrm">last_final</span></span><span class="mopen">(</span><span class="mop"><span class="mord mathrm" style="margin-right:0.01389em;">prev</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mclose">)))</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0044em;vertical-align:-0.31em;"></span><span class="mop"><span class="mord mathrm">epoch_length</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">âˆ’</span><span class="mord">3</span></span></span></span> is in the epoch <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and must logically include approvals from both more than <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:-0.1667em;"></span><span class="mord"><span class="mord">/</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> of <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">BP</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> and more than <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:-0.1667em;"></span><span class="mord"><span class="mord">/</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> of <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">BP</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> (both stake-weighted).</li>
<li>The first block <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> with <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mop"><span class="mord mathrm">h</span></span><span class="mopen">(</span><span class="mop"><span class="mord mathrm">last_final</span></span><span class="mopen">(</span><span class="mop"><span class="mord mathrm" style="margin-right:0.01389em;">prev</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mclose">)))</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0044em;vertical-align:-0.31em;"></span><span class="mop"><span class="mord mathrm">epoch_length</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">âˆ’</span><span class="mord">3</span></span></span></span> is in the epoch <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and must logically include approvals from more than <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:-0.1667em;"></span><span class="mord"><span class="mord">/</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> of <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">BP</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> (stake-weighted).</li>
</ul>
<p>(see the definition of <em>logically including</em> approvals in <a href="ChainSpec/Consensus.html#approvals-requirements">approval requirements</a>)</p>
<h2 id="safety"><a class="header" href="#safety">Safety</a></h2>
<p>Note that with the implementation above a honest block producer can never produce two endorsements with the same <code>prev_height</code> (call this condition <em>conflicting endorsements</em>), neither can they produce a skip message <code>s</code> and an endorsement <code>e</code> such that <code>s.prev_height &lt; e.prev_height and s.target_height &gt;= e.target_height</code> (call this condition <em>conflicting skip and endorsement</em>).</p>
<p><strong>Theorem</strong> Suppose that there are blocks <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> such that <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel amsrm">â‰</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">final</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">final</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>. Then, more than <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:-0.1667em;"></span><span class="mord"><span class="mord">/</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> of the block producer in some epoch must have signed either conflicting endorsements or conflicting skip and endorsement.</p>
<p><strong>Proof</strong> Without loss of generality, we can assume that these blocks are chosen such that their heights are smallest possible. Specifically, we can assume that <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">h</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">h</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">2</span></span></span></span> and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">h</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">h</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">2</span></span></span></span>. Also, letting <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> be the highest block that is an ancestor of both <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, we can assume that there is no block <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> such that <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">final</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> or <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">final</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</p>
<p><strong>Lemma</strong> There is such an epoch <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span></span></span></span> that all blocks <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> such that <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8193em;vertical-align:-0.136em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">â‰¤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> or <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8193em;vertical-align:-0.136em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">â‰¤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> include approvals from more than <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:-0.1667em;"></span><span class="mord"><span class="mord">/</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> of the block producers in <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span></span></span></span>.</p>
<p><strong>Proof</strong> There are two cases.</p>
<p>Case 1: Blocks <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> are all in the same epoch. Because the set of blocks in a given epoch in a given chain is a contiguous range, all blocks between them (specifically, all blocks <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> such that <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> or <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>) are also in the same epoch, so all those blocks include approvals from more than <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:-0.1667em;"></span><span class="mord"><span class="mord">/</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> of the block producers in that epoch.</p>
<p>Case 2: Blocks <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> are not all in the same epoch. Suppose that <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> are in different epochs. Let <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span></span></span></span> be the epoch of <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> be the preceding epoch (<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> cannot be in the same epoch as the genesis block). Let <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span> and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span> be the first and the last block of <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> in <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">chain</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>. Then, there must exist a block <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span></span></span></span> in epoch <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> such that <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">h</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">h</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">h</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>. Because <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">h</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">h</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">âˆ’</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">2</span></span></span></span>, we have <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, and since there are no final blocks <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> such that <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, we conclude that <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8193em;vertical-align:-0.136em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">â‰¤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>. Because there are no epochs between <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span></span></span></span> and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>, we conclude that <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is in epoch <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>. Also, <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">h</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">â‰¥</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">h</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">â‰¥</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">h</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0044em;vertical-align:-0.31em;"></span><span class="mop"><span class="mord mathrm">epoch_length</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">âˆ’</span><span class="mord">3</span></span></span></span>. Thus, any block after <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and until the end of <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span></span></span></span> must include approvals from more than <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:-0.1667em;"></span><span class="mord"><span class="mord">/</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> of the block producers in <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span></span></span></span>. Applying the same argument to <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">chain</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>, we can determine that <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is either in <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span></span></span></span> or <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>, and in both cases all blocks <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> such that <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8193em;vertical-align:-0.136em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">â‰¤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> include approvals from more than <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:-0.1667em;"></span><span class="mord"><span class="mord">/</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> of block producers in <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span></span></span></span> (the set of block producers in <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span></span></span></span> is the same in <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">chain</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">chain</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> because the last block of the epoch preceding <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>, if any, is before <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and thus is shared by both chains). The case where <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> are in the same epoch, but <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> are in different epochs is handled similarly. Thus, the lemma is proven.</p>
<p>Now back to the theorem. Without loss of generality, assume that <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">h</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">â‰¤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">h</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>. On the one hand, if <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">chain</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> doesn't include a block at height <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">h</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>, then the first block at height greater than <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">h</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> must include skips from more than <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:-0.1667em;"></span><span class="mord"><span class="mord">/</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> of the block producers in <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span></span></span></span> which conflict with endorsements in <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm" style="margin-right:0.01389em;">prev</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>, therefore, more than <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:-0.1667em;"></span><span class="mord"><span class="mord">/</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> of the block producers in <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span></span></span></span> must have signed conflicting skip and endorsement. Similarly, if <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">chain</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> doesn't include a block at height <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">h</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span>, more than <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:-0.1667em;"></span><span class="mord"><span class="mord">/</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> of the block producers in <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span></span></span></span> signed both an endorsement in <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and a skip in the first block in <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">chain</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> at height greater than <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">h</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>. On the other hand, if <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">chain</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> includes both a block at height <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">h</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> and a block at height <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">h</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span>, the latter must include endorsements for the former, which conflict with endorsements for <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>. Therefore, more than <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:-0.1667em;"></span><span class="mord"><span class="mord">/</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> of the block producers in <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span></span></span></span> must have signed conflicting endorsements. Thus, the theorem is proven.</p>
<h2 id="liveness"><a class="header" href="#liveness">Liveness</a></h2>
<p>See the proof of liveness in <a href="https://discovery-domain.org/papers/doomslug.pdf">Doomslug Whitepaper</a> and the recent <a href="https://discovery-domain.org/papers/nightshade.pdf">Nightshade</a> sharding protocol.</p>
<p>The consensus in this section differs in that it requires two consecutive blocks with endorsements. The proof in the linked paper trivially extends, by observing that once the delay is sufficiently long for a honest block producer to collect enough endorsements, the next block producer ought to have enough time to collect all the endorsements too.</p>
<h2 id="approval-condition"><a class="header" href="#approval-condition">Approval condition</a></h2>
<p>The approval condition above</p>
<blockquote>
<p>Any valid block must logically include approvals from block producers whose cumulative stake exceeds <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:-0.1667em;"></span><span class="mord"><span class="mord">/</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> of the total stake in the epoch. For a block <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> and its previous block <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">â€²</span></span></span></span></span></span></span></span></span></span></span></span> each approval in <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> must be an <code>Endorsement</code> with the hash of <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">â€²</span></span></span></span></span></span></span></span></span></span></span></span> if and only if <code>B.height == B'.height + 1</code>, otherwise it must be a <code>Skip</code> with the height of <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">â€²</span></span></span></span></span></span></span></span></span></span></span></span>.</p>
</blockquote>
<p>Is more complex that desired, and it is tempting to unify the two conditions. Unfortunately, they cannot be unified.</p>
<p>It is critical that for endorsements each approval has the <code>prev_hash</code> equal to the hash of the previous block, because otherwise the <a href="ChainSpec/Consensus.html#safety">safety proof</a> above doesn't work, in the second case the endorsements in <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> can be the very same approvals.</p>
<p>It is critical that for the skip messages we do <strong>not</strong> require the hashes in the approvals to match the hash of the previous block, because otherwise a malicious actor can create two blocks at the same height, and distribute them such that half of the block producers have one as their head, and the other half has the other. The two halves of the block producers will be sending skip messages with different <code>prev_hash</code> but the same <code>prev_height</code> to the future block producers, and if there's a requirement that the <code>prev_hash</code> in the skip matches exactly the <code>prev_hash</code> of the block, no block producer will be able to create their blocks.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="light-client"><a class="header" href="#light-client">Light Client</a></h1>
<p>The state of the light client is defined by:</p>
<ol>
<li><code>BlockHeaderInnerLiteView</code> for the current head (which contains <code>height</code>, <code>epoch_id</code>, <code>next_epoch_id</code>, <code>prev_state_root</code>, <code>outcome_root</code>, <code>timestamp</code>, the hash of the block producers set for the next epoch <code>next_bp_hash</code>, and the merkle root of all the block hashes <code>block_merkle_root</code>);</li>
<li>The set of block producers for the current and next epochs.</li>
</ol>
<p>The <code>epoch_id</code> refers to the epoch to which the block that is the current known head belongs, and <code>next_epoch_id</code> is the epoch that will follow.</p>
<p>Light clients operate by periodically fetching instances of <code>LightClientBlockView</code> via particular RPC end-point described <a href="ChainSpec/LightClient.html#rpc-end-points">below</a>.</p>
<p>Light client doesn't need to receive <code>LightClientBlockView</code> for all the blocks. Having the <code>LightClientBlockView</code> for block <code>B</code> is sufficient to be able to verify any statement about state or outcomes in any block in the ancestry of <code>B</code> (including <code>B</code> itself). In particular, having the <code>LightClientBlockView</code> for the head is sufficient to locally verify any statement about state or outcomes in any block on the canonical chain.</p>
<p>However, to verify the validity of a particular <code>LightClientBlockView</code>, the light client must have verified a <code>LightClientBlockView</code> for at least one block in the preceding epoch, thus to sync to the head the light client will have to fetch and verify a <code>LightClientBlockView</code> per epoch passed.</p>
<h2 id="validating-light-client-block-views"><a class="header" href="#validating-light-client-block-views">Validating Light Client Block Views</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum ApprovalInner {
    Endorsement(CryptoHash),
    Skip(BlockHeight)
}

pub struct ValidatorStakeView {
    pub account_id: AccountId,
    pub public_key: PublicKey,
    pub stake: Balance,
}

pub struct BlockHeaderInnerLiteView {
    pub height: BlockHeight,
    pub epoch_id: CryptoHash,
    pub next_epoch_id: CryptoHash,
    pub prev_state_root: CryptoHash,
    pub outcome_root: CryptoHash,
    pub timestamp: u64,
    pub next_bp_hash: CryptoHash,
    pub block_merkle_root: CryptoHash,
}

pub struct LightClientBlockLiteView {
    pub prev_block_hash: CryptoHash,
    pub inner_rest_hash: CryptoHash,
    pub inner_lite: BlockHeaderInnerLiteView,
}


pub struct LightClientBlockView {
    pub prev_block_hash: CryptoHash,
    pub next_block_inner_hash: CryptoHash,
    pub inner_lite: BlockHeaderInnerLiteView,
    pub inner_rest_hash: CryptoHash,
    pub next_bps: Option&lt;Vec&lt;ValidatorStakeView&gt;&gt;,
    pub approvals_after_next: Vec&lt;Option&lt;Signature&gt;&gt;,
}
<span class="boring">}
</span></code></pre></pre>
<p>Recall that the hash of the block is</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>sha256(concat(
    sha256(concat(
        sha256(borsh(inner_lite)),
        sha256(borsh(inner_rest))
    )),
    prev_hash
))
<span class="boring">}
</span></code></pre></pre>
<p>The fields <code>prev_block_hash</code>, <code>next_block_inner_hash</code> and <code>inner_rest_hash</code> are used to reconstruct the hashes of the current and next block, and the approvals that will be signed, in the following way (where <code>block_view</code> is an instance of <code>LightClientBlockView</code>):</p>
<pre><code class="language-python">def reconstruct_light_client_block_view_fields(block_view):
    current_block_hash = sha256(concat(
        sha256(concat(
            sha256(borsh(block_view.inner_lite)),
            block_view.inner_rest_hash,
        )),
        block_view.prev_block_hash
    ))

    next_block_hash = sha256(concat(
        block_view.next_block_inner_hash,
        current_block_hash
    ))

    approval_message = concat(
        borsh(ApprovalInner::Endorsement(next_block_hash)),
        little_endian(block_view.inner_lite.height + 2)
    )

    return (current_block_hash, next_block_hash, approval_message)
</code></pre>
<p>The light client updates its head with the information from <code>LightClientBlockView</code> iff:</p>
<ol>
<li>The height of the block is higher than the height of the current head;</li>
<li>The epoch of the block is equal to the <code>epoch_id</code> or <code>next_epoch_id</code> known for the current head;</li>
<li>If the epoch of the block is equal to the <code>next_epoch_id</code> of the head, then <code>next_bps</code> is not <code>None</code>;</li>
<li><code>approvals_after_next</code> contain valid signatures on <code>approval_message</code> from the block producers of the corresponding epoch (see next section);</li>
<li>The signatures present in <code>approvals_after_next</code> correspond to more than 2/3 of the total stake (see next section).</li>
<li>If <code>next_bps</code> is not none, <code>sha256(borsh(next_bps))</code> corresponds to the <code>next_bp_hash</code> in <code>inner_lite</code>.</li>
</ol>
<pre><code class="language-python">def validate_and_update_head(block_view):
    global head
    global epoch_block_producers_map

    current_block_hash, next_block_hash, approval_message = reconstruct_light_client_block_view_fields(block_view)

    # (1)
    if block_view.inner_lite.height &lt;= head.inner_lite.height:
        return False

    # (2)
    if block_view.inner_lite.epoch_id not in [head.inner_lite.epoch_id, head.inner_lite.next_epoch_id]:
        return False

    # (3)
    if block_view.inner_lite.epoch_id == head.inner_lite.next_epoch_id and block_view.next_bps is None:
        return False

    # (4) and (5)
    total_stake = 0
    approved_stake = 0

    epoch_block_producers = epoch_block_producers_map[block_view.inner_lite.epoch_id]
    for maybe_signature, block_producer in zip(block_view.approvals_after_next, epoch_block_producers):
        total_stake += block_producer.stake

        if maybe_signature is None:
            continue

        approved_stake += block_producer.stake
        if not verify_signature(
            public_key: block_producer.public_key,
            signature: maybe_signature,
            message: approval_message
        ):
            return False

    threshold = total_stake * 2 // 3
    if approved_stake &lt;= threshold:
        return False

    # (6)
    if block_view.next_bps is not None:
        if sha256(borsh(block_view.next_bps)) != block_view.inner_lite.next_bp_hash:
            return False

        epoch_block_producers_map[block_view.inner_lite.next_epoch_id] = block_view.next_bps

    head = block_view
</code></pre>
<h2 id="signature-verification"><a class="header" href="#signature-verification">Signature verification</a></h2>
<p>To simplify the protocol we require that the next block and the block after next are both in the same epoch as the block that <code>LightClientBlockView</code> corresponds to. It is guaranteed that each epoch has at least one final block for which the next two blocks that build on top of it are in the same epoch.</p>
<p>By construction by the time the <code>LightClientBlockView</code> is being validated, the block producers set for its epoch is known. Specifically, when the first light client block view of the previous epoch was processed, due to (3) above the <code>next_bps</code> was not <code>None</code>, and due to (6) above it was corresponding to the <code>next_bp_hash</code> in the block header.</p>
<p>The sum of all the stakes of <code>next_bps</code> in the previous epoch is <code>total_stake</code> referred to in (5) above.</p>
<p>The signatures in the <code>LightClientBlockView::approvals_after_next</code> are signatures on <code>approval_message</code>. The  <code>i</code>-th signature in <code>approvals_after_next</code>, if present, must validate against the <code>i</code>-th public key in <code>next_bps</code> from the previous epoch. <code>approvals_after_next</code> can contain fewer elements than <code>next_bps</code> in the previous epoch.</p>
<p><code>approvals_after_next</code> can also contain more signatures than the length of <code>next_bps</code> in the previous epoch. This is due to the fact that, as per <a href="ChainSpec/./Consensus.html">consensus specification</a>, the last blocks in each epoch contain signatures from both the block producers of the current epoch, and the next epoch. The trailing signatures can be safely ignored by the light client implementation.</p>
<h2 id="proof-verification"><a class="header" href="#proof-verification">Proof Verification</a></h2>
<h3 id="transaction-outcome-proofs"><a class="header" href="#transaction-outcome-proofs">Transaction Outcome Proofs</a></h3>
<p>To verify that a transaction or receipt happens on chain, a light client can request a proof through rpc by providing <code>id</code>, which is of type</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum TransactionOrReceiptId {
    Transaction { hash: CryptoHash, sender: AccountId },
    Receipt { id: CryptoHash, receiver: AccountId },
}
<span class="boring">}
</span></code></pre></pre>
<p>and the block hash of light client head. The rpc will return the following struct</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct RpcLightClientExecutionProofResponse {
    /// Proof of execution outcome
    pub outcome_proof: ExecutionOutcomeWithIdView,
    /// Proof of shard execution outcome root
    pub outcome_root_proof: MerklePath,
    /// A light weight representation of block that contains the outcome root
    pub block_header_lite: LightClientBlockLiteView,
    /// Proof of the existence of the block in the block merkle tree,
    /// which consists of blocks up to the light client head
    pub block_proof: MerklePath,
}
<span class="boring">}
</span></code></pre></pre>
<p>which includes everything that a light client needs to prove the execution outcome of the given transaction or receipt.
Here <code>ExecutionOutcomeWithIdView</code> is</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct ExecutionOutcomeWithIdView {
    /// Proof of the execution outcome
    pub proof: MerklePath,
    /// Block hash of the block that contains the outcome root
    pub block_hash: CryptoHash,
    /// Id of the execution (transaction or receipt)
    pub id: CryptoHash,
    /// The actual outcome
    pub outcome: ExecutionOutcomeView,
}
<span class="boring">}
</span></code></pre></pre>
<p>The proof verification can be broken down into two steps, execution outcome root verification and block merkle root
verification.</p>
<h4 id="execution-outcome-root-verification"><a class="header" href="#execution-outcome-root-verification">Execution Outcome Root Verification</a></h4>
<p>If the outcome root of the transaction or receipt is included in block <code>H</code>, then <code>outcome_proof</code> includes the block hash
of <code>H</code>, as well as the merkle proof of the execution outcome in its given shard. The outcome root in <code>H</code> can be
reconstructed by</p>
<pre><code class="language-python">shard_outcome_root = compute_root(sha256(borsh(execution_outcome)), outcome_proof.proof)
block_outcome_root = compute_root(sha256(borsh(shard_outcome_root)), outcome_root_proof)
</code></pre>
<p>This outcome root must match the outcome root in <code>block_header_lite.inner_lite</code>.</p>
<h4 id="block-merkle-root-verification"><a class="header" href="#block-merkle-root-verification">Block Merkle Root Verification</a></h4>
<p>Recall that block hash can be computed from <code>LightClientBlockLiteView</code> by</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>sha256(concat(
    sha256(concat(
        sha256(borsh(inner_lite)),
        sha256(borsh(inner_rest))
    )),
    prev_hash
))
<span class="boring">}
</span></code></pre></pre>
<p>The expected block merkle root can be computed by</p>
<pre><code class="language-python">block_hash = compute_block_hash(block_header_lite)
block_merkle_root = compute_root(block_hash, block_proof)
</code></pre>
<p>which must match the block merkle root in the light client block of the light client head.</p>
<h2 id="rpc-end-points"><a class="header" href="#rpc-end-points">RPC end-points</a></h2>
<h3 id="light-client-block"><a class="header" href="#light-client-block">Light Client Block</a></h3>
<p>There's a single end-point that full nodes exposed that light clients can use to fetch new <code>LightClientBlockView</code>s:</p>
<pre><code>http post http://127.0.0.1:3030/ jsonrpc=2.0 method=next_light_client_block params:=&quot;[&lt;last known hash&gt;]&quot; id=&quot;dontcare&quot;
</code></pre>
<p>The RPC returns the <code>LightClientBlock</code> for the block as far into the future from the last known hash as possible for the light client to still accept it. Specifically, it either returns the last final block of the next epoch, or the last final known block. If there's no newer final block than the one the light client knows about, the RPC returns an empty result.</p>
<p>A standalone light client would bootstrap by requesting next blocks until it receives an empty result, and then periodically request the next light client block.</p>
<p>A smart contract-based light client that enables a bridge to NEAR on a different blockchain naturally cannot request blocks itself. Instead external oracles query the next light client block from one of the full nodes, and submit it to the light client smart contract. The smart contract-based light client performs the same checks described above, so the oracle doesn't need to be trusted.</p>
<h3 id="light-client-proof"><a class="header" href="#light-client-proof">Light Client Proof</a></h3>
<p>The following rpc end-point returns <code>RpcLightClientExecutionProofResponse</code> that a light client needs for verifying execution outcomes.</p>
<p>For transaction execution outcome, the rpc is</p>
<pre><code>http post http://127.0.0.1:3030/ jsonrpc=2.0 method=EXPERIMENTAL_light_client_proof params:=&quot;{&quot;type&quot;: &quot;transaction&quot;, &quot;transaction_hash&quot;: &lt;transaction_hash&gt;, &quot;sender_id&quot;: &lt;sender_id&gt;, &quot;light_client_head&quot;: &lt;light_client_head&gt;}&quot; id=&quot;dontcare&quot;
</code></pre>
<p>For receipt execution outcome, the rpc is</p>
<pre><code>http post http://127.0.0.1:3030/ jsonrpc=2.0 method=EXPERIMENTAL_light_client_proof params:=&quot;{&quot;type&quot;: &quot;receipt&quot;, &quot;receipt_id&quot;: &lt;receipt_id&gt;, &quot;receiver_id&quot;: &lt;receiver_id&gt;, &quot;light_client_head&quot;: &lt;light_client_head&gt;}&quot; id=&quot;dontcare&quot;
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="selecting-chunk-and-block-producers"><a class="header" href="#selecting-chunk-and-block-producers">Selecting Chunk and Block Producers</a></h1>
<h2 id="background"><a class="header" href="#background">Background</a></h2>
<p>Near is intended to be a sharded blockchain. At the time of writing (March 2021), challenges (an
important security feature for a sharded network) are not fully implemented. As a stepping stone
towards the full sharded solution, Near will go through a phase called &quot;Simple Nightshade&quot;. In this
protocol, block producers will track all shards (i.e. validate all transactions, eliminating the need
for challenges), and there will be an additional type of participant called a &quot;chunk-only producer&quot;
which tracks only a single shard. A block includes one chunk for each shard, and it is the chunks
which include the transactions that were executed for its associated shard. The purpose of this
design is to allow decentralization (running a node which supports a chunk-only producer should be
possible for a large number of participants) while maintaining security (since block producers track
all shards). For more details on chunks see the subsequent chapter on Transactions. Note: the
purpose of the &quot;chunk-only&quot; nomenclature is to reduce confusion since block producers will also
produce chunks some times (they track all shards, so they will be able to produce chunks for any
shard easily); thus the key distinction is that chunk-only producers only produce chunks, i.e. never
produce blocks.</p>
<p>Near is a permission-less blockchain, so anyone (with sufficient stake) can become a chunk-only
producer, or a block producer. In this section we outline the algorithm by which chunk-only
producers and block producers are selected in each epoch from the proposals of participants in the
network. Additionally, we will specify the algorithm for assigning those chunk-only producers and
block producers to be the one responsible for producing the chunk/block at each height and for each
shard.</p>
<p>There are several desiderata for these algorithms:</p>
<ul>
<li>Larger stakes should be preferred (more staked tokens means more security)</li>
<li>The frequency with which a given participant is selected to produce a particular chunk/block is
proportional to that participant's stake</li>
<li>All participants selected as chunk/block producers should be selected to produce at least one
chunk/block during the epoch</li>
<li>It should be possible to determine which chunk/block producer is supposed to produce the
chunk/block at height <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">h</span></span></span></span>, for any <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">h</span></span></span></span> within the epoch, in constant time</li>
<li>The block producer chosen at height <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">h</span></span></span></span> should have been a chunk producer for some shard at
height <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">âˆ’</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span>, this minimizes network communication between chunk producers and block
producers</li>
<li>The number of distinct chunk-only/block producers should be as large as is allowed by the
scalability in the consensus algorithm (too large and the system would be too slow, too small and
the system would be too centralized) <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8491em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">â€ </span></span></span></span></span></span></span></span></span></span></span></span></li>
</ul>
<blockquote>
<p><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord">â€ </span></span></span></span> Note: By &quot;distinct block producers&quot; we mean the number of different signing keys.
We recognize it is possible for a single &quot;logical entity&quot; to split their stake into two or more
proposals (Sybil attack), however steps to prevent this kind of attack against centralization are
out of scope for this document.</p>
</blockquote>
<h2 id="assumptions"><a class="header" href="#assumptions">Assumptions</a></h2>
<ul>
<li>The maximum number of distinct chunk-only producers and block producers supported by the consensus
algorithm is a fixed constant. This will be a parameter of the protocol itself (i.e. all nodes
must agree on the constant). In this document, we will denote the maximum number of chunk-only
producers as <code>MAX_NUM_CP</code> and the maximum number of block producers by <code>MAX_NUM_BP</code>.</li>
<li>The minimum number of blocks in the epoch is known at the time of block producer selection. This
minimum does not need to be incredibly accurate, but we will assume it is within a factor of 2 of
the actual number of blocks in the epoch. In this document we will refer to this as the &quot;length of
the epoch&quot;, denoted by <code>epoch_length</code>.</li>
<li>To meet the requirement that any chosen validator will be selected to produce at least one
chunk/block in the epoch, we assume it is acceptable for the probability of this <em>not</em> happening
to be sufficiently low. Let <code>PROBABILITY_NEVER_SELECTED</code> be a protocol constant which gives the
maximum allowable probability that the chunk-only/block producer with the least stake will never
be selected to produce a chunk/block during the epoch. We will additionally assume the chunk/block
producer assigned to make each chunk/block is chosen independently, and in proportion to the
participant's stake. Therefore, the probability that the block producer with least stake is never
chosen is given by the expression <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">âˆ’</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0991em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3175em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">min</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mclose">)</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">epoch_length</span></span></span></span></span></span></span></span></span></span></span></span>, where
<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3175em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">min</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is the least stake of any block producer and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span> is the total relevant
stake (what stake is &quot;relevant&quot; depends on whether the validator is a chunk-only producer or a
block producer; more details below). Hence, the algorithm will enforce the condition <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">âˆ’</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0991em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3175em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">min</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mclose">)</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">epoch_length</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.9933em;vertical-align:-0.31em;"></span><span class="mord text"><span class="mord">PROBABILITY_NEVER_SELECTED</span></span></span></span></span>.</li>
</ul>
<p>In mainnet and testnet, <code>epoch_length</code> is set to <code>43200</code>. Let <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9933em;vertical-align:-0.31em;"></span><span class="mord text"><span class="mord">PROBABILITY_NEVER_SELECTED</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.001</span></span></span></span>,
we obtain, <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3175em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">min</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">160/1000</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">000</span></span></span></span>.</p>
<h2 id="algorithm-for-selecting-block-and-chunk-producers"><a class="header" href="#algorithm-for-selecting-block-and-chunk-producers">Algorithm for selecting block and chunk producers</a></h2>
<p>A potential validator cannot specify whether they want to become a block producer or a chunk-only producer.
There is only one type of proposal. The same algorithm is used for selecting block producers and chunk producers,
but with different thresholds. The threshold for becoming block producers is higher, so if a node is selected as a block
producer, it will also be a chunk producer, but not the other way around. Validators who are selected as chunk producers
but not block producers are chunk-only producers.</p>
<h3 id="select_validators"><a class="header" href="#select_validators">select_validators</a></h3>
<h3 id="input"><a class="header" href="#input">Input</a></h3>
<ul>
<li><code>max_num_validators: u16</code> max number of validators to be selected</li>
<li><code>min_stake_fraction: Ratio&lt;u128&gt;</code> minimum stake ratio for selected validator</li>
<li><code>validator_proposals: Vec&lt;ValidatorStake&gt;</code> (proposed stakes for the next epoch from nodes sending
staking transactions)</li>
</ul>
<h3 id="output"><a class="header" href="#output">Output</a></h3>
<ul>
<li><code>(validators: Vec&lt;ValidatorStake&gt;, sampler: WeightedIndex)</code></li>
</ul>
<h3 id="steps"><a class="header" href="#steps">Steps</a></h3>
<pre><code class="language-python">sorted_proposals =
    sorted_descending(validator_proposals, key=lambda v: (v.stake, v.account_id))

total_stake = 0

validators = []
for v in sorted_proposals[0:max_num_validators]:
    total_stake += v.stake
    if (v.stake / total_stake) &gt; min_stake_fraction:
        validators.append(v)
    else:
        break

validator_sampler = WeightedIndex([v.stake for v in validators])

return (validators, validator_sampler)
</code></pre>
<h2 id="algorithm-for-selecting-block-producers"><a class="header" href="#algorithm-for-selecting-block-producers">Algorithm for selecting block producers</a></h2>
<h3 id="input-1"><a class="header" href="#input-1">Input</a></h3>
<ul>
<li><code>MAX_NUM_BP: u16</code> Max number of block producers, see Assumptions</li>
<li><code>min_stake_fraction: Ratio&lt;u128&gt;</code> <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3175em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">min</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span>, see Assumptions</li>
<li><code>validator_proposals: Vec&lt;ValidatorStake&gt;</code> (proposed stakes for the next epoch from nodes sending
staking transactions)</li>
</ul>
<pre><code class="language-python">select_validators(MAX_NUM_BP, min_stake_fraction, validator_proposals)
</code></pre>
<h2 id="algorithm-for-selecting-chunk-producers"><a class="header" href="#algorithm-for-selecting-chunk-producers">Algorithm for selecting chunk producers</a></h2>
<h3 id="input-2"><a class="header" href="#input-2">Input</a></h3>
<ul>
<li><code>MAX_NUM_CP: u16</code> max number of chunk producers, see Assumptions</li>
<li><code>min_stake_fraction: Ratio&lt;u128&gt;</code> <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3175em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">min</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span>, see Assumptions</li>
<li><code>num_shards: u64</code> number of shards</li>
<li><code>validator_proposals: Vec&lt;ValidatorStake&gt;</code> (proposed stakes for the next epoch from nodes sending
staking transactions)</li>
</ul>
<pre><code class="language-python">select_validators(MAX_NUM_CP, min_stake_fraction/num_shards, validator_proposals)
</code></pre>
<p>The reasoning for using <code>min_stake_fraction/num_shards</code> as the threshold here is that
we will assign chunk producers to shards later and the algorithm (described below) will try to assign
them in a way that the total stake in each shard is distributed as evenly as possible.
So the total stake in each shard will be roughly be <code>total_stake_all_chunk_producers / num_shards</code>.</p>
<h2 id="algorithm-for-assigning-chunk-producers-to-shards"><a class="header" href="#algorithm-for-assigning-chunk-producers-to-shards">Algorithm for assigning chunk producers to shards</a></h2>
<p>Note that block producers are a subset of chunk producers, so this algorithm will also assign block producers
to shards. This also means that a block producer may only be assigned to a subset of shards. For the security of
the protocol, all block producers must track all shards, even if they are not assigned to produce chunks for all shards.
We enforce that in the implementation level, not the protocol level. A validator node will panic if it doesn't track all
shards.</p>
<h3 id="input-3"><a class="header" href="#input-3">Input</a></h3>
<ul>
<li><code>chunk_producers: Vec&lt;ValidatorStake&gt;</code></li>
<li><code>num_shards: usize</code></li>
<li><code>min_validators_per_shard: usize</code></li>
</ul>
<h3 id="output-1"><a class="header" href="#output-1">Output</a></h3>
<ul>
<li><code>validator_shard_assignments: Vec&lt;Vec&lt;ValidatorStake&gt;&gt;</code>
<ul>
<li><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span>-th element gives the validators assigned to shard <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></li>
</ul>
</li>
</ul>
<h3 id="steps-1"><a class="header" href="#steps-1">Steps</a></h3>
<ul>
<li>While any shard has fewer than <code>min_validators_per_shard</code> validators assigned to it:
<ul>
<li>Let <code>cp_i</code> be the next element of <code>chunk_producers</code> (cycle back to the beginning as needed)
<ul>
<li>Note: if there are more shards than chunk producers, then some chunk producers will
be assigned to multiple shards. This is undesirable because we want each chunk-only producer
to be a assigned to exactly one shard. However, block producers are also chunk producers,
so even if we must wrap around a little, chunk-only producers may still not be assigned
multiple shards. Moreover, we assume that in practice there will be many more chunk producers
than shards (in particular because block producers are also chunk producers).</li>
</ul>
</li>
<li>Let <code>shard_id</code> be the shard with the fewest number of assigned validators such that <code>cp_i</code> has
not been assigned to <code>shard_id</code></li>
<li>Assign <code>cp_i</code> to <code>shard_id</code></li>
</ul>
</li>
<li>While there are any validators which have not been assigned to any shard:
<ul>
<li>Let <code>cp_i</code> be the next validator not assigned to any shard</li>
<li>Let <code>shard_id</code> be the shard with the least total stake (total stake = sum of stakes of all
validators assigned to that shard)</li>
<li>Assign <code>cp_i</code> to <code>shard_id</code></li>
</ul>
</li>
<li>Return the shard assignments</li>
</ul>
<p>In addition to the above description, we have a <a href="https://github.com/birchmd/bp-shard-assign-poc">proof-of-concept (PoC) on
GitHub</a>. Note: this PoC has not been updated since
the change to Simple Nightshade, so it assumes we are assigning block producers to shards. However,
the same algorithm works to assign chunk producers to shards; it is only a matter of renaming
variables referencing &quot;block producers&quot; to reference &quot;chunk producers&quot; instead.</p>
<h2 id="algorithm-for-sampling-validators-proportional-to-stake"><a class="header" href="#algorithm-for-sampling-validators-proportional-to-stake">Algorithm for sampling validators proportional to stake</a></h2>
<!-- cspell:ignore Vose's byteorder -->
<p>We sample validators with probability proportional to their stake using the following data structure.</p>
<ul>
<li><code>weighted_sampler: WeightedIndex</code>
<ul>
<li>Allow <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span></span></span></span> sampling</li>
<li>This structure will be based on the
<a href="https://docs.rs/rand/latest/rand/distr/weighted/struct.WeightedIndex.html">WeightedIndex</a>
implementation (see a description of <a href="https://en.wikipedia.org/wiki/Alias_method">Vose's Alias
Method</a> for details)</li>
</ul>
</li>
</ul>
<p>This algorithm is applied using both chunk-only producers and block producers in the subsequent
algorithms for selecting a specific block producer and chunk producer at each height.</p>
<h3 id="input-4"><a class="header" href="#input-4">Input</a></h3>
<ul>
<li><code>rng_seed: [u8; 32]</code>
<ul>
<li>See usages of this algorithm below to see how this seed is generated</li>
</ul>
</li>
<li><code>validators: Vec&lt;ValidatorStake&gt;</code></li>
<li><code>sampler: WeightedIndex</code></li>
</ul>
<h3 id="output-2"><a class="header" href="#output-2">Output</a></h3>
<ul>
<li><code>selection: ValidatorStake</code></li>
</ul>
<h3 id="steps-2"><a class="header" href="#steps-2">Steps</a></h3>
<pre><code class="language-python"># The seed is used as an entropy source for the random numbers.
# The first 8 bytes select a block producer uniformly.
uniform_index = int.from_bytes(rng_seed[0:8], byteorder='little') % len(validators)

# The next 16 bytes uniformly pick some weight between 0 and the total
# weight (i.e. stake) of all block producers.
let uniform_weight = int.from_bytes(rng_seed[8:24], byteorder='little') \
    % sampler.weight_sum()

# Return either the uniformly selected block producer, or its &quot;alias&quot;
# depending on the uniformly selected weight.
index = uniform_index \
    if uniform_weight &lt; sampler.no_alias_odds[uniform_index] \
    else sampler.aliases[uniform_index]

return validators[index]
</code></pre>
<h2 id="algorithm-for-selecting-producer-of-block-at-height-h"><a class="header" href="#algorithm-for-selecting-producer-of-block-at-height-h">Algorithm for selecting producer of block at height <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">h</span></span></span></span></a></h2>
<h3 id="input-5"><a class="header" href="#input-5">Input</a></h3>
<ul>
<li><code>h: BlockHeight</code>
<ul>
<li>Height to compute the block producer for</li>
<li>Only heights within the epoch corresponding to the given block producers make sense as input</li>
</ul>
</li>
<li><code>block_producers: Vec&lt;ValidatorStake&gt;</code> (output from above)</li>
<li><code>block_producer_sampler: WeightedIndex</code></li>
<li><code>epoch_rng_seed: [u8; 32]</code>
<ul>
<li>Fixed seed for the epoch determined from Verified Random Function (VRF) output of last block in
the previous epoch</li>
</ul>
</li>
</ul>
<h3 id="output-3"><a class="header" href="#output-3">Output</a></h3>
<ul>
<li><code>block_producer: ValidatorStake</code></li>
</ul>
<h3 id="steps-3"><a class="header" href="#steps-3">Steps</a></h3>
<pre><code class="language-python"># Concatenates the bytes of the epoch seed with the height,
# then computes the sha256 hash.
block_seed = combine(epoch_rng_seed, h)

# Use the algorithm defined above
return select_validator(rng_seed=block_seed, validators=block_producers, sampler=block_producer_sampler)
</code></pre>
<h2 id="algorithm-for-selection-of-chunk-producer-at-height-h-for-all-shards"><a class="header" href="#algorithm-for-selection-of-chunk-producer-at-height-h-for-all-shards">Algorithm for selection of chunk producer at height <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">h</span></span></span></span> for all shards</a></h2>
<h3 id="input-6"><a class="header" href="#input-6">Input</a></h3>
<ul>
<li>(same inputs as selection of block producer at height h)</li>
<li><code>num_shards: usize</code></li>
<li><code>chunk_producer_sampler: Vec&lt;WeightedIndex&gt;</code> (outputs from chunk-only producer selection)</li>
<li><code>validator_shard_assignments: Vec&lt;Vec&lt;ValidatorStake&gt;&gt;</code></li>
</ul>
<h3 id="output-4"><a class="header" href="#output-4">Output</a></h3>
<ul>
<li><code>chunk_producers: Vec&lt;ValidatorStake&gt;</code>
<ul>
<li><code>i</code>th element gives the validator that will produce the chunk for shard <code>i</code>. Note: at least one
of these will be a block producer, while others will be chunk-only producers.</li>
</ul>
</li>
</ul>
<h3 id="steps-4"><a class="header" href="#steps-4">Steps</a></h3>
<pre><code class="language-python">bp = block_producer_at_height(
    h + 1,
    block_producers,
    block_producer_sampler,
    epoch_rng_seed,
)

result = []
for shard_id in range(num_shards):
    # concatenate bytes and take hash to create unique seed
    shard_seed = combine(epoch_rng_seed, h, shard_id)
    # Use selection algorithm defined above
    cp = select_validator(
        rng_seed=shard_seed,
        validators=validator_shard_assignments[shard_id],
        sampler=chunk_producer_sampler[shard_id]
    )
    result.append(cp)

# Ensure the block producer for the next block also produces one of the shards.
# `bp` could already be in the result because block producers are also
# chunk producers (see algorithm for selecting chunk producers from proposals).
if bp not in result:
    # select a random shard for the block producer to also create the chunk for
    rand_shard_seed = combine(epoch_rng_seed, h)
    bp_shard_id = int.from_bytes(rand_shard_seed[0:8], byteorder='little') % num_shards
    result[bp_shard_id] = bp

return result
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="transactions-in-the-blockchain-layer"><a class="header" href="#transactions-in-the-blockchain-layer">Transactions in the Blockchain Layer</a></h1>
<p>A client creates a transaction, computes the transaction hash and signs this hash to get a signed transaction.
Now this signed transaction can be sent to a node.</p>
<p>When a node receives a new signed transaction, it validates the transaction (if the node tracks the shard) and gossips about it to all its peers. Eventually, the valid transaction is added to a transaction pool.</p>
<p>Every validating node has its own transaction pool. The transaction pool maintains transactions that were either not yet discarded, or not yet included onto the chain.</p>
<p>Before producing a chunk, transactions are ordered and validated again. This is done to produce chunks with only valid transactions.</p>
<h2 id="transaction-ordering"><a class="header" href="#transaction-ordering">Transaction ordering</a></h2>
<p>The transaction pool groups transactions by a pair of <code>(signer_id, signer_public_key)</code>.
The <code>signer_id</code> is the account ID of the user who signed the transaction, the <code>signer_public_key</code> is the public key of the account's access key that was used to sign the transactions.
Transactions within a group are not ordered.</p>
<p>The valid order of the transactions in a chunk is the following:</p>
<ul>
<li>transactions are ordered in batches.</li>
<li>within a batch all transactions keys should be different.</li>
<li>a set of transaction keys in each subsequent batch should be a sub-set of keys from the previous batch.</li>
<li>transactions with the same key should be ordered in strictly increasing order of their corresponding nonces.</li>
</ul>
<p>Note:</p>
<ul>
<li>the order within a batch is undefined. Each node should use a unique secret seed for that ordering to prevent users from finding the lowest keys, and then using that information to take advantage of every node.</li>
</ul>
<p>Transaction pool provides a draining structure that allows it to pull transactions in a proper order.</p>
<h2 id="transaction-validation"><a class="header" href="#transaction-validation">Transaction validation</a></h2>
<p>The transaction validation happens twice, once before adding it to the transaction pool, then before adding it to a chunk.</p>
<h3 id="before-adding-to-a-transaction-pool"><a class="header" href="#before-adding-to-a-transaction-pool">Before adding to a transaction pool</a></h3>
<p>This is done to quickly filter out transactions that have an invalid signature or are invalid on the latest state.</p>
<h3 id="before-adding-to-a-chunk"><a class="header" href="#before-adding-to-a-chunk">Before adding to a chunk</a></h3>
<p>A chunk producer has to create a chunk with valid and ordered transactions limited by two criteria:</p>
<ul>
<li>the maximum number of transactions for a chunk. </li>
<li>the total gas burnt for transactions within a chunk.</li>
</ul>
<p>To order and filter transactions, the chunk producer gets a pool iterator and passes it to the runtime adapter.
The runtime adapter pulls transactions one by one.
The valid transactions are added to the result; invalid transactions are discarded.
Once one of the chunk limits is reached, all the remaining transactions from the iterator are returned back to the pool.</p>
<h2 id="pool-iterator"><a class="header" href="#pool-iterator">Pool iterator</a></h2>
<p>Pool Iterator is a trait that iterates over transaction groups until all transaction group are empty.
Pool Iterator returns a mutable reference to a transaction group that implements a draining iterator.
The draining iterator is like a normal iterator, but it removes the returned entity from the group.
It pulls transactions from the group in order from the smallest nonce to largest.</p>
<p>The pool iterator and draining iterators for transaction groups allow the runtime adapter to create proper order.
For every transaction group, the runtime adapter keeps pulling transactions until the valid transaction is found.
If the transaction group becomes empty, then it's skipped.</p>
<p>The runtime adapter may implement the following code to pull all valid transactions:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut valid_transactions = vec![];
let mut pool_iter = pool.pool_iterator();
while let Some(group_iter) = pool_iter.next() {
    while let Some(tx) = group_iter.next() {
        if is_valid(tx) {
            valid_transactions.push(tx);
            break;
        }
    }
}
valid_transactions
<span class="boring">}
</span></code></pre></pre>
<h3 id="transaction-ordering-example-using-pool-iterator"><a class="header" href="#transaction-ordering-example-using-pool-iterator">Transaction ordering example using pool iterator</a></h3>
<p>Let's say:</p>
<ul>
<li>account IDs as uppercase letters (<code>&quot;A&quot;</code>, <code>&quot;B&quot;</code>, <code>&quot;C&quot;</code> ...)</li>
<li>public keys are lowercase letters (<code>&quot;a&quot;</code>, <code>&quot;b&quot;</code>, <code>&quot;c&quot;</code> ...)</li>
<li>nonces are numbers (<code>1</code>, <code>2</code>, <code>3</code> ...)</li>
</ul>
<p>A pool might have group of transactions in the hashmap:</p>
<pre><code>transactions: {
  (&quot;A&quot;, &quot;a&quot;) -&gt; [1, 3, 2, 1, 2]
  (&quot;B&quot;, &quot;b&quot;) -&gt; [13, 14]
  (&quot;C&quot;, &quot;d&quot;) -&gt; [7]
  (&quot;A&quot;, &quot;c&quot;) -&gt; [5, 2, 3]
}
</code></pre>
<p>There are 3 accounts (<code>&quot;A&quot;</code>, <code>&quot;B&quot;</code>, <code>&quot;C&quot;</code>). Account <code>&quot;A&quot;</code> used 2 public keys (<code>&quot;a&quot;</code>, <code>&quot;c&quot;</code>). Other accounts used 1 public key each.
Transactions within each group may have repeated nonces while in the pool.
That's because the pool doesn't filter transactions with the same nonce, only transactions with the same hash.</p>
<p>For this example, let's say that transactions are valid if the nonce is even and strictly greater than the previous nonce for the same key.</p>
<h5 id="initialization"><a class="header" href="#initialization">Initialization</a></h5>
<p>When <code>.pool_iterator()</code> is called, a new <code>PoolIteratorWrapper</code> is created and it holds the mutable reference to the pool,
so the pool can't be modified outside of this iterator. The wrapper looks like this:</p>
<pre><code>pool: {
    transactions: {
      (&quot;A&quot;, &quot;a&quot;) -&gt; [1, 3, 2, 1, 2]
      (&quot;B&quot;, &quot;b&quot;) -&gt; [13, 14]
      (&quot;C&quot;, &quot;d&quot;) -&gt; [7]
      (&quot;A&quot;, &quot;c&quot;) -&gt; [5, 2, 3]
    }
}
sorted_groups: [],
</code></pre>
<p><code>sorted_groups</code> is a queue of sorted transaction groups that were already sorted and pulled from the pool.</p>
<h5 id="transaction-1"><a class="header" href="#transaction-1">Transaction #1</a></h5>
<p>The first group to be selected is for key <code>(&quot;A&quot;, &quot;a&quot;)</code>, the pool iterator sorts transactions by nonces and returns the mutable references to the group. Sorted nonces are:
<code>[1, 1, 2, 2, 3]</code>. Runtime adapter pulls <code>1</code>, then <code>1</code>, and then <code>2</code>. Both transactions with nonce <code>1</code> are invalid because of odd nonce.</p>
<p>Transaction with nonce <code>2</code> is even, and since we don't know of any previous nonces, it is valid, and therefore added to the list of valid transactions.</p>
<p>Since the runtime adapter found a valid transaction, the transaction group is dropped, and the pool iterator wrapper becomes the following:</p>
<pre><code>pool: {
    transactions: {
      (&quot;B&quot;, &quot;b&quot;) -&gt; [13, 14]
      (&quot;C&quot;, &quot;d&quot;) -&gt; [7]
      (&quot;A&quot;, &quot;c&quot;) -&gt; [5, 2, 3]
    }
}
sorted_groups: [
  (&quot;A&quot;, &quot;a&quot;) -&gt; [2, 3]
],
</code></pre>
<h5 id="transaction-2"><a class="header" href="#transaction-2">Transaction #2</a></h5>
<p>The next group is for key <code>(&quot;B&quot;, &quot;b&quot;)</code>, the pool iterator sorts transactions by nonce and returns the mutable references to the group. Sorted nonces are:
<code>[13, 14]</code>. Runtime adapter pulls <code>13</code>, then <code>14</code>. The transaction with nonce <code>13</code> is invalid because of odd nonce.</p>
<p>Transaction with nonce <code>14</code> is added to the list of valid transactions.</p>
<p>The transaction group is dropped, but it's empty, so the pool iterator drops it completely:</p>
<pre><code>pool: {
    transactions: {
      (&quot;C&quot;, &quot;d&quot;) -&gt; [7]
      (&quot;A&quot;, &quot;c&quot;) -&gt; [5, 2, 3]
    }
}
sorted_groups: [
  (&quot;A&quot;, &quot;a&quot;) -&gt; [2, 3]
],
</code></pre>
<h5 id="transaction-3"><a class="header" href="#transaction-3">Transaction #3</a></h5>
<p>The next group is for key <code>(&quot;C&quot;, &quot;d&quot;)</code>, the pool iterator sorts transactions by nonces and returns the mutable references to the group. Sorted nonces are:
<code>[7]</code>. Runtime adapter pulls <code>7</code>. The transaction with nonce <code>7</code> is invalid because of odd nonce.</p>
<p>No valid transactions is added for this group.</p>
<p>The transaction group is dropped, it's empty, so the pool iterator drops it completely:</p>
<pre><code>pool: {
    transactions: {
      (&quot;A&quot;, &quot;c&quot;) -&gt; [5, 2, 3]
    }
}
sorted_groups: [
  (&quot;A&quot;, &quot;a&quot;) -&gt; [2, 3]
],
</code></pre>
<p>The next group is for key <code>(&quot;A&quot;, &quot;c&quot;)</code>, the pool iterator sorts transactions by nonces and returns the mutable references to the group. Sorted nonces are:
<code>[2, 3, 5]</code>. Runtime adapter pulls <code>2</code>.</p>
<p>It's a valid transaction, so it's added to the list of valid transactions.</p>
<p>Again, the transaction group is dropped, it's empty, so the pool iterator drops it completely:</p>
<pre><code>pool: {
    transactions: { }
}
sorted_groups: [
  (&quot;A&quot;, &quot;a&quot;) -&gt; [2, 3]
  (&quot;A&quot;, &quot;c&quot;) -&gt; [3, 5]
],
</code></pre>
<h5 id="transaction-4"><a class="header" href="#transaction-4">Transaction #4</a></h5>
<p>The next group is pulled not from the pool, but from the sorted_groups. The key is <code>(&quot;A&quot;, &quot;a&quot;)</code>.
It's already sorted, so the iterator returns the mutable reference. Nonces are:
<code>[2, 3]</code>. Runtime adapter pulls <code>2</code>, then pulls <code>3</code>.</p>
<p>The transaction with nonce <code>2</code> is invalid, because we've already pulled a transaction #1 from this group and it had nonce <code>2</code>.
The new nonce has to be larger than the previous nonce, so this transaction is invalid.</p>
<p>The transaction with nonce <code>3</code> is invalid because of odd nonce.</p>
<p>No valid transactions are added for this group.</p>
<p>The transaction group is dropped, it's empty, so the pool iterator drops it completely:</p>
<pre><code>pool: {
    transactions: { }
}
sorted_groups: [
  (&quot;A&quot;, &quot;c&quot;) -&gt; [3, 5]
],
</code></pre>
<p>The next group is for key <code>(&quot;A&quot;, &quot;c&quot;)</code>, with nonces <code>[3, 5]</code>.
Runtime adapter pulls <code>3</code>, then pulls <code>5</code>. Both transactions are invalid, because the nonce is odd.</p>
<p>No transactions are added.</p>
<p>The transaction group is dropped, the pool iterator wrapper becomes empty:</p>
<pre><code>pool: {
    transactions: { }
}
sorted_groups: [ ],
</code></pre>
<p>When runtime adapter tries to pull the next group, the pool iterator returns <code>None</code>, so the runtime adapter drops the iterator.</p>
<h5 id="dropping-iterator"><a class="header" href="#dropping-iterator">Dropping iterator</a></h5>
<p>If the iterator was not fully drained, but some transactions still remained, they would be reinserted back into the pool.</p>
<h5 id="chunk-transactions"><a class="header" href="#chunk-transactions">Chunk Transactions</a></h5>
<p>Transactions that were pulled from the pool:</p>
<pre><code>// First batch
(&quot;A&quot;, &quot;a&quot;, 1),
(&quot;A&quot;, &quot;a&quot;, 1),
(&quot;A&quot;, &quot;a&quot;, 2),
(&quot;B&quot;, &quot;b&quot;, 13),
(&quot;B&quot;, &quot;b&quot;, 14),
(&quot;C&quot;, &quot;d&quot;, 7),
(&quot;A&quot;, &quot;c&quot;, 2),

// Next batch
(&quot;A&quot;, &quot;a&quot;, 2),
(&quot;A&quot;, &quot;a&quot;, 3),
(&quot;A&quot;, &quot;c&quot;, 3),
(&quot;A&quot;, &quot;c&quot;, 5),
</code></pre>
<p>The valid transactions are:</p>
<pre><code>(&quot;A&quot;, &quot;a&quot;, 2),
(&quot;B&quot;, &quot;b&quot;, 14),
(&quot;A&quot;, &quot;c&quot;, 2),
</code></pre>
<p>In total there were only 3 valid transactions that resulted in one batch.</p>
<h3 id="order-validation"><a class="header" href="#order-validation">Order validation</a></h3>
<p>Other validators need to check the order of transactions in the produced chunk.
It can be done in linear time using a greedy algorithm.</p>
<p>To select a first batch we need to iterate over transactions one by one until we see a transaction
with the key that we've already included in the first batch.
This transaction belongs to the next batch.</p>
<p>Now all transactions in the N+1 batch should have a corresponding transaction with the same key in the N batch.
If there are no transaction with the same key in the N batch, then the order is invalid.</p>
<p>We also enforce the order of the sequence of transactions for the same key, the nonces of them should be in strictly increasing order.</p>
<p>Here is the algorithm that validates the order:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn validate_order(txs: &amp;Vec&lt;Transaction&gt;) -&gt; bool {
    let mut nonces: HashMap&lt;Key, Nonce&gt; = HashMap::new();
    let mut batches: HashMap&lt;Key, usize&gt; = HashMap::new();
    let mut current_batch = 1;

    for tx in txs {
        let key = tx.key();

        // Verifying nonce
        let nonce = tx.nonce();
        if let Some(last_nonce) = nonces.get(key) {
            if nonce &lt;= last_nonce {
                // Nonces should increase.
                return false;
            }
        }
        nonces.insert(key, nonce);

        // Verifying batch
        if let Some(last_batch) = batches.get(key) {
            if last_batch == current_batch {
                current_batch += 1;
            } else if last_batch &lt; current_batch - 1 {
                // Was skipped this key in the previous batch
                return false;
            }
        } else {
            if current_batch &gt; 1 {
                // Not in first batch
                return false;
            }
        }
        batches.insert(key, batch);
    }
    true
}
<span class="boring">}
</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="upgradability"><a class="header" href="#upgradability">Upgradability</a></h1>
<p>This part of specification describes specifics of upgrading the protocol, and touches on few different parts of the system.</p>
<p>Three different levels of upgradability are:</p>
<ol>
<li>Updating without any changes to underlying data structures or protocol;</li>
<li>Updating when underlying data structures changed (config, database or something else internal to the node and probably client specific);</li>
<li>Updating with protocol changes that all validating nodes must adjust to.</li>
</ol>
<h2 id="versioning"><a class="header" href="#versioning">Versioning</a></h2>
<p>There are 2 different important versions:</p>
<ul>
<li>Version of binary defines it's internal data structures / database and configs. This version is client specific and doesn't need to be matching between nodes.</li>
<li>Version of the protocol, defining the &quot;language&quot; nodes are speaking.</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Latest version of protocol that this binary can work with.
type ProtocolVersion = u32;
<span class="boring">}
</span></code></pre></pre>
<h2 id="client-versioning"><a class="header" href="#client-versioning">Client versioning</a></h2>
<p>Clients should follow <a href="https://semver.org/">semantic versioning</a>.
Specifically:</p>
<ul>
<li>MAJOR version defines protocol releases.</li>
<li>MINOR version defines changes that are client specific but require database migration, change of config or something similar. This includes client-specific features. Client should execute migrations on start, by detecting that information on disk is produced by previous version and auto-migrate it to new one.</li>
<li>PATCH version defines when bug fixes, which should not require migrations or protocol changes.</li>
</ul>
<p>Clients can define how current version of data is stored and migrations applied.
General recommendation is to store version in the database and on binary start, check version of database and perform required migrations.</p>
<h2 id="protocol-upgrade"><a class="header" href="#protocol-upgrade">Protocol Upgrade</a></h2>
<p>Generally, we handle data structure upgradability via enum wrapper around it. See <code>BlockHeader</code> structure for example.</p>
<h3 id="versioned-data-structures"><a class="header" href="#versioned-data-structures">Versioned data structures</a></h3>
<p>Given we expect many data structures to change or get updated as protocol evolves, a few changes are required to support that.</p>
<p>The major one is adding backward compatible <code>Versioned</code> data structures like this one:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>enum VersionedBlockHeader {
    BlockHeaderV1(BlockHeaderV1),
    /// Current version, where `BlockHeader` is used internally for all operations.
    BlockHeaderV2(BlockHeader),
}
<span class="boring">}
</span></code></pre></pre>
<p>Where <code>VersionedBlockHeader</code> will be stored on disk and sent over the wire.
This allows to encode and decode old versions (up to 256 given https://borsh.io specification). If some data structures has more than 256 versions, old versions are probably can be retired and reused.</p>
<p>Internally current version is used. Previous versions either much interfaces / traits that are defined by different components or are up-casted into the next version (saving for hash validation).</p>
<h3 id="consensus-1"><a class="header" href="#consensus-1">Consensus</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Name</th><th>Value</th></tr></thead><tbody>
<tr><td><code>PROTOCOL_UPGRADE_BLOCK_THRESHOLD</code></td><td><code>80%</code></td></tr>
<tr><td><code>PROTOCOL_UPGRADE_NUM_EPOCHS</code></td><td><code>2</code></td></tr>
</tbody></table>
</div>
<p>The way the version will be indicated by validators, will be via</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Add `version` into block header.
struct BlockHeaderInnerRest {
    ...
    /// Latest version that current producing node binary is running on.
    version: ProtocolVersion,
}
<span class="boring">}
</span></code></pre></pre>
<!-- cspell:ignore defaultdict -->
<p>The condition to switch to next protocol version is based on % of stake <code>PROTOCOL_UPGRADE_NUM_EPOCHS</code> epochs prior indicated about switching to the next version:</p>
<pre><code class="language-python">def next_epoch_protocol_version(last_block):
    &quot;&quot;&quot;Determines next epoch's protocol version given last block.&quot;&quot;&quot;
    epoch_info = epoch_manager.get_epoch_info(last_block)
    # Find epoch that decides if version should change by walking back.
    for _ in PROTOCOL_UPGRADE_NUM_EPOCHS:
        epoch_info = epoch_manager.prev_epoch(epoch_info)
        # Stop if this is the first epoch.
        if epoch_info.prev_epoch_id == GENESIS_EPOCH_ID:
            break
    versions = collections.defaultdict(0)
    # Iterate over all blocks in previous epoch and collect latest version for each validator.
    authors = {}
    for block in epoch_info:
        author_id = epoch_manager.get_block_producer(block.header.height)
        if author_id not in authors:
            authors[author_id] = block.header.rest.version
    # Weight versions with stake of each validator.
    for author in authors:
        versions[authors[author] += epoch_manager.validators[author].stake
    (version, stake) = max(versions.items(), key=lambda x: x[1])
    if stake &gt; PROTOCOL_UPGRADE_BLOCK_THRESHOLD * epoch_info.total_block_producer_stake:
        return version
    # Otherwise return version that was used in that deciding epoch.
    return epoch_info.version
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="epochs-and-staking"><a class="header" href="#epochs-and-staking">Epochs and Staking</a></h1>
<ul>
<li><a href="ChainSpec/EpochAndStaking/Epoch.html">Epoch</a></li>
<li><a href="ChainSpec/EpochAndStaking/EpochManager.html">EpochManager</a></li>
<li><a href="ChainSpec/EpochAndStaking/Staking.html">Staking</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="epoch"><a class="header" href="#epoch">Epoch</a></h1>
<p>All blocks are split into epochs. Within one epoch, the set of validators is fixed, and validator rotation
happens at epoch boundaries.</p>
<p>Genesis block is in its own epoch. After that, a block is either in its parent's epoch or
starts a new epoch if it meets certain conditions.</p>
<p>Within one epoch, validator assignment is based on block height: each height has a block producer assigned to it, and
each height and shard have a chunk producer.</p>
<h3 id="end-of-an-epoch"><a class="header" href="#end-of-an-epoch">End of an epoch</a></h3>
<p>Let <code>estimated_next_epoch_start = first_block_in_epoch.height + epoch_length</code></p>
<p>A <code>block</code> is defined to be the last block in its epoch if it's the genesis block or if the following condition is met:</p>
<ul>
<li><code>block.last_finalized_height + 3 &gt;= estimated_next_epoch_start</code></li>
</ul>
<p><code>epoch_length</code> is defined in <code>genesis_config</code> and has a value of <code>43200</code> height delta on mainnet (12 hours at 1 block per second).</p>
<p>Since every final block must have two more blocks on top of it, it means that the last block in an epoch will have a height of at least <code>block.last_finalized_height + 2</code>, so for the last block it holds that <code>block.height + 1 &gt;= estimated_next_epoch_start</code>. Its height will be at least <code>estimated_next_epoch_start - 1</code>.</p>
<p>Note that an epoch only ends when there is a final block above a certain height. If there are no final blocks, the epoch will be stretched until the required final block appears. An epoch can potentially be longer than <code>epoch_length</code>.</p>
<p><img src="ChainSpec/EpochAndStaking//images/epoch_end_diagram.png" alt="Diagram of epoch end" /></p>
<h3 id="epochheight"><a class="header" href="#epochheight">EpochHeight</a></h3>
<p>Epochs on one chain can be identified by height, which is defined the following way:</p>
<ul>
<li>Special epoch that contains genesis block only: undefined</li>
<li>Epoch starting from the block that's after genesis: <code>0</code> (NOTE: in current implementation it's <code>1</code> due to a bug, so there are two epochs with height <code>1</code>)</li>
<li>Following epochs: height of the parent epoch plus one</li>
</ul>
<h3 id="epoch-id"><a class="header" href="#epoch-id">Epoch id</a></h3>
<p>Every block stores the id of its epoch - <code>epoch_id</code>.</p>
<p>Epoch id is defined as</p>
<ul>
<li>For special genesis block epoch it's <code>0</code></li>
<li>For epoch with height <code>0</code> it's <code>0</code> (NOTE: the first two epochs use the same epoch id)</li>
<li>For epoch with height <code>1</code> it's the hash of genesis block</li>
<li>For epoch with height <code>T+2</code> it's the hash of the last block in epoch <code>T</code></li>
</ul>
<h3 id="epoch-end"><a class="header" href="#epoch-end">Epoch end</a></h3>
<ul>
<li>After processing the last block of epoch <code>T</code>, <code>EpochManager</code> aggregates information from block of the epoch, and computes
validator set for epoch <code>T+2</code>. This process is described in <a href="ChainSpec/EpochAndStaking/EpochManager.html">EpochManager</a>.</li>
<li>After that, the validator set rotates to epoch <code>T+1</code>, and the next block is produced by the validator from the new set</li>
<li>Applying the first block of epoch <code>T+1</code>, in addition to a normal transition, also applies the per-epoch state transitions:
validator rewards, stake unlocks and slashing.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="epochmanager"><a class="header" href="#epochmanager">EpochManager</a></h1>
<h2 id="finalizing-an-epoch"><a class="header" href="#finalizing-an-epoch">Finalizing an epoch</a></h2>
<p>At the last block of epoch <code>T</code>, <code>EpochManager</code> computes <code>EpochInfo</code> for epoch <code>T+2</code>, which
is defined by <code>EpochInfo</code> for <code>T+1</code> and the information aggregated from blocks of epoch <code>T</code>.</p>
<p><code>EpochInfo</code> is all the information that <code>EpochManager</code> stores for the epoch, which is:</p>
<ul>
<li><code>epoch_height</code>: epoch height (<code>T+2</code>)</li>
<li><code>validators</code>: the list of validators selected for epoch <code>T+2</code></li>
<li><code>validator_to_index</code>: Mapping from account id to index in <code>validators</code></li>
<li><code>block_producers_settlement</code>: defines the mapping from height to block producer</li>
<li><code>chunk_producers_settlement</code>: defines the mapping from height and shard id to chunk producer</li>
<li><code>hidden_validators_settlement</code>: TODO</li>
<li><code>fishermen</code>, <code>fishermen_to_index</code>: TODO. disabled on mainnet through a large <code>fishermen_threshold</code> in config</li>
<li><code>stake_change</code>: TODO</li>
<li><code>validator_reward</code>: validator reward for epoch <code>T</code></li>
<li><code>validator_kickout</code>: see <a href="ChainSpec/EpochAndStaking/EpochManager.html#kickout-set">Kickout set</a></li>
<li><code>minted_amount</code>: minted tokens in epoch <code>T</code></li>
<li><code>seat_price</code>: seat price of the epoch</li>
<li><code>protocol_version</code>: TODO</li>
</ul>
<p>Aggregating blocks of the epoch computes the following sets:</p>
<ul>
<li><code>block_stats</code>/<code>chunk_stats</code>: uptime statistics in the form of <code>produced</code> and <code>expected</code> blocks/chunks for each validator of <code>T</code></li>
<li><code>proposals</code>: stake proposals made in epoch <code>T</code>. If an account made multiple proposals, the last one is used.</li>
<li><code>slashes</code>: see <a href="ChainSpec/EpochAndStaking/EpochManager.html#slash-set">Slash set</a></li>
</ul>
<h3 id="slash-set"><a class="header" href="#slash-set">Slash set</a></h3>
<!-- cspell:ignore slashable -->
<p>NOTE: slashing is currently disabled. The following is the current design, which can change.</p>
<p>Slash sets are maintained on block basis. If a validator gets slashed in epoch <code>T</code>, subsequent blocks of epochs <code>T</code> and
<code>T+1</code> keep it in their slash sets. At the end of epoch <code>T</code>, the slashed validator is also added to <code>kickout[T+2]</code>.
Proposals from blocks in slash sets are ignored.</p>
<p>It's kept in the slash set (and kickout sets) for two or three epochs depending on whether it was going to be a validator in <code>T+1</code>:</p>
<ul>
<li>Common case: <code>v</code> is in <code>validators[T]</code> and in <code>validators[T+1]</code>
<ul>
<li>proposals from <code>v</code> in <code>T</code>, <code>T+1</code> and <code>T+2</code> are ignored</li>
<li><code>v</code> is added to <code>kickout[T+2]</code>, <code>kickout[T+3]</code> and <code>kickout[T+4]</code>  as slashed</li>
<li><code>v</code> can stake again starting with the first block of <code>T+3</code>.</li>
</ul>
</li>
<li>If <code>v</code> is in <code>validators[T]</code> but not in <code>validators[T+1]</code> (e.g. if it unstaked in <code>T-1</code>)
<ul>
<li>proposals from <code>v</code> in <code>T</code> and <code>T+1</code> are ignored</li>
<li><code>v</code> is added to <code>kickout[T+2]</code> and <code>kickout[T+3]</code> as slashed</li>
<li><code>v</code> can make a proposal in <code>T+2</code> to become a validator in <code>T+4</code></li>
</ul>
</li>
<li>If <code>v</code> is in <code>validators[T-1]</code> but not in <code>validators[T]</code> (e.g. did slashable behavior right before rotating out)
<ul>
<li>proposals from <code>v</code> in <code>T</code> and <code>T+1</code> are ignored</li>
<li><code>v</code> is added to <code>kickout[T+2]</code> and <code>kickout[T+3]</code> as slashed</li>
<li><code>v</code> can make a proposal in <code>T+2</code> to become a validator in <code>T+4</code></li>
</ul>
</li>
</ul>
<h2 id="computing-epochinfo"><a class="header" href="#computing-epochinfo">Computing EpochInfo</a></h2>
<h3 id="kickout-set"><a class="header" href="#kickout-set">Kickout set</a></h3>
<p><code>kickout[T+2]</code> contains validators of epoch <code>T+1</code> that stop being validators in <code>T+2</code>, and also accounts that are not
necessarily validators of <code>T+1</code>, but are kept in slashing sets due to the rule described <a href="ChainSpec/EpochAndStaking/EpochManager.html#slash-set">above</a>.</p>
<p><code>kickout[T+2]</code> is computed the following way:</p>
<ol>
<li><code>Slashed</code>: accounts in the slash set of the last block in <code>T</code></li>
<li><code>Unstaked</code>: accounts that remove their stake in epoch <code>T</code>, if their stake is non-zero for epoch <code>T+1</code></li>
<li><code>NotEnoughBlocks/NotEnoughChunks</code>: For each validator compute the ratio of blocks produced to expected blocks produced (same with chunks produced/expected).
If the percentage is below <code>block_producer_kickout_threshold</code> (<code>chunk_producer_kickout_threshold</code>), the validator is kicked out.
<ul>
<li>Exception: If all validators of <code>T</code> are either in <code>kickout[T+1]</code> or to be kicked out, we don't kick out the
validator with the maximum number of blocks produced. If there are multiple, we choose the one with
lowest validator id in the epoch.</li>
</ul>
</li>
<li><code>NotEnoughStake</code>: computed after validator selection. Accounts who have stake in epoch <code>T+1</code>, but don't meet stake threshold for epoch <code>T+2</code>.</li>
<li><code>DidNotGetASeat</code>: computed after validator selection. Accounts who have stake in epoch <code>T+1</code>, meet stake threshold for epoch <code>T+2</code>, but didn't get any seats.</li>
</ol>
<h3 id="processing-proposals"><a class="header" href="#processing-proposals">Processing proposals</a></h3>
<p>The set of proposals is processed by the validator selection algorithm, but before that, the set of proposals is adjusted
the following way:</p>
<ol>
<li>If an account is in the slash set as of the end of <code>T</code>, or gets kicked out for <code>NotEnoughBlocks/NotEnoughChunks</code> in epoch <code>T</code>,
its proposal is ignored.</li>
<li>If a validator is in <code>validators[T+1]</code>, and didn't make a proposal, add an implicit proposal with its stake in <code>T+1</code>.</li>
<li>If a validator is in both <code>validators[T]</code> and <code>validators[T+1]</code>, and made a proposal in <code>T</code> (including implicit),
then its reward for epoch <code>T</code> is automatically added to the proposal.</li>
</ol>
<p>The adjusted set of proposals is used to compute the seat price, and determine <code>validators</code>,<code>block_producers_settlement</code>,
<code>chunk_producers_settlement</code>sets. This algorithm is described in <a href="ChainSpec/EpochAndStaking/../../Economics/Economics.html#validator-selection">Economics</a>.</p>
<h3 id="validator-reward"><a class="header" href="#validator-reward">Validator reward</a></h3>
<p>Rewards calculation is described in the <a href="ChainSpec/EpochAndStaking/../../Economics/Economics.html#validator-rewards-calculation">Economics</a> section.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="staking-and-slashing"><a class="header" href="#staking-and-slashing">Staking and slashing</a></h1>
<h2 id="stake-invariant"><a class="header" href="#stake-invariant">Stake invariant</a></h2>
<p><code>Account</code> has two fields representing its tokens: <code>amount</code> and <code>locked</code>. <code>amount + locked</code> is the total number of
tokens an account has: locking/unlocking actions involve transferring balance between the two fields, and slashing
is done by subtracting from the <code>locked</code> value.</p>
<p>On a stake action the balance gets locked immediately (but the locked balance can only increase), and the stake proposal is 
passed to the epoch manager. Proposals get accumulated during an epoch and get processed all at once when an epoch is finalized.
Unlocking only happens at the start of an epoch.</p>
<p>Account's stake is defined per epoch and is stored in <code>EpochInfo</code>'s <code>validators</code> and <code>fishermen</code> sets. <code>locked</code> is always
equal to the maximum of the last three stakes and the highest proposal in the current epoch.</p>
<h3 id="returning-stake"><a class="header" href="#returning-stake">Returning stake</a></h3>
<p><code>locked</code> is the number of tokens locked for staking, it's computed the following way:</p>
<ul>
<li>initially it's the value in genesis or <code>0</code> for new accounts</li>
<li>on a staking proposal with a value higher than <code>locked</code>, it increases to that value</li>
<li>at the start of each epoch it's recomputed:
<ol>
<li>consider the most recent 3 epochs</li>
<li>for non-slashed accounts, take the maximum of their stakes in those epochs</li>
<li>if an account made a proposal in the block that starts the epoch, also take the maximum with the proposal value</li>
<li>change <code>locked</code> to the resulting value (and update <code>amount</code> so that <code>amount + locked</code> stays the same)</li>
</ol>
</li>
</ul>
<h3 id="slashing"><a class="header" href="#slashing">Slashing</a></h3>
<p>TODO.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="network"><a class="header" href="#network">Network</a></h1>
<!-- cspell:ignore permissioned isinstance -->
<p>Network layer constitutes the lower level of the NEAR protocol and is ultimately responsible of transporting messages between peers. To provide an efficient routing it maintains a routing table between all peers actively connected to the network, and sends messages between them using best paths. There is a mechanism in place that allows new peers joining the network to discover other peers, and rebalance network connections in such a way that latency is minimized. Cryptographic signatures are used to check identities from peers participating in the protocol since it is non-permissioned system.</p>
<p>This document should serve as reference for all the clients to implement networking layer.</p>
<h2 id="messages-1"><a class="header" href="#messages-1">Messages</a></h2>
<p>Data structures used for messages between peers are enumerated in <a href="NetworkSpec/Messages.html">Message</a>.</p>
<h2 id="discovering-the-network"><a class="header" href="#discovering-the-network">Discovering the network</a></h2>
<p>When a node starts for the first time it tries to connect to a list of bootstrap nodes specified via a config file. The address for each node</p>
<p>It is expected that a node periodically requests a list of peers from its neighboring nodes to learn about other nodes in the network. This will allow every node to discover each other, and have relevant information to try to establish a new connection with it. When a node receives a message of type <a href="NetworkSpec/Messages.html#peermessage"><code>PeersRequest</code></a> it is expected to answer with a message of type <a href="NetworkSpec/Messages.html#peermessage"><code>PeersResponse</code></a> with information from healthy peers known to this node.</p>
<h3 id="handshakes"><a class="header" href="#handshakes">Handshakes</a></h3>
<p>To establish a new connections between pair of nodes, they will follow the following protocol. Node A open a connection with node B and sends a <a href="NetworkSpec/Messages.html#handshake">Handshake</a> to it. If handshake is valid (see reasons to <a href="NetworkSpec/NetworkSpec.html#decline-handshake">decline the handshake</a>) then node B will proceed to send <a href="NetworkSpec/Messages.html#handshake">Handshake</a> to node A. After each node accept a handshake it will mark the other node as an active connection, until one of them stop the connection.</p>
<p><a href="NetworkSpec/Messages.html#handshake">Handshake</a> contains relevant information about the node, the current chain and information to create a new edge between both nodes.</p>
<h4 id="decline-handshake"><a class="header" href="#decline-handshake">Decline handshake</a></h4>
<p>When a node receives a handshake from other node it will decline this connection if one of the following situations happens:</p>
<ol>
<li>Other node has different genesis.</li>
<li>Edge nonce is too low</li>
</ol>
<h4 id="edge"><a class="header" href="#edge">Edge</a></h4>
<p>Edges are used to let other nodes in the network know that there is currently an active connection between a pair of nodes. See the definition of <a href="NetworkSpec/Messages.html#edge">this data structure</a>.</p>
<p>If the nonce of the edge is odd, it denotes an <code>Added</code> edge, otherwise it denotes a <code>Removed</code> edge. Each node should keep track of the nonce used for edges between every pair of nodes. Peer C believes that the peers A and B are currently connected if and only if the edge with the highest nonce known to C for them has an odd nonce.</p>
<p>When two nodes successfully connect to each other, they broadcast the new edge to let other peers know about this connection. When a node is disconnected from other node, it should bump the nonce by 1, sign the new edge and broadcast it to let other nodes know that the connection was removed.</p>
<p>A removed connection will be valid, if it contains valid information from the added edge it is invalidating. This prevents peers bump nonce by more than one when deleting an edge.</p>
<p>When node A proposes an edge to B with nonce X, it will only accept it and sign it iff:</p>
<ul>
<li>X = 1 and B doesn't know about any previous edge between A and B</li>
<li>X is odd and X &gt; Y where Y is the nonce of the edge with the highest nonce between A and B known to B.</li>
</ul>
<!-- TODO: What is a valid edge: pseudo code -->
<h2 id="routing-table"><a class="header" href="#routing-table">Routing Table</a></h2>
<p>Every node maintains a routing table with all existing connections and relevant information to route messages. The explicit graph with all active connection is stored at all times.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct RoutingTable {
    /// PeerId associated for every known account id.
    account_peers: HashMap&lt;AccountId, AnnounceAccount&gt;,
    /// Active PeerId that are part of the shortest path to each PeerId.
    peer_forwarding: HashMap&lt;PeerId, HashSet&lt;PeerId&gt;&gt;,
    /// Store last update for known edges.
    edges_info: HashMap&lt;(PeerId, PeerId), Edge&gt;,
    /// Hash of messages that requires routing back to respective previous hop.
    route_back: HashMap&lt;CryptoHash, PeerId&gt;,
    /// Current view of the network. Nodes are Peers and edges are active connections.
    raw_graph: Graph,
}

<span class="boring">}
</span></code></pre></pre>
<ul>
<li>
<p><code>account_peers</code> is a mapping from each known account to the correspondent <a href="NetworkSpec/Messages.html#announceaccount">announcement</a>. Given that validators are known by its <a href="NetworkSpec/Messages.html#accountid">AccountId</a> when a node needs to send a message to a validator it finds the <a href="NetworkSpec/Messages.html#peerid">PeerId</a> associated with the <a href="NetworkSpec/Messages.html#accountid">AccountId</a> in this table.</p>
</li>
<li>
<p><code>peer_forwarding</code>: For node <code>S</code>, <code>peer_forwarding</code> constitutes a mapping from each <a href="NetworkSpec/Messages.html#peerid">PeerId</a> <code>T</code>, to the set of peers that are directly connected to <code>S</code> and belong to the shortest route, in terms of number of edges, between <code>S</code> and <code>T</code>. When node <code>S</code> needs to send a message to node <code>T</code> and they are not directly connected, <code>S</code> choose one peer among the set <code>peer_forwarding[S]</code> and sends a routed message to it with destination <code>T</code>.</p>
</li>
</ul>
<!-- TODO: Add example. Draw a graph. Show routing table for each node. -->
<!-- TODO: Notice when two nodes are totally disconnected, and when two nodes are directly connected -->
<ul>
<li>
<p><code>edges_info</code> is a mapping between each unordered pair of peers <code>A</code> and <code>B</code> to the edge with highest nonce known between those peers. It might be</p>
</li>
<li>
<p><code>route_back</code> used to compute the route for certain messages. Read more about it on <a href="NetworkSpec/NetworkSpec.html#routing-back">Routing back section</a></p>
</li>
<li>
<p><code>raw_graph</code> is the explicit <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">graph</a> representation of the network. Each vertex of this graph is a peer, and each edge is an active connection between a pair of peers, i.e. the edge with highest nonce between this pair of peers is of type <code>Added</code>. It is used to compute the shortest path from the source to all other peers.</p>
</li>
</ul>
<h3 id="updates"><a class="header" href="#updates">Updates</a></h3>
<p><code>RoutingTable</code> should be update accordingly when the node receives updates from the network:</p>
<ul>
<li>New edges: <code>edges_info</code> map is updated with new edges if their nonce is higher. This is relevant to know whether a new connection was created, or some connection stopped.</li>
</ul>
<pre><code class="language-python">def on_edges_received(self, edges):
    for edge in edges:
        # Check the edge is valid
        if edge.is_valid():
            peer0 = edge.peer0
            peer1 = edge.peer1

            # Find edge with higher nonce known up to this point.
            current_edge = self.routing_table.edges_info.get((peer0, peer1))

            # If there is no known edge, or the known edge has smaller nonce
            if current_edge is None or current_edge.nonce &lt; edge.nonce:
                # Update with the new edge
                self.routing_table.edges_info[(peer0, peer1)] = edge
</code></pre>
<ul>
<li>Announce account: <code>account_peers</code> map is updated with announcements from more recent epochs.</li>
</ul>
<pre><code class="language-python">def on_announce_accounts_received(self, announcements):
    for announce_account in announcements:
        # Check the announcement is valid
        if announce_account.is_valid():
            account_id = announce_account.account_id

            # Find most recent announcement for account_id being announced
            current_announce_account = self.routing_table.account_peers.get(account_id)

            # If new epoch is happens after current epoch.
            if announce_account.epoch &gt; current_announce_account.epoch:
                # Update with the new announcement
                self.routing_table.account_peers[announce_id] = announce_account
</code></pre>
<ul>
<li>Route back messages: Read about it on <a href="NetworkSpec/NetworkSpec.html#routing-back">Routing back section</a></li>
</ul>
<h3 id="routing"><a class="header" href="#routing">Routing</a></h3>
<p>When a node needs to send a message to another peer, it checks in the routing table if it is connected to that peer, possibly not directly but through several hops. Then it select one of the shortest path to the target peer and sends a <a href="NetworkSpec/Messages.html#routedmessage"><code>RoutedMessage</code></a> to the first peer in the path.</p>
<p>When it receives a <a href="NetworkSpec/Messages.html#routedmessage"><code>RoutedMessage</code></a>, it check if it is the target, in that case consume the body of the message, otherwise it finds a route to the target following described approach and sends the message again. It is important that before routing a message each peer check signature from original author of the message, passing a message with invalid signature can result in ban for the sender. It is not required however checking the content of the message itself.</p>
<p>Each <a href="NetworkSpec/Messages.html#routedmessage"><code>RoutedMessage</code></a> is equipped with a time-to-live integer. If this message is not for the node processing it, it decrement the field by one before routing it; if the value is 0, the node drops the message instead of routing it.</p>
<h4 id="routing-back"><a class="header" href="#routing-back">Routing back</a></h4>
<p>It is possible that node <code>A</code> is known to <code>B</code> but not the other way around. In case node <code>A</code> sends a request that requires a response to <code>B</code>, the response is routed back through the same path used to send the message from <code>A</code> to <code>B</code>. When a node receives a <a href="NetworkSpec/Messages.html#routedmessage">RoutedMessage</a> that requires a response it stores in the map <code>route_back</code> the hash of the message mapped to the <a href="NetworkSpec/Messages.html#peerid">PeerId</a> of the sender.   After the message reaches the final destination and response is computed it is routed back using as target the hash of the original message. When a node receives a Routed Message such that the target is a hash, the node checks for the previous sender in the <code>route_back</code> map, and sends the message to it if it exists, otherwise it drops the message.</p>
<p>The hash of a <code>RoutedMessage</code> to be stored on the map <code>route_back</code> is computed as:</p>
<pre><code class="language-python">def route_back_hash(routed_message):
    return sha256(concat(
        borsh(routed_message.target),
        borsh(routed_message.author),
        borsh(routed_message.body)
    ))
</code></pre>
<pre><code class="language-python">def send_routed_message(self, routed_message, sender):
    &quot;&quot;&quot;
    sender: PeerId of the node through which the message was received.

    Don't confuse sender with routed_message.author:
    routed_message.author is the PeerId from the original creator of the message

    The only situation in which sender == routed_message.author is when the message was
    not received from the network, but was created by the node and should be routed.
    &quot;&quot;&quot;
    if routed_message.requires_response():
        crypto_hash = route_back_hash(routed_message)
        self.routing_table.route_back[crypto_hash] = sender

    next_peer = self.find_closest_peer_to(routed_message.target)
    self.send_message(next_peer, routed_message)

def on_routed_message_received(self, routed_message, sender):
    # routed_message.target is of type CryptoHash or PeerId
    if isinstance(routed_message.target, CryptoHash):
        # This is the response for a routed message.
        # `target` is the PeerId that sent this message.
        target = self.routing_table.route_back.get(routed_message.target)

        if target is None:
            # Drop message if there is no known route back for it
            return
        else:
            del self.routing_table.route_back[routed_message.target]
    else:
        target = routed_message.target

    if target == self.peer_id:
        self.handle_message(routed_message.body)
    else:
        self.send_routed_message(routed_message, sender)
</code></pre>
<h3 id="synchronization"><a class="header" href="#synchronization">Synchronization</a></h3>
<p>When two node connect to each other they exchange all known edges (from <code>RoutingTable::edges_info</code>) and account announcements (from <code>RoutingTable::account_peers</code>). Also they broadcast the newly created edge to all nodes directly connected to them. After a node learns about a new <code>AnnounceAccount</code> or a new <code>Edge</code> they automatically broadcast this information to the rest of the nodes, so everyone is kept up to date.</p>
<h2 id="security"><a class="header" href="#security">Security</a></h2>
<p>Messages exchanged between peers (both direct or routed) are cryptographically signed with sender private key. Nodes ID contains public key of each node that allow other peer to verify this messages. To keep secure communication most of this message requires some nonce/timestamp that forbid a malicious actor reuse a signed message out of context.</p>
<p>In the case of routing messages each intermediate hop should verify that message hash and signatures are valid before routing to next hop.</p>
<h3 id="abusive-behavior"><a class="header" href="#abusive-behavior">Abusive behavior</a></h3>
<p>When a node A sends more than <code>MAX_PEER_MSG_PER_MIN</code> messages per minute to node B, it will be banned and unable to keep sending messages to it. This a protection mechanism against abusive node to avoid being spammed by some peers.</p>
<h2 id="implementation-details"><a class="header" href="#implementation-details">Implementation Details</a></h2>
<p>There are some issues that should be handled by the network layer but details about how to implement them are not enforced by the protocol, however we propose here how to address them.</p>
<h3 id="balancing-network"><a class="header" href="#balancing-network">Balancing network</a></h3>
<p><a href="https://github.com/nearprotocol/nearcore/issues/2395#issuecomment-610077017">Github comment</a></p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="messages-2"><a class="header" href="#messages-2">Messages</a></h1>
<p>All message sent in the network are of type <code>PeerMessage</code>. They are encoded using <a href="https://borsh.io/">Borsh</a> which allows a rich structure, small size and fast encoding/decoding. For details about data structures used as part of the message see the <a href="https://github.com/nearprotocol/nearcore">reference code</a>.</p>
<h2 id="encoding"><a class="header" href="#encoding">Encoding</a></h2>
<p>A <code>PeerMessage</code> is converted into an array of bytes (<code>Vec&lt;u8&gt;</code>) using borsh serialization. An encoded message is conformed by 4 bytes with the length of the serialized <code>PeerMessage</code> concatenated with the serialized <code>PeerMessage</code>.</p>
<p>Check <a href="https://github.com/nearprotocol/borsh#specification">Borsh specification</a> details to see how it handles each data structure.</p>
<h2 id="data-structures-3"><a class="header" href="#data-structures-3">Data structures</a></h2>
<h3 id="peerid"><a class="header" href="#peerid">PeerID</a></h3>
<p>The id of a peer in the network is its <a href="https://github.com/nearprotocol/nearcore/blob/master/core/crypto/src/signature.rs">PublicKey</a>.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct PeerId(PublicKey);
<span class="boring">}
</span></code></pre></pre>
<h3 id="peerinfo"><a class="header" href="#peerinfo">PeerInfo</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct PeerInfo {
    id: PeerId,
    addr: Option&lt;SocketAddr&gt;,
    account_id: Option&lt;AccountId&gt;,
}
<span class="boring">}
</span></code></pre></pre>
<p><code>PeerInfo</code> contains relevant information to try to connect to other peer. <a href="https://doc.rust-lang.org/std/net/enum.SocketAddr.html"><code>SocketAddr</code></a> is a tuple of the form: <code>IP:port</code>.</p>
<h3 id="accountid"><a class="header" href="#accountid">AccountID</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>type AccountId = String;
<span class="boring">}
</span></code></pre></pre>
<h3 id="peermessage"><a class="header" href="#peermessage">PeerMessage</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>enum PeerMessage {
    Handshake(Handshake),
    HandshakeFailure(PeerInfo, HandshakeFailureReason),
    /// When a failed nonce is used by some peer, this message is sent back as evidence.
    LastEdge(Edge),
    /// Contains accounts and edge information.
    Sync(SyncData),
    RequestUpdateNonce(EdgeInfo),
    ResponseUpdateNonce(Edge),
    PeersRequest,
    PeersResponse(Vec&lt;PeerInfo&gt;),
    BlockHeadersRequest(Vec&lt;CryptoHash&gt;),
    BlockHeaders(Vec&lt;BlockHeader&gt;),
    BlockRequest(CryptoHash),
    Block(Block),
    Transaction(SignedTransaction),
    Routed(RoutedMessage),
    /// Gracefully disconnect from other peer.
    Disconnect,
    Challenge(Challenge),
}
<span class="boring">}
</span></code></pre></pre>
<h3 id="announceaccount"><a class="header" href="#announceaccount">AnnounceAccount</a></h3>
<p>Each peer should announce its account</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct AnnounceAccount {
    /// AccountId to be announced.
    account_id: AccountId,
    /// PeerId from the owner of the account.
    peer_id: PeerId,
    /// This announcement is only valid for this `epoch`.
    epoch_id: EpochId,
    /// Signature using AccountId associated secret key.
    signature: Signature,
}
<span class="boring">}
</span></code></pre></pre>
<h3 id="handshake"><a class="header" href="#handshake">Handshake</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct Handshake {
    /// Protocol version.
    pub version: u32,
    /// Oldest supported protocol version.
    pub oldest_supported_version: u32,
    /// Sender's peer id.
    pub peer_id: PeerId,
    /// Receiver's peer id.
    pub target_peer_id: PeerId,
    /// Sender's listening addr.
    pub listen_port: Option&lt;u16&gt;,
    /// Peer's chain information.
    pub chain_info: PeerChainInfoV2,
    /// Info for new edge.
    pub edge_info: EdgeInfo,
}
<span class="boring">}
</span></code></pre></pre>
<!-- TODO: Make diagram about handshake process, since it is very complex -->
<h3 id="edge-1"><a class="header" href="#edge-1">Edge</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct Edge {
    /// Since edges are not directed `peer0 &lt; peer1` should hold.
    peer0: PeerId,
    peer1: PeerId,
    /// Nonce to keep tracking of the last update on this edge.
    nonce: u64,
    /// Signature from parties validating the edge. These are signature of the added edge.
    signature0: Signature,
    signature1: Signature,
    /// Info necessary to declare an edge as removed.
    /// The bool says which party is removing the edge: false for Peer0, true for Peer1
    /// The signature from the party removing the edge.
    removal_info: Option&lt;(bool, Signature)&gt;,
}
<span class="boring">}
</span></code></pre></pre>
<h3 id="edgeinfo"><a class="header" href="#edgeinfo">EdgeInfo</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct EdgeInfo {
    nonce: u64,
    signature: Signature,
}
<span class="boring">}
</span></code></pre></pre>
<h3 id="routedmessage"><a class="header" href="#routedmessage">RoutedMessage</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct RoutedMessage {
    /// Peer id which is directed this message.
    /// If `target` is hash, this a message should be routed back.
    target: PeerIdOrHash,
    /// Original sender of this message
    author: PeerId,
    /// Signature from the author of the message. If this signature is invalid we should ban
    /// last sender of this message. If the message is invalid we should ben author of the message.
    signature: Signature,
    /// Time to live for this message. After passing through some hop this number should be
    /// decreased by 1. If this number is 0, drop this message.
    ttl: u8,
    /// Message
    body: RoutedMessageBody,
}
<span class="boring">}
</span></code></pre></pre>
<h3 id="routedmessagebody"><a class="header" href="#routedmessagebody">RoutedMessageBody</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>enum RoutedMessageBody {
    BlockApproval(Approval),
    ForwardTx(SignedTransaction),

    TxStatusRequest(AccountId, CryptoHash),
    TxStatusResponse(FinalExecutionOutcomeView),
    QueryRequest {
        query_id: String,
        block_id_or_finality: BlockIdOrFinality,
        request: QueryRequest,
    },
    QueryResponse {
        query_id: String,
        response: Result&lt;QueryResponse, String&gt;,
    },
    ReceiptOutcomeRequest(CryptoHash),
    ReceiptOutComeResponse(ExecutionOutcomeWithIdAndProof),
    StateRequestHeader(ShardId, CryptoHash),
    StateRequestPart(ShardId, CryptoHash, u64),
    StateResponse(StateResponseInfo),
    PartialEncodedChunkRequest(PartialEncodedChunkRequestMsg),
    PartialEncodedChunkResponse(PartialEncodedChunkResponseMsg),
    PartialEncodedChunk(PartialEncodedChunk),
    Ping(Ping),
    Pong(Pong),
}
<span class="boring">}
</span></code></pre></pre>
<h2 id="cryptohash"><a class="header" href="#cryptohash">CryptoHash</a></h2>
<p><code>CryptoHash</code> are objects with 256 bits of information.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct Digest(pub [u8; 32]);

pub struct CryptoHash(pub Digest);
<span class="boring">}
</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="routing-table-exchange-algorithm"><a class="header" href="#routing-table-exchange-algorithm">Routing table exchange algorithm</a></h1>
<!-- cspell:ignore neps -->
<ul>
<li>Proposal Name: New routing table exchange algorithm</li>
<li>Start Date: 6/21/2021</li>
<li>NEP PR: <a href="https://github.com/near/nearcore/pull/4112"><code>nearprotocol/neps#0000</code></a></li>
<li>Issue(s): https://github.com/near/nearcore/issues/3838.</li>
<li><a href="https://github.com/near/NEPs/pull/220">GitHub PR</a></li>
</ul>
<h1 id="summary"><a class="header" href="#summary">Summary</a></h1>
<p>Currently, every node on the network stores its own copy of the <a href="NetworkSpec/./NetworkSpec.html#routing-table">Routing Graph</a>.
The process of exchanging and verifying edges requires sending full copy of routing table on every synchronization.
Sending full copy of routing table is wasteful, in this spec we propose a solution, which allows doing partial  synchronization.
This should reduce both bandwidth used, and amount of CPU time.</p>
<p>Typically, only one full sync would be required when a node connects to the network for the first time.
For given two nodes doing synchronization, we propose a method, which requires bandwidth/processing time proportional to the size of data which needs to be exchanged for given nodes.</p>
<h1 id="algorithm"><a class="header" href="#algorithm">Algorithm</a></h1>
<p>In this spec we describe the implementation of <code>Routing Graph Reconciliation</code> algorithm using Inverse Bloom Filters.
An overview of different <code>Routing Graph Reconciliation</code> algorithms can be a found at
<a href="https://github.com/pmnoxx/docs/blob/piotr-test-markdown/near/ROUTING_GRAPH_RECONCILIATION.pdf">ROUTING_GRAPH_RECONCILIATION.pdf</a></p>
<p>The process of exchanging <code>routing tables</code> involves exchanging edges between a pair of nodes.
For given nodes <code>A</code>, <code>B</code>, that involves adding edges which <code>A</code> has, but <code>B</code> doesn't and vice-versa.
For each connection we create a data structure <a href="NetworkSpec/RoutingTableExchangeAlgorithm.html#ibfset">IbfSet</a>.
It stores <code>Inverse Bloom Filters</code> <a href="NetworkSpec/RoutingTableExchangeAlgorithm.html#ibf">Ibf</a> of powers of <code>2^k</code> for <code>k</code> in range <code>10..17</code>.
This allows us to recover around <code>2^17 / 1.3</code> edges with <code>99%</code> probability according to <a href="https://www.ics.uci.edu/%7Eeppstein/pubs/EppGooUye-SIGCOMM-11.pdf">Efficient Set Reconciliation without Prior Context</a>.
Otherwise, we do full routing table exchange.</p>
<p>We have chosen a minimum size of <code>Ibf</code> to be <code>2^10</code>, because the overhead of processing <code>IBF</code> of smaller size of negligible, and to reduce the number of messages required in exchange.
On the other side, we limit <code>Ibf</code> to size of <code>2^17</code> to reduce memory usage required for each data structure.</p>
<h1 id="routing-table-1"><a class="header" href="#routing-table-1">Routing Table</a></h1>
<p>We are extending [Routing Table](NetworkSpec.md#Routing Table) by additional field <code>peer_ibf_set</code></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct RoutingTable {
   /// Other fields
   ///    ..
   /// Data structure used for exchanging routing tables.
   pub peer_ibf_set: IbfPeerSet,
}
<span class="boring">}
</span></code></pre></pre>
<ul>
<li><code>peer_ibf_set</code> - a helper data structure, which allows doing partial synchronization.</li>
</ul>
<h1 id="ibfpeerset"><a class="header" href="#ibfpeerset">IbfPeerSet</a></h1>
<p><code>IbfPeerSet</code> contains a mapping between <code>PeerId</code> and <code>IbfSet</code>.
It's used to store metadata for each peer, which can be used to compute set difference between routing tables of current peer and peer contained in the mapping.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct SimpleEdge {
  pub key: (PeerId, PeerId),
  pub nonce: u64,
}

pub struct IbfPeerSet {
    peer2seed: HashMap&lt;PeerId, u64&gt;,
    unused_seeds: Vec&lt;u64&gt;,
    seed2ibf: HashMap&lt;u64, IbfSet&lt;SimpleEdge&gt;&gt;,
    slot_map: SlotMap,
    edges: u64,
}
<span class="boring">}
</span></code></pre></pre>
<ul>
<li><code>peer2seed</code> - contains a mapping from <code>PeerId</code> to <code>seed</code> used to generate <code>IbfSet</code></li>
<li><code>unused_seeds</code> - list of currently unused seeds, which will be used for new incoming connections</li>
<li><code>seed2ibf</code> - contains a mapping from <code>seed</code> to <code>IbfSet</code></li>
<li><code>slot_map</code> - a helper data structure, which is used to store <code>Edges</code>, this allows us to save memory by not storing
duplicates.</li>
<li><code>edges</code> - total number of edges in the data structure</li>
</ul>
<h1 id="messages-3"><a class="header" href="#messages-3">Messages</a></h1>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct RoutingSyncV2 {
    pub version: u64,
    pub known_edges: u64,
    pub ibf_level: u64,
    pub ibf: Vec&lt;IbfElem&gt;,
    pub request_all_edges: bool,
    pub seed: u64,
    pub edges: Vec&lt;Edge&gt;,
    pub requested_edges: Vec&lt;u64&gt;,
    pub done: bool,
}
<span class="boring">}
</span></code></pre></pre>
<ul>
<li><code>version</code> - version of routing table, currently 0, for future use</li>
<li><code>known_edges</code> - number of edges peer knows about, this allows us to decide whenever to request all edges
immediately or not.</li>
<li><code>ibf_level</code> - level of inverse bloom filter requested from <code>10</code> to <code>17</code>.</li>
<li><code>request_all_edges</code> - true if peer decides to request all edges from other peer</li>
<li><code>seed</code> - seed used to generate ibf</li>
<li><code>edges</code> - list of edges send to the other peer</li>
<li><code>requested_edges</code> - list of hashes of edges peer want to get</li>
<li><code>done</code> - true if it's the last message in synchronization</li>
</ul>
<h2 id="ibfset"><a class="header" href="#ibfset">IbfSet</a></h2>
<p>Structure used to represent set of <code>Inverse Bloom Filters</code> for given peer.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct IbfSet&lt;T: Hash + Clone&gt; {
    seed: u64,
    ibf: Vec&lt;Ibf&gt;,
    h2e: HashMap&lt;u64, SlotMapId&gt;,
    hasher: DefaultHasher,
    pd: PhantomData&lt;T&gt;,
}
<span class="boring">}
</span></code></pre></pre>
<ul>
<li><code>seed</code> - seed used to generate IbfSet</li>
<li><code>ibf</code> - list of <code>Inverse Bloom Filters</code> with sizes from <code>10</code> to <code>17</code>.</li>
<li><code>h2e</code> - mapping from hash of given edge to id of the edge. This is used to save memory, to avoid storing multiple
copies of given edge.</li>
<li><code>hasher</code> - hashing function</li>
</ul>
<h2 id="ibf"><a class="header" href="#ibf">Ibf</a></h2>
<p>Structure representing Reverse Bloom Filter.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct Ibf {
    k: i32,
    pub data: Vec&lt;IbfElem&gt;,
    hasher: IbfHasher,
    pub seed: u64,
}
<span class="boring">}
</span></code></pre></pre>
<ul>
<li><code>k</code> - number of elements in vector</li>
<li><code>data</code> - vector of elements of bloom filter</li>
<li><code>seed</code> - seed of each inverse bloom filter</li>
<li><code>hasher</code> - hashing function</li>
</ul>
<h2 id="ibfelem"><a class="header" href="#ibfelem">IbfElem</a></h2>
<p>Element of bloom filter</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct IbfElem {
    xor_elem: u64,
    xor_hash: u64,
}
<span class="boring">}
</span></code></pre></pre>
<ul>
<li><code>xor_element</code> - xor of hashes of edges stored in given box</li>
<li><code>xor_hash</code> - xor of hashes of hashes of edges stored in give n box</li>
</ul>
<h2 id="routing-table-exchange"><a class="header" href="#routing-table-exchange">Routing table exchange</a></h2>
<p>The process of exchanging routing tables involves multiple steps.
It could be reduced if needed by adding an estimator of how many edges differ, but it's not implemented for sake of simplicity.</p>
<h2 id="step-1"><a class="header" href="#step-1">Step 1</a></h2>
<p>Peer <code>A</code> connects to peer <code>B</code>.</p>
<h2 id="step-2"><a class="header" href="#step-2">Step 2</a></h2>
<p>Peer <code>B</code> chooses unique <code>seed</code>, and generates <code>IbfPeerSet</code> based on seed and all known edges in
[Routing Table](NetworkSpec.md#Routing Table).</p>
<h2 id="step-3---10"><a class="header" href="#step-3---10">Step 3 - 10</a></h2>
<p>On odd steps peer <code>B</code> sends message to peer <code>A</code>, with Ibf of size <code>2^(step+7)</code>.
On even steps, peer <code>A</code> does it.</p>
<ul>
<li>Case 1 - if we were unable to find all edges we continue to the next step.</li>
<li>Case 2 - otherwise, we know what the set difference is.
We compute the set of hashes of edges given node knows about, and doesn't know about.
Current peer sends to the other peer the edges it knows about, and asks about edges, based on hashes, it doesn't know about the other peer.
The other peer sends the response, and the routing table exchange ends.</li>
</ul>
<h2 id="step-11"><a class="header" href="#step-11">Step 11</a></h2>
<p>In case the synchronization isn't done yet, each side sends list of hashes of edges it knows about.</p>
<h2 id="step-12"><a class="header" href="#step-12">Step 12</a></h2>
<p>Each side sends list of edges the other side requested.</p>
<h1 id="security-considerations"><a class="header" href="#security-considerations">Security considerations</a></h1>
<h3 id="avoid-extra-computation-if-another-peer-reconnects-to-server"><a class="header" href="#avoid-extra-computation-if-another-peer-reconnects-to-server">Avoid extra computation if another peer reconnects to server</a></h3>
<p>In order to avoid extra computation whenever a peer reconnects to server, we can keep a pool of <code>IbfPeerSet</code> structures.
The number of such structures which we need to keep is going to be equal to the peak number of incoming connections, which servers have had plus the number of outgoing connections.</p>
<h3 id="producing-edges-where-there-is-a-hash-collision"><a class="header" href="#producing-edges-where-there-is-a-hash-collision">Producing edges, where there is a hash collision</a></h3>
<p>We use unique <code>IbfPeerSet</code> structure, for each connection, this prevents seeds to be guessed.
Therefore, we are resistant to that type of attack.</p>
<h1 id="memory-overhead"><a class="header" href="#memory-overhead">Memory overhead</a></h1>
<p>For each connection we need to use approximately <code>(2^10 + ... 2^17) * sizeof(IbfElem) bytes = 2^18 * 16 bytes = 4 MiB</code>.
Assuming we keep extra <code>40</code> of such data structures, we would need extra <code>160 MiB</code>.</p>
<h1 id="performance-overhead"><a class="header" href="#performance-overhead">Performance overhead</a></h1>
<p>On each update we need up update each <code>IbfSet</code> structure <code>3*8 = 24</code> times.
Assuming we keep <code>40</code> such data structures, that requires up to <code>960</code> updates.</p>
<h1 id="alternative-approaches"><a class="header" href="#alternative-approaches">Alternative approaches</a></h1>
<h3 id="only-use-one-ibfpeerset-structure-for-everyone"><a class="header" href="#only-use-one-ibfpeerset-structure-for-everyone">Only use one <code>IbfPeerSet</code> structure for everyone</a></h3>
<p>This would reduce number of updates we need to do, and memory usage.
However, it would be possible to guess the hash function used, which would expose us to security vulnerability.
It would be simple to produce two edges, such that there is a hash collision, which would cause routing table exchange to fail.</p>
<h3 id="increase-number-of-ibfset-structures-per-ibfpeerset"><a class="header" href="#increase-number-of-ibfset-structures-per-ibfpeerset">Increase number of <code>IbfSet</code> structures per <code>IbfPeerSet</code></a></h3>
<p>In theory, we could increase the sizes of <code>IBF</code> structures used from <code>2^10..2^17</code> to <code>2^10..2^20</code>.
This would allow us to recover the set difference if it's up to <code>2^20/3</code> instead of <code>2^17/3</code> at cost of increasing memory overhead from <code>160 MiB to 640 Mib</code>.</p>
<h3 id="simplify-algorithm-to-only-exchange-list-of-hashes-of-known-edges-of-each-peer"><a class="header" href="#simplify-algorithm-to-only-exchange-list-of-hashes-of-known-edges-of-each-peer">Simplify algorithm to only exchange list of hashes of known edges of each peer</a></h3>
<p>Each edge has a size of about 400 bytes.
Let's assume we need to send 1 million edges.
By sending list of 4 bytes hashes of all known edges on each synchronization we would only need to send <code>4 MiB</code> of metadata plus the size of edges that differ.
This approach would be simpler, but not as efficient in terms of bandwidth.
That would still be an improvement of having to send just <code>4 MiB</code> over <code>400 MiB</code> with existing implementation.</p>
<h1 id="future-improvements"><a class="header" href="#future-improvements">Future improvements</a></h1>
<h2 id="reduce-memory-usage"><a class="header" href="#reduce-memory-usage">Reduce memory usage</a></h2>
<h3 id="used-a-fixed-number-of-ibfpeerset-structures-for-each-node-theoretically-smaller-number-of-sets-could-be-used-for-example-10-this-would-require-estimating-how-likely-it-is-to-produce-edges-such-that-they-produce-collisions"><a class="header" href="#used-a-fixed-number-of-ibfpeerset-structures-for-each-node-theoretically-smaller-number-of-sets-could-be-used-for-example-10-this-would-require-estimating-how-likely-it-is-to-produce-edges-such-that-they-produce-collisions">Used a fixed number of <code>IbfPeerSet</code> structures for each node Theoretically, smaller number of sets could be used. For example 10, this would require estimating how likely it is to produce edges such that they produce collisions</a></h3>
<p>It may be still possible to generate offline such set of edges that can cause recovery of edges from <code>IBF</code> to fail for one node.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="overview-2"><a class="header" href="#overview-2">Overview</a></h1>
<p>This chapter covers the NEAR Protocol runtime specification.</p>
<h3 id="runtime-specification"><a class="header" href="#runtime-specification">Runtime Specification</a></h3>
<ul>
<li><a href="RuntimeSpec/./AccountStorage.html">Account Receipt Storage</a></li>
<li><a href="RuntimeSpec/./Actions.html">Actions</a></li>
<li><a href="RuntimeSpec/./ApplyingChunk.html">Applying chunk</a></li>
<li><a href="RuntimeSpec/./Components/Components.html">Components</a>
<ul>
<li><a href="RuntimeSpec/./Components/RuntimeCrate.html">Runtime Crate</a></li>
<li><a href="RuntimeSpec/./Components/BindingsSpec/BindingsSpec.html">Bindings Specification</a>
<ul>
<li><a href="RuntimeSpec/./Components/BindingsSpec/ContextAPI.html">Context API</a></li>
<li><a href="RuntimeSpec/./Components/BindingsSpec/EconomicsAPI.html">Economics API</a></li>
<li><a href="RuntimeSpec/./Components/BindingsSpec/MathAPI.html">Math API</a></li>
<li><a href="RuntimeSpec/./Components/BindingsSpec/MiscellaneousAPI.html">Miscellaneous API</a></li>
<li><a href="RuntimeSpec/./Components/BindingsSpec/PromisesAPI.html">Promises API</a></li>
<li><a href="RuntimeSpec/./Components/BindingsSpec/RegistersAPI.html">Registers API</a></li>
<li><a href="RuntimeSpec/./Components/BindingsSpec/TrieAPI.html">Trie API</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="RuntimeSpec/./Fees/Fees.html">Fees</a></li>
<li><a href="RuntimeSpec/./FunctionCall.html">Function Call</a></li>
<li><a href="RuntimeSpec/./Preparation.html">Contract Preparation</a></li>
<li><a href="RuntimeSpec/./Receipts.html">Receipts</a></li>
<li><a href="RuntimeSpec/./Refunds.html">Refunds</a></li>
<li><a href="RuntimeSpec/./Runtime.html">Runtime</a></li>
<li><a href="RuntimeSpec/./Transactions.html">Transactions</a></li>
<li><a href="RuntimeSpec/./Scenarios/Scenarios.html">Scenarios</a>
<ul>
<li><a href="RuntimeSpec/./Scenarios/CrossContractCall.html">Cross-ContractCall</a></li>
<li><a href="RuntimeSpec/./Scenarios/FinancialTransaction.html">Financial Transaction</a></li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="account-receipt-storage"><a class="header" href="#account-receipt-storage">Account Receipt Storage</a></h1>
<p>There is a definition of all the keys and values we store in the Account Storage</p>
<h2 id="received-data"><a class="header" href="#received-data">Received data</a></h2>
<p><em>key = <code>receiver_id: String</code>,<code>data_id: CryptoHash</code></em>
<em>value = <code>Option&lt;Vec&lt;u8&gt;&gt;</code></em></p>
<p>Runtime saves incoming data from <a href="RuntimeSpec/Receipts.html#data">DataReceipt</a> until every <a href="RuntimeSpec/Receipts.html#input_data_ids">input_data_ids</a> in <a href="RuntimeSpec/AccountStorage.html#postponed-receipts">postponed receipt</a> <a href="RuntimeSpec/Receipts.html#actionreceipt">ActionReceipt</a> for <code>receiver_id</code> account is satisfied.</p>
<h2 id="postponed-receipts"><a class="header" href="#postponed-receipts">Postponed receipts</a></h2>
<p>For each awaited <code>DataReceipt</code> we store</p>
<p><em>key = <code>receiver_id</code>,<code>data_id</code></em>
<em>value = <code>receipt_id</code></em></p>
<p>Runtime saves incoming <a href="RuntimeSpec/Receipts.html#actionreceipt">ActionReceipt</a> until all ``</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="actions"><a class="header" href="#actions">Actions</a></h1>
<p>There are a several action types in Near:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum Action {
    CreateAccount(CreateAccountAction),
    DeployContract(DeployContractAction),
    FunctionCall(FunctionCallAction),
    Transfer(TransferAction),
    Stake(StakeAction),
    AddKey(AddKeyAction),
    DeleteKey(DeleteKeyAction),
    DeleteAccount(DeleteAccountAction),
    Delegate(SignedDelegateAction),
}
<span class="boring">}
</span></code></pre></pre>
<p>Each transaction consists a list of actions to be performed on the <code>receiver_id</code> side. Since transactions are first
converted to receipts when they are processed, we will mostly concern ourselves with actions in the context of receipt
processing.</p>
<p>For the following actions, <code>predecessor_id</code> and <code>receiver_id</code> are required to be equal:</p>
<ul>
<li><code>DeployContract</code></li>
<li><code>Stake</code></li>
<li><code>AddKey</code></li>
<li><code>DeleteKey</code></li>
<li><code>DeleteAccount</code></li>
</ul>
<p>NOTE: if the first action in the action list is <code>CreateAccount</code>, <code>predecessor_id</code> becomes <code>receiver_id</code>
for the rest of the actions until <code>DeleteAccount</code>. This gives permission by another account to act on the newly created account.</p>
<h2 id="createaccountaction"><a class="header" href="#createaccountaction">CreateAccountAction</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct CreateAccountAction {}
<span class="boring">}
</span></code></pre></pre>
<p>If <code>receiver_id</code> has length == 64, this account id is considered to be <code>hex(public_key)</code>, meaning creation of account only succeeds if followed up with <code>AddKey(public_key)</code> action.</p>
<p><strong>Outcome</strong>:</p>
<ul>
<li>creates an account with <code>id</code> = <code>receiver_id</code></li>
<li>sets Account <code>storage_usage</code> to <code>account_cost</code> (genesis config)</li>
</ul>
<h3 id="errors"><a class="header" href="#errors">Errors</a></h3>
<p><strong>Execution Error</strong>:</p>
<ul>
<li>If the action tries to create a top level account whose length is no greater than 32 characters, and <code>predecessor_id</code> is not
<code>registrar_account_id</code>, which is defined by the protocol, the following error will be returned</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// A top-level account ID can only be created by registrar.
CreateAccountOnlyByRegistrar {
    account_id: AccountId,
    registrar_account_id: AccountId,
    predecessor_id: AccountId,
}
<span class="boring">}
</span></code></pre></pre>
<ul>
<li>If the action tries to create an account that is neither a top-level account or a subaccount of <code>predecessor_id</code>,
the following error will be returned</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// A newly created account must be under a namespace of the creator account
CreateAccountNotAllowed { account_id: AccountId, predecessor_id: AccountId },
<span class="boring">}
</span></code></pre></pre>
<h2 id="deploycontractaction"><a class="header" href="#deploycontractaction">DeployContractAction</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct DeployContractAction {
    pub code: Vec&lt;u8&gt;
}
<span class="boring">}
</span></code></pre></pre>
<p><strong>Outcome</strong>:</p>
<ul>
<li>sets the contract code for account</li>
</ul>
<h3 id="errors-1"><a class="header" href="#errors-1">Errors</a></h3>
<p><strong>Validation Error</strong>:</p>
<ul>
<li>if the length of <code>code</code> exceeds <code>max_contract_size</code>, which is a genesis parameter, the following error will be returned:</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// The size of the contract code exceeded the limit in a DeployContract action.
ContractSizeExceeded { size: u64, limit: u64 },
<span class="boring">}
</span></code></pre></pre>
<p><strong>Execution Error</strong>:</p>
<ul>
<li>If state or storage is corrupted, it may return <code>StorageError</code>.</li>
</ul>
<h2 id="functioncallaction"><a class="header" href="#functioncallaction">FunctionCallAction</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct FunctionCallAction {
    /// Name of exported Wasm function
    pub method_name: String,
    /// Serialized arguments
    pub args: Vec&lt;u8&gt;,
    /// Prepaid gas (gas_limit) for a function call
    pub gas: Gas,
    /// Amount of tokens to transfer to a receiver_id
    pub deposit: Balance,
}
<span class="boring">}
</span></code></pre></pre>
<p>Calls a method of a particular contract. See <a href="RuntimeSpec/./FunctionCall.html">details</a>.</p>
<h2 id="transferaction"><a class="header" href="#transferaction">TransferAction</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct TransferAction {
    /// Amount of tokens to transfer to a receiver_id
    pub deposit: Balance,
}
<span class="boring">}
</span></code></pre></pre>
<p><strong>Outcome</strong>:</p>
<ul>
<li>transfers amount specified in <code>deposit</code> from <code>predecessor_id</code> to a <code>receiver_id</code> account</li>
</ul>
<h3 id="errors-2"><a class="header" href="#errors-2">Errors</a></h3>
<p><strong>Execution Error</strong>:</p>
<ul>
<li>If the deposit amount plus the existing amount on the receiver account exceeds <code>u128::MAX</code>,
a <code>StorageInconsistentState(&quot;Account balance integer overflow&quot;)</code> error will be returned.</li>
</ul>
<h2 id="stakeaction"><a class="header" href="#stakeaction">StakeAction</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct StakeAction {
    // Amount of tokens to stake
    pub stake: Balance,
    // This public key is a public key of the validator node
    pub public_key: PublicKey,
}
<span class="boring">}
</span></code></pre></pre>
<p><strong>Outcome</strong>:</p>
<ul>
<li>A validator proposal that contains the staking public key and the staking amount is generated and will be included
in the next block.</li>
</ul>
<h3 id="errors-3"><a class="header" href="#errors-3">Errors</a></h3>
<p><strong>Validation Error</strong>:</p>
<ul>
<li>If the <code>public_key</code> is not an ristretto compatible ed25519 key, the following error will be returned:</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// An attempt to stake with a public key that is not convertible to ristretto.
UnsuitableStakingKey { public_key: PublicKey },
<span class="boring">}
</span></code></pre></pre>
<p><strong>Execution Error</strong>:</p>
<ul>
<li>If an account has not staked but it tries to unstake, the following error will be returned:</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Account is not yet staked, but tries to unstake
TriesToUnstake { account_id: AccountId },
<span class="boring">}
</span></code></pre></pre>
<ul>
<li>If an account tries to stake more than the amount of tokens it has, the following error will be returned:</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// The account doesn't have enough balance to increase the stake.
TriesToStake {
    account_id: AccountId,
    stake: Balance,
    locked: Balance,
    balance: Balance,
}
<span class="boring">}
</span></code></pre></pre>
<ul>
<li>If the staked amount is below the minimum stake threshold, the following error will be returned:</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>InsufficientStake {
    account_id: AccountId,
    stake: Balance,
    minimum_stake: Balance,
}
<span class="boring">}
</span></code></pre></pre>
<p>The minimum stake is determined by <code>last_epoch_seat_price / minimum_stake_divisor</code> where <code>last_epoch_seat_price</code> is the
seat price determined at the end of last epoch and <code>minimum_stake_divisor</code> is a genesis config parameter and its current
value is 10.</p>
<h2 id="addkeyaction"><a class="header" href="#addkeyaction">AddKeyAction</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct AddKeyAction {
    pub public_key: PublicKey,
    pub access_key: AccessKey,
}
<span class="boring">}
</span></code></pre></pre>
<p><strong>Outcome</strong>:</p>
<ul>
<li>Adds a new <a href="RuntimeSpec//DataStructures/AccessKey.html">AccessKey</a> to the receiver's account and associates it with a <code>public_key</code> provided.</li>
</ul>
<h3 id="errors-4"><a class="header" href="#errors-4">Errors</a></h3>
<p><strong>Validation Error</strong>:</p>
<p>If the access key is of type <code>FunctionCallPermission</code>, the following errors can happen</p>
<ul>
<li>If <code>receiver_id</code> in <code>access_key</code> is not a valid account id, the following error will be returned </li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Invalid account ID.
InvalidAccountId { account_id: AccountId },
<span class="boring">}
</span></code></pre></pre>
<ul>
<li>If the length of some method name exceed <code>max_length_method_name</code>, which is a genesis parameter (current value is 256),
the following error will be returned </li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// The length of some method name exceeded the limit in a Add Key action.
AddKeyMethodNameLengthExceeded { length: u64, limit: u64 },
<span class="boring">}
</span></code></pre></pre>
<ul>
<li>If the sum of length of method names (with 1 extra character for every method name) exceeds <code>max_number_bytes_method_names</code>, which is a genesis parameter (current value is 2000),
the following error will be returned</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// The total number of bytes of the method names exceeded the limit in a Add Key action.
AddKeyMethodNamesNumberOfBytesExceeded { total_number_of_bytes: u64, limit: u64 }
<span class="boring">}
</span></code></pre></pre>
<p><strong>Execution Error</strong>:</p>
<ul>
<li>If an account tries to add an access key with a given public key, but an existing access key with this public key already exists, the following error will be returned</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// The public key is already used for an existing access key
AddKeyAlreadyExists { account_id: AccountId, public_key: PublicKey }
<span class="boring">}
</span></code></pre></pre>
<ul>
<li>If state or storage is corrupted, a <code>StorageError</code> will be returned.</li>
</ul>
<h2 id="deletekeyaction"><a class="header" href="#deletekeyaction">DeleteKeyAction</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct DeleteKeyAction {
    pub public_key: PublicKey,
}
<span class="boring">}
</span></code></pre></pre>
<p><strong>Outcome</strong>:</p>
<ul>
<li>Deletes the <a href="RuntimeSpec//DataStructures/AccessKey.html">AccessKey</a> associated with <code>public_key</code>.</li>
</ul>
<h3 id="errors-5"><a class="header" href="#errors-5">Errors</a></h3>
<p><strong>Execution Error</strong>:</p>
<ul>
<li>When an account tries to delete an access key that doesn't exist, the following error is returned</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Account tries to remove an access key that doesn't exist
DeleteKeyDoesNotExist { account_id: AccountId, public_key: PublicKey }
<span class="boring">}
</span></code></pre></pre>
<ul>
<li><code>StorageError</code> is returned if state or storage is corrupted.</li>
</ul>
<h2 id="deleteaccountaction"><a class="header" href="#deleteaccountaction">DeleteAccountAction</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct DeleteAccountAction {
    /// The remaining account balance will be transferred to the AccountId below
    pub beneficiary_id: AccountId,
}
<span class="boring">}
</span></code></pre></pre>
<p><strong>Outcomes</strong>:</p>
<ul>
<li>The account, as well as all the data stored under the account, is deleted and the tokens are transferred to <code>beneficiary_id</code>.</li>
</ul>
<h3 id="errors-6"><a class="header" href="#errors-6">Errors</a></h3>
<p><strong>Validation Error</strong>:</p>
<ul>
<li>If <code>beneficiary_id</code> is not a valid account id, the following error will be returned</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Invalid account ID.
InvalidAccountId { account_id: AccountId },
<span class="boring">}
</span></code></pre></pre>
<ul>
<li>If this action is not the last action in the action list of a receipt, the following error will be returned</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// The delete action must be a final action in transaction
DeleteActionMustBeFinal
<span class="boring">}
</span></code></pre></pre>
<ul>
<li>If the account still has locked balance due to staking, the following error will be returned</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Account is staking and can not be deleted
DeleteAccountStaking { account_id: AccountId }
<span class="boring">}
</span></code></pre></pre>
<p><strong>Execution Error</strong>:</p>
<ul>
<li>If state or storage is corrupted, a <code>StorageError</code> is returned.</li>
</ul>
<h2 id="delegate-actions"><a class="header" href="#delegate-actions">Delegate Actions</a></h2>
<p>Introduced with <a href="https://github.com/near/NEPs/blob/master/neps/nep-0366.md">NEP-366</a> to enable meta transactions.</p>
<p>In summary, a delegate action is an indirect submission of a transaction.
It allows a relayer to do the payment (gas and token costs) for a transaction authored by a user.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// The struct contained in transactions and receipts, inside `Action::Delegate(_)``.
struct SignedDelegateAction {
    /// The actual action, see below.
    pub delegate_action: DelegateAction,
    /// NEP-483 proposal compliant signature
    pub signature: Signature,
}
<span class="boring">}
</span></code></pre></pre>
<p>Note that the signature follows a scheme which is proposed to be standardized in <a href="https://github.com/near/NEPs/pull/483">NEP-483</a>.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// The struct a user creates and signs to create a meta transaction.
struct DelegateAction {
    /// Signer of the delegated actions
    pub sender_id: AccountId,
    /// Receiver of the delegated actions.
    pub receiver_id: AccountId,
    /// List of actions to be executed.
    ///
    /// With the meta transactions MVP defined in NEP-366, nested
    /// DelegateActions are not allowed. A separate type is used to enforce it.
    pub actions: Vec&lt;NonDelegateAction&gt;,
    /// Nonce to ensure that the same delegate action is not sent twice by a
    /// relayer and should match for given account's `public_key`.
    /// After this action is processed it will increment.
    pub nonce: Nonce,
    /// The maximal height of the block in the blockchain below which the given DelegateAction is valid.
    pub max_block_height: BlockHeight,
    /// Public key used to sign this delegated action.
    pub public_key: PublicKey,
}
<span class="boring">}
</span></code></pre></pre>
<h3 id="outcomes"><a class="header" href="#outcomes">Outcomes</a></h3>
<ul>
<li>All actions inside <code>delegate_action.actions</code> are submitted with the <code>delegate_action.sender_id</code> as the predecessor, <code>delegate_action.receiver_id</code> as the receiver, and the relayer (predecessor of <code>DelegateAction</code>) as the signer.</li>
<li>All gas and balance costs for submitting <code>delegate_action.actions</code> are subtracted from the relayer.</li>
</ul>
<h3 id="errors-7"><a class="header" href="#errors-7">Errors</a></h3>
<p><strong>Validation Error</strong>:</p>
<ul>
<li>If the list of Transaction actions contains several <code>DelegateAction</code></li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// There should be the only one DelegateAction
DelegateActionMustBeOnlyOne
<span class="boring">}
</span></code></pre></pre>
<p><strong>Execution Error</strong>:</p>
<ul>
<li>If the Sender's account doesn't exist</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Happens when TX receiver_id doesn't exist
AccountDoesNotExist
<span class="boring">}
</span></code></pre></pre>
<ul>
<li>If the <code>signature</code> does not match the data and the <code>public_key</code> of the given key, then the following error will be returned</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Signature does not match the provided actions and given signer public key.
DelegateActionInvalidSignature
<span class="boring">}
</span></code></pre></pre>
<ul>
<li>If the <code>sender_id</code> doesn't match the <code>tx.receiver_id</code></li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Receiver of the transaction doesn't match Sender of the delegate action
DelegateActionSenderDoesNotMatchTxReceiver
<span class="boring">}
</span></code></pre></pre>
<ul>
<li>If the current block is equal or greater than <code>max_block_height</code></li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Delegate action has expired
DelegateActionExpired
<span class="boring">}
</span></code></pre></pre>
<ul>
<li>If the <code>public_key</code> does not exist for Sender account</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// The given public key doesn't exist for Sender account
DelegateActionAccessKeyError
<span class="boring">}
</span></code></pre></pre>
<ul>
<li>If the <code>nonce</code> does match the <code>public_key</code> for the <code>sender_id</code></li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Nonce must be greater sender[public_key].nonce
DelegateActionInvalidNonce
<span class="boring">}
</span></code></pre></pre>
<ul>
<li>If <code>nonce</code> is too large</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// DelegateAction nonce is larger than the upper bound given by the block height (block_height * 1e6)
DelegateActionNonceTooLarge
<span class="boring">}
</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="applying-chunk"><a class="header" href="#applying-chunk">Applying chunk</a></h1>
<h2 id="inputs-and-outputs"><a class="header" href="#inputs-and-outputs">Inputs and outputs</a></h2>
<p>Runtime.apply takes following inputs:</p>
<ul>
<li>trie and current state root</li>
<li><em>validator_accounts_update</em></li>
<li><em>incoming_receipts</em></li>
<li><em>transactions</em></li>
</ul>
<p>and produces following outputs:</p>
<ul>
<li>new state root</li>
<li><em>validator_proposals</em></li>
<li><em>outgoing_receipts</em></li>
<li>(executed receipt) <em>outcomes</em></li>
<li><em>proof</em></li>
</ul>
<h2 id="processing-order"><a class="header" href="#processing-order">Processing order</a></h2>
<ul>
<li>If this is first block of an epoch, dispense <a href="RuntimeSpec/../Economics/Economics.html#validator-rewards-calculation">epoch rewards</a> to validators (in order of <em>validator_accounts_update.stake_info</em>)</li>
<li>Slash locked balance for malicious behavior (in order of <em>validator_accounts_update.slashing_info</em>)</li>
<li>If <a href="RuntimeSpec/../Economics/Economics.html#protocol-treasury">treasury account</a> was not one of validators and this is first block of an epoch, dispense treasury account reward</li>
<li>If this is first block of new version or first block with chunk of new version, apply corresponding migrations</li>
<li>If this block do not have chunk for this shard, end process early</li>
<li>Process <a href="RuntimeSpec/Transactions.html">transactions</a> (in order of <em>transactions</em>)</li>
<li>Process local <a href="RuntimeSpec/Receipts.html">receipts</a> (in order of <em>transactions</em> that generated them)</li>
<li>Process delayed <a href="RuntimeSpec/Receipts.html">receipts</a> (ordered first by block where they were generated, then first local receipts based on order of generating <em>transactions</em>,
then incoming receipts, ordered by <em>incoming_receipts</em> order)</li>
<li>Process incoming <a href="RuntimeSpec/Receipts.html">receipts</a> (ordered by <em>incoming_receipts</em>)</li>
</ul>
<p>When processing receipts we track gas used (including gas used on migrations). If we use up gas limit, we finish processing the last receipt and stop to process delayed receipts, and for local
and incoming receipts we add them to delayed receipts.</p>
<ul>
<li>If any of the delayed receipts were processed or any new receipts were delayed, update indices of first and last unprocessed receipts in state</li>
<li>Remove duplicate validator proposals (for each account we only keep last one in receipts processing order)</li>
</ul>
<p>Please note that local receipts are receipts generated by transaction where receiver is the same as signer of the transaction</p>
<h2 id="delayed-receipts"><a class="header" href="#delayed-receipts">Delayed receipts</a></h2>
<p>In each block we have maximal amount of Gas we can use to process receipts and migrations, currently 1000 TGas. If any incoming or local receipts are not processed due to lack of remaining Gas, they are stored in state with key <pre>TrieKey::DelayedReceipt { id }</pre> where id is unique index for each shard, assigned consecutively. Currently sender does not need to stake any tokens to store delayed receipts. State also contains special key <pre>TrieKey::DelayedReceiptIndices</pre> where first and last ids of delayed receipts not yet processed are stored.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="components"><a class="header" href="#components">Components</a></h1>
<p>Here is the high-level diagram of various runtime components, including some blockchain layer components.
<img src="RuntimeSpec/Components//images/runtime_architecture.svg" alt="Runtime Architecture" /></p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="runtime-crate"><a class="header" href="#runtime-crate">Runtime crate</a></h1>
<p>Runtime crate encapsulates the logic of how transactions and receipts should be handled. If it encounters
a smart contract call within a transaction or a receipt it calls <code>near-vm-runner</code>, for all other actions, like account
creation, it processes them in-place.</p>
<h2 id="runtime-class"><a class="header" href="#runtime-class">Runtime class</a></h2>
<p>The main entry point of the <code>Runtime</code> is method <code>apply</code>.
It applies new singed transactions and incoming receipts for some chunk/shard on top of
given trie and the given state root.
If the validator accounts update is provided, updates validators accounts.
All new signed transactions should be valid and already verified by the chunk producer.
If any transaction is invalid, the method returns an <code>InvalidTxError</code>.
In case of success, the method returns <code>ApplyResult</code> that contains the new state root, trie changes,
new outgoing receipts, stats for validators (e.g. total rent paid by all the affected accounts),
execution outcomes.</p>
<h3 id="apply-arguments"><a class="header" href="#apply-arguments">Apply arguments</a></h3>
<p>It takes the following arguments:</p>
<ul>
<li><code>trie: Arc&lt;Trie&gt;</code> - the trie that contains the latest state.</li>
<li><code>root: CryptoHash</code> - the hash of the state root in the trie.</li>
<li><code>validator_accounts_update: &amp;Option&lt;ValidatorAccountsUpdate&gt;</code> - optional field that contains updates for validator accounts.
It's provided at the beginning of the epoch or when someone is slashed.</li>
<li><code>apply_state: &amp;ApplyState</code> - contains block index and timestamp, epoch length, gas price and gas limit.</li>
<li><code>prev_receipts: &amp;[Receipt]</code> - the list of incoming receipts, from the previous block.</li>
<li><code>transactions: &amp;[SignedTransaction]</code> - the list of new signed transactions.</li>
</ul>
<h3 id="apply-logic"><a class="header" href="#apply-logic">Apply logic</a></h3>
<p>The execution consists of the following stages:</p>
<ol>
<li>Snapshot the initial state.</li>
<li>Apply validator accounts update, if available.</li>
<li>Convert new signed transactions into the receipts.</li>
<li>Process receipts.</li>
<li>Check that incoming and outgoing balances match.</li>
<li>Finalize trie update.</li>
<li>Return <code>ApplyResult</code>.</li>
</ol>
<h2 id="validator-accounts-update"><a class="header" href="#validator-accounts-update">Validator accounts update</a></h2>
<p>Validator accounts are accounts that staked some tokens to become a validator.
The validator accounts update usually happens when the current chunk is the first chunk of the epoch.
It also happens when there is a challenge in the current block with one of the participants belong to the current shard.</p>
<p>This update distributes validator rewards, return locked tokens and maybe slashes some accounts out of their stake.</p>
<h2 id="signed-transaction-conversion"><a class="header" href="#signed-transaction-conversion">Signed Transaction conversion</a></h2>
<p>New signed transaction transactions are provided by the chunk producer in the chunk. These transactions should be ordered and already validated.
Runtime does validation again for the following reasons:</p>
<ul>
<li>to charge accounts for transactions fees, transfer balances, prepaid gas and account rents;</li>
<li>to create new receipts;</li>
<li>to compute burnt gas;</li>
<li>to validate transactions again, in case the chunk producer was malicious.</li>
</ul>
<p>If the transaction has the same <code>signer_id</code> and <code>receiver_id</code>, then the new receipt is added to the list of new local receipts,
otherwise it's added to the list of new outgoing receipts.</p>
<h2 id="receipt-processing"><a class="header" href="#receipt-processing">Receipt processing</a></h2>
<p>Receipts are processed one by one in the following order:</p>
<ol>
<li>Previously delayed receipts from the state.</li>
<li>New local receipts.</li>
<li>New incoming receipts.</li>
</ol>
<p>After each processed receipt, we compare total gas burnt (so far) with the gas limit.
When the total gas burnt reaches or exceeds the gas limit, the processing stops.
The remaining receipts are considered delayed and stored into the state.</p>
<h3 id="delayed-receipts-1"><a class="header" href="#delayed-receipts-1">Delayed receipts</a></h3>
<p>Delayed receipts are stored as a persistent queue in the state.
Initially, the first unprocessed index and the next available index are initialized to 0.
When a new delayed receipt is added, it's written under the next available index in to the state and the next available index is incremented by 1.
When a delayed receipt is processed, it's read from the state using the first unprocessed index and the first unprocessed index is incremented.
At the end of the receipt processing, the all remaining local and incoming receipts are considered to be delayed and stored to the state in their respective order.
If during receipt processing, we've changed indices, then the delayed receipt indices are stored to the state as well.</p>
<h3 id="receipt-processing-algorithm"><a class="header" href="#receipt-processing-algorithm">Receipt processing algorithm</a></h3>
<p>The receipt processing algorithm is the following:</p>
<ol>
<li>Read indices from the state or initialize with zeros.</li>
<li>While the first unprocessed index is less than the next available index do the following
<ol>
<li>If the total burnt gas is at least the gas limit, break.</li>
<li>Read the receipt from the first unprocessed index.</li>
<li>Remove the receipt from the state.</li>
<li>Increment the first unprocessed index.</li>
<li>Process the receipt.</li>
<li>Add the new burnt gas to the total burnt gas.</li>
<li>Remember that the delayed queue indices has changed.</li>
</ol>
</li>
<li>Process the new local receipts and then the new incoming receipts
<ul>
<li>If the total burnt gas is less then the gas limit:
<ol>
<li>Process the receipt.</li>
<li>Add the new burnt gas to the total burnt gas.</li>
</ol>
</li>
<li>Else:
<ol>
<li>Store the receipt under the next available index.</li>
<li>Increment the next available index.</li>
<li>Remember that the delayed queue indices has changed.</li>
</ol>
</li>
</ul>
</li>
<li>If the delayed queue indices has changed, store the new indices to the state.</li>
</ol>
<h2 id="balance-checker"><a class="header" href="#balance-checker">Balance checker</a></h2>
<p>Balance checker computes the total incoming balance and the total outgoing balance.</p>
<p>The total incoming balance consists of the following:</p>
<ul>
<li>Incoming validator rewards from validator accounts update.</li>
<li>Sum of the initial accounts balances for all affected accounts. We compute it using the snapshot of the initial state.</li>
<li>Incoming receipts balances. The prepaid fees and gas multiplied their gas prices with the attached balances from transfers and function calls.
Refunds are considered to be free of charge for fees, but still has attached deposits.</li>
<li>Balances for the processed delayed receipts.</li>
<li>Initial balances for the postponed receipts. Postponed receipts are receipts from the previous blocks that were processed, but were not executed.
They are action receipts with some expected incoming data. Usually for a callback on top of awaited promise.
When the expected data arrives later than the action receipt, then the action receipt is postponed.
Note, the data receipts are 0 cost, because they are completely prepaid when issued.</li>
</ul>
<p>The total outgoing balance consists of the following:</p>
<ul>
<li>Sum of the final accounts balance for all affected accounts.</li>
<li>Outgoing receipts balances.</li>
<li>New delayed receipts. Local and incoming receipts that were not processed this time.</li>
<li>Final balances for the postponed receipts.</li>
<li>Total rent paid by all affected accounts.</li>
<li>Total new validator rewards. It's computed from total gas burnt rewards.</li>
<li>Total balance burnt. In case the balance is burnt for some reason (e.g. account was deleted during the refund), it's accounted there.</li>
<li>Total balance slashed. In case a validator is slashed for some reason, the balance is account here.</li>
</ul>
<p>When you sum up incoming balances and outgoing balances, they should match.
If they don't match, we throw an error.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="bindings-specification"><a class="header" href="#bindings-specification">Bindings Specification</a></h1>
<p>This is the low-level interface available to the smart contracts, it consists of the functions that the host (represented by
Wasmer inside near-vm-runner) exposes to the guest (the smart contract compiled to Wasm).</p>
<p>Due to Wasm restrictions the methods operate only with primitive types, like <code>u64</code>.</p>
<p>Also for all functions in the bindings specification the following is true:</p>
<ul>
<li>Method execution could result in <code>MemoryAccessViolation</code> error if one of the following happens:
<ul>
<li>The method causes host to read a piece of memory from the guest but it points outside the guest's memory;</li>
<li>The guest causes host to read from the register, but register id is invalid.</li>
</ul>
</li>
</ul>
<p>Execution of a bindings function call result in an error being generated. This error causes execution of the smart contract
to be terminated and the error message written into the logs of the transaction that caused the execution. Many bindings
functions can throw specialized error messages, but there is also a list of error messages that can be thrown by almost
any function:</p>
<ul>
<li><code>IntegerOverflow</code> -- happens when guest passes some data to the host but when host tries to apply arithmetic operation
on it it causes overflow or underflow;</li>
<li><code>GasExceeded</code> -- happens when operation performed by the guest causes more gas than the remaining prepaid gas;</li>
<li><code>GasLimitExceeded</code> -- happens when the execution uses more gas than allowed by the global limit imposed in the economics
config;</li>
<li><code>StorageError</code> -- happens when method fails to do some operation on the trie.</li>
</ul>
<p>The following binding methods cannot be invoked in a view call:</p>
<ul>
<li><code>signer_account_id</code></li>
<li><code>signer_account_pk</code></li>
<li><code>predecessor_account_id</code></li>
<li><code>attached_deposit</code></li>
<li><code>prepaid_gas</code></li>
<li><code>used_gas</code></li>
<li><code>promise_create</code></li>
<li><code>promise_then</code></li>
<li><code>promise_and</code></li>
<li><code>promise_batch_create</code></li>
<li><code>promise_batch_then</code></li>
<li><code>promise_batch_action_create_account</code></li>
<li><code>promise_batch_action_deploy_account</code></li>
<li><code>promise_batch_action_function_call</code></li>
<li><code>promise_batch_action_transfer</code></li>
<li><code>promise_batch_action_stake</code></li>
<li><code>promise_batch_action_add_key_with_full_access</code></li>
<li><code>promise_batch_action_add_key_with_function_call</code></li>
<li><code>promise_batch_action_delete_key</code></li>
<li><code>promise_batch_action_delete_account</code></li>
<li><code>promise_results_count</code></li>
<li><code>promise_result</code></li>
<li><code>promise_return</code></li>
</ul>
<p>If they are invoked the smart contract execution will panic with <code>ProhibitedInView(&lt;method name&gt;)</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="context-api"><a class="header" href="#context-api">Context API</a></h1>
<p>Context API mostly provides read-only functions that access current information about the blockchain, the accounts
(that originally initiated the chain of cross-contract calls, the immediate contract that called the current one, the account of the current contract),
other important information like storage usage.</p>
<p>Many of the below functions are currently implemented through <code>data_read</code> which allows to read generic context data.
However, there is no reason to have <code>data_read</code> instead of the specific functions:</p>
<ul>
<li><code>data_read</code> does not solve forward compatibility. If later we want to add another context function, e.g. <code>executed_operations</code>
we can just declare it as a new function, instead of encoding it as <code>DATA_TYPE_EXECUTED_OPERATIONS = 42</code> which is passed
as the first argument to <code>data_read</code>;</li>
<li><code>data_read</code> does not help with renaming. If later we decide to rename <code>signer_account_id</code> to <code>originator_id</code> then one could
argue that contracts that rely on <code>data_read</code> would not break, while contracts relying on <code>signer_account_id()</code> would. However
the name change often means the change of the semantics, which means the contracts using this function are no longer safe to
execute anyway.</li>
</ul>
<p>However there is one reason to not have <code>data_read</code> -- it makes <code>API</code> more human-like which is a general direction Wasm APIs, like WASI are moving towards to.</p>
<hr />
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>current_account_id(register_id: u64)
<span class="boring">}
</span></code></pre></pre>
<p>Saves the account id of the current contract that we execute into the register.</p>
<h6 id="panics"><a class="header" href="#panics">Panics</a></h6>
<ul>
<li>If the registers exceed the memory limit panics with <code>MemoryAccessViolation</code>;</li>
</ul>
<hr />
<h4 id="signer_account_id"><a class="header" href="#signer_account_id">signer_account_id</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>signer_account_id(register_id: u64)
<span class="boring">}
</span></code></pre></pre>
<p>All contract calls are a result of some transaction that was signed by some account using
some access key and submitted into a memory pool (either through the wallet using RPC or by a node itself). This function returns the id of that account.</p>
<h6 id="normal-operation"><a class="header" href="#normal-operation">Normal operation</a></h6>
<ul>
<li>Saves the bytes of the signer account id into the register.</li>
</ul>
<h6 id="panics-1"><a class="header" href="#panics-1">Panics</a></h6>
<ul>
<li>If the registers exceed the memory limit panics with <code>MemoryAccessViolation</code>;</li>
<li>If called in a view function panics with <code>ProhibitedInView</code>.</li>
</ul>
<h6 id="current-bugs"><a class="header" href="#current-bugs">Current bugs</a></h6>
<ul>
<li>Currently we conflate <code>originator_id</code> and <code>sender_id</code> in our code base.</li>
</ul>
<hr />
<h4 id="signer_account_pk"><a class="header" href="#signer_account_pk">signer_account_pk</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>signer_account_pk(register_id: u64)
<span class="boring">}
</span></code></pre></pre>
<p>Saves the public key fo the access key that was used by the signer into the register.
In rare situations smart contract might want to know the exact access key that was used to send the original transaction,
e.g. to increase the allowance or manipulate with the public key.</p>
<h6 id="panics-2"><a class="header" href="#panics-2">Panics</a></h6>
<ul>
<li>If the registers exceed the memory limit panics with <code>MemoryAccessViolation</code>;</li>
<li>If called in a view function panics with <code>ProhibitedInView</code>.</li>
</ul>
<h6 id="current-bugs-1"><a class="header" href="#current-bugs-1">Current bugs</a></h6>
<ul>
<li>Not implemented.</li>
</ul>
<hr />
<h4 id="predecessor_account_id"><a class="header" href="#predecessor_account_id">predecessor_account_id</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>predecessor_account_id(register_id: u64)
<span class="boring">}
</span></code></pre></pre>
<p>All contract calls are a result of a receipt, this receipt might be created by a transaction
that does function invocation on the contract or another contract as a result of cross-contract call.</p>
<h6 id="normal-operation-1"><a class="header" href="#normal-operation-1">Normal operation</a></h6>
<ul>
<li>Saves the bytes of the predecessor account id into the register.</li>
</ul>
<h6 id="panics-3"><a class="header" href="#panics-3">Panics</a></h6>
<ul>
<li>If the registers exceed the memory limit panics with <code>MemoryAccessViolation</code>;</li>
<li>If called in a view function panics with <code>ProhibitedInView</code>.</li>
</ul>
<h6 id="current-bugs-2"><a class="header" href="#current-bugs-2">Current bugs</a></h6>
<ul>
<li>Not implemented.</li>
</ul>
<hr />
<h4 id="input-7"><a class="header" href="#input-7">input</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>input(register_id: u64)
<span class="boring">}
</span></code></pre></pre>
<p>Reads input to the contract call into the register. Input is expected to be in JSON-format.</p>
<h6 id="normal-operation-2"><a class="header" href="#normal-operation-2">Normal operation</a></h6>
<ul>
<li>If input is provided saves the bytes (potentially zero) of input into register.</li>
<li>If input is not provided does not modify the register.</li>
</ul>
<h6 id="returns"><a class="header" href="#returns">Returns</a></h6>
<ul>
<li>If input was not provided returns <code>0</code>;</li>
<li>If input was provided returns <code>1</code>; If input is zero bytes returns <code>1</code>, too.</li>
</ul>
<h6 id="panics-4"><a class="header" href="#panics-4">Panics</a></h6>
<ul>
<li>If the registers exceed the memory limit panics with <code>MemoryAccessViolation</code>;</li>
</ul>
<h6 id="current-bugs-3"><a class="header" href="#current-bugs-3">Current bugs</a></h6>
<ul>
<li>Implemented as part of <code>data_read</code>. However there is no reason to have one unified function, like <code>data_read</code> that can
be used to read all</li>
</ul>
<hr />
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>block_index() -&gt; u64
<span class="boring">}
</span></code></pre></pre>
<p>Returns the current block height from genesis.</p>
<hr />
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>block_timestamp() -&gt; u64
<span class="boring">}
</span></code></pre></pre>
<p>Returns the current block timestamp (number of non-leap-nanoseconds since January 1, 1970 0:00:00 UTC).</p>
<hr />
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>epoch_height() -&gt; u64
<span class="boring">}
</span></code></pre></pre>
<p>Returns the current epoch height from genesis.</p>
<hr />
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>storage_usage() -&gt; u64
<span class="boring">}
</span></code></pre></pre>
<p>Returns the number of bytes used by the contract if it was saved to the trie as of the
invocation. This includes:</p>
<ul>
<li>The data written with <code>storage_*</code> functions during current and previous execution;</li>
<li>The bytes needed to store the account protobuf and the access keys of the given account.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="economics-api"><a class="header" href="#economics-api">Economics API</a></h1>
<p>Accounts own certain balance; and each transaction and each receipt have certain amount of balance and prepaid gas
attached to them.
During the contract execution, the contract has access to the following <code>u128</code> values:</p>
<ul>
<li><code>account_balance</code> -- the balance attached to the given account. This includes the <code>attached_deposit</code> that was attached
to the transaction;</li>
<li><code>attached_deposit</code> -- the balance that was attached to the call that will be immediately deposited before
the contract execution starts;</li>
<li><code>prepaid_gas</code> -- the tokens attached to the call that can be used to pay for the gas;</li>
<li><code>used_gas</code> -- the gas that was already burnt during the contract execution and attached to promises (cannot exceed <code>prepaid_gas</code>);</li>
</ul>
<p>If contract execution fails <code>prepaid_gas - used_gas</code> is refunded back to <code>signer_account_id</code> and <code>attached_deposit</code>
is refunded back to <code>predecessor_account_id</code>.</p>
<p>The following spec is the same for all functions:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>account_balance(balance_ptr: u64)
attached_deposit(balance_ptr: u64)

<span class="boring">}
</span></code></pre></pre>
<p>-- writes the value into the <code>u128</code> variable pointed by <code>balance_ptr</code>.</p>
<h6 id="panics-5"><a class="header" href="#panics-5">Panics</a></h6>
<ul>
<li>If <code>balance_ptr + 16</code> points outside the memory of the guest with <code>MemoryAccessViolation</code>;</li>
<li>If called in a view function panics with <code>ProhibitedInView</code>.</li>
</ul>
<h6 id="current-bugs-4"><a class="header" href="#current-bugs-4">Current bugs</a></h6>
<ul>
<li>Use a different name;</li>
</ul>
<hr />
<h4 id=""><a class="header" href="#"></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>prepaid_gas() -&gt; u64
used_gas() -&gt; u64
<span class="boring">}
</span></code></pre></pre>
<h6 id="panics-6"><a class="header" href="#panics-6">Panics</a></h6>
<ul>
<li>If called in a view function panics with <code>ProhibitedInView</code>.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="math-api"><a class="header" href="#math-api">Math API</a></h1>
<h4 id="random_seed"><a class="header" href="#random_seed">random_seed</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>random_seed(register_id: u64)
<span class="boring">}
</span></code></pre></pre>
<p>Returns random seed that can be used for pseudo-random number generation in deterministic way.</p>
<h6 id="panics-7"><a class="header" href="#panics-7">Panics</a></h6>
<ul>
<li>If the size of the registers exceed the set limit <code>MemoryAccessViolation</code>;</li>
</ul>
<hr />
<h4 id="sha256"><a class="header" href="#sha256">sha256</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>sha256(value_len: u64, value_ptr: u64, register_id: u64)
<span class="boring">}
</span></code></pre></pre>
<p>Hashes the random sequence of bytes using sha256 and returns it into <code>register_id</code>.</p>
<h6 id="panics-8"><a class="header" href="#panics-8">Panics</a></h6>
<ul>
<li>If <code>value_len + value_ptr</code> points outside the memory or the registers use more memory than the limit with <code>MemoryAccessViolation</code>.</li>
</ul>
<hr />
<h4 id="keccak256"><a class="header" href="#keccak256">keccak256</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>keccak256(value_len: u64, value_ptr: u64, register_id: u64)
<span class="boring">}
</span></code></pre></pre>
<p>Hashes the random sequence of bytes using keccak256 and returns it into <code>register_id</code>.</p>
<h6 id="panics-9"><a class="header" href="#panics-9">Panics</a></h6>
<ul>
<li>If <code>value_len + value_ptr</code> points outside the memory or the registers use more memory than the limit with <code>MemoryAccessViolation</code>.</li>
</ul>
<hr />
<h4 id="keccak512"><a class="header" href="#keccak512">keccak512</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>keccak512(value_len: u64, value_ptr: u64, register_id: u64)
<span class="boring">}
</span></code></pre></pre>
<p>Hashes the random sequence of bytes using keccak512 and returns it into <code>register_id</code>.</p>
<h6 id="panics-10"><a class="header" href="#panics-10">Panics</a></h6>
<ul>
<li>If <code>value_len + value_ptr</code> points outside the memory or the registers use more memory than the limit with <code>MemoryAccessViolation</code>.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="miscellaneous-api"><a class="header" href="#miscellaneous-api">Miscellaneous API</a></h1>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>value_return(value_len: u64, value_ptr: u64)
<span class="boring">}
</span></code></pre></pre>
<p>Sets the blob of data as the return value of the contract.</p>
<h6 id="panics-11"><a class="header" href="#panics-11">Panics</a></h6>
<ul>
<li>If <code>value_len + value_ptr</code> exceeds the memory container or points to an unused register it panics with <code>MemoryAccessViolation</code>;</li>
</ul>
<hr />
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>panic()
<span class="boring">}
</span></code></pre></pre>
<p>Terminates the execution of the program with panic <code>GuestPanic(&quot;explicit guest panic&quot;)</code>.</p>
<hr />
<h4 id="panic_utf8"><a class="header" href="#panic_utf8">panic_utf8</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>panic_utf8(len: u64, ptr: u64)
<span class="boring">}
</span></code></pre></pre>
<p>Terminates the execution of the program with panic <code>GuestPanic(s)</code>, where <code>s</code> is the given UTF-8 encoded string.</p>
<h6 id="normal-behavior"><a class="header" href="#normal-behavior">Normal behavior</a></h6>
<p>If <code>len == u64::MAX</code> then treats the string as null-terminated with character <code>'\0'</code>;</p>
<h6 id="panics-12"><a class="header" href="#panics-12">Panics</a></h6>
<ul>
<li>If string extends outside the memory of the guest with <code>MemoryAccessViolation</code>;</li>
<li>If string is not UTF-8 returns <code>BadUtf8</code>.</li>
<li>If string length without null-termination symbol is larger than <code>config.max_log_len</code> returns <code>BadUtf8</code>.</li>
</ul>
<hr />
<h4 id="log_utf8"><a class="header" href="#log_utf8">log_utf8</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>log_utf8(len: u64, ptr: u64)
<span class="boring">}
</span></code></pre></pre>
<p>Logs the UTF-8 encoded string.</p>
<h6 id="normal-behavior-1"><a class="header" href="#normal-behavior-1">Normal behavior</a></h6>
<p>If <code>len == u64::MAX</code> then treats the string as null-terminated with character <code>'\0'</code>;</p>
<h6 id="panics-13"><a class="header" href="#panics-13">Panics</a></h6>
<ul>
<li>If string extends outside the memory of the guest with <code>MemoryAccessViolation</code>;</li>
<li>If string is not UTF-8 returns <code>BadUtf8</code>.</li>
<li>If string length without null-termination symbol is larger than <code>config.max_log_len</code> returns <code>BadUtf8</code>.</li>
</ul>
<hr />
<h4 id="log_utf16"><a class="header" href="#log_utf16">log_utf16</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>log_utf16(len: u64, ptr: u64)
<span class="boring">}
</span></code></pre></pre>
<p>Logs the UTF-16 encoded string. <code>len</code> is the number of bytes in the string.
See https://stackoverflow.com/a/5923961 that explains that null termination is not defined through encoding.</p>
<h6 id="normal-behavior-2"><a class="header" href="#normal-behavior-2">Normal behavior</a></h6>
<p>If <code>len == u64::MAX</code> then treats the string as null-terminated with two-byte sequence of <code>0x00 0x00</code>.</p>
<h6 id="panics-14"><a class="header" href="#panics-14">Panics</a></h6>
<ul>
<li>If string extends outside the memory of the guest with <code>MemoryAccessViolation</code>;</li>
</ul>
<hr />
<h4 id="abort"><a class="header" href="#abort">abort</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>abort(msg_ptr: u32, filename_ptr: u32, line: u32, col: u32)
<span class="boring">}
</span></code></pre></pre>
<p>Special import kept for compatibility with AssemblyScript contracts. Not called by smart contracts directly, but instead
called by the code generated by AssemblyScript.</p>
<h1 id="future-improvements-1"><a class="header" href="#future-improvements-1">Future Improvements</a></h1>
<p>In the future we can have some of the registers to be on the guest.
For instance a guest can tell the host that it has some pre-allocated memory that it wants to be used for the register,
e.g.</p>
<h4 id="set_guest_register"><a class="header" href="#set_guest_register">set_guest_register</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>set_guest_register(register_id: u64, register_ptr: u64, max_register_size: u64)
<span class="boring">}
</span></code></pre></pre>
<p>will assign <code>register_id</code> to a span of memory on the guest. Host then would also know the size of that buffer on guest
and can throw a panic if there is an attempted copying that exceeds the guest register size.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="promises-api"><a class="header" href="#promises-api">Promises API</a></h1>
<h4 id="promise_create"><a class="header" href="#promise_create">promise_create</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>promise_create(account_id_len: u64,
               account_id_ptr: u64,
               method_name_len: u64,
               method_name_ptr: u64,
               arguments_len: u64,
               arguments_ptr: u64,
               amount_ptr: u64,
               gas: u64) -&gt; u64
<span class="boring">}
</span></code></pre></pre>
<p>Creates a promise that will execute a method on account with given arguments and attaches the given amount.
<code>amount_ptr</code> point to slices of bytes representing <code>u128</code>.</p>
<h6 id="panics-15"><a class="header" href="#panics-15">Panics</a></h6>
<ul>
<li>If <code>account_id_len + account_id_ptr</code> or <code>method_name_len + method_name_ptr</code> or <code>arguments_len + arguments_ptr</code>
or <code>amount_ptr + 16</code> points outside the memory of the guest or host, with <code>MemoryAccessViolation</code>.</li>
<li>If called in a view function panics with <code>ProhibitedInView</code>.</li>
</ul>
<h6 id="returns-1"><a class="header" href="#returns-1">Returns</a></h6>
<ul>
<li>Index of the new promise that uniquely identifies it within the current execution of the method.</li>
</ul>
<hr />
<h5 id="promise_then"><a class="header" href="#promise_then">promise_then</a></h5>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>promise_then(promise_idx: u64,
             account_id_len: u64,
             account_id_ptr: u64,
             method_name_len: u64,
             method_name_ptr: u64,
             arguments_len: u64,
             arguments_ptr: u64,
             amount_ptr: u64,
             gas: u64) -&gt; u64
<span class="boring">}
</span></code></pre></pre>
<p>Attaches the callback that is executed after promise pointed by <code>promise_idx</code> is complete.</p>
<h6 id="panics-16"><a class="header" href="#panics-16">Panics</a></h6>
<ul>
<li>If <code>promise_idx</code> does not correspond to an existing promise panics with <code>InvalidPromiseIndex</code>.</li>
<li>If <code>account_id_len + account_id_ptr</code> or <code>method_name_len + method_name_ptr</code> or <code>arguments_len + arguments_ptr</code>
or <code>amount_ptr + 16</code> points outside the memory of the guest or host, with <code>MemoryAccessViolation</code>.</li>
<li>If called in a view function panics with <code>ProhibitedInView</code>.</li>
</ul>
<h6 id="returns-2"><a class="header" href="#returns-2">Returns</a></h6>
<ul>
<li>Index of the new promise that uniquely identifies it within the current execution of the method.</li>
</ul>
<hr />
<h4 id="promise_and"><a class="header" href="#promise_and">promise_and</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>promise_and(promise_idx_ptr: u64, promise_idx_count: u64) -&gt; u64
<span class="boring">}
</span></code></pre></pre>
<p>Creates a new promise which completes when time all promises passed as arguments complete. Cannot be used with registers.
<code>promise_idx_ptr</code> points to an array of <code>u64</code> elements, with <code>promise_idx_count</code> denoting the number of elements.
The array contains indices of promises that need to be waited on jointly.</p>
<h6 id="panics-17"><a class="header" href="#panics-17">Panics</a></h6>
<ul>
<li>If <code>promise_ids_ptr + 8 * promise_idx_count</code> extend outside the guest memory with <code>MemoryAccessViolation</code>;</li>
<li>If any of the promises in the array do not correspond to existing promises panics with <code>InvalidPromiseIndex</code>.</li>
<li>If called in a view function panics with <code>ProhibitedInView</code>.</li>
</ul>
<h6 id="returns-3"><a class="header" href="#returns-3">Returns</a></h6>
<ul>
<li>Index of the new promise that uniquely identifies it within the current execution of the method.</li>
</ul>
<hr />
<h4 id="promise_results_count"><a class="header" href="#promise_results_count">promise_results_count</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>promise_results_count() -&gt; u64
<span class="boring">}
</span></code></pre></pre>
<p>If the current function is invoked by a callback we can access the execution results of the promises that
caused the callback. This function returns the number of complete and incomplete callbacks.</p>
<p>Note, we are only going to have incomplete callbacks once we have <code>promise_or</code> combinator.</p>
<h6 id="normal-execution"><a class="header" href="#normal-execution">Normal execution</a></h6>
<ul>
<li>If there is only one callback <code>promise_results_count()</code> returns <code>1</code>;</li>
<li>If there are multiple callbacks (e.g. created through <code>promise_and</code>) <code>promise_results_count()</code> returns their number.</li>
<li>If the function was called not through the callback <code>promise_results_count()</code> returns <code>0</code>.</li>
</ul>
<h6 id="panics-18"><a class="header" href="#panics-18">Panics</a></h6>
<ul>
<li>If called in a view function panics with <code>ProhibitedInView</code>.</li>
</ul>
<hr />
<h4 id="promise_result"><a class="header" href="#promise_result">promise_result</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>promise_result(result_idx: u64, register_id: u64) -&gt; u64
<span class="boring">}
</span></code></pre></pre>
<p>If the current function is invoked by a callback we can access the execution results of the promises that
caused the callback. This function returns the result in blob format and places it into the register.</p>
<h6 id="normal-execution-1"><a class="header" href="#normal-execution-1">Normal execution</a></h6>
<ul>
<li>If promise result is complete and successful copies its blob into the register;</li>
<li>If promise result is complete and failed or incomplete keeps register unused;</li>
</ul>
<h6 id="returns-4"><a class="header" href="#returns-4">Returns</a></h6>
<ul>
<li>If promise result is not complete returns <code>0</code>;</li>
<li>If promise result is complete and successful returns <code>1</code>;</li>
<li>If promise result is complete and failed returns <code>2</code>.</li>
</ul>
<h6 id="panics-19"><a class="header" href="#panics-19">Panics</a></h6>
<ul>
<li>If <code>result_idx</code> does not correspond to an existing result panics with <code>InvalidResultIndex</code>.</li>
<li>If copying the blob exhausts the memory limit it panics with <code>MemoryAccessViolation</code>.</li>
<li>If called in a view function panics with <code>ProhibitedInView</code>.</li>
</ul>
<h6 id="current-bugs-5"><a class="header" href="#current-bugs-5">Current bugs</a></h6>
<ul>
<li>We currently have two separate functions to check for result completion and copy it.</li>
</ul>
<hr />
<h4 id="promise_return"><a class="header" href="#promise_return">promise_return</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>promise_return(promise_idx: u64)
<span class="boring">}
</span></code></pre></pre>
<p>When promise <code>promise_idx</code> finishes executing its result is considered to be the result of the current function.</p>
<h6 id="panics-20"><a class="header" href="#panics-20">Panics</a></h6>
<ul>
<li>If <code>promise_idx</code> does not correspond to an existing promise panics with <code>InvalidPromiseIndex</code>.</li>
</ul>
<h6 id="current-bugs-6"><a class="header" href="#current-bugs-6">Current bugs</a></h6>
<ul>
<li>The current name <code>return_promise</code> is inconsistent with the naming convention of Promise API.</li>
</ul>
<h4 id="promise_batch_create"><a class="header" href="#promise_batch_create">promise_batch_create</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>promise_batch_create(account_id_len: u64, account_id_ptr: u64) -&gt; u64
<span class="boring">}
</span></code></pre></pre>
<p>Creates a new promise towards given <code>account_id</code> without any actions attached to it.</p>
<h6 id="panics-21"><a class="header" href="#panics-21">Panics</a></h6>
<ul>
<li>If <code>account_id_len + account_id_ptr</code> points outside the memory of the guest or host, with <code>MemoryAccessViolation</code>.</li>
<li>If called in a view function panics with <code>ProhibitedInView</code>.</li>
</ul>
<h6 id="returns-5"><a class="header" href="#returns-5">Returns</a></h6>
<ul>
<li>Index of the new promise that uniquely identifies it within the current execution of the method.</li>
</ul>
<hr />
<h4 id="promise_batch_then"><a class="header" href="#promise_batch_then">promise_batch_then</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>promise_batch_then(promise_idx: u64, account_id_len: u64, account_id_ptr: u64) -&gt; u64
<span class="boring">}
</span></code></pre></pre>
<p>Attaches a new empty promise that is executed after promise pointed by <code>promise_idx</code> is complete.</p>
<h6 id="panics-22"><a class="header" href="#panics-22">Panics</a></h6>
<ul>
<li>If <code>promise_idx</code> does not correspond to an existing promise panics with <code>InvalidPromiseIndex</code>.</li>
<li>If <code>account_id_len + account_id_ptr</code> points outside the memory of the guest or host, with <code>MemoryAccessViolation</code>.</li>
<li>If called in a view function panics with <code>ProhibitedInView</code>.</li>
</ul>
<h6 id="returns-6"><a class="header" href="#returns-6">Returns</a></h6>
<ul>
<li>Index of the new promise that uniquely identifies it within the current execution of the method.</li>
</ul>
<hr />
<h4 id="promise_batch_action_create_account"><a class="header" href="#promise_batch_action_create_account">promise_batch_action_create_account</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>promise_batch_action_create_account(promise_idx: u64)
<span class="boring">}
</span></code></pre></pre>
<p>Appends <code>CreateAccount</code> action to the batch of actions for the given promise pointed by <code>promise_idx</code>.
Details for the action: https://github.com/nearprotocol/NEPs/pull/8/files#diff-15b6752ec7d78e7b85b8c7de4a19cbd4R48</p>
<h6 id="panics-23"><a class="header" href="#panics-23">Panics</a></h6>
<ul>
<li>If <code>promise_idx</code> does not correspond to an existing promise panics with <code>InvalidPromiseIndex</code>.</li>
<li>If the promise pointed by the <code>promise_idx</code> is an ephemeral promise created by <code>promise_and</code>.</li>
<li>If called in a view function panics with <code>ProhibitedInView</code>.</li>
</ul>
<hr />
<h4 id="promise_batch_action_deploy_contract"><a class="header" href="#promise_batch_action_deploy_contract">promise_batch_action_deploy_contract</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>promise_batch_action_deploy_contract(promise_idx: u64, code_len: u64, code_ptr: u64)
<span class="boring">}
</span></code></pre></pre>
<p>Appends <code>DeployContract</code> action to the batch of actions for the given promise pointed by <code>promise_idx</code>.
Details for the action: https://github.com/nearprotocol/NEPs/pull/8/files#diff-15b6752ec7d78e7b85b8c7de4a19cbd4R49</p>
<h6 id="panics-24"><a class="header" href="#panics-24">Panics</a></h6>
<ul>
<li>If <code>promise_idx</code> does not correspond to an existing promise panics with <code>InvalidPromiseIndex</code>.</li>
<li>If the promise pointed by the <code>promise_idx</code> is an ephemeral promise created by <code>promise_and</code>.</li>
<li>If <code>code_len + code_ptr</code> points outside the memory of the guest or host, with <code>MemoryAccessViolation</code>.</li>
<li>If called in a view function panics with <code>ProhibitedInView</code>.</li>
</ul>
<hr />
<h4 id="promise_batch_action_function_call"><a class="header" href="#promise_batch_action_function_call">promise_batch_action_function_call</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>promise_batch_action_function_call(promise_idx: u64,
                                   method_name_len: u64,
                                   method_name_ptr: u64,
                                   arguments_len: u64,
                                   arguments_ptr: u64,
                                   amount_ptr: u64,
                                   gas: u64)
<span class="boring">}
</span></code></pre></pre>
<p>Appends <code>FunctionCall</code> action to the batch of actions for the given promise pointed by <code>promise_idx</code>.
Details for the action: https://github.com/nearprotocol/NEPs/pull/8/files#diff-15b6752ec7d78e7b85b8c7de4a19cbd4R50</p>
<p><em>NOTE: Calling <code>promise_batch_create</code> and then <code>promise_batch_action_function_call</code> will produce the same promise as calling <code>promise_create</code> directly.</em></p>
<h6 id="panics-25"><a class="header" href="#panics-25">Panics</a></h6>
<ul>
<li>If <code>promise_idx</code> does not correspond to an existing promise panics with <code>InvalidPromiseIndex</code>.</li>
<li>If the promise pointed by the <code>promise_idx</code> is an ephemeral promise created by <code>promise_and</code>.</li>
<li>If <code>account_id_len + account_id_ptr</code> or <code>method_name_len + method_name_ptr</code> or <code>arguments_len + arguments_ptr</code>
or <code>amount_ptr + 16</code> points outside the memory of the guest or host, with <code>MemoryAccessViolation</code>.</li>
<li>If called in a view function panics with <code>ProhibitedInView</code>.</li>
</ul>
<hr />
<h4 id="promise_batch_action_transfer"><a class="header" href="#promise_batch_action_transfer">promise_batch_action_transfer</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>promise_batch_action_transfer(promise_idx: u64, amount_ptr: u64)
<span class="boring">}
</span></code></pre></pre>
<p>Appends <code>Transfer</code> action to the batch of actions for the given promise pointed by <code>promise_idx</code>.
Details for the action: https://github.com/nearprotocol/NEPs/pull/8/files#diff-15b6752ec7d78e7b85b8c7de4a19cbd4R51</p>
<h6 id="panics-26"><a class="header" href="#panics-26">Panics</a></h6>
<ul>
<li>If <code>promise_idx</code> does not correspond to an existing promise panics with <code>InvalidPromiseIndex</code>.</li>
<li>If the promise pointed by the <code>promise_idx</code> is an ephemeral promise created by <code>promise_and</code>.</li>
<li>If <code>amount_ptr + 16</code> points outside the memory of the guest or host, with <code>MemoryAccessViolation</code>.</li>
<li>If called in a view function panics with <code>ProhibitedInView</code>.</li>
</ul>
<hr />
<h4 id="promise_batch_action_stake"><a class="header" href="#promise_batch_action_stake">promise_batch_action_stake</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>promise_batch_action_stake(promise_idx: u64,
                           amount_ptr: u64,
                           bls_public_key_len: u64,
                           bls_public_key_ptr: u64)
<span class="boring">}
</span></code></pre></pre>
<p>Appends <code>Stake</code> action to the batch of actions for the given promise pointed by <code>promise_idx</code>.
Details for the action: https://github.com/nearprotocol/NEPs/pull/8/files#diff-15b6752ec7d78e7b85b8c7de4a19cbd4R52</p>
<h6 id="panics-27"><a class="header" href="#panics-27">Panics</a></h6>
<ul>
<li>If <code>promise_idx</code> does not correspond to an existing promise panics with <code>InvalidPromiseIndex</code>.</li>
<li>If the promise pointed by the <code>promise_idx</code> is an ephemeral promise created by <code>promise_and</code>.</li>
<li>If the given BLS public key is not a valid BLS public key (e.g. wrong length) <code>InvalidPublicKey</code>.</li>
<li>If <code>amount_ptr + 16</code> or <code>bls_public_key_len + bls_public_key_ptr</code> points outside the memory of the guest or host, with <code>MemoryAccessViolation</code>.</li>
<li>If called in a view function panics with <code>ProhibitedInView</code>.</li>
</ul>
<hr />
<h4 id="promise_batch_action_add_key_with_full_access"><a class="header" href="#promise_batch_action_add_key_with_full_access">promise_batch_action_add_key_with_full_access</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>promise_batch_action_add_key_with_full_access(promise_idx: u64,
                                              public_key_len: u64,
                                              public_key_ptr: u64,
                                              nonce: u64)
<span class="boring">}
</span></code></pre></pre>
<p>Appends <code>AddKey</code> action to the batch of actions for the given promise pointed by <code>promise_idx</code>.
Details for the action: https://github.com/nearprotocol/NEPs/pull/8/files#diff-15b6752ec7d78e7b85b8c7de4a19cbd4R54
The access key will have <code>FullAccess</code> permission, details: [/Proposals/0005-access-keys.md#guide-level-explanation](click here)</p>
<h6 id="panics-28"><a class="header" href="#panics-28">Panics</a></h6>
<ul>
<li>If <code>promise_idx</code> does not correspond to an existing promise panics with <code>InvalidPromiseIndex</code>.</li>
<li>If the promise pointed by the <code>promise_idx</code> is an ephemeral promise created by <code>promise_and</code>.</li>
<li>If the given public key is not a valid public key (e.g. wrong length) <code>InvalidPublicKey</code>.</li>
<li>If <code>public_key_len + public_key_ptr</code> points outside the memory of the guest or host, with <code>MemoryAccessViolation</code>.</li>
<li>If called in a view function panics with <code>ProhibitedInView</code>.</li>
</ul>
<hr />
<h4 id="promise_batch_action_add_key_with_function_call"><a class="header" href="#promise_batch_action_add_key_with_function_call">promise_batch_action_add_key_with_function_call</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>promise_batch_action_add_key_with_function_call(promise_idx: u64,
                                                public_key_len: u64,
                                                public_key_ptr: u64,
                                                nonce: u64,
                                                allowance_ptr: u64,
                                                receiver_id_len: u64,
                                                receiver_id_ptr: u64,
                                                method_names_len: u64,
                                                method_names_ptr: u64)
<span class="boring">}
</span></code></pre></pre>
<p>Appends <code>AddKey</code> action to the batch of actions for the given promise pointed by <code>promise_idx</code>.
Details for the action: https://github.com/nearprotocol/NEPs/pull/8/files#diff-156752ec7d78e7b85b8c7de4a19cbd4R54
The access key will have <code>FunctionCall</code> permission, details: [/Proposals/0005-access-keys.md#guide-level-explanation](click here)</p>
<ul>
<li>If the <code>allowance</code> value (not the pointer) is <code>0</code>, the allowance is set to <code>None</code> (which means unlimited allowance). And positive value represents a <code>Some(...)</code> allowance.</li>
<li>Given <code>method_names</code> is a <code>utf-8</code> string with <code>,</code> used as a separator. The vm will split the given string into a vector of strings.</li>
</ul>
<h6 id="panics-29"><a class="header" href="#panics-29">Panics</a></h6>
<ul>
<li>If <code>promise_idx</code> does not correspond to an existing promise panics with <code>InvalidPromiseIndex</code>.</li>
<li>If the promise pointed by the <code>promise_idx</code> is an ephemeral promise created by <code>promise_and</code>.</li>
<li>If the given public key is not a valid public key (e.g. wrong length) <code>InvalidPublicKey</code>.</li>
<li>if <code>method_names</code> is not a valid <code>utf-8</code> string, fails with <code>BadUTF8</code>.</li>
<li>If <code>public_key_len + public_key_ptr</code>, <code>allowance_ptr + 16</code>, <code>receiver_id_len + receiver_id_ptr</code> or
<code>method_names_len + method_names_ptr</code> points outside the memory of the guest or host, with <code>MemoryAccessViolation</code>.</li>
<li>If called in a view function panics with <code>ProhibitedInView</code>.</li>
</ul>
<hr />
<h4 id="promise_batch_action_delete_key"><a class="header" href="#promise_batch_action_delete_key">promise_batch_action_delete_key</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>promise_batch_action_delete_key(promise_idx: u64,
                                public_key_len: u64,
                                public_key_ptr: u64)
<span class="boring">}
</span></code></pre></pre>
<p>Appends <code>DeleteKey</code> action to the batch of actions for the given promise pointed by <code>promise_idx</code>.
Details for the action: https://github.com/nearprotocol/NEPs/pull/8/files#diff-15b6752ec7d78e7b85b8c7de4a19cbd4R55</p>
<h6 id="panics-30"><a class="header" href="#panics-30">Panics</a></h6>
<ul>
<li>If <code>promise_idx</code> does not correspond to an existing promise panics with <code>InvalidPromiseIndex</code>.</li>
<li>If the promise pointed by the <code>promise_idx</code> is an ephemeral promise created by <code>promise_and</code>.</li>
<li>If the given public key is not a valid public key (e.g. wrong length) <code>InvalidPublicKey</code>.</li>
<li>If <code>public_key_len + public_key_ptr</code> points outside the memory of the guest or host, with <code>MemoryAccessViolation</code>.</li>
<li>If called in a view function panics with <code>ProhibitedInView</code>.</li>
</ul>
<hr />
<h4 id="promise_batch_action_delete_account"><a class="header" href="#promise_batch_action_delete_account">promise_batch_action_delete_account</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>promise_batch_action_delete_account(promise_idx: u64,
                                    beneficiary_id_len: u64,
                                    beneficiary_id_ptr: u64)
<span class="boring">}
</span></code></pre></pre>
<p>Appends <code>DeleteAccount</code> action to the batch of actions for the given promise pointed by <code>promise_idx</code>.
Action is used to delete an account. It can be performed on a newly created account, on your own account or an account with
insufficient funds to pay rent. Takes <code>beneficiary_id</code> to indicate where to send the remaining funds.</p>
<h6 id="panics-31"><a class="header" href="#panics-31">Panics</a></h6>
<ul>
<li>If <code>promise_idx</code> does not correspond to an existing promise panics with <code>InvalidPromiseIndex</code>.</li>
<li>If the promise pointed by the <code>promise_idx</code> is an ephemeral promise created by <code>promise_and</code>.</li>
<li>If <code>beneficiary_id_len + beneficiary_id_ptr</code> points outside the memory of the guest or host, with <code>MemoryAccessViolation</code>.</li>
<li>If called in a view function panics with <code>ProhibitedInView</code>.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="registers-api"><a class="header" href="#registers-api">Registers API</a></h1>
<!-- cspell:ignore Ewasm BigNum -->
<p>Registers allow the host function to return the data into a buffer located inside the host oppose to the buffer
located on the client. A special operation can be used to copy the content of the buffer into the host. Memory pointers
can then be used to point either to the memory on the guest or the memory on the host, see below. Benefits:</p>
<ul>
<li>We can have functions that return values that are not necessarily used, e.g. inserting key-value into a trie can
also return the preempted old value, which might not be necessarily used. Previously, if we returned something we
would have to pass the blob from host into the guest, even if it is not used;</li>
<li>We can pass blobs of data between host functions without going through the guest, e.g. we can remove the value
from the storage and insert it into under a different key;</li>
<li>It makes API cleaner, because we don't need to pass <code>buffer_len</code> and <code>buffer_ptr</code> as arguments to other functions;</li>
<li>It allows merging certain functions together, see <code>storage_iter_next</code>;</li>
<li>This is consistent with other APIs that were created for high performance, e.g. allegedly Ewasm has implemented
SNARK-like computations in Wasm by exposing a BigNum library through stack-like interface to the guest. The guest
can manipulate then with the stack of 256-bit numbers that is located on the host.</li>
</ul>
<h4 id="host--host-blob-passing"><a class="header" href="#host--host-blob-passing">Host â†’ host blob passing</a></h4>
<p>The registers can be used to pass the blobs between host functions. For any function that
takes a pair of arguments <code>*_len: u64, *_ptr: u64</code> this pair is pointing to a region of memory either on the guest or
the host:</p>
<ul>
<li>If <code>*_len != u64::MAX</code> it points to the memory on the guest;</li>
<li>If <code>*_len == u64::MAX</code> it points to the memory under the register <code>*_ptr</code> on the host.</li>
</ul>
<p>For example:
<code>storage_write(u64::MAX, 0, u64::MAX, 1, 2)</code> -- insert key-value into storage, where key is read from register 0,
value is read from register 1, and result is saved to register 2.</p>
<p>Note, if some function takes <code>register_id</code> then it means this function can copy some data into this register. If
<code>register_id == u64::MAX</code> then the copying does not happen. This allows some micro-optimizations in the future.</p>
<p>Note, we allow multiple registers on the host, identified with <code>u64</code> number. The guest does not have to use them in
order and can for instance save some blob in register <code>5000</code> and another value in register <code>1</code>.</p>
<h4 id="specification"><a class="header" href="#specification">Specification</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>read_register(register_id: u64, ptr: u64)
<span class="boring">}
</span></code></pre></pre>
<p>Writes the entire content from the register <code>register_id</code> into the memory of the guest starting with <code>ptr</code>.</p>
<h6 id="panics-32"><a class="header" href="#panics-32">Panics</a></h6>
<ul>
<li>If the content extends outside the memory allocated to the guest. In Wasmer, it returns <code>MemoryAccessViolation</code> error message;</li>
<li>If <code>register_id</code> is pointing to unused register returns <code>InvalidRegisterId</code> error message.</li>
</ul>
<h6 id="undefined-behavior"><a class="header" href="#undefined-behavior">Undefined Behavior</a></h6>
<ul>
<li>If the content of register extends outside the preallocated memory on the host side, or the pointer points to a
wrong location this function will overwrite memory that it is not supposed to overwrite causing an undefined behavior.</li>
</ul>
<hr />
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>register_len(register_id: u64) -&gt; u64
<span class="boring">}
</span></code></pre></pre>
<p>Returns the size of the blob stored in the given register.</p>
<h6 id="normal-operation-3"><a class="header" href="#normal-operation-3">Normal operation</a></h6>
<ul>
<li>If register is used, then returns the size, which can potentially be zero;</li>
<li>If register is not used, returns <code>u64::MAX</code></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="trie-api"><a class="header" href="#trie-api">Trie API</a></h1>
<p>Here we provide a specification of trie API. After this NEP is merged, the cases where our current implementation does
not follow the specification are considered to be bugs that need to be fixed.</p>
<hr />
<h4 id="storage_write"><a class="header" href="#storage_write">storage_write</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>storage_write(key_len: u64, key_ptr: u64, value_len: u64, value_ptr: u64, register_id: u64) -&gt; u64
<span class="boring">}
</span></code></pre></pre>
<p>Writes key-value into storage.</p>
<h6 id="normal-operation-4"><a class="header" href="#normal-operation-4">Normal operation</a></h6>
<ul>
<li>If key is not in use it inserts the key-value pair and does not modify the register;</li>
<li>If key is in use it inserts the key-value and copies the old value into the <code>register_id</code>.</li>
</ul>
<h6 id="returns-7"><a class="header" href="#returns-7">Returns</a></h6>
<ul>
<li>If key was not used returns <code>0</code>;</li>
<li>If key was used returns <code>1</code>.</li>
</ul>
<h6 id="panics-33"><a class="header" href="#panics-33">Panics</a></h6>
<ul>
<li>If <code>key_len + key_ptr</code> or <code>value_len + value_ptr</code> exceeds the memory container or points to an unused register it panics
with <code>MemoryAccessViolation</code>. (When we say that something panics with the given error we mean that we use Wasmer API to
create this error and terminate the execution of VM. For mocks of the host that would only cause a non-name panic.)</li>
<li>If returning the preempted value into the registers exceed the memory container it panics with <code>MemoryAccessViolation</code>;</li>
</ul>
<h6 id="current-bugs-7"><a class="header" href="#current-bugs-7">Current bugs</a></h6>
<ul>
<li><code>External::storage_set</code> trait can return an error which is then converted to a generic non-descriptive
<code>StorageUpdateError</code>, <a href="https://github.com/nearprotocol/nearcore/blob/942bd7bdbba5fb3403e5c2f1ee3c08963947d0c6/runtime/wasm/src/runtime.rs#L210">here</a>
however the actual implementation does not return error at all, <a href="https://github.com/nearprotocol/nearcore/blob/4773873b3cd680936bf206cebd56bdc3701ddca9/runtime/runtime/src/ext.rs#L95">see</a>;</li>
<li>Does not return into the registers.</li>
</ul>
<hr />
<h4 id="storage_read"><a class="header" href="#storage_read">storage_read</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>storage_read(key_len: u64, key_ptr: u64, register_id: u64) -&gt; u64
<span class="boring">}
</span></code></pre></pre>
<p>Reads the value stored under the given key.</p>
<h6 id="normal-operation-5"><a class="header" href="#normal-operation-5">Normal operation</a></h6>
<ul>
<li>If key is used copies the content of the value into the <code>register_id</code>, even if the content is zero bytes;</li>
<li>If key is not present then does not modify the register.</li>
</ul>
<h6 id="returns-8"><a class="header" href="#returns-8">Returns</a></h6>
<ul>
<li>If key was not present returns <code>0</code>;</li>
<li>If key was present returns <code>1</code>.</li>
</ul>
<h6 id="panics-34"><a class="header" href="#panics-34">Panics</a></h6>
<ul>
<li>If <code>key_len + key_ptr</code> exceeds the memory container or points to an unused register it panics with <code>MemoryAccessViolation</code>;</li>
<li>If returning the preempted value into the registers exceed the memory container it panics with <code>MemoryAccessViolation</code>;</li>
</ul>
<h6 id="current-bugs-8"><a class="header" href="#current-bugs-8">Current bugs</a></h6>
<ul>
<li>This function currently does not exist.</li>
</ul>
<hr />
<h4 id="storage_remove"><a class="header" href="#storage_remove">storage_remove</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>storage_remove(key_len: u64, key_ptr: u64, register_id: u64) -&gt; u64
<span class="boring">}
</span></code></pre></pre>
<p>Removes the value stored under the given key.</p>
<h6 id="normal-operation-6"><a class="header" href="#normal-operation-6">Normal operation</a></h6>
<p>Very similar to <code>storage_read</code>:</p>
<ul>
<li>If key is used, removes the key-value from the trie and copies the content of the value into the <code>register_id</code>, even if the content is zero bytes.</li>
<li>If key is not present then does not modify the register.</li>
</ul>
<h6 id="returns-9"><a class="header" href="#returns-9">Returns</a></h6>
<ul>
<li>If key was not present returns <code>0</code>;</li>
<li>If key was present returns <code>1</code>.</li>
</ul>
<h6 id="panics-35"><a class="header" href="#panics-35">Panics</a></h6>
<ul>
<li>If <code>key_len + key_ptr</code> exceeds the memory container or points to an unused register it panics with <code>MemoryAccessViolation</code>;</li>
<li>If the registers exceed the memory limit panics with <code>MemoryAccessViolation</code>;</li>
<li>If returning the preempted value into the registers exceed the memory container it panics with <code>MemoryAccessViolation</code>;</li>
</ul>
<h6 id="current-bugs-9"><a class="header" href="#current-bugs-9">Current bugs</a></h6>
<ul>
<li>Does not return into the registers.</li>
</ul>
<hr />
<h4 id="storage_has_key"><a class="header" href="#storage_has_key">storage_has_key</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>storage_has_key(key_len: u64, key_ptr: u64) -&gt; u64
<span class="boring">}
</span></code></pre></pre>
<p>Checks if there is a key-value pair.</p>
<h6 id="normal-operation-7"><a class="header" href="#normal-operation-7">Normal operation</a></h6>
<ul>
<li>If key is used returns <code>1</code>, even if the value is zero bytes;</li>
<li>Otherwise returns <code>0</code>.</li>
</ul>
<h6 id="panics-36"><a class="header" href="#panics-36">Panics</a></h6>
<ul>
<li>If <code>key_len + key_ptr</code> exceeds the memory container it panics with <code>MemoryAccessViolation</code>;</li>
</ul>
<hr />
<h4 id="storage_iter_prefix"><a class="header" href="#storage_iter_prefix">storage_iter_prefix</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>storage_iter_prefix(prefix_len: u64, prefix_ptr: u64) -&gt; u64
<span class="boring">}
</span></code></pre></pre>
<p>DEPRECATED, calling it will result in <code>HostError::Deprecated</code> error.
Creates an iterator object inside the host.
Returns the identifier that uniquely differentiates the given iterator from other iterators that can be simultaneously
created.</p>
<h6 id="normal-operation-8"><a class="header" href="#normal-operation-8">Normal operation</a></h6>
<ul>
<li>It iterates over the keys that have the provided prefix. The order of iteration is defined by the lexicographic
order of the bytes in the keys. If there are no keys, it creates an empty iterator, see below on empty iterators;</li>
</ul>
<h6 id="panics-37"><a class="header" href="#panics-37">Panics</a></h6>
<ul>
<li>If <code>prefix_len + prefix_ptr</code> exceeds the memory container it panics with <code>MemoryAccessViolation</code>;</li>
</ul>
<hr />
<h4 id="storage_iter_range"><a class="header" href="#storage_iter_range">storage_iter_range</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>storage_iter_range(start_len: u64, start_ptr: u64, end_len: u64, end_ptr: u64) -&gt; u64
<span class="boring">}
</span></code></pre></pre>
<p>DEPRECATED, calling it will result in <code>HostError::Deprecated</code> error.
Similarly to <code>storage_iter_prefix</code>
creates an iterator object inside the host.</p>
<h6 id="normal-operation-9"><a class="header" href="#normal-operation-9">Normal operation</a></h6>
<p>Unless lexicographically <code>start &lt; end</code>, it creates an empty iterator.
Iterates over all key-values such that keys are between <code>start</code> and <code>end</code>, where <code>start</code> is inclusive and <code>end</code> is exclusive.</p>
<p>Note, this definition allows for <code>start</code> or <code>end</code> keys to not actually exist on the given trie.</p>
<h6 id="panics-38"><a class="header" href="#panics-38">Panics</a></h6>
<ul>
<li>If <code>start_len + start_ptr</code> or <code>end_len + end_ptr</code> exceeds the memory container or points to an unused register it panics with <code>MemoryAccessViolation</code>;</li>
</ul>
<hr />
<h4 id="storage_iter_next"><a class="header" href="#storage_iter_next">storage_iter_next</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>storage_iter_next(iterator_id: u64, key_register_id: u64, value_register_id: u64) -&gt; u64
<span class="boring">}
</span></code></pre></pre>
<p>DEPRECATED, calling it will result in <code>HostError::Deprecated</code> error.
Advances iterator and saves the next key and value in the register.</p>
<h6 id="normal-operation-10"><a class="header" href="#normal-operation-10">Normal operation</a></h6>
<ul>
<li>If iterator is not empty (after calling next it points to a key-value), copies the key into <code>key_register_id</code> and value into <code>value_register_id</code> and returns <code>1</code>;</li>
<li>If iterator is empty returns <code>0</code>.</li>
</ul>
<p>This allows us to iterate over the keys that have zero bytes stored in values.</p>
<h6 id="panics-39"><a class="header" href="#panics-39">Panics</a></h6>
<ul>
<li>If <code>key_register_id == value_register_id</code> panics with <code>MemoryAccessViolation</code>;</li>
<li>If the registers exceed the memory limit panics with <code>MemoryAccessViolation</code>;</li>
<li>If <code>iterator_id</code> does not correspond to an existing iterator panics with <code>InvalidIteratorId</code></li>
<li>If between the creation of the iterator and calling <code>storage_iter_next</code> any modification to storage was done through
<code>storage_write</code> or <code>storage_remove</code> the iterator is invalidated and the error message is <code>IteratorWasInvalidated</code>.</li>
</ul>
<h6 id="current-bugs-10"><a class="header" href="#current-bugs-10">Current bugs</a></h6>
<ul>
<li>Not implemented, currently we have <code>storage_iter_next</code> and <code>data_read</code> + <code>DATA_TYPE_STORAGE_ITER</code> that together fulfill
the purpose, but have unspecified behavior.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="runtime-fees"><a class="header" href="#runtime-fees">Runtime Fees</a></h1>
<p>Runtime fees are measured in Gas. Gas price will be discussed separately.</p>
<p>When a transaction is converted into a receipt, the signer account is charged for the full cost of the transaction.
This cost consists of extra attached gas, attached deposits and the transaction fee.</p>
<p>The total transaction fee is the sum of the following:</p>
<ul>
<li>A fee for creation of the receipt</li>
<li>A fee for every action</li>
</ul>
<p>Every <a href="RuntimeSpec/Fees//GenesisConfig/RuntimeFeeConfig/Fee.html">Fee</a> consists of 3 values measured in gas:</p>
<ul>
<li><code>send_sir</code> and <code>send_not_sir</code> - the gas burned when the action is being created to be sent to a receiver.
<ul>
<li><code>send_sir</code> is used when <code>current_account_id == receiver_id</code> (<code>current_account_id</code> is a <code>signer_id</code> for a signed transaction).</li>
<li><code>send_not_sir</code> is used when <code>current_account_id != receiver_id</code></li>
</ul>
</li>
<li><code>execution</code> - the gas burned when the action is being executed on the receiver's account.</li>
</ul>
<h2 id="receipt-creation-cost"><a class="header" href="#receipt-creation-cost">Receipt creation cost</a></h2>
<p>There are 2 types of receipts:</p>
<ul>
<li>Action receipts <a href="RuntimeSpec/Fees//RuntimeSpec/Receipts.html#actionreceipt">ActionReceipt</a></li>
<li>Data receipts <a href="RuntimeSpec/Fees//RuntimeSpec/Receipts.html#datareceipt">DataReceipt</a></li>
</ul>
<p>A transaction is converted into an <a href="RuntimeSpec/Fees//RuntimeSpec/Receipts.html#actionreceipt">ActionReceipt</a>.
Data receipts are used for data dependencies and will be discussed separately.</p>
<p>The <code>Fee</code> for an action receipt creation is described in the config <a href="RuntimeSpec/Fees//GenesisConfig/RuntimeFeeConfig.html#action_receipt_creation_config"><code>action_receipt_creation_config</code></a>.</p>
<p>Example: when a signed transaction is being converted into a receipt, the gas for <code>action_receipt_creation_config.send</code> is being burned immediately,
while the gas for <code>action_receipt_creation_config.execution</code> is only charged, but not burned. It'll be burned when
the newly created receipt is executed on the receiver's account.</p>
<h2 id="fees-for-actions"><a class="header" href="#fees-for-actions">Fees for actions</a></h2>
<p>Every <a href="RuntimeSpec/Fees//RuntimeSpec/Actions"><code>Action</code></a> has a corresponding Fee(s) described in the config <a href="RuntimeSpec/Fees//GenesisConfig/RuntimeFeeConfig/ActionCreationConfig.html"><code>action_creation_config</code></a>.
Similar to a receipt creation costs, the <code>send</code> gas is burned when an action is added to a receipt to be sent, and the <code>execution</code> gas is only charged, but not burned.</p>
<p>Fees are either a base fee or a fee per byte of some data within the action.</p>
<p>Here is the list of actions and their corresponding fees:</p>
<ul>
<li><a href="RuntimeSpec/Fees//RuntimeSpec/Actions.html#createaccountaction">CreateAccount</a> uses
<ul>
<li>the base fee <a href="RuntimeSpec/Fees//GenesisConfig/RuntimeFeeConfig/ActionCreationConfig.html#create_account_cost"><code>create_account_cost</code></a></li>
</ul>
</li>
<li><a href="RuntimeSpec/Fees//RuntimeSpec/Actions.html#deploycontractaction">DeployContract</a> uses the sum of the following fees:
<ul>
<li>the base fee <a href="RuntimeSpec/Fees//GenesisConfig/RuntimeFeeConfig/ActionCreationConfig.html#deploy_contract_cost"><code>deploy_contract_cost</code></a></li>
<li>the fee per byte of the contract code to be deployed with the fee <a href="RuntimeSpec/Fees//GenesisConfig/RuntimeFeeConfig/ActionCreationConfig.html#deploy_contract_cost_per_byte"><code>deploy_contract_cost_per_byte</code></a>
To compute the number of bytes for a deploy contract action <code>deploy_contract_action</code> use <code>deploy_contract_action.code.len()</code></li>
</ul>
</li>
<li><a href="RuntimeSpec/Fees//RuntimeSpec/Actions.html#functioncallaction">FunctionCall</a> uses the sum of the following fees:
<ul>
<li>the base fee <a href="RuntimeSpec/Fees//GenesisConfig/RuntimeFeeConfig/ActionCreationConfig.html#function_call_cost"><code>function_call_cost</code></a></li>
<li>the fee per byte of method name string and per byte of arguments with the fee <a href="RuntimeSpec/Fees//GenesisConfig/RuntimeFeeConfig/ActionCreationConfig.html#function_call_cost_per_byte"><code>function_call_cost_per_byte</code></a>.
To compute the number of bytes for a function call action <code>function_call_action</code> use <code>function_call_action.method_name.as_bytes().len() + function_call_action.args.len()</code></li>
</ul>
</li>
<li><a href="RuntimeSpec/Fees//RuntimeSpec/Actions.html#transferaction">Transfer</a> uses one of the following fees:
<ul>
<li>if the <code>receiver_id</code> is an <a href="RuntimeSpec/Fees//DataStructures/Account#near-implicit-account-id">Implicit Account ID</a>, then a sum of base fees is used:
<ul>
<li>the create account base fee <a href="RuntimeSpec/Fees//GenesisConfig/RuntimeFeeConfig/ActionCreationConfig.html#create_account_cost"><code>create_account_cost</code></a></li>
<li>the transfer base fee <a href="RuntimeSpec/Fees//GenesisConfig/RuntimeFeeConfig/ActionCreationConfig.html#transfer_cost"><code>transfer_cost</code></a></li>
<li>the add full access key base fee <a href="RuntimeSpec/Fees//GenesisConfig/RuntimeFeeConfig/AccessKeyCreationConfig.html#full_access_cost"><code>add_key_cost.full_access_cost</code></a></li>
</ul>
</li>
<li>if the <code>receiver_id</code> is NOT an <a href="RuntimeSpec/Fees//DataStructures/Account.html#near-implicit-account-id">Implicit Account ID</a>, then only the base fee is used:
<ul>
<li>the transfer base fee <a href="RuntimeSpec/Fees//GenesisConfig/RuntimeFeeConfig/ActionCreationConfig.html#transfer_cost"><code>transfer_cost</code></a></li>
</ul>
</li>
</ul>
</li>
<li><a href="RuntimeSpec/Fees//RuntimeSpec/Actions.html#stakeaction">Stake</a> uses
<ul>
<li>the base fee <a href="RuntimeSpec/Fees//GenesisConfig/RuntimeFeeConfig/ActionCreationConfig.html#stake_cost"><code>stake_cost</code></a></li>
</ul>
</li>
<li><a href="RuntimeSpec/Fees//RuntimeSpec/Actions.html#addkeyaction">AddKey</a> uses one of the following fees:
<ul>
<li>if the access key is <a href="RuntimeSpec/Fees//DataStructures/AccessKey"><code>AccessKeyPermission::FullAccess</code></a> the base fee is used
<ul>
<li>the add full access key base fee <a href="RuntimeSpec/Fees//GenesisConfig/RuntimeFeeConfig/AccessKeyCreationConfig.html#full_access_cost"><code>add_key_cost.full_access_cost</code></a></li>
</ul>
</li>
<li>if the access key is <a href="RuntimeSpec/Fees//DataStructures/AccessKey.html#accesskeypermissionfunctioncall"><code>AccessKeyPermission::FunctionCall</code></a> the sum of the fees is used
<ul>
<li>the add function call permission access key base fee <a href="RuntimeSpec/Fees//GenesisConfig/RuntimeFeeConfig/AccessKeyCreationConfig.html#full_access_cost"><code>add_key_cost.function_call_cost</code></a></li>
<li>the fee per byte of method names with extra byte for every method with the fee <a href="RuntimeSpec/Fees//GenesisConfig/RuntimeFeeConfig/AccessKeyCreationConfig.html#function_call_cost_per_byte"><code>add_key_cost.function_call_cost_per_byte</code></a>
To compute the number of bytes for <code>function_call_permission</code> use <code>function_call_permission.method_names.iter().map(|name| name.as_bytes().len() as u64 + 1).sum::&lt;u64&gt;()</code></li>
</ul>
</li>
</ul>
</li>
<li><a href="RuntimeSpec/Fees//RuntimeSpec/Actions.html#deletekeyaction">DeleteKey</a> uses
<ul>
<li>the base fee <a href="RuntimeSpec/Fees//GenesisConfig/RuntimeFeeConfig/ActionCreationConfig.html#delete_key_cost"><code>delete_key_cost</code></a></li>
</ul>
</li>
<li><a href="RuntimeSpec/Fees//RuntimeSpec/Actions.html#deleteaccountaction">DeleteAccount</a> uses
<ul>
<li>the base fee <a href="RuntimeSpec/Fees//GenesisConfig/RuntimeFeeConfig/ActionCreationConfig.html#delete_account_cost"><code>delete_account_cost</code></a></li>
<li>action receipt creation fee for creating Transfer to send remaining funds to <code>beneficiary_id</code></li>
<li>full transfer fee described in the corresponding item</li>
</ul>
</li>
</ul>
<h2 id="gas-tracking"><a class="header" href="#gas-tracking">Gas tracking</a></h2>
<p>In <code>Runtime</code>, gas is tracked in the following fields of <code>ActionResult</code> struct:</p>
<ul>
<li><code>gas_burnt</code> - irreversible amount of gas spent on computations.</li>
<li><code>gas_used</code> - includes burnt gas and gas attached to the new <code>ActionReceipt</code>s created during the method execution.</li>
<li><code>gas_burnt_for_function_call</code> - stores gas burnt during function call execution. Later, contract account gets 30% of it as a reward for a possibility to invoke the function.</li>
</ul>
<p>Initially runtime charges <code>gas_used</code> from the account. Some gas may be refunded later, see <a href="RuntimeSpec/Fees/../Refunds.html">Refunds</a>.</p>
<p>At first, we charge fees related to conversion from <code>SignedTransaction</code> to <code>ActionReceipt</code> and future execution of this receipt:</p>
<ul>
<li>costs of all <code>SignedTransaction</code>s passed to <code>Runtime::apply</code> are computed in <code>tx_cost</code> function during validation;</li>
<li><code>total_cost</code> is deducted from signer, which is a sum of:
<ul>
<li><code>gas_to_balance(gas_burnt)</code> where <code>gas_burnt</code> is action receipt send fee + <code>total_send_fees(transaction.actions)</code>);</li>
<li><code>gas_to_balance(gas_remaining)</code> where <code>gas_remaining</code> is action receipt exec fee + <code>total_prepaid_exec_fees(transaction.actions)</code> to pay all remaining fees caused by transaction;</li>
<li><code>total_deposit(transaction.actions)</code>;</li>
</ul>
</li>
<li>each transaction is converted to receipt and passed to <code>Runtime::process_receipt</code>.</li>
</ul>
<p>Then each <code>ActionReceipt</code> is passed to <code>Runtime::apply_action_receipt</code> where gas is tracked as follows:</p>
<ul>
<li><code>ActionResult</code> is created with <code>ActionReceipt</code> execution fee;</li>
<li>all actions inside <code>ActionReceipt</code> are passed to <code>Runtime::apply_action</code>;</li>
<li><code>ActionResult</code> with charged base execution fees is created there;</li>
<li>if action execution leads to new <code>ActionReceipt</code>s creation, corresponding <code>action_[action_name]</code> function adds new fees to the <code>ActionResult</code>. E.g. <code>action_delete_account</code> also charges the following fees:
<ul>
<li><code>gas_burnt</code>: <strong>send</strong> fee for <strong>new</strong> <code>ActionReceipt</code> creation + complex <strong>send</strong> fee for <code>Transfer</code> to beneficiary account</li>
<li><code>gas_used</code>: <code>gas_burnt</code> + <strong>exec</strong> fee for created <code>ActionReceipt</code> + complex <strong>exec</strong> fee for <code>Transfer</code></li>
</ul>
</li>
<li>all computed <code>ActionResult</code>s are merged into one, where all gas values are summed up;</li>
<li>unused gas is refunded in <code>generate_refund_receipts</code>, after subtracting the gas refund fee, see <a href="RuntimeSpec/Fees/../Refunds.html">Refunds</a>.</li>
</ul>
<p>Inside <code>VMLogic</code>, the fees are tracked in the <code>GasCounter</code> struct.
The VM itself is called in the <code>action_function_call</code> inside <code>Runtime</code>. When all actions are processed, the result is returned as a <code>VMOutcome</code>, which is later merged with <code>ActionResult</code>.</p>
<h1 id="example"><a class="header" href="#example">Example</a></h1>
<!-- cspell:ignore VGYT Fwya Wckywk Ejuz -->
<p>Let's say we have the following transaction:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>Transaction {
    signer_id: &quot;alice.near&quot;,
    public_key: &quot;2onVGYTFwyaGetWckywk92ngBiZeNpBeEjuzSznEdhRE&quot;,
    nonce: 23,
    receiver_id: &quot;lockup.alice.near&quot;,
    block_hash: &quot;3CwEMonK6MmKgjKePiFYgydbAvxhhqCPHKuDMnUcGGTK&quot;,
    actions: [
        Action::CreateAccount(CreateAccountAction {}),
        Action::Transfer(TransferAction {
            deposit: 100000000000000000000000000,
        }),
        Action::DeployContract(DeployContractAction {
            code: vec![/*&lt;...128000 bytes...&gt;*/],
        }),
        Action::FunctionCall(FunctionCallAction {
            method_name: &quot;new&quot;,
            args: b&quot;{\&quot;owner_id\&quot;: \&quot;alice.near\&quot;}&quot;.to_vec(),
            gas: 25000000000000,
            deposit: 0,
        }),
    ],
}
<span class="boring">}
</span></code></pre></pre>
<p>It has <code>signer_id != receiver_id</code> so it will use <code>send_not_sir</code> for send fees.</p>
<p>It contains 4 actions with 2 actions that requires to compute number of bytes.
We assume <code>code</code> in <code>DeployContractAction</code> contains <code>128000</code> bytes. And <code>FunctionCallAction</code> has
<code>method_name</code> with length of <code>3</code> and <code>args</code> length of <code>26</code>, so total of <code>29</code>.</p>
<p>First let's compute the amount that will be burned immediately for sending a receipt.</p>
<pre><code class="language-python">burnt_gas = \
    config.action_receipt_creation_config.send_not_sir + \
    config.action_creation_config.create_account_cost.send_not_sir + \
    config.action_creation_config.transfer_cost.send_not_sir + \
    config.action_creation_config.deploy_contract_cost.send_not_sir + \
    128000 * config.action_creation_config.deploy_contract_cost_per_byte.send_not_sir + \
    config.action_creation_config.function_call_cost.send_not_sir + \
    29 * config.action_creation_config.function_call_cost_per_byte.send_not_sir
</code></pre>
<p>Now, by using <code>burnt_gas</code>, we can calculate the total transaction fee</p>
<pre><code class="language-python">total_transaction_fee = burnt_gas + \
    config.action_receipt_creation_config.execution + \
    config.action_creation_config.create_account_cost.execution + \
    config.action_creation_config.transfer_cost.execution + \
    config.action_creation_config.deploy_contract_cost.execution + \
    128000 * config.action_creation_config.deploy_contract_cost_per_byte.execution + \
    config.action_creation_config.function_call_cost.execution + \
    29 * config.action_creation_config.function_call_cost_per_byte.execution
</code></pre>
<p>This <code>total_transaction_fee</code> is the amount of gas required to create a new receipt from the transaction.</p>
<p>NOTE: There are extra amounts required to prepay for deposit in <code>TransferAction</code> and gas in <code>FunctionCallAction</code>, but this is not part of the total transaction fee.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="function-call"><a class="header" href="#function-call">Function Call</a></h1>
<p>In this section we provide an explanation how the <code>FunctionCall</code> action execution works, what are
the inputs and what are the outputs. Suppose runtime received the following ActionReceipt:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>ActionReceipt {
     id: &quot;A1&quot;,
     signer_id: &quot;alice&quot;,
     signer_public_key: &quot;6934...e248&quot;,
     receiver_id: &quot;dex&quot;,
     predecessor_id: &quot;alice&quot;,
     input_data_ids: [],
     output_data_receivers: [],
     actions: [FunctionCall { gas: 100000, deposit: 100000u128, method_name: &quot;exchange&quot;, args: &quot;{arg1, arg2, ...}&quot;, ... }],
 }
<span class="boring">}
</span></code></pre></pre>
<h3 id="input_data_ids-to-promiseresults"><a class="header" href="#input_data_ids-to-promiseresults"><code>input_data_ids</code> to <code>PromiseResult</code>s</a></h3>
<p><code>ActionReceipt.input_data_ids</code> must be satisfied before execution (see
<a href="RuntimeSpec//RuntimeSpec/Receipts#receipt-matching">Receipt Matching</a>). Each of <code>ActionReceipt.input_data_ids</code> will be converted to
the <code>PromiseResult::Successful(Vec&lt;u8&gt;)</code> if <code>data_id.data</code> is <code>Some(Vec&lt;u8&gt;)</code> otherwise if
<code>data_id.data</code> is <code>None</code> promise will be <code>PromiseResult::Failed</code>.</p>
<h2 id="input-8"><a class="header" href="#input-8">Input</a></h2>
<p>The <code>FunctionCall</code> executes in the <code>receiver_id</code> account environment.</p>
<ul>
<li>a vector of <a href="RuntimeSpec/FunctionCall.html#input_data_ids-to-promiseresults">Promise Results</a> which can be accessed by a <code>promise_result</code>
import <a href="RuntimeSpec/Components/BindingsSpec/PromisesAPI.html">PromisesAPI</a> <code>promise_result</code>)</li>
<li>the original Transaction <code>signer_id</code>, <code>signer_public_key</code> data from the ActionReceipt (e.g.
<code>method_name</code>, <code>args</code>, <code>predecessor_id</code>, <code>deposit</code>, <code>prepaid_gas</code> (which is <code>gas</code> in
FunctionCall))</li>
<li>a general blockchain data (e.g. <code>block_index</code>, <code>block_timestamp</code>)</li>
<li>read data from the account storage</li>
</ul>
<p>A full list of the data available for the contract can be found in <a href="RuntimeSpec/Components/BindingsSpec/ContextAPI.html">Context
API</a> and <a href="RuntimeSpec/Components/BindingsSpec/TrieAPI.html">Trie</a></p>
<h2 id="execution"><a class="header" href="#execution">Execution</a></h2>
<p>In order to implement this action, the runtime will:</p>
<ul>
<li>load the contract code from the <code>receiver_id</code> <a href="RuntimeSpec/../DataStructures/Account.html#account">account</a>â€™s
storage;</li>
<li>parse, validate and instrument the contract code (see <a href="RuntimeSpec/./Preparation.html">Preparation</a>);</li>
<li>optionally, convert the contract code to a different executable format;</li>
<li>instantiate the WASM module, linking runtime-provided functions defined in the
<a href="RuntimeSpec/Components/BindingsSpec/BindingsSpec.html">Bindings Spec</a> &amp; running the start function; and</li>
<li>invoke the function that has been exported from the wasm module with the name matching
that specified in the <code>FunctionCall.method_name</code> field.</li>
</ul>
<p>Note that some of these steps may be executed during the
<a href="RuntimeSpec/./Actions.html#deploycontractaction"><code>DeployContractAction</code></a> instead. This is largely an
optimization of the <code>FunctionCall</code> gas fee, and must not result in an observable behavioral
difference of the <code>FunctionCall</code> action.</p>
<p>During the execution of the contract, the runtime will:</p>
<ul>
<li>count burnt gas on execution;</li>
<li>count used gas (which is <code>burnt gas</code> + gas attached to the new created receipts);</li>
<li>measure the increase in accountâ€™s storage usage as a result of this call;</li>
<li>collect logs produced by the contract;</li>
<li>set the return data; and</li>
<li>create new receipts through <a href="RuntimeSpec/Components/BindingsSpec/PromisesAPI.html">PromisesAPI</a>.</li>
</ul>
<h2 id="output-5"><a class="header" href="#output-5">Output</a></h2>
<p>The output of the <code>FunctionCall</code>:</p>
<ul>
<li>storage updates - changes to the account trie storage which will be applied on a successful call</li>
<li><code>burnt_gas</code>, <code>used_gas</code> - see <a href="RuntimeSpec/Fees/Fees.html">Runtime Fees</a></li>
<li><code>balance</code> - unspent account balance (account balance could be spent on deposits of newly created
<code>FunctionCall</code>s or <a href="RuntimeSpec/Actions.html#transferaction"><code>TransferAction</code>s</a> to other contracts)</li>
<li><code>storage_usage</code> - storage_usage after ActionReceipt application</li>
<li><code>logs</code> - during contract execution, utf8/16 string log records could be created. Logs are not
persistent currently.</li>
<li><code>new_receipts</code> - new <code>ActionReceipts</code> created during the execution. These receipts are going to
be sent to the respective <code>receiver_id</code>s (see <a href="RuntimeSpec//RuntimeSpec/Receipts#receipt-matching">Receipt Matching explanation</a>)</li>
<li>result could be either <a href="RuntimeSpec/FunctionCall.html#value-result"><code>ReturnData::Value(Vec&lt;u8&gt;)</code></a> or
<a href="RuntimeSpec/FunctionCall.html#receiptindex-result"><code>ReturnData::ReceiptIndex(u64)</code></a>`</li>
</ul>
<h3 id="value-result"><a class="header" href="#value-result">Value Result</a></h3>
<p>If applied <code>ActionReceipt</code> contains <a href="RuntimeSpec/Receipts.html#output_data_receivers"><code>output_data_receivers</code></a>,
runtime will create <code>DataReceipt</code> for each of <code>data_id</code> and <code>receiver_id</code> and <code>data</code> equals
returned value. Eventually, these <code>DataReceipt</code> will be delivered to the corresponding receivers.</p>
<h3 id="receiptindex-result"><a class="header" href="#receiptindex-result">ReceiptIndex Result</a></h3>
<p>Successful result could not return any Value, but generates a bunch of new ActionReceipts instead.
One example could be a callback. In this case, we assume the new Receipt will send its Value
Result to the <a href="RuntimeSpec/Receipts.html#output_data_receivers"><code>output_data_receivers</code></a> of the current
<code>ActionReceipt</code>.</p>
<h3 id="errors-8"><a class="header" href="#errors-8">Errors</a></h3>
<p>As with other actions, errors can be divided into two categories: validation error and execution
error.</p>
<h4 id="validation-error"><a class="header" href="#validation-error">Validation Error</a></h4>
<ul>
<li>
<p>If there is zero gas attached to the function call, a</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// The attached amount of gas in a FunctionCall action has to be a positive number.
FunctionCallZeroAttachedGas,
<span class="boring">}
</span></code></pre></pre>
<p>error will be returned</p>
</li>
<li>
<p>If the length of the method name to be called exceeds <code>max_length_method_name</code>, a genesis
parameter whose current value is <code>256</code>, a</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// The length of the method name exceeded the limit in a Function Call action.
FunctionCallMethodNameLengthExceeded { length: u64, limit: u64 }
<span class="boring">}
</span></code></pre></pre>
<p>error is returned.</p>
</li>
<li>
<p>If the length of the argument to the function call exceeds <code>max_arguments_length</code>, a genesis
parameter whose current value is <code>4194304</code> (4MB), a</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// The length of the arguments exceeded the limit in a Function Call action.
FunctionCallArgumentsLengthExceeded { length: u64, limit: u64 }
<span class="boring">}
</span></code></pre></pre>
<p>error is returned.</p>
</li>
</ul>
<h4 id="execution-error"><a class="header" href="#execution-error">Execution Error</a></h4>
<p>There are three types of errors which may occur when applying a function call action:
<code>FunctionCallError</code>, <code>ExternalError</code>, and <code>StorageError</code>.</p>
<ul>
<li>
<p><code>FunctionCallError</code> includes everything from around the execution of the wasm binary,
from compiling wasm to native to traps occurred while executing the compiled native binary. More specifically,
it includes the following errors:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum FunctionCallError {
    /// Wasm compilation error
    CompilationError(CompilationError),
    /// Wasm binary env link error
    LinkError {
        msg: String,
    },
    /// Import/export resolve error
    MethodResolveError(MethodResolveError),
    /// A trap happened during execution of a binary
    WasmTrap(WasmTrap),
    WasmUnknownError,
    HostError(HostError),
}
<span class="boring">}
</span></code></pre></pre>
</li>
<li>
<p><code>CompilationError</code> includes errors that can occur during the compilation of wasm binary.</p>
</li>
<li>
<p><code>LinkError</code> is returned when wasmer runtime is unable to link the wasm module with provided imports.</p>
</li>
<li>
<p><code>MethodResolveError</code> occurs when the method in the action cannot be found in the contract code.</p>
</li>
<li>
<p><code>WasmTrap</code> error happens when a trap occurs during the execution of the binary. Traps here include</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum WasmTrap {
    /// An `unreachable` opcode was executed.
    Unreachable,
    /// Call indirect incorrect signature trap.
    IncorrectCallIndirectSignature,
    /// Memory out of bounds trap.
    MemoryOutOfBounds,
    /// Call indirect out of bounds trap.
    CallIndirectOOB,
    /// An arithmetic exception, e.g. divided by zero.
    IllegalArithmetic,
    /// Misaligned atomic access trap.
    MisalignedAtomicAccess,
    /// Breakpoint trap.
    BreakpointTrap,
    /// Stack overflow.
    StackOverflow,
    /// Generic trap.
    GenericTrap,
}
<span class="boring">}
</span></code></pre></pre>
</li>
<li>
<p><code>WasmUnknownError</code> occurs when something inside wasmer goes wrong</p>
</li>
<li>
<p><code>HostError</code> includes errors that might be returned during the execution of a host function. Those errors are</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum HostError {
    /// String encoding is bad UTF-16 sequence
    BadUTF16,
    /// String encoding is bad UTF-8 sequence
    BadUTF8,
    /// Exceeded the prepaid gas
    GasExceeded,
    /// Exceeded the maximum amount of gas allowed to burn per contract
    GasLimitExceeded,
    /// Exceeded the account balance
    BalanceExceeded,
    /// Tried to call an empty method name
    EmptyMethodName,
    /// Smart contract panicked
    GuestPanic { panic_msg: String },
    /// IntegerOverflow happened during a contract execution
    IntegerOverflow,
    /// `promise_idx` does not correspond to existing promises
    InvalidPromiseIndex { promise_idx: u64 },
    /// Actions can only be appended to non-joint promise.
    CannotAppendActionToJointPromise,
    /// Returning joint promise is currently prohibited
    CannotReturnJointPromise,
    /// Accessed invalid promise result index
    InvalidPromiseResultIndex { result_idx: u64 },
    /// Accessed invalid register id
    InvalidRegisterId { register_id: u64 },
    /// Iterator `iterator_index` was invalidated after its creation by performing a mutable operation on trie
    IteratorWasInvalidated { iterator_index: u64 },
    /// Accessed memory outside the bounds
    MemoryAccessViolation,
    /// VM Logic returned an invalid receipt index
    InvalidReceiptIndex { receipt_index: u64 },
    /// Iterator index `iterator_index` does not exist
    InvalidIteratorIndex { iterator_index: u64 },
    /// VM Logic returned an invalid account id
    InvalidAccountId,
    /// VM Logic returned an invalid method name
    InvalidMethodName,
    /// VM Logic provided an invalid public key
    InvalidPublicKey,
    /// `method_name` is not allowed in view calls
    ProhibitedInView { method_name: String },
    /// The total number of logs will exceed the limit.
    NumberOfLogsExceeded { limit: u64 },
    /// The storage key length exceeded the limit.
    KeyLengthExceeded { length: u64, limit: u64 },
    /// The storage value length exceeded the limit.
    ValueLengthExceeded { length: u64, limit: u64 },
    /// The total log length exceeded the limit.
    TotalLogLengthExceeded { length: u64, limit: u64 },
    /// The maximum number of promises within a FunctionCall exceeded the limit.
    NumberPromisesExceeded { number_of_promises: u64, limit: u64 },
    /// The maximum number of input data dependencies exceeded the limit.
    NumberInputDataDependenciesExceeded { number_of_input_data_dependencies: u64, limit: u64 },
    /// The returned value length exceeded the limit.
    ReturnedValueLengthExceeded { length: u64, limit: u64 },
    /// The contract size for DeployContract action exceeded the limit.
    ContractSizeExceeded { size: u64, limit: u64 },
    /// The host function was deprecated.
    Deprecated { method_name: String },
}
<span class="boring">}
</span></code></pre></pre>
</li>
<li>
<p><code>ExternalError</code> includes errors that occur during the execution inside <code>External</code>, which is an interface between runtime
and the rest of the system. The possible errors are:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum ExternalError {
    /// Unexpected error which is typically related to the node storage corruption.
    /// It's possible the input state is invalid or malicious.
    StorageError(StorageError),
    /// Error when accessing validator information. Happens inside epoch manager.
    ValidatorError(EpochError),
}
<span class="boring">}
</span></code></pre></pre>
</li>
<li>
<p><code>StorageError</code> occurs when state or storage is corrupted.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="contract-preparation"><a class="header" href="#contract-preparation">Contract preparation</a></h1>
<p>This document describes the contract preparation and instrumentation process as well as the
limitations this process imposes on the contract authors.</p>
<p>In order to provide high performance execution of the <a href="RuntimeSpec/./FunctionCall.html">function calls</a>, the near validator utilizes
ahead-of-time preparation of the contract WASM code. Today the contract code is prepared during the
execution of the <a href="RuntimeSpec/./Actions.html#deploycontractaction"><code>DeployContractAction</code></a>. The results are then saved and later reported to the
user when a [<code>FunctionCall</code>] is invoked.</p>
<p>Note that only some parts of this document are normative. This document delves into implementation
details, which may change in the future as long as the behavior documented by the normative
portions of this book is maintained. The non-normative portions of this document will be called out
as such.</p>
<h2 id="high-level-overview"><a class="header" href="#high-level-overview">High level overview</a></h2>
<p><strong>This section is not normative.</strong></p>
<p>Upon initiation of a contract deployment, broadly the following operations will be executed:
validation, instrumentation, conversion to machine code (compilation) and storage of the compiled
artifacts in the accountâ€™s storage.</p>
<p>Functions exported from the contract module may then be invoked through the mechanisms provided
by the protocol. Two common ways to call a function is by submitting a function call action onto
the chain or via a cross-contract call.</p>
<p>Most of the errors that have occurred as part of validation, instrumentation, compilation, etc. are
saved and reported when a <code>FunctionCallAction</code> is submitted. Deployment itself may only report
errors relevant to itself, as described in the specification for <a href="RuntimeSpec/./Actions.html#deploycontractaction"><code>DeployContractAction</code></a>.</p>
<h2 id="validation"><a class="header" href="#validation">Validation</a></h2>
<p>A number of limits are imposed on the WebAssembly module that is being parsed:</p>
<ul>
<li>The length of the wasm code must not exceed <code>max_contract_size</code> genesis configuration parameter;</li>
<li>The wasm module must be a valid module according to the WebAssembly core 1.0 specification (this
means no extensions such as multi value returns or SIMD; this limitation may be relaxed in the
future).</li>
<li>The wasm module may contain no more than:
<ul>
<li><code>1_000_000</code> distinct signatures;</li>
<li><code>1_000_000</code> function imports and local function definitions;</li>
<li><code>100_000</code> imports;</li>
<li><code>100_000</code> exports;</li>
<li><code>1_000_000</code> global imports and module-local global definitions;</li>
<li><code>100_000</code> data segments;</li>
<li><code>1</code> table;</li>
<li><code>1</code> memory;</li>
</ul>
</li>
<li>UTF-8 strings comprising the wasm module definition (e.g. export name) may not exceed <code>100_000</code>
bytes each;</li>
<li>Function definitions may not specify more than <code>50_000</code> locals;</li>
<li>Signatures may not specify more than <code>1_000</code> parameters;</li>
<li>Signatures may not specify more than <code>1_000</code> results;</li>
<li>Tables may not specify more than <code>10_000_000</code> entries;</li>
</ul>
<p>If the contract code is invalid, the first violation in the binary encoding of the WebAssembly
module shall be reported. These additional requirements are imposed after the module is parsed:</p>
<ul>
<li>The wasm module may contain no more function imports and local definitions than specified in the
<code>max_functions_number_per_contract</code> genesis configuration parameter; and</li>
</ul>
<p>These additional requirements are imposed after the instrumentation, as documented in the later
sections:</p>
<ul>
<li>All imports may only import from the <code>env</code> module.</li>
</ul>
<h2 id="memory-normalization"><a class="header" href="#memory-normalization">Memory normalization</a></h2>
<p>All near contracts have the same amount of memory made available for execution. The exact amount is
specified specified by the <code>initial_memory_pages</code> and <code>max_memory_pages</code> genesis configuration
parameters. In order to ensure a level playing field, any module-local memory definitions are
transparently replaced with an import of a standard memory instance from <code>env.memory</code>.</p>
<p>If the original memory instance definition specified limits different from those specified by the
genesis configuration parameters, the limits are reset to the configured parameters.</p>
<h2 id="gas-instrumentation"><a class="header" href="#gas-instrumentation">Gas instrumentation</a></h2>
<p>In order to implement precise and efficient gas accounting, the contract code is analyzed and
instrumented with additional operations before the compilation occurs. One such instrumentation
implements accounting of the gas fees.</p>
<p>Gas fees are accounted for at a granularity of sequences of instructions forming a metered block
and are consumed before execution of any instruction part of such a sequence. The accounting
mechanism verifies the remaining gas is sufficient, and subtracts the gas fee from the remaining
gas budget before continuing execution. In the case where the remaining gas balance is insufficient
to continue execution, the <code>GasExceeded</code> error is raised and execution of the contract is
terminated.</p>
<p>The gas instrumentation analysis will segment a wasm function into metered blocks. In the end,
every instruction will belong to exactly one metered block. The algorithm uses a stack of metered
blocks and instructions are assigned to the metered block on top of the stack. The following
terminology will be used throughout this section to refer to metered block operations:</p>
<ul>
<li>active metered block â€“ the metered block at the top of the stack;</li>
<li>pop â€“ the active metered block is removed from the top of the stack;</li>
<li>push â€“ a new metered block is added to the stack, becoming the new active metered block.</li>
</ul>
<p>A metered block is pushed onto the stack upon a function entry and after every <code>if</code> and <code>loop</code>
instruction. After the <code>br</code>, <code>br_if</code>, <code>br_table</code>, <code>else</code> &amp; <code>return</code> (pseudo-)instructions the
active metered block is popped and a new metered block is pushed onto the stack.</p>
<p>The <code>end</code> pseudo-instruction associated with the <code>if</code> &amp; <code>loop</code> instructions, or when it terminates
the function body, will cause the top-most metered block to be popped off the stack. As a
consequence, the instructions within a metered block need not be consecutive in the original
function. If the <code>if..end</code>, <code>loop..end</code> or <code>block..end</code> control block terminated by this <code>end</code>
pseudo-instruction contained any branching instructions targeting control blocks other than the
control block terminated by this <code>end</code> pseudo instruction, the currently active metered block is
popped and a new metered block is pushed.</p>
<p>Note that some of the instructions considered to affect the control flow in the WebAssembly
specification such as <code>call</code>, <code>call_indirect</code> or <code>unreachable</code> do not affect metered block
construction and are accounted for much like other instructions not mentioned in this section. This
also means that calling the <code>used_gas</code> host function at different points of the same metered block
would return the same value if the <code>base</code> cost was <code>0</code>.</p>
<p>All the instructions covered by a metered block are assigned a fee based on the <code>regular_op_cost</code>
genesis parameter. Pseudo-instructions do not cause any fee to be charged. A sum of these fees is
then charged by instrumentation inserted at the beginning of each metered block.</p>
<h3 id="examples-1"><a class="header" href="#examples-1">Examples</a></h3>
<p><strong>This section is not normative.</strong></p>
<p>In this section some examples of the instrumentation are presented as an understanding aid to the
specification above. The examples are annotated with comments describing how much gas is charged at
a specific point of the program. The programs presented here are not intended to be executable or
to produce meaningful behavior.</p>
<h4 id="block-instruction-does-not-terminate-a-metered-block"><a class="header" href="#block-instruction-does-not-terminate-a-metered-block"><code>block</code> instruction does not terminate a metered block</a></h4>
<pre><code class="language-wat">(func
  (; charge_gas(6 regular_op_cost) ;)
  nop
  block
    nop
    unreachable
    nop
  end
  nop)
</code></pre>
<p>This function has just 1 metered block, covering both the <code>block..end</code> block as well as the 2 <code>nop</code>
instructions outside of it. As a result the gas fee for all 6 instructions will be charged at the
beginning of the function (even if we can see <code>unreachable</code> would be executed after 4 instructions,
terminating the execution).</p>
<h4 id="branching-instructions-pop-a-metered-block"><a class="header" href="#branching-instructions-pop-a-metered-block">Branching instructions pop a metered block</a></h4>
<p>Introducing a conditional branch to the example from the previous section would split the metered
block and the gas accounting would be introduced in two locations:</p>
<pre><code class="language-wat">(func
  (; charge_gas([nop block br.0 nop]) ;)
  nop
  block
    br 0
    (; charge_gas([nop nop]) ;)
    nop
    nop
  end
  nop)
</code></pre>
<p>Note that the first metered block is disjoint and covers the <code>[nop, block, br 0]</code> instruction
sequence as well as the final <code>nop</code>. The analysis is able to deduce that the <code>br 0</code> will not be
able to jump past the final <code>nop</code> instruction, and therefore is able to account for the gas fees
incurred by this instruction earlier.</p>
<p>Replacing <code>br 0</code> with a <code>return</code> would enable jumping past this final <code>nop</code> instruction, splitting
the code into three distinct metered blocks instead:</p>
<pre><code class="language-wat">(func
  (; charge_gas([nop block return]) ;)
  nop
  block
    return
    (; charge_gas([nop nop]) ;)
    nop
    nop
  end
  (; charge_gas([nop]) ;)
  nop)
</code></pre>
<h4 id="if-and-loop-push-a-new-metered-block"><a class="header" href="#if-and-loop-push-a-new-metered-block"><code>if</code> and <code>loop</code> push a new metered block</a></h4>
<pre><code class="language-wat">(func
  (; charge_gas([loop unreachable]) ;)
  loop
    (; charge_gas([br 0]) ;)
    br 0
  end
  unreachable
)
</code></pre>
<p>In this example the <code>loop</code> instruction will always introduce a new nested metered block for its
body, for the <code>end</code> pseudo-instruction as well as <code>br 0</code> cause a backward jump back to the
beginning of the loop body. A similar reasoning works for <code>if .. else .. end</code> sequence since the
body is only executed conditionally:</p>
<pre><code class="language-wat">(func
  (; charge_gas([i32.const.42 if nop]) ;)
  i32.const 42
  if
    (; charge_gas([nop nop]) ;)
    nop
    nop
  else
    (; charge_gas([unreachable]) ;)
    unreachable
  end
  nop)
</code></pre>
<h2 id="operand-stack-depth-instrumentation"><a class="header" href="#operand-stack-depth-instrumentation">Operand stack depth instrumentation</a></h2>
<p>The <code>max_stack_height</code> genesis parameter imposes a limit on the number of entries the wasm
operand stack may contain during the contract execution.</p>
<p>The maximum operand stack height required for a function to execute successfully is computed
statically by simulating the operand stack operations executed by each instruction. For example,
<code>i32.const 1</code> pushes 1 entry on the operand stack, whereas <code>i32.add</code> pops two entries and pushes 1
entry containing the result value. The maximum operand stack height of the <code>if..else..end</code> control
block is the larger of the heights for two bodies of the conditional. Stack operations for each
instruction are otherwise specified in the section 4 of the WebAssembly core 1.0 specification.</p>
<p>Before the <code>call</code> or <code>call_indirect</code> instructions are executed, the callee's required stack is
added to the current stack height counter and is compared with the <code>max_stack_height</code> parameter. A
trap is raised if the counter exceeds the limit. The instruction is executed, otherwise.</p>
<p>Note that the stack depth instrumentation runs after the gas instrumentation. At each point where
gas is charged one entry worth of operand stack space is considered to be used.</p>
<h3 id="examples-2"><a class="header" href="#examples-2">Examples</a></h3>
<p><strong>This section is not normative.</strong></p>
<p>Picking the example from the gas instrumentation section, we can tell that this function will use
just 1 operand slot. Lets annotate the operand stack operations at each of the instructions:</p>
<pre><code class="language-wat">(func
  (; charge_gas(...) ;)    (; [] =&gt; [gas] =&gt; [] ;)
  i32.const 42             (; [] =&gt; [i32]       ;)
  if                       (; [i32] =&gt; []       ;)
    (; charge_gas(...) ;)    (; [] =&gt; [gas] =&gt; [] ;)
    nop                      (; []                ;)
    nop                      (; []                ;)
  else
    (; charge_gas(...) ;)    (; [] =&gt; [gas] =&gt; [] ;)
    unreachable              (; []                ;)
  end
  nop                      (; [] ;)
)
</code></pre>
<p>We can see that at no point in time the operand stack contained more than 1 entry. As a result,
the runtime will check that 1 entry is available in the operand stack before the function is
invoked.</p>
<!-- TODO: describe the ahead-of-time compilation details and the errors it may cause or limits it
     may impose -->
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="receipt"><a class="header" href="#receipt">Receipt</a></h1>
<p>All cross-contract (we assume that each account lives in its own shard) communication in Near happens through Receipts.</p>
<p>Receipts are stateful in a sense that they serve not only as messages between accounts but also can be stored in the account storage to await DataReceipts.</p>
<p>Each receipt has a <a href="RuntimeSpec/Receipts.html#predecessor_id"><code>predecessor_id</code></a> (who sent it) and <a href="RuntimeSpec/Receipts.html#receiver_id"><code>receiver_id</code></a> the current account.</p>
<p>Receipts are one of 2 types: action receipts or data receipts.</p>
<p>Data Receipts are receipts that contains some data for some <code>ActionReceipt</code> with the same <code>receiver_id</code>.
Data Receipts have 2 fields: the unique data identifier <code>data_id</code> and <code>data</code> the received result.
<code>data</code> is an <code>Option</code> field and it indicates whether the result was a success or a failure. If it's <code>Some</code>, it means
the remote execution was successful and it represents the result as a vector of bytes.</p>
<p>Each <code>ActionReceipt</code> also contains fields related to data:</p>
<ul>
<li><a href="RuntimeSpec/Receipts.html#input_data_ids"><code>input_data_ids</code></a> - a vector of input data with the <code>data_id</code>s required for the execution of this receipt.</li>
<li><a href="RuntimeSpec/Receipts.html#output_data_receivers"><code>output_data_receivers</code></a> - a vector of output data receivers. It indicates where to send outgoing data.
Each <code>DataReceiver</code> consists of <code>data_id</code> and <code>receiver_id</code> for routing.</li>
</ul>
<p>Before any action receipt is executed, all input data dependencies need to be satisfied.
Which means all corresponding data receipts have to be received.
If any of the data dependencies are missing, the action receipt is postponed until all missing data dependencies arrive.</p>
<p>Because chain and runtime guarantees that no receipts are missing, we can rely that every action receipt will be executed eventually (<a href="RuntimeSpec/Receipts.html#receipt-matching">Receipt Matching explanation</a>).</p>
<p>Each <code>Receipt</code> has the following fields:</p>
<h4 id="predecessor_id"><a class="header" href="#predecessor_id">predecessor_id</a></h4>
<ul>
<li><strong><code>type</code></strong>: <code>AccountId</code></li>
</ul>
<p>The account_id which issued a receipt.
In case of a gas or deposit refund, the account ID is <code>system</code>.</p>
<h4 id="receiver_id"><a class="header" href="#receiver_id">receiver_id</a></h4>
<ul>
<li><strong><code>type</code></strong>: <code>AccountId</code></li>
</ul>
<p>The destination account_id.</p>
<h4 id="receipt_id"><a class="header" href="#receipt_id">receipt_id</a></h4>
<ul>
<li><strong><code>type</code></strong>: <code>CryptoHash</code></li>
</ul>
<p>An unique id for the receipt.</p>
<h4 id="receipt-1"><a class="header" href="#receipt-1">receipt</a></h4>
<ul>
<li><strong><code>type</code></strong>: <a href="RuntimeSpec/Receipts.html#actionreceipt">ActionReceipt</a> | <a href="RuntimeSpec/Receipts.html#datareceipt">DataReceipt</a></li>
</ul>
<p>There are 2 types of Receipt: <a href="RuntimeSpec/Receipts.html#actionreceipt">ActionReceipt</a> and <a href="RuntimeSpec/Receipts.html#datareceipt">DataReceipt</a>. An <code>ActionReceipt</code> is a request to apply <a href="RuntimeSpec/Actions.html">Actions</a>, while a <code>DataReceipt</code> is a result of the application of these actions.</p>
<h2 id="actionreceipt"><a class="header" href="#actionreceipt">ActionReceipt</a></h2>
<p><code>ActionReceipt</code> represents a request to apply actions on the <code>receiver_id</code> side. It could be derived as a result of a <code>Transaction</code> execution or another <code>ActionReceipt</code> processing. <code>ActionReceipt</code> consists the following fields:</p>
<h4 id="signer_id"><a class="header" href="#signer_id">signer_id</a></h4>
<ul>
<li><strong><code>type</code></strong>: <code>AccountId</code></li>
</ul>
<p>An account_id which signed the original <a href="RuntimeSpec/Transactions.html">transaction</a>.
In case of a deposit refund, the account ID is <code>system</code>.</p>
<h4 id="signer_public_key"><a class="header" href="#signer_public_key">signer_public_key</a></h4>
<ul>
<li><strong><code>type</code></strong>: <code>PublicKey</code></li>
</ul>
<p>The public key of an <a href="RuntimeSpec/../DataStructures/AccessKey.html">AccessKey</a> which was used to sign the original transaction.
In case of a deposit refund, the public key is empty (all bytes are 0).</p>
<h4 id="gas_price"><a class="header" href="#gas_price">gas_price</a></h4>
<ul>
<li><strong><code>type</code></strong>: <code>u128</code></li>
</ul>
<p>Gas price which was set in a block where the original <a href="RuntimeSpec/Transactions.html">transaction</a> has been applied.</p>
<h4 id="output_data_receivers"><a class="header" href="#output_data_receivers">output_data_receivers</a></h4>
<ul>
<li><strong><code>type</code></strong>: <code>[DataReceiver{ data_id: CryptoHash, receiver_id: AccountId }]</code></li>
</ul>
<p>If smart contract finishes its execution with some value (not Promise), runtime creates a [<code>DataReceipt</code>]s for each of the <code>output_data_receivers</code>.</p>
<h4 id="input_data_ids"><a class="header" href="#input_data_ids">input_data_ids</a></h4>
<ul>
<li><strong><code>type</code></strong>: <code>[CryptoHash]_</code></li>
</ul>
<p><code>input_data_ids</code> are the receipt data dependencies. <code>input_data_ids</code> correspond to <code>DataReceipt.data_id</code>.</p>
<h4 id="actions-1"><a class="header" href="#actions-1">actions</a></h4>
<ul>
<li><strong><code>type</code></strong>: <a href="RuntimeSpec/Actions.html#functioncallaction"><code>FunctionCall</code></a> | <a href="RuntimeSpec/Actions.html#transferaction"><code>TransferAction</code></a> | <a href="RuntimeSpec/Actions.html#stakeaction"><code>StakeAction</code></a> | <a href="RuntimeSpec/Actions.html#addkeyaction"><code>AddKeyAction</code></a> | <a href="RuntimeSpec/Actions.html#deletekeyaction"><code>DeleteKeyAction</code></a> | <a href="RuntimeSpec/Actions.html#createaccountaction"><code>CreateAccountAction</code></a> | <a href="RuntimeSpec/Actions.html#deleteaccountaction"><code>DeleteAccountAction</code></a></li>
</ul>
<h2 id="datareceipt"><a class="header" href="#datareceipt">DataReceipt</a></h2>
<p><code>DataReceipt</code> represents a final result of some contract execution.</p>
<h4 id="data_id"><a class="header" href="#data_id">data_id</a></h4>
<ul>
<li><strong><code>type</code></strong>: <code>CryptoHash</code></li>
</ul>
<p>A unique <code>DataReceipt</code> identifier.</p>
<h4 id="data"><a class="header" href="#data">data</a></h4>
<ul>
<li><strong><code>type</code></strong>: <code>Option([u8])</code></li>
</ul>
<p>Associated data in bytes. <code>None</code> indicates an error during execution.</p>
<h2 id="creating-receipt"><a class="header" href="#creating-receipt">Creating Receipt</a></h2>
<p>Receipts can be generated during the execution of a <a href="RuntimeSpec//RuntimeSpec/Transactions#signed-transaction">SignedTransaction</a> (see <a href="RuntimeSpec/./Scenarios/FinancialTransaction.html">example</a>) or during application of some <code>ActionReceipt</code> which contains a <a href="RuntimeSpec/Receipts.html#actions"><code>FunctionCall</code></a> action. The result of the <code>FunctionCall</code> could be either another <code>ActionReceipt</code> or a <code>DataReceipt</code> (returned data).</p>
<h2 id="receipt-matching"><a class="header" href="#receipt-matching">Receipt Matching</a></h2>
<p>Runtime doesn't require that Receipts come in a particular order. Each Receipt is processed individually. The goal of the <code>Receipt Matching</code> process is to match all <a href="RuntimeSpec/Receipts.html#actionreceipt"><code>ActionReceipt</code>s</a> to the corresponding <a href="RuntimeSpec/Receipts.html#datareceipt"><code>DataReceipt</code>s</a>.</p>
<h2 id="processing-actionreceipt"><a class="header" href="#processing-actionreceipt">Processing ActionReceipt</a></h2>
<p>For each incoming <a href="RuntimeSpec/Receipts.html#actionreceipt"><code>ActionReceipt</code></a> runtime checks whether we have all the <a href="RuntimeSpec/Receipts.html#datareceipt"><code>DataReceipt</code>s</a> (defined as <a href="RuntimeSpec/Receipts.html#input_data_ids"><code>ActionsReceipt.input_data_ids</code></a>) required for execution. If all the required <a href="RuntimeSpec/Receipts.html#datareceipt"><code>DataReceipt</code>s</a> are already in the <a href="RuntimeSpec/Receipts.html#received-datareceipt">storage</a>, runtime can apply this <code>ActionReceipt</code> immediately. Otherwise we save this receipt as a <a href="RuntimeSpec/Receipts.html#postponed-actionreceipt">Postponed ActionReceipt</a>. Also we save <a href="RuntimeSpec/Receipts.html#pending-datareceipt-count">Pending DataReceipts Count</a> and <a href="RuntimeSpec/Receipts.html#pending-datareceipt-for-postponed-actionreceipt">a link from pending <code>DataReceipt</code> to the <code>Postponed ActionReceipt</code></a>. Now runtime will wait for all the missing <code>DataReceipt</code>s to apply the <code>Postponed ActionReceipt</code>.</p>
<h4 id="postponed-actionreceipt"><a class="header" href="#postponed-actionreceipt">Postponed ActionReceipt</a></h4>
<p>A Receipt which runtime stores until all the designated <a href="RuntimeSpec/Receipts.html#datareceipt"><code>DataReceipt</code>s</a> arrive.</p>
<ul>
<li><strong><code>key</code></strong> = <code>account_id</code>,<code>receipt_id</code></li>
<li><strong><code>value</code></strong> = <code>[u8]</code></li>
</ul>
<p><em>Where <code>account_id</code> is <a href="RuntimeSpec/Receipts.html#receiver_id"><code>Receipt.receiver_id</code></a>, <code>receipt_id</code> is <a href="RuntimeSpec/Receipts.html#receipt_id"><code>Receipt.receipt_id</code></a> and value is a serialized <a href="RuntimeSpec/Receipts.html#receipt-1"><code>Receipt</code></a> (which type must be <a href="RuntimeSpec/Receipts.html#actionreceipt">ActionReceipt</a>).</em></p>
<h4 id="pending-datareceipt-count"><a class="header" href="#pending-datareceipt-count">Pending DataReceipt Count</a></h4>
<p>A counter which counts pending <a href="RuntimeSpec/Receipts.html#datareceipt"><code>DataReceipt</code>s</a> for a <a href="RuntimeSpec/Receipts.html#postponed-actionreceipt">Postponed Receipt</a> initially set to the length of missing <a href="RuntimeSpec/Receipts.html#input_data_ids"><code>input_data_ids</code></a> of the incoming <code>ActionReceipt</code>. It's decrementing with every new received <a href="RuntimeSpec/Receipts.html#datareceipt"><code>DataReceipt</code></a>:</p>
<ul>
<li><strong><code>key</code></strong> = <code>account_id</code>,<code>receipt_id</code></li>
<li><strong><code>value</code></strong> = <code>u32</code></li>
</ul>
<p><em>Where <code>account_id</code> is AccountId, <code>receipt_id</code> is CryptoHash and value is an integer.</em></p>
<h4 id="pending-datareceipt-for-postponed-actionreceipt"><a class="header" href="#pending-datareceipt-for-postponed-actionreceipt">Pending DataReceipt for Postponed ActionReceipt</a></h4>
<p>We index each pending <code>DataReceipt</code> so when a new <a href="RuntimeSpec/Receipts.html#datareceipt"><code>DataReceipt</code></a> arrives we connect it to the <a href="RuntimeSpec/Receipts.html#postponed-actionreceipt">Postponed Receipt</a> it belongs to.</p>
<ul>
<li><strong><code>key</code></strong> = <code>account_id</code>,<code>data_id</code></li>
<li><strong><code>value</code></strong> = <code>receipt_id</code></li>
</ul>
<h2 id="processing-datareceipt"><a class="header" href="#processing-datareceipt">Processing DataReceipt</a></h2>
<h4 id="received-datareceipt"><a class="header" href="#received-datareceipt">Received DataReceipt</a></h4>
<p>First of all, runtime saves the incoming <code>DataReceipt</code> to the storage as:</p>
<ul>
<li><strong><code>key</code></strong> = <code>account_id</code>,<code>data_id</code></li>
<li><strong><code>value</code></strong> = <code>[u8]</code></li>
</ul>
<p><em>Where <code>account_id</code> is <a href="RuntimeSpec/Receipts.html#receiver_id"><code>Receipt.receiver_id</code></a>, <code>data_id</code> is <a href="RuntimeSpec/Receipts.html#data_id"><code>DataReceipt.data_id</code></a> and value is a <a href="RuntimeSpec/Receipts.html#data"><code>DataReceipt.data</code></a> (which is typically a serialized result of the call to a particular contract).</em></p>
<p>Next, runtime checks if there are any <a href="RuntimeSpec/Receipts.html#postponed-actionreceipt"><code>Postponed ActionReceipt</code></a> waiting for this <code>DataReceipt</code> by querying <a href="RuntimeSpec/Receipts.html#pending-datareceipt-for-postponed-actionreceipt"><code>Pending DataReceipt</code> to the Postponed Receipt</a>. If there is no postponed <code>receipt_id</code> yet, we do nothing else. If there is a postponed <code>receipt_id</code>, we do the following:</p>
<ul>
<li>decrement <a href="RuntimeSpec/Receipts.html#pending-datareceipt-count"><code>Pending Data Count</code></a> for the postponed <code>receipt_id</code></li>
<li>remove found <a href="RuntimeSpec/Receipts.html#pending-datareceipt-for-postponed-actionreceipt"><code>Pending DataReceipt</code> to the <code>Postponed ActionReceipt</code></a></li>
</ul>
<p>If <a href="RuntimeSpec/Receipts.html#pending-datareceipt-count"><code>Pending DataReceipt Count</code></a> is now 0 that means all the <a href="RuntimeSpec/Receipts.html#input_data_ids"><code>Receipt.input_data_ids</code></a> are in storage and runtime can safely apply the <a href="RuntimeSpec/Receipts.html#postponed-actionreceipt">Postponed Receipt</a> and remove it from the store.</p>
<h2 id="case-1-call-to-multiple-contracts-and-await-responses"><a class="header" href="#case-1-call-to-multiple-contracts-and-await-responses">Case 1: Call to multiple contracts and await responses</a></h2>
<p>Suppose runtime got the following <code>ActionReceipt</code>:</p>
<pre><code class="language-python"># Non-relevant fields are omitted.
Receipt{
    receiver_id: &quot;alice&quot;,
    receipt_id: &quot;693406&quot;
    receipt: ActionReceipt {
        input_data_ids: []
    }
}
</code></pre>
<p>If execution return Result::Value</p>
<p>Suppose runtime got the following <code>ActionReceipt</code> (we use a python-like pseudo code):</p>
<pre><code class="language-python"># Non-relevant fields are omitted.
Receipt{
    receiver_id: &quot;alice&quot;,
    receipt_id: &quot;5e73d4&quot;
    receipt: ActionReceipt {
        input_data_ids: [&quot;e5fa44&quot;, &quot;7448d8&quot;]
    }
}
</code></pre>
<p>We can't apply this receipt right away: there are missing DataReceipt'a with IDs: [&quot;e5fa44&quot;, &quot;7448d8&quot;]. Runtime does the following:</p>
<pre><code class="language-python">postponed_receipts[&quot;alice,5e73d4&quot;] = borsh_serialize(
    Receipt{
        receiver_id: &quot;alice&quot;,
        receipt_id: &quot;5e73d4&quot;
        receipt: ActionReceipt {
            input_data_ids: [&quot;e5fa44&quot;, &quot;7448d8&quot;]
        }
    }
)
pending_data_receipt_store[&quot;alice,e5fa44&quot;] = &quot;5e73d4&quot;
pending_data_receipt_store[&quot;alice,7448d8&quot;] = &quot;5e73d4&quot;
pending_data_receipt_count = 2
</code></pre>
<p><em>Note: the subsequent Receipts could arrived in the current block or next, that's why we save <a href="RuntimeSpec/Receipts.html#postponed-actionreceipt">Postponed ActionReceipt</a> in the storage</em></p>
<p>Then the first pending <code>Pending DataReceipt</code> arrives:</p>
<pre><code class="language-python"># Non-relevant fields are omitted.
Receipt {
    receiver_id: &quot;alice&quot;,
    receipt: DataReceipt {
        data_id: &quot;e5fa44&quot;,
        data: &quot;some data for alice&quot;,
    }
}
</code></pre>
<pre><code class="language-python">data_receipts[&quot;alice,e5fa44&quot;] = borsh_serialize(Receipt{
    receiver_id: &quot;alice&quot;,
    receipt: DataReceipt {
        data_id: &quot;e5fa44&quot;,
        data: &quot;some data for alice&quot;,
    }
};
pending_data_receipt_count[&quot;alice,5e73d4&quot;] = 1`
del pending_data_receipt_store[&quot;alice,e5fa44&quot;]
</code></pre>
<p>And finally the last <code>Pending DataReceipt</code> arrives:</p>
<pre><code class="language-python"># Non-relevant fields are omitted.
Receipt{
    receiver_id: &quot;alice&quot;,
    receipt: DataReceipt {
        data_id: &quot;7448d8&quot;,
        data: &quot;some more data for alice&quot;,
    }
}
</code></pre>
<pre><code class="language-python">data_receipts[&quot;alice,7448d8&quot;] = borsh_serialize(Receipt{
    receiver_id: &quot;alice&quot;,
    receipt: DataReceipt {
        data_id: &quot;7448d8&quot;,
        data: &quot;some more data for alice&quot;,
    }
};
postponed_receipt_id = pending_data_receipt_store[&quot;alice,5e73d4&quot;]
postponed_receipt = postponed_receipts[postponed_receipt_id]
del postponed_receipts[postponed_receipt_id]
del pending_data_receipt_count[&quot;alice,5e73d4&quot;]
del pending_data_receipt_store[&quot;alice,7448d8&quot;]
apply_receipt(postponed_receipt)
</code></pre>
<h2 id="receipt-validation-error"><a class="header" href="#receipt-validation-error">Receipt Validation Error</a></h2>
<p>Some postprocessing validation is done after an action receipt is applied. The validation includes:</p>
<ul>
<li>
<p>Whether the generated receipts are valid. A generated receipt can be invalid, if, for example, a function call
generates a receipt to call another function on some other contract, but the contract name is invalid. Here there are
mainly two types of errors:</p>
</li>
<li>
<p>account id is invalid. If the receiver id of the receipt is invalid, a</p>
</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// The `receiver_id` of a Receipt is not valid.
InvalidReceiverId { account_id: AccountId },
<span class="boring">}
</span></code></pre></pre>
<p>error is returned.</p>
<ul>
<li>some action is invalid. The errors returned here are the same as the validation errors mentioned in <a href="RuntimeSpec/Actions.html">actions</a>.</li>
<li>Whether the account still has enough balance to pay for storage. If, for example, the execution of one function call
action leads to some receipts that require transfer to be generated as a result, the account may no longer have enough
balance after the transferred amount is deducted. In this case, a</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// ActionReceipt can't be completed, because the remaining balance will not be enough to cover storage.
LackBalanceForState {
    /// An account which needs balance
    account_id: AccountId,
    /// Balance required to complete an action.
    amount: Balance,
},
<span class="boring">}
</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="refunds"><a class="header" href="#refunds">Refunds</a></h1>
<p>When execution of a receipt fails or there is some unused amount of prepaid gas left after a function call, the Runtime generates refund receipts.</p>
<p>The are 2 types of refunds:</p>
<ul>
<li>Refunds for the failed receipt for attached deposits. Let's call them <strong>deposit refunds</strong>.</li>
<li>Refunds for the unused gas and fees. Let's call them <strong>gas refunds</strong>.</li>
</ul>
<p>Refund receipts are identified by having <code>predecessor_id == &quot;system&quot;</code>. They are also special because they don't cost any gas to generate or execute. As a result, they also do not contribute to the block gas limit.</p>
<p>If the execution of a refund fails, the refund amount is burnt.
The refund receipt is an <code>ActionReceipt</code> that consists of a single action <code>Transfer</code> with the <code>deposit</code> amount of the refund.</p>
<h2 id="deposit-refunds"><a class="header" href="#deposit-refunds">Deposit Refunds</a></h2>
<p>Deposit refunds are generated when an action receipt fails to execute. All attached deposit amounts are summed together and
sent as a refund to a <code>predecessor_id</code> (because only the predecessor can attach deposits).</p>
<p>Deposit refunds have the following fields in the <code>ActionReceipt</code>:</p>
<ul>
<li><code>signer_id</code> is <code>system</code></li>
<li><code>signer_public_key</code> is ED25519 key with data equal to 32 bytes of <code>0</code>.</li>
</ul>
<p>Deposit refunds are free for the user and incur no refund fee.</p>
<h2 id="gas-refunds"><a class="header" href="#gas-refunds">Gas Refunds</a></h2>
<p>Gas refunds are generated when a receipt used the amount of gas lower than the attached amount of gas.</p>
<p>If the receipt execution succeeded, the gas amount is equal to <code>prepaid_gas + execution_gas - used_gas</code>.</p>
<p>If the receipt execution failed, the gas amount is equal to <code>prepaid_gas + execution_gas - burnt_gas</code>.</p>
<p>The difference between <code>burnt_gas</code> and <code>used_gas</code> is the <code>used_gas</code> also includes the fees and the prepaid gas of
newly generated receipts, e.g. from cross-contract calls in function calls actions.</p>
<p>From this unspent gas amount, the network charges a gas refund fee, starting with protocol version 78. The exact fee is calculated as <code>max(gas_refund_penalty * unspent_gas, min_gas_refund_penalty)</code>. As of version 78, <code>gas_refund_penalty</code> is 0% and <code>min_gas_refund_penalty</code> 0 Tgas, always resulting in a zero-cost fee. This is only a stepping stone to give projects time to adapt before the fee is taking effect. The plan is to increase this to 5% and 1 Tgas, as specified in <a href="https://github.com/near/NEPs/blob/master/neps/nep-0536.md">NEP-536</a>. There is no fixed timeline available for this.</p>
<p>Should the gas refund fee be equal or larger than the unspent gas, no refund will be produced.</p>
<p>If there is gas to refund left, the gas amount is converted to tokens by multiplying by the gas price at which the original transaction was generated.</p>
<p>Gas refunds have the following fields in the <code>ActionReceipt</code>:</p>
<ul>
<li><code>signer_id</code> is the actual <code>signer_id</code> from the receipt that generates this refund.</li>
<li><code>signer_public_key</code> is the <code>signer_public_key</code> from the receipt that generates this refund.</li>
</ul>
<h2 id="access-key-allowance-refunds"><a class="header" href="#access-key-allowance-refunds">Access Key Allowance refunds</a></h2>
<p>When an account used a restricted access key with <code>FunctionCallPermission</code>, it may have had a limited allowance.
The allowance was charged for the full amount of receipt fees including full prepaid gas.
To refund the allowance we distinguish between Deposit refunds and Gas refunds using <code>signer_id</code> in the action receipt.</p>
<p>If the <code>signer_id == receiver_id &amp;&amp; predecessor_id == &quot;system&quot;</code> it means it's a gas refund and the runtime should try to refund the allowance.</p>
<p>Note, that it's not always possible to refund the allowance, because the access key can be deleted between the moment when the transaction was
issued and when the gas refund arrived. In this case we use the best effort to refund the allowance. It means:</p>
<ul>
<li>the access key on the <code>signer_id</code> account with the public key <code>signer_public_key</code> should exist</li>
<li>the access key permission should be <code>FunctionCallPermission</code></li>
<li>the allowance should be set to <code>Some</code> limited value, instead of unlimited allowance (<code>None</code>)</li>
<li>the runtime uses saturating add to increase the allowance, to avoid overflows</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="runtime"><a class="header" href="#runtime">Runtime</a></h1>
<p>Runtime layer is used to execute smart contracts and other actions created by the users and preserve the state between the executions.
It can be described from three different angles: going step-by-step through various scenarios, describing the components
of the runtime, and describing the functions that the runtime performs.</p>
<h2 id="scenarios"><a class="header" href="#scenarios">Scenarios</a></h2>
<ul>
<li>Financial transaction -- we examine what happens when the runtime needs to process a simple financial transaction;</li>
<li>Cross-contract call -- the scenario when the user calls a contract that in turn calls another contract.</li>
</ul>
<h2 id="components-1"><a class="header" href="#components-1">Components</a></h2>
<p>The components of the runtime can be described through the crates:</p>
<ul>
<li><code>near-vm-logic</code> -- describes the interface that smart contract uses to interact with the blockchain.
Encapsulates the behavior of the blockchain visible to the smart contract, e.g. fee rules, storage access rules, promise rules;</li>
<li><code>near-vm-runner</code> crate -- a wrapper around Wasmer that does the actual execution of the smart contract code. It exposes the
interface provided by <code>near-vm-logic</code> to the smart contract;</li>
<li><code>runtime</code> crate -- encapsulates the logic of how transactions and receipts should be handled. If it encounters
a smart contract call within a transaction or a receipt it calls <code>near-vm-runner</code>, for all other actions, like account
creation, it processes them in-place.</li>
</ul>
<p>The utility crates are:</p>
<ul>
<li><code>near-runtime-fees</code> -- a convenience crate that encapsulates configuration of fees. We might get rid ot it later;</li>
<li><code>near-vm-errors</code> -- contains the hierarchy of errors that can be occurred during transaction or receipt processing;</li>
<li><code>near-vm-runner-standalone</code> -- a runnable tool that allows running the runtime without the blockchain, e.g. for
integration testing of L2 projects;</li>
<li><code>runtime-params-estimator</code> -- benchmarks the runtime and generates the config with the fees.</li>
</ul>
<p>Separately, from the components we describe <a href="RuntimeSpec/Components/BindingsSpec/BindingsSpec.html">the Bindings Specification</a> which is an
important part of the runtime that specifies the functions that the smart contract can call from its host -- the runtime.
The specification is defined in <code>near-vm-logic</code>, but it is exposed to the smart contract in <code>near-vm-runner</code>.</p>
<h2 id="functions"><a class="header" href="#functions">Functions</a></h2>
<ul>
<li>Receipt consumption and production</li>
<li>Fees</li>
<li>Virtual machine</li>
<li>Verification</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="transactions"><a class="header" href="#transactions">Transactions</a></h1>
<p>A transaction in Near is a list of <a href="RuntimeSpec/Actions.html">actions</a> and additional information:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct Transaction {
    /// An account on which behalf transaction is signed
    pub signer_id: AccountId,
    /// An access key which was used to sign a transaction
    pub public_key: PublicKey,
    /// Nonce is used to determine order of transaction in the pool.
    /// It increments for a combination of `signer_id` and `public_key`
    pub nonce: Nonce,
    /// Receiver account for this transaction. If
    pub receiver_id: AccountId,
    /// The hash of the block in the blockchain on top of which the given transaction is valid
    pub block_hash: CryptoHash,
    /// A list of actions to be applied
    pub actions: Vec&lt;Action&gt;,
}
<span class="boring">}
</span></code></pre></pre>
<h2 id="signed-transaction"><a class="header" href="#signed-transaction">Signed Transaction</a></h2>
<p><code>SignedTransaction</code> is what the node receives from a wallet through JSON-RPC endpoint and then routed to the shard where <code>receiver_id</code> account lives. Signature proves an ownership of the corresponding <code>public_key</code> (which is an AccessKey for a particular account) as well as authenticity of the transaction itself.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct SignedTransaction {
    pub transaction: Transaction,
    /// A signature of a hash of the Borsh-serialized Transaction
    pub signature: Signature,
<span class="boring">}
</span></code></pre></pre>
<p>Take a look some <a href="RuntimeSpec/Scenarios/Scenarios.html">scenarios</a> how transaction can be applied.</p>
<h2 id="batched-transaction"><a class="header" href="#batched-transaction">Batched Transaction</a></h2>
<p>A <code>Transaction</code> can contain a list of actions. When there are more than one action in a transaction, we refer to such
transaction as batched transaction. When such a transaction is applied, it is equivalent to applying each of the actions
separately, except:</p>
<ul>
<li>After processing a <code>CreateAccount</code> action, the rest of the action is applied on behalf of the account that is just created.
This allows one to, in one transaction, create an account, deploy a contract to the account, and call some initialization
function on the contract.</li>
<li><code>DeleteAccount</code> action, if present, must be the last action in the transaction.</li>
</ul>
<p>The number of actions in one transaction is limited by <code>VMLimitConfig::max_actions_per_receipt</code>, the current value of which
is 100.</p>
<h2 id="transaction-validation-and-errors"><a class="header" href="#transaction-validation-and-errors">Transaction Validation and Errors</a></h2>
<p>When a transaction is received, various checks will be performed to ensure its validity. This section lists the checks
and potentially errors returned when they fail.</p>
<h3 id="basic-validation"><a class="header" href="#basic-validation">Basic Validation</a></h3>
<p>Basic validation of a transaction can be done without the state.</p>
<h4 id="valid-signer_id-format"><a class="header" href="#valid-signer_id-format">Valid <code>signer_id</code> format</a></h4>
<p>Whether <code>signer_id</code> is valid. If not, a</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// TX signer_id is not in a valid format or not satisfy requirements see `near_core::primitives::utils::is_valid_account_id`
InvalidSignerId { signer_id: AccountId },
<span class="boring">}
</span></code></pre></pre>
<p>error is returned.</p>
<h4 id="valid-receiver_id-format"><a class="header" href="#valid-receiver_id-format">Valid <code>receiver_id</code> format</a></h4>
<p>Whether <code>receiver_id</code> is valid. If not, a</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// TX receiver_id is not in a valid format or not satisfy requirements see `near_core::primitives::utils::is_valid_account_id`
InvalidReceiverId { receiver_id: AccountId },
<span class="boring">}
</span></code></pre></pre>
<p>error is returned.</p>
<h4 id="valid-signature"><a class="header" href="#valid-signature">Valid <code>signature</code></a></h4>
<p>Whether transaction is signed by the access key that corresponds to <code>public_key</code>. If not, a</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// TX signature is not valid
InvalidSignature
<span class="boring">}
</span></code></pre></pre>
<p>error is returned.</p>
<h4 id="number-of-actions-does-not-exceed-max_actions_per_receipt"><a class="header" href="#number-of-actions-does-not-exceed-max_actions_per_receipt">Number of actions does not exceed <code>max_actions_per_receipt</code></a></h4>
<p>Whether the number of actions included in the transaction is not greater than <code>max_actions_per_receipt</code>. If not, a</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span> /// The number of actions exceeded the given limit.
TotalNumberOfActionsExceeded { total_number_of_actions: u64, limit: u64 }
<span class="boring">}
</span></code></pre></pre>
<p>error is returned.</p>
<h4 id="deleteaccount-is-the-last-action"><a class="header" href="#deleteaccount-is-the-last-action"><code>DeleteAccount</code> is the last action</a></h4>
<p>Among the actions in the transaction, whether <code>DeleteAccount</code>, if present, is the last action. If not, a</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// The delete action must be a final action in transaction
DeleteActionMustBeFinal
<span class="boring">}
</span></code></pre></pre>
<p>error is returned.</p>
<h4 id="prepaid-gas-does-not-exceed-max_total_prepaid_gas"><a class="header" href="#prepaid-gas-does-not-exceed-max_total_prepaid_gas">Prepaid gas does not exceed <code>max_total_prepaid_gas</code></a></h4>
<p>Whether total prepaid gas does not exceed <code>max_total_prepaid_gas</code>. If not, a</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// The total prepaid gas (for all given actions) exceeded the limit.
TotalPrepaidGasExceeded { total_prepaid_gas: Gas, limit: Gas }
<span class="boring">}
</span></code></pre></pre>
<p>error is returned.</p>
<h4 id="valid-actions"><a class="header" href="#valid-actions">Valid actions</a></h4>
<p>Whether each included action is valid. Details of such check can be found in <a href="RuntimeSpec/Actions.html">Actions</a>.</p>
<h3 id="validation-with-state"><a class="header" href="#validation-with-state">Validation With State</a></h3>
<p>After the basic validation is done, we check the transaction against current state to perform further validation.</p>
<h4 id="existing-signer_id"><a class="header" href="#existing-signer_id">Existing <code>signer_id</code></a></h4>
<p>Whether <code>signer_id</code> exists. If not, a</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// TX signer_id is not found in a storage
SignerDoesNotExist { signer_id: AccountId },
<span class="boring">}
</span></code></pre></pre>
<p>error is returned.</p>
<h4 id="valid-transaction-nonce"><a class="header" href="#valid-transaction-nonce">Valid transaction nonce</a></h4>
<p>Whether the transaction nonce is greater than the existing nonce on the access key. If not, a</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Transaction nonce must be strictly greater than `account[access_key].nonce`.
InvalidNonce { tx_nonce: Nonce, ak_nonce: Nonce },
<span class="boring">}
</span></code></pre></pre>
<p>error is returned.</p>
<h4 id="enough-balance-to-cover-transaction-cost"><a class="header" href="#enough-balance-to-cover-transaction-cost">Enough balance to cover transaction cost</a></h4>
<p>If <code>signer_id</code> account has enough balance to cover the cost of the transaction. If not, a</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span> /// Account does not have enough balance to cover TX cost
NotEnoughBalance {
    signer_id: AccountId,
    balance: Balance,
    cost: Balance,
}
<span class="boring">}
</span></code></pre></pre>
<p>error is returned.</p>
<h4 id="access-key-is-allowed-to-cover-transaction-cost"><a class="header" href="#access-key-is-allowed-to-cover-transaction-cost">Access Key is allowed to cover transaction cost</a></h4>
<p>If the transaction is signed by a function call access key and the function call access key does not have enough
allowance to cover the cost of the transaction, a</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Access Key does not have enough allowance to cover transaction cost
NotEnoughAllowance {
    account_id: AccountId,
    public_key: PublicKey,
    allowance: Balance,
    cost: Balance,
}
<span class="boring">}
</span></code></pre></pre>
<p>error is returned.</p>
<h4 id="sufficient-account-balance-to-cover-storage"><a class="header" href="#sufficient-account-balance-to-cover-storage">Sufficient account balance to cover storage</a></h4>
<p>If <code>signer_id</code> account does not have enough balance to cover its storage after paying for the cost of the transaction, a</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Signer account doesn't have enough balance after transaction.
LackBalanceForState {
    /// An account which doesn't have enough balance to cover storage.
    signer_id: AccountId,
    /// Required balance to cover the state.
    amount: Balance,
}
<span class="boring">}
</span></code></pre></pre>
<p>error is returned.</p>
<h4 id="function-call-access-key-validations"><a class="header" href="#function-call-access-key-validations">Function call access key validations</a></h4>
<p>If a transaction is signed by a function call access key, the following errors are possible:</p>
<ul>
<li><code>InvalidAccessKeyError::RequiresFullAccess</code> if the transaction contains more than one action or if the only action it
contains is not a <code>FunctionCall</code> action.</li>
<li><code>InvalidAccessKeyError::DepositWithFunctionCall</code> if the function call action has nonzero <code>deposit</code>.</li>
<li><code>InvalidAccessKeyError::ReceiverMismatch { tx_receiver: AccountId, ak_receiver: AccountId }</code> if transaction's <code>receiver_id</code> does not match the <code>receiver_id</code> of the access key.</li>
<li><code>InvalidAccessKeyError::MethodNameMismatch { method_name: String }</code> if the name of the method that the transaction tries to call is not allowed by the access key.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="scenarios-1"><a class="header" href="#scenarios-1">Scenarios</a></h1>
<p>In the following sections we go over the common scenarios that runtime takes care of.</p>
<ul>
<li><a href="RuntimeSpec/Scenarios/FinancialTransaction.html">Financial Transaction</a></li>
<li><a href="RuntimeSpec/Scenarios/CrossContractCall.html">Cross-Contract Call</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="cross-contract-call"><a class="header" href="#cross-contract-call">Cross-Contract Call</a></h1>
<p>This guide assumes that you have read the <a href="RuntimeSpec/Scenarios/FinancialTransaction.html">Financial Transaction</a> section.</p>
<p>Suppose Alice is a calling a function <code>reserve_trip(city: String, date: u64)</code> on a smart contract deployed to a <code>travel_agency</code>
account which in turn calls <code>reserve(date: u64)</code> on a smart contract deployed to a <code>hotel_near</code> account and attaches
a callback to method <code>hotel_reservation_complete(date: u64)</code> on <code>travel_agency</code>.</p>
<img src="RuntimeSpec/Scenarios//images/receipt_flow_diagram.svg" alt="Receipt Flow Diagram"/>
<h2 id="pre-requisites"><a class="header" href="#pre-requisites">Pre-requisites</a></h2>
<p>It possible for Alice to call the <code>travel_agency</code> in several different ways.</p>
<p>In the simplest scenario Alice has an account <code>alice_near</code> and she has a full access key.
She then composes the following transaction that calls the <code>travel_agency</code>:</p>
<pre><code>Transaction {
    signer_id: &quot;alice_near&quot;,
    public_key: &quot;ed25519:32zVgoqtuyRuDvSMZjWQ774kK36UTwuGRZMmPsS6xpMy&quot;,
    nonce: 57,
    receiver_id: &quot;travel_agency&quot;,
    block_hash: &quot;CjNSmWXTWhC3EhRVtqLhRmWMTkRbU96wUACqxMtV1uGf&quot;,
    actions: vec![
        Action::FunctionCall(FunctionCallAction {
            method_name: &quot;reserve_trip&quot;,
            args: &quot;{\&quot;city\&quot;: \&quot;Venice\&quot;, \&quot;date\&quot;: 20191201}&quot;,
            gas: 1000000,
            tokens: 100,
        })
    ],
}
</code></pre>
<p>Here the public key corresponds to the full access key of <code>alice_near</code> account. All other fields in <code>Transaction</code> were
discussed in the <a href="RuntimeSpec/Scenarios/FinancialTransaction.html">Financial Transaction</a> section. The <code>FunctionCallAction</code> action describes how
the contract should be called. The <code>receiver_id</code> field in <code>Transaction</code> already establishes what contract should be executed,
<code>FunctionCallAction</code> merely describes how it should be executed. Interestingly, the arguments is just a blob of bytes,
it is up to the contract developer what serialization format they choose for their arguments. In this example, the contract
developer has chosen to use JSON and so the tool that Alice uses to compose this transaction is expected to use JSON too
to pass the arguments. <code>gas</code> declares how much gas <code>alice_near</code> has prepaid for dynamically calculated fees of the smart
contract executions and other actions that this transaction may spawn. The <code>tokens</code> is the amount of <code>alice_near</code> attaches
to be deposited to whatever smart contract that it is calling to. Notice, <code>gas</code> and <code>tokens</code> are in different units of
measurement.</p>
<p>Now, consider a slightly more complex scenario. In this scenario Alice uses a restricted access key to call the function.
That is the permission of the access key is not <code>AccessKeyPermission::FullAccess</code> but is instead: <code>AccessKeyPermission::FunctionCall(FunctionCallPermission)</code>
where</p>
<pre><code>FunctionCallPermission {
    allowance: Some(3000),
    receiver_id: &quot;travel_agency&quot;,
    method_names: [ &quot;reserve_trip&quot;, &quot;cancel_trip&quot; ]
}
</code></pre>
<p>This scenario might arise when someone Alice's parent has given them a restricted access to <code>alice_near</code> account by
creating an access key that can be used strictly for trip management.
This access key allows up to <code>3000</code> tokens to be spent (which includes token transfers and payments for gas), it can
be only used to call <code>travel_agency</code> and it can be only used with the <code>reserve_trip</code> and <code>cancel_trip</code> methods.
The way runtime treats this case is almost exactly the same as the previous one, with the only difference on how it verifies
the signature of on the signed transaction, and that it also checks for allowance to not be exceeded.</p>
<p>Finally, in the last scenario, Alice does not have an account (or the existence of <code>alice_near</code> is irrelevant). However,
alice has full or restricted access key directly on <code>travel_agency</code> account. In that case <code>signer_id == receiver_id</code> in the
<code>Transaction</code> object and runtime will convert transaction to the first receipt and apply that receipt in the same block.</p>
<p>This section will focus on the first scenario, since the other two are the same with some minor differences.</p>
<h2 id="transaction-to-receipt"><a class="header" href="#transaction-to-receipt">Transaction to receipt</a></h2>
<p>The process of converting transaction to receipt is very similar to the <a href="RuntimeSpec/Scenarios/FinancialTransaction.html">Financial Transaction</a>
with several key points to note:</p>
<ul>
<li>Since Alice attaches 100 tokens to the function call, we subtract them from <code>alice_near</code> upon converting transaction to receipt,
similar to the regular financial transaction;</li>
<li>Since we are attaching 1000000 prepaid gas, we will not only subtract the gas costs of processing the receipt from <code>alice_near</code>, but
will also purchase 1000000 gas using the current gas price.</li>
</ul>
<h2 id="processing-the-reserve_trip-receipt"><a class="header" href="#processing-the-reserve_trip-receipt">Processing the <code>reserve_trip</code> receipt</a></h2>
<p>The receipt created on the shard that hosts <code>alice_near</code> will eventually arrive to the shard hosting <code>travel_agency</code> account.
It will be processed in <code>Runtime::apply</code> which will check that receipt does not have data dependencies (which is the case because
this function call is not a callback) and will call <code>Runtime::apply_action_receipt</code>.
At this point receipt processing is similar to receipt processing from the <a href="RuntimeSpec/Scenarios/FinancialTransaction.html">Financial Transaction</a>
section, with one difference that we will also call <code>action_function_call</code> which will do the following:</p>
<ul>
<li>Retrieve the Wasm code of the smart contract (either from the database or from the cache);</li>
<li>Initialize runtime context through <code>VMContext</code> and create <code>RuntimeExt</code> which provides access to the trie when the smart contract
call the storage API. Specifically <code>&quot;{\&quot;city\&quot;: \&quot;Venice\&quot;, \&quot;date\&quot;: 20191201}&quot;</code> arguments will be set in <code>VMContext</code>.</li>
<li>Calls <code>near_vm_runner::run</code> which does the following:
<ul>
<li>Inject gas, stack, and other kinds of metering;</li>
<li>Verify that Wasm code does not use floats;</li>
<li>Checks that bindings API functions that the smart contract is trying to call are actually those provided by <code>near_vm_logic</code>;</li>
<li>Compiles Wasm code into the native binary;</li>
<li>Calls <code>reserve_trip</code> on the smart contract.
<ul>
<li>During the execution of the smart contract it will at some point call <code>promise_create</code> and <code>promise_then</code>, which will
call method on <code>RuntimeExt</code> that will record that two promises were created and that the second one should
wait on the first one. Specifically, <code>promise_create</code> will call <code>RuntimeExt::create_receipt(vec![], &quot;hotel_near&quot;)</code>
returning <code>0</code> and then <code>RuntimeExt::create_receipt(vec![0], &quot;travel_agency&quot;)</code>;</li>
</ul>
</li>
</ul>
</li>
<li><code>action_function_call</code> then collects receipts from <code>VMContext</code> along with the execution result, logs, and information
about used gas;</li>
<li><code>apply_action_receipt</code> then goes over the collected receipts from each action and returns them at the end of <code>Runtime::apply</code> together with
other receipts.</li>
</ul>
<h2 id="processing-the-reserve-receipt"><a class="header" href="#processing-the-reserve-receipt">Processing the <code>reserve</code> receipt</a></h2>
<p>This receipt will have <code>output_data_receivers</code> with one element corresponding to the receipt that calls <code>hotel_reservation_complete</code>,
which will tell the runtime that it should create <code>DataReceipt</code> and send it towards <code>travel_agency</code> once the execution of <code>reserve(date: u64)</code> is complete.</p>
<p>The rest of the smart contract execution is similar to the above.</p>
<h2 id="processing-the-hotel_reservation_complete-receipt"><a class="header" href="#processing-the-hotel_reservation_complete-receipt">Processing the <code>hotel_reservation_complete</code> receipt</a></h2>
<p>Upon receiving the <code>hotel_reservation_complete</code> receipt the runtime will notice that its <code>input_data_ids</code> is not empty
which means that it cannot be executed until <code>reserve</code> receipt is complete. It will store the receipt in the trie together
with the counter of how many <code>DataReceipt</code> it is waiting on.</p>
<p>It will not call the Wasm smart contract at this point.</p>
<h2 id="processing-the-datareceipt"><a class="header" href="#processing-the-datareceipt">Processing the <code>DataReceipt</code></a></h2>
<p>Once the runtime receives the <code>DataReceipt</code> it takes the receipt with <code>hotel_reservation_complete</code> function call
and executes it following the same execution steps as with the <code>reserve_trip</code> receipt.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="financial-transaction"><a class="header" href="#financial-transaction">Financial Transaction</a></h1>
<p>Suppose Alice wants to transfer 100 tokens to Bob.
In this case we are talking about native Near Protocol tokens, oppose to user-defined tokens implemented through a smart contract.
There are several way this can be done:</p>
<ul>
<li>Direct transfer through a transaction containing transfer action;</li>
<li>Alice calling a smart contract that in turn creates a financial transaction towards Bob.</li>
</ul>
<p>In this section we are talking about the former simpler scenario.</p>
<h2 id="pre-requisites-1"><a class="header" href="#pre-requisites-1">Pre-requisites</a></h2>
<p>For this to work both Alice and Bob need to have <em>accounts</em> and an access to them through
<em>the full access keys</em>.</p>
<p>Suppose Alice has account <code>alice_near</code> and Bob has account <code>bob_near</code>. Also, some time in the past,
each of them has created a public-secret key-pair, saved the secret key somewhere (e.g. in a wallet application)
and created a full access key with the public key for the account.</p>
<p>We also need to assume that both Alice and Bob have some number of tokens on their accounts. Alice needs &gt;100 tokens on her account
so that she could transfer 100 tokens to Bob, but also Alice and Bob need to have some tokens on balance to pay for the data they store on-chain for their accounts -- which is essentially the refundable cost of the storage occupied by the account in the Near Protocol network.</p>
<h2 id="creating-a-transaction"><a class="header" href="#creating-a-transaction">Creating a transaction</a></h2>
<p>To send the transaction neither Alice nor Bob need to run a node.
However, Alice needs a way to create and sign a transaction structure.
Suppose Alice uses near-shell or any other third-party tool for that.
The tool then creates the following structure:</p>
<pre><code>Transaction {
    signer_id: &quot;alice_near&quot;,
    public_key: &quot;ed25519:32zVgoqtuyRuDvSMZjWQ774kK36UTwuGRZMmPsS6xpMy&quot;,
    nonce: 57,
    receiver_id: &quot;bob_near&quot;,
    block_hash: &quot;CjNSmWXTWhC3EhRVtqLhRmWMTkRbU96wUACqxMtV1uGf&quot;,
    actions: vec![
        Action::Transfer(TransferAction {deposit: 100} )
    ],
}
</code></pre>
<p>Which contains one token transfer action, the id of the account that signs this transaction (<code>alice_near</code>)
the account towards which this transaction is addressed (<code>bob_near</code>). Alice also uses the public key
associated with one of the full access keys of <code>alice_near</code> account.</p>
<p>Additionally, Alice uses the <em>nonce</em> which is unique value that allows Near Protocol to differentiate the transactions (in case there are several transfers coming in rapid
succession) which should be strictly increasing with each transaction. Unlike in Ethereum, nonces are associated with access keys, oppose to
the entire accounts, so several users using the same account through different access keys need not to worry about accidentally
reusing each other's nonces.</p>
<p>The block hash is used to calculate a transaction's &quot;freshness&quot;.  It
is used to make sure a transaction does not get lost (let's say
somewhere in the network) and then arrive days, weeks, or years later
when it is not longer relevant and would be undesirable to execute.
A transaction does not need to arrive at a specific block, instead
it is required to arrive within a certain number of blocks from the block
identified by the <code>block_hash</code>.  Any transaction arriving outside this
threshold is considered to be invalid.  Allowed delay is defined by
<code>transaction_validity_period</code> option in the chainâ€™s genesis file.  On
mainnet, this value is 86400 (which corresponds to roughly a day) and
on testnet it is 100.</p>
<p>near-shell or other tool that Alice uses then signs this transaction, by: computing the hash of the transaction and signing it
with the secret key, resulting in a <code>SignedTransaction</code> object.</p>
<h2 id="sending-the-transaction"><a class="header" href="#sending-the-transaction">Sending the transaction</a></h2>
<p>To send the transaction, near-shell connects through the RPC to any Near Protocol node and submits it.
If users wants to wait until the transaction is processed they can use <code>send_tx_commit</code> JSONRPC method which waits for the
transaction to appear in a block. Otherwise the user can use <code>send_tx_async</code>.</p>
<h2 id="transaction-to-receipt-1"><a class="header" href="#transaction-to-receipt-1">Transaction to receipt</a></h2>
<p>We skip the details on how the transaction arrives to be processed by the runtime, since it is a part of the blockchain layer
discussion.
We consider the moment where <code>SignedTransaction</code> is getting passed to <code>Runtime::apply</code> of the
<code>runtime</code> crate.
<code>Runtime::apply</code> immediately passes transaction to <code>Runtime::process_transaction</code>
which in turn does the following:</p>
<ul>
<li>Verifies that transaction is valid;</li>
<li>Applies initial reversible and irreversible charges to <code>alice_near</code> account;</li>
<li>Creates a receipt with the same set of actions directed towards <code>bob_near</code>.</li>
</ul>
<p>The first two items are performed inside <code>Runtime::verify_and_charge_transaction</code> method.
Specifically it does the following checks:</p>
<ul>
<li>Verifies that the signature of the transaction is correct based on the transaction hash and the attached public key;</li>
<li>Retrieves the latest state of the <code>alice_near</code> account, and simultaneously checks that it exists;</li>
<li>Retrieves the state of the access key of that <code>alice_near</code> used to sign the transaction;</li>
<li>Checks that transaction nonce is greater than the nonce of the latest transaction executed with that access key;</li>
<li>Subtracts the <code>total_cost</code> of the transaction from the account balance, or throws <code>InvalidTxError::NotEnoughBalance</code>. If the transaction is part of a transaction by a FunctionCall Access Key, subtracts the <code>total_cost</code> from the <code>allowance</code> or throws <code>InvalidAccessKeyError::NotEnoughAllowance</code>;</li>
<li>Checks whether the <code>signer</code> account has insufficient balance for the storage deposit and throws <code>InvalidTxError::LackBalanceForState</code> if so</li>
<li>If the transaction is part of a transaction by a FunctionCall Access Key, throws <code>InvalidAccessKeyError::RequiresFullAccess</code>;</li>
<li>Updates the <code>alice_near</code> account with the new balance and the used access key with the new nonce;</li>
</ul>
<p>If any of the above operations fail all of the changes will be reverted.</p>
<h2 id="processing-receipt"><a class="header" href="#processing-receipt">Processing receipt</a></h2>
<p>The receipt created in the previous section will eventually arrive to a runtime on the shard that hosts <code>bob_near</code> account.
Again, it will be processed by <code>Runtime::apply</code> which will immediately call <code>Runtime::process_receipt</code>.
It will check that this receipt does not have data dependencies (which is only the case of function calls) and will then call <code>Runtime::apply_action_receipt</code> on <code>TransferAction</code>.</p>
<p><code>Runtime::apply_action_receipt</code> will perform the following checks:</p>
<ul>
<li>Retrieves the state of <code>bob_near</code> account, if it still exists (it is possible that Bob has deleted his account concurrently with the transfer transaction);</li>
<li>Computes the cost of processing a receipt and a transfer action;</li>
<li>Computes how much reward should be burnt;</li>
<li>Checks if <code>bob_near</code> still exists and if it does, deposits the transferred tokens to <code>bob_near</code>;</li>
<li>Checks if <code>bob_near</code> still exists and if so, deposits the gas reward to the <code>bob_near</code> account;</li>
<li>Checks if <code>bob_near</code> has enough balance for the storage deposit, the transaction's temporary state is dropped/rolled back if there is not enough balance;</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="economics"><a class="header" href="#economics">Economics</a></h1>
<p><code>This is under heavy development</code></p>
<h2 id="units"><a class="header" href="#units">Units</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Name</th><th>Value</th></tr></thead><tbody>
<tr><td>yoctoNEAR</td><td>smallest indivisible amount of native currency <em>NEAR</em>.</td></tr>
<tr><td>NEAR</td><td><code>10**24</code> yoctoNEAR</td></tr>
<tr><td>block</td><td>smallest on-chain unit of time</td></tr>
<tr><td>gas</td><td>unit to measure usage of blockchain</td></tr>
</tbody></table>
</div>
<h2 id="general-parameters"><a class="header" href="#general-parameters">General Parameters</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Name</th><th>Value</th></tr></thead><tbody>
<tr><td><code>INITIAL_SUPPLY</code></td><td><code>10**33</code> yoctoNEAR</td></tr>
<tr><td><code>MIN_GAS_PRICE</code></td><td><code>10**5</code> yoctoNEAR</td></tr>
<tr><td><code>REWARD_PCT_PER_YEAR</code></td><td><code>0.025</code></td></tr>
<tr><td><code>EPOCH_LENGTH</code></td><td><code>43,200</code> blocks</td></tr>
<tr><td><code>EPOCHS_A_YEAR</code></td><td><code>730</code> epochs</td></tr>
<tr><td><code>INITIAL_MAX_STORAGE</code></td><td><code>10 * 2**40</code> bytes == <code>10</code> TB</td></tr>
<tr><td><code>TREASURY_PCT</code></td><td><code>0.1</code></td></tr>
<tr><td><code>TREASURY_ACCOUNT_ID</code></td><td><code>treasury</code></td></tr>
<tr><td><code>CONTRACT_PCT</code></td><td><code>0.3</code></td></tr>
<tr><td><code>INVALID_STATE_SLASH_PCT</code></td><td><code>0.05</code></td></tr>
<tr><td><code>ADJ_FEE</code></td><td><code>0.01</code></td></tr>
<tr><td><code>TOTAL_SEATS</code></td><td><code>100</code></td></tr>
<tr><td><code>ONLINE_THRESHOLD_MIN</code></td><td><code>0.9</code></td></tr>
<tr><td><code>ONLINE_THRESHOLD_MAX</code></td><td><code>0.99</code></td></tr>
<tr><td><code>BLOCK_PRODUCER_KICKOUT_THRESHOLD</code></td><td><code>0.8</code></td></tr>
<tr><td><code>CHUNK_PRODUCER_KICKOUT_THRESHOLD</code></td><td><code>0.8</code></td></tr>
<tr><td><code>CHUNK_VALIDATOR_KICKOUT_THRESHOLD</code></td><td><code>0.7</code></td></tr>
</tbody></table>
</div>
<h2 id="general-variables"><a class="header" href="#general-variables">General Variables</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Name</th><th>Description</th><th>Initial value</th></tr></thead><tbody>
<tr><td><code>totalSupply[t]</code></td><td>Total supply of NEAR at given epoch[t]</td><td><code>INITIAL_SUPPLY</code></td></tr>
<tr><td><code>gasPrice[t]</code></td><td>The cost of 1 unit of <em>gas</em> in NEAR tokens (see Transaction Fees section below)</td><td><code>MIN_GAS_PRICE</code></td></tr>
<tr><td><code>storageAmountPerByte[t]</code></td><td>keeping constant, <code>INITIAL_SUPPLY / INITIAL_MAX_STORAGE</code></td><td><code>~9.09 * 10**19</code> yoctoNEAR</td></tr>
</tbody></table>
</div>
<h2 id="issuance"><a class="header" href="#issuance">Issuance</a></h2>
<p>The protocol sets a ceiling for the maximum issuance of tokens, and dynamically decreases this issuance depending on the amount of total fees in the system.</p>
<div class="table-wrapper"><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody>
<tr><td><code>reward[t]</code></td><td><code>totalSupply[t]</code> * <code>REWARD_PCT_PER_YEAR</code> * <code>epochTime[t]</code> / <code>NUM_SECONDS_IN_A_YEAR</code></td></tr>
<tr><td><code>epochFee[t]</code></td><td><code>sum([(1 - DEVELOPER_PCT_PER_YEAR) * block.txFee + block.stateFee for block in epoch[t]])</code></td></tr>
<tr><td><code>issuance[t]</code></td><td>The amount of token issued at a certain epoch[t], <code>issuance[t] = reward[t] - epochFee[t]</code></td></tr>
</tbody></table>
</div>
<p>Where <code>totalSupply[t]</code> is the total number of tokens in the system at a given time <em>t</em> and <code>epochTime[t]</code> is the
duration of the epoch in seconds.
If <code>epochFee[t] &gt; reward[t]</code> the issuance is negative, thus the <code>totalSupply[t]</code> decreases in given epoch.</p>
<h2 id="transaction-fees"><a class="header" href="#transaction-fees">Transaction Fees</a></h2>
<p>Each transaction before inclusion must buy gas enough to cover the cost of bandwidth and execution.</p>
<p>Gas unifies execution and bytes of bandwidth usage of blockchain. Each WASM instruction or pre-compiled function gets assigned an amount of gas based on measurements on common-denominator computer. Same goes for weighting the used bandwidth based on general unified costs.</p>
<p>Gas is priced dynamically in <code>NEAR</code> tokens. At each block <code>t</code>, we update <code>gasPrice[t] = gasPrice[t - 1] * (1 + (gasUsed[t - 1] / gasLimit[t - 1] - 0.5) * ADJ_FEE)</code>.</p>
<p>Where <code>gasUsed[t] = sum([sum([gas(tx) for tx in chunk]) for chunk in block[t]])</code>.
<code>gasLimit[t]</code> is defined as <code>gasLimit[t] = gasLimit[t - 1] + validatorGasDiff[t - 1]</code>, where <code>validatorGasDiff</code> is parameter with which each chunk producer can either increase or decrease gas limit based on how long it to execute the previous chunk. <code>validatorGasDiff[t]</code> can be only within <code>Â±0.1%</code> of <code>gasLimit[t]</code> and only if <code>gasUsed[t - 1] &gt; 0.9 * gasLimit[t - 1]</code>.</p>
<h2 id="state-stake"><a class="header" href="#state-stake">State Stake</a></h2>
<p>Amount of <code>NEAR</code> on the account represents right for this account to take portion of the blockchain's overall global state. Transactions fail if account doesn't have enough balance to cover the storage required for given account.</p>
<pre><code class="language-python">def check_storage_cost(account):
    # Compute requiredAmount given size of the account.
    requiredAmount = sizeOf(account) * storageAmountPerByte
    return Ok() if account.amount + account.locked &gt;= requiredAmount else Error(requiredAmount)

# Check when transaction is received to verify that it is valid.
def verify_transaction(tx, signer_account):
    # ...
    # Updates signer's account with the amount it will have after executing this tx.
    update_post_amount(signer_account, tx)
    result = check_storage_cost(signer_account)
    # If enough balance OR account is been deleted by the owner.
    if not result.ok() or DeleteAccount(tx.signer_id) in tx.actions:
        assert LackBalanceForState(signer_id: tx.signer_id, amount: result.err())

# After account touched / changed, we check it still has enough balance to cover it's storage.
def on_account_change(block_height, account):
    # ... execute transaction / receipt changes ...
    # Validate post-condition and revert if it fails.
    result = check_storage_cost(sender_account)
    if not result.ok():
        assert LackBalanceForState(signer_id: tx.signer_id, amount: result.err())
</code></pre>
<p>Where <code>sizeOf(account)</code> includes size of <code>account_id</code>, <code>account</code> structure and size of all the data stored under the account.</p>
<p>Account can end up with not enough balance in case it gets slashed. Account will become unusable as all originating transactions will fail (including deletion).
The only way to recover it in this case is by sending extra funds from a different accounts.</p>
<h2 id="validators"><a class="header" href="#validators">Validators</a></h2>
<p>NEAR validators provide their resources in exchange for a reward <code>epochReward[t]</code>, where [t] represents the considered epoch</p>
<div class="table-wrapper"><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody>
<tr><td><code>epochReward[t]</code></td><td><code>= coinbaseReward[t] + epochFee[t]</code></td></tr>
<tr><td><code>coinbaseReward[t]</code></td><td>The maximum inflation per epoch[t], as a function of <code>REWARD_PCT_PER_YEAR / EPOCHS_A_YEAR</code></td></tr>
</tbody></table>
</div>
<h3 id="validator-selection"><a class="header" href="#validator-selection">Validator Selection</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct Proposal {
    account_id: AccountId,
    stake: Balance,
    public_key: PublicKey,
}
<span class="boring">}
</span></code></pre></pre>
<p>During the epoch, outcome of staking transactions produce <code>proposals</code>, which are collected, in the form of <code>Proposal</code>s.
There are separate proposals for block producers and chunk-only producers, see <a href="Economics/../ChainSpec/SelectingBlockProducers.html">Selecting Chunk and Block Producers</a>.
for more information.
At the end of every epoch <code>T</code>, next algorithm gets executed to determine validators for epoch <code>T + 2</code>:</p>
<ol>
<li>For every chunk/block producer in <code>epoch[T]</code> determine <code>num_blocks_produced</code>, <code>num_chunks_produced</code> based on what they produced during the epoch.</li>
<li>Remove validators, for whom <code>num_blocks_produced &lt; num_blocks_expected * BLOCK_PRODUCER_KICKOUT_THRESHOLD</code> or <code>num_chunks_produced &lt; num_chunks_expected * CHUNK_PRODUCER_KICKOUT_THRESHOLD</code>.</li>
<li>Collect chunk-only and block producer <code>proposals</code>, if validator was also a validator in <code>epoch[T]</code>, considered stake of the proposal is <code>0 if proposal.stake == 0 else proposal.stake + reward[proposal.account_id]</code>.</li>
<li>Use the chunk/block producer selection algorithms outlined in <a href="Economics/../ChainSpec/SelectingBlockProducers.html">Selecting Chunk and Block Producers</a>.</li>
</ol>
<h3 id="validator-rewards-calculation"><a class="header" href="#validator-rewards-calculation">Validator Rewards Calculation</a></h3>
<p>Note: all calculations are done in Rational numbers.</p>
<p>Total reward every epoch <code>t</code> is equal to:</p>
<pre><code class="language-python">total_reward[t] = floor(totalSupply * max_inflation_rate * epoch_length)
</code></pre>
<p>where <code>max_inflation_rate</code> is taken from the epoch config while <code>totalSupply</code> and <code>epoch_length</code> are
taken from the last block in the epoch.</p>
<p>After that a fraction of the reward goes to the treasury and the remaining amount will be used for computing validator rewards:</p>
<pre><code class="language-python">treasury_reward[t] = floor(reward[t] * protocol_reward_rate)
validator_reward[t] = total_reward[t] - treasury_reward[t]
</code></pre>
<p>Validators that didn't meet the threshold for either blocks or chunks get kicked out and don't get any reward, otherwise uptime
of a validator is computed as an average of (block produced/expected, chunk produced/expected,
and chunk endorsements produced/expected) and adjusted wrt the <code>ONLINE_THRESHOLD</code>, <code>ONLINE_THRESHOLD_MIN</code>, <code>ONLINE_THRESHOLD_MAX</code> parameters:</p>
<pre><code class="language-python">pct_online[t][j] = mean(num_blocks_produced[t][j] / num_blocks_expected[t][j],
                        num_chunks_produced[t][j] / num_chunks_expected[t][j],
                        num_endorsements_produced[t][j] / num_endorsements_expected[t][j])
if pct_online &gt; ONLINE_THRESHOLD:
    uptime[t][j] = min(1, (pct_online[t][j] - ONLINE_THRESHOLD_MIN) / (ONLINE_THRESHOLD_MAX - ONLINE_THRESHOLD_MIN))
else:
    uptime[t][j] = 0
</code></pre>
<p>Where <code>expected_produced_blocks</code> and <code>expected_produced_chunks</code> is the number of blocks and chunks respectively that is expected to be produced by given validator <code>j</code> in the epoch <code>t</code>.</p>
<p>The specific <code>validator[t][j]</code> reward for epoch <code>t</code> is then proportional to the fraction of stake of this validator from total stake:</p>
<pre><code class="language-python">validator_reward[t][j] = floor(uptime[t][j] * stake[t][j] * total_reward[t] / total_stake[t])
</code></pre>
<h3 id="slashing-1"><a class="header" href="#slashing-1">Slashing</a></h3>
<h4 id="chunkproofs"><a class="header" href="#chunkproofs">ChunkProofs</a></h4>
<pre><code class="language-python"># Check that chunk is invalid, because the proofs in header don't match the body.
def chunk_proofs_condition(chunk):
    # TODO

# At the end of the epoch, run update validators and
# determine how much to slash validators.
def end_of_epoch_update_validators(validators):
    # ...
    for validator in validators:
        if validator.is_slashed:
            validator.stake -= INVALID_STATE_SLASH_PCT * validator.stake
</code></pre>
<h4 id="chunkstate"><a class="header" href="#chunkstate">ChunkState</a></h4>
<pre><code class="language-python"># Check that chunk header post state root is invalid,
# because the execution of previous chunk doesn't lead to it.
def chunk_state_condition(prev_chunk, prev_state, chunk_header):
    # TODO

# At the end of the epoch, run update validators and
# determine how much to slash validators.
def end_of_epoch(..., validators):
    # ...
    for validator in validators:
        if validator.is_slashed:
            validator.stake -= INVALID_STATE_SLASH_PCT * validator.stake
</code></pre>
<h2 id="protocol-treasury"><a class="header" href="#protocol-treasury">Protocol Treasury</a></h2>
<p>Treasury account <code>TREASURY_ACCOUNT_ID</code> receives fraction of reward every epoch <code>t</code>:</p>
<pre><code class="language-python"># At the end of the epoch, update treasury
def end_of_epoch(..., reward):
    # ...
    accounts[TREASURY_ACCOUNT_ID].amount = treasury_reward[t]
</code></pre>
<h2 id="contract-rewards"><a class="header" href="#contract-rewards">Contract Rewards</a></h2>
<p>Contract account is rewarded with 30% of gas burnt during the execution of its functions.
The reward is credited to the contract account after applying the corresponding receipt with <a href="Economics/../RuntimeSpec/Actions.html#functioncallaction"><code>FunctionCallAction</code></a>, gas is converted to tokens using gas price of the current block.</p>
<p>You can read more about:</p>
<ul>
<li><a href="Economics/../RuntimeSpec/Receipts.html">receipts execution</a>;</li>
<li><a href="Economics/../RuntimeSpec/Fees/Fees.html">runtime fees</a> with description <a href="Economics/../RuntimeSpec/Fees/Fees.html#gas-tracking">how gas is charged</a>.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="genesisconfig"><a class="header" href="#genesisconfig">GenesisConfig</a></h1>
<h2 id="protocol_version"><a class="header" href="#protocol_version">protocol_version</a></h2>
<p><code>type: u32</code></p>
<p>Protocol version that this genesis works with.</p>
<h2 id="genesis_time"><a class="header" href="#genesis_time">genesis_time</a></h2>
<p><code>type: DateTime</code></p>
<p>Official time of blockchain start.</p>
<h2 id="genesis_height"><a class="header" href="#genesis_height">genesis_height</a></h2>
<p><code>type: u64</code></p>
<p>Height of the genesis block. Note that genesis height is not necessarily 0.
For example, mainnet genesis height is <code>9820210</code>.</p>
<h2 id="chain_id"><a class="header" href="#chain_id">chain_id</a></h2>
<p><code>type: String</code></p>
<p>ID of the blockchain. This must be unique for every blockchain.
If your testnet blockchains do not have unique chain IDs, you will have a bad time.</p>
<h2 id="num_block_producers"><a class="header" href="#num_block_producers">num_block_producers</a></h2>
<p><code>type: u32</code></p>
<p>Number of block producer seats at genesis.</p>
<h2 id="block_producers_per_shard"><a class="header" href="#block_producers_per_shard">block_producers_per_shard</a></h2>
<p><code>type: [ValidatorId]</code></p>
<p>Defines number of shards and number of validators per each shard at genesis.</p>
<h2 id="avg_fisherman_per_shard"><a class="header" href="#avg_fisherman_per_shard">avg_fisherman_per_shard</a></h2>
<p><code>type: [ValidatorId]</code></p>
<p>Expected number of fisherman per shard.</p>
<h2 id="dynamic_resharding"><a class="header" href="#dynamic_resharding">dynamic_resharding</a></h2>
<p><code>type: bool</code></p>
<p>Enable dynamic re-sharding.</p>
<h2 id="epoch_length"><a class="header" href="#epoch_length">epoch_length</a></h2>
<p><code>type: BlockIndex</code></p>
<p>Epoch length counted in blocks.</p>
<h2 id="gas_limit"><a class="header" href="#gas_limit">gas_limit</a></h2>
<p><code>type: Gas</code></p>
<p>Initial gas limit for a block</p>
<h2 id="gas_price-1"><a class="header" href="#gas_price-1">gas_price</a></h2>
<p><code>type: Balance</code></p>
<p>Initial gas price</p>
<h2 id="block_producer_kickout_threshold"><a class="header" href="#block_producer_kickout_threshold">block_producer_kickout_threshold</a></h2>
<p><code>type: u8</code></p>
<p>Criterion for kicking out block producers (this is a number between 0 and 100)</p>
<h2 id="chunk_producer_kickout_threshold"><a class="header" href="#chunk_producer_kickout_threshold">chunk_producer_kickout_threshold</a></h2>
<p><code>type: u8</code></p>
<p>Criterion for kicking out chunk producers (this is a number between 0 and 100)</p>
<h2 id="gas_price_adjustment_rate"><a class="header" href="#gas_price_adjustment_rate">gas_price_adjustment_rate</a></h2>
<p><code>type: Fraction</code></p>
<p>Gas price adjustment rate</p>
<h2 id="runtime_config"><a class="header" href="#runtime_config">runtime_config</a></h2>
<p><em>type: <a href="GenesisConfig/RuntimeConfig.html">RuntimeConfig</a></em></p>
<p>Runtime configuration (mostly economics constants).</p>
<h2 id="validators-1"><a class="header" href="#validators-1">validators</a></h2>
<p><code>type: [AccountInfo]</code></p>
<p>List of initial validators.</p>
<h2 id="records"><a class="header" href="#records">records</a></h2>
<p><em>type: Vec&lt;<a href="GenesisConfig/StateRecord.html">StateRecord</a>&gt;</em></p>
<p>Records in storage at genesis (get split into shards at genesis creation).</p>
<h2 id="transaction_validity_period"><a class="header" href="#transaction_validity_period">transaction_validity_period</a></h2>
<p><code>type: u64</code></p>
<p>Number of blocks for which a given transaction is valid</p>
<h2 id="developer_reward_percentage"><a class="header" href="#developer_reward_percentage">developer_reward_percentage</a></h2>
<p><code>type: Fraction</code></p>
<p>Developer reward percentage.</p>
<h2 id="protocol_reward_percentage"><a class="header" href="#protocol_reward_percentage">protocol_reward_percentage</a></h2>
<p><code>type: Fraction</code></p>
<p>Protocol treasury percentage.</p>
<h2 id="max_inflation_rate"><a class="header" href="#max_inflation_rate">max_inflation_rate</a></h2>
<p><code>type: Fraction</code></p>
<p>Maximum inflation on the total supply every epoch.</p>
<h2 id="total_supply"><a class="header" href="#total_supply">total_supply</a></h2>
<p><code>type: Balance</code></p>
<p>Total supply of tokens at genesis.</p>
<h2 id="num_blocks_per_year"><a class="header" href="#num_blocks_per_year">num_blocks_per_year</a></h2>
<p><code>type: u64</code></p>
<p>Expected number of blocks per year</p>
<h2 id="protocol_treasury_account"><a class="header" href="#protocol_treasury_account">protocol_treasury_account</a></h2>
<p><code>type: AccountId</code></p>
<p>Protocol treasury account</p>
<h2 id="protocol-economics"><a class="header" href="#protocol-economics">protocol economics</a></h2>
<blockquote>
<p>For the specific economic specs, refer to <a href="GenesisConfig/../Economics/Economics.html">Economics Section</a>.</p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="extcostsconfig"><a class="header" href="#extcostsconfig">ExtCostsConfig</a></h1>
<h2 id="base"><a class="header" href="#base">base</a></h2>
<p><code>type: Gas</code></p>
<p>Base cost for calling a host function.</p>
<h2 id="read_memory_base"><a class="header" href="#read_memory_base">read_memory_base</a></h2>
<p><code>type: Gas</code></p>
<p>Base cost for guest memory read</p>
<h2 id="read_memory_byte"><a class="header" href="#read_memory_byte">read_memory_byte</a></h2>
<p><code>type: Gas</code></p>
<p>Cost for guest memory read</p>
<h2 id="write_memory_base"><a class="header" href="#write_memory_base">write_memory_base</a></h2>
<p><code>type: Gas</code></p>
<p>Base cost for guest memory write</p>
<h2 id="write_memory_byte"><a class="header" href="#write_memory_byte">write_memory_byte</a></h2>
<p><code>type: Gas</code></p>
<p>Cost for guest memory write per byte</p>
<h2 id="read_register_base"><a class="header" href="#read_register_base">read_register_base</a></h2>
<p><code>type: Gas</code></p>
<p>Base cost for reading from register</p>
<h2 id="read_register_byte"><a class="header" href="#read_register_byte">read_register_byte</a></h2>
<p><code>type: Gas</code></p>
<p>Cost for reading byte from register</p>
<h2 id="write_register_base"><a class="header" href="#write_register_base">write_register_base</a></h2>
<p><code>type: Gas</code></p>
<p>Base cost for writing into register</p>
<h2 id="write_register_byte"><a class="header" href="#write_register_byte">write_register_byte</a></h2>
<p><code>type: Gas</code></p>
<p>Cost for writing byte into register</p>
<h2 id="utf8_decoding_base"><a class="header" href="#utf8_decoding_base">utf8_decoding_base</a></h2>
<p><code>type: Gas</code></p>
<p>Base cost of decoding utf8.</p>
<h2 id="utf8_decoding_byte"><a class="header" href="#utf8_decoding_byte">utf8_decoding_byte</a></h2>
<p><code>type: Gas</code></p>
<p>Cost per bye of decoding utf8.</p>
<h2 id="utf16_decoding_base"><a class="header" href="#utf16_decoding_base">utf16_decoding_base</a></h2>
<p><code>type: Gas</code></p>
<p>Base cost of decoding utf16.</p>
<h2 id="utf16_decoding_byte"><a class="header" href="#utf16_decoding_byte">utf16_decoding_byte</a></h2>
<p><code>type: Gas</code></p>
<p>Cost per bye of decoding utf16.</p>
<h2 id="sha256_base"><a class="header" href="#sha256_base">sha256_base</a></h2>
<p><code>type: Gas</code></p>
<p>Cost of getting sha256 base</p>
<h2 id="sha256_byte"><a class="header" href="#sha256_byte">sha256_byte</a></h2>
<p><code>type: Gas</code></p>
<p>Cost of getting sha256 per byte</p>
<h2 id="keccak256_base"><a class="header" href="#keccak256_base">keccak256_base</a></h2>
<p><code>type: Gas</code></p>
<p>Cost of getting keccak256 base</p>
<h2 id="keccak256_byte"><a class="header" href="#keccak256_byte">keccak256_byte</a></h2>
<p><code>type: Gas</code></p>
<p>Cost of getting keccak256 per byte</p>
<h2 id="keccak512_base"><a class="header" href="#keccak512_base">keccak512_base</a></h2>
<p><code>type: Gas</code></p>
<p>Cost of getting keccak512 base</p>
<h2 id="keccak512_byte"><a class="header" href="#keccak512_byte">keccak512_byte</a></h2>
<p><code>type: Gas</code></p>
<p>Cost of getting keccak512 per byte</p>
<h2 id="log_base"><a class="header" href="#log_base">log_base</a></h2>
<p><code>type: Gas</code></p>
<p>Cost for calling logging.</p>
<h2 id="log_byte"><a class="header" href="#log_byte">log_byte</a></h2>
<p><code>type: Gas</code></p>
<p>Cost for logging per byte</p>
<h2 id="storage-api"><a class="header" href="#storage-api">Storage API</a></h2>
<h3 id="storage_write_base"><a class="header" href="#storage_write_base">storage_write_base</a></h3>
<p><code>type: Gas</code></p>
<p>Storage trie write key base cost</p>
<h3 id="storage_write_key_byte"><a class="header" href="#storage_write_key_byte">storage_write_key_byte</a></h3>
<p><code>type: Gas</code></p>
<p>Storage trie write key per byte cost</p>
<h3 id="storage_write_value_byte"><a class="header" href="#storage_write_value_byte">storage_write_value_byte</a></h3>
<p><code>type: Gas</code></p>
<p>Storage trie write value per byte cost</p>
<h3 id="storage_write_evicted_byte"><a class="header" href="#storage_write_evicted_byte">storage_write_evicted_byte</a></h3>
<p><code>type: Gas</code></p>
<p>Storage trie write cost per byte of evicted value.</p>
<h3 id="storage_read_base"><a class="header" href="#storage_read_base">storage_read_base</a></h3>
<p><code>type: Gas</code></p>
<p>Storage trie read key base cost</p>
<h3 id="storage_read_key_byte"><a class="header" href="#storage_read_key_byte">storage_read_key_byte</a></h3>
<p><code>type: Gas</code></p>
<p>Storage trie read key per byte cost</p>
<h3 id="storage_read_value_byte"><a class="header" href="#storage_read_value_byte">storage_read_value_byte</a></h3>
<p><code>type: Gas</code></p>
<p>Storage trie read value cost per byte cost</p>
<h3 id="storage_remove_base"><a class="header" href="#storage_remove_base">storage_remove_base</a></h3>
<p><code>type: Gas</code></p>
<p>Remove key from trie base cost</p>
<h3 id="storage_remove_key_byte"><a class="header" href="#storage_remove_key_byte">storage_remove_key_byte</a></h3>
<p><code>type: Gas</code></p>
<p>Remove key from trie per byte cost</p>
<h3 id="storage_remove_ret_value_byte"><a class="header" href="#storage_remove_ret_value_byte">storage_remove_ret_value_byte</a></h3>
<p><code>type: Gas</code></p>
<p>Remove key from trie ret value byte cost</p>
<h3 id="storage_has_key_base"><a class="header" href="#storage_has_key_base">storage_has_key_base</a></h3>
<p><code>type: Gas</code></p>
<p>Storage trie check for key existence cost base</p>
<h3 id="storage_has_key_byte"><a class="header" href="#storage_has_key_byte">storage_has_key_byte</a></h3>
<p><code>type: Gas</code></p>
<p>Storage trie check for key existence per key byte</p>
<h3 id="storage_iter_create_prefix_base"><a class="header" href="#storage_iter_create_prefix_base">storage_iter_create_prefix_base</a></h3>
<p><code>type: Gas</code></p>
<p>Create trie prefix iterator cost base</p>
<h3 id="storage_iter_create_prefix_byte"><a class="header" href="#storage_iter_create_prefix_byte">storage_iter_create_prefix_byte</a></h3>
<p><code>type: Gas</code></p>
<p>Create trie prefix iterator cost per byte.</p>
<h3 id="storage_iter_create_range_base"><a class="header" href="#storage_iter_create_range_base">storage_iter_create_range_base</a></h3>
<p><code>type: Gas</code></p>
<p>Create trie range iterator cost base</p>
<h3 id="storage_iter_create_from_byte"><a class="header" href="#storage_iter_create_from_byte">storage_iter_create_from_byte</a></h3>
<p><code>type: Gas</code></p>
<p>Create trie range iterator cost per byte of from key.</p>
<h3 id="storage_iter_create_to_byte"><a class="header" href="#storage_iter_create_to_byte">storage_iter_create_to_byte</a></h3>
<p><code>type: Gas</code></p>
<p>Create trie range iterator cost per byte of to key.</p>
<h3 id="storage_iter_next_base"><a class="header" href="#storage_iter_next_base">storage_iter_next_base</a></h3>
<p><code>type: Gas</code></p>
<p>Trie iterator per key base cost</p>
<h3 id="storage_iter_next_key_byte"><a class="header" href="#storage_iter_next_key_byte">storage_iter_next_key_byte</a></h3>
<p><code>type: Gas</code></p>
<p>Trie iterator next key byte cost</p>
<h3 id="storage_iter_next_value_byte"><a class="header" href="#storage_iter_next_value_byte">storage_iter_next_value_byte</a></h3>
<p><code>type: Gas</code></p>
<p>Trie iterator next key byte cost</p>
<h3 id="touching_trie_node"><a class="header" href="#touching_trie_node">touching_trie_node</a></h3>
<p><code>type: Gas</code></p>
<p>Cost per touched trie node</p>
<h2 id="promise-api"><a class="header" href="#promise-api">Promise API</a></h2>
<h3 id="promise_and_base"><a class="header" href="#promise_and_base">promise_and_base</a></h3>
<p><code>type: Gas</code></p>
<p>Cost for calling promise_and</p>
<h3 id="promise_and_per_promise"><a class="header" href="#promise_and_per_promise">promise_and_per_promise</a></h3>
<p><code>type: Gas</code></p>
<p>Cost for calling promise_and for each promise</p>
<h3 id="promise_return-1"><a class="header" href="#promise_return-1">promise_return</a></h3>
<p><code>type: Gas</code></p>
<p>Cost for calling promise_return</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="vmconfig"><a class="header" href="#vmconfig">VMConfig</a></h1>
<p>Config of wasm operations.</p>
<h2 id="ext_costs"><a class="header" href="#ext_costs">ext_costs</a></h2>
<p><code>type: [ExtCostsConfig]</code> <a href="GenesisConfig/ExtCostsConfig.html">ExtCostsConfig</a></p>
<p>Costs for runtime externals</p>
<h2 id="grow_mem_cost"><a class="header" href="#grow_mem_cost">grow_mem_cost</a></h2>
<p>`type: u32</p>
<p>Gas cost of a growing memory by single page.</p>
<h2 id="regular_op_cost"><a class="header" href="#regular_op_cost">regular_op_cost</a></h2>
<p>`type: u32</p>
<p>Gas cost of a regular operation.</p>
<h2 id="linear_op_base_cost"><a class="header" href="#linear_op_base_cost">linear_op_base_cost</a></h2>
<p>`type: u64</p>
<p>Base gas cost of a bulk memory/table operation.</p>
<h2 id="linear_op_unit_cost"><a class="header" href="#linear_op_unit_cost">linear_op_unit_cost</a></h2>
<p>`type: u64</p>
<p>Gas cost per unit of a bulk memory/table operation.</p>
<h2 id="max_gas_burnt"><a class="header" href="#max_gas_burnt">max_gas_burnt</a></h2>
<p>`type: Gas</p>
<p>Max amount of gas that can be used, excluding gas attached to promises.</p>
<h2 id="max_stack_height"><a class="header" href="#max_stack_height">max_stack_height</a></h2>
<p>`type: u32</p>
<p>How tall the stack is allowed to grow?</p>
<h2 id="initial_memory_pages"><a class="header" href="#initial_memory_pages">initial_memory_pages</a></h2>
<p>`type: u32</p>
<h2 id="max_memory_pages"><a class="header" href="#max_memory_pages">max_memory_pages</a></h2>
<p>`type: u32</p>
<p>The initial number of memory pages.
What is the maximal memory pages amount is allowed to have for
a contract.</p>
<h2 id="registers_memory_limit"><a class="header" href="#registers_memory_limit">registers_memory_limit</a></h2>
<p>`type: u64</p>
<p>Limit of memory used by registers.</p>
<h2 id="max_register_size"><a class="header" href="#max_register_size">max_register_size</a></h2>
<p>`type: u64</p>
<p>Maximum number of bytes that can be stored in a single register.</p>
<h2 id="max_number_registers"><a class="header" href="#max_number_registers">max_number_registers</a></h2>
<p>`type: u64</p>
<p>Maximum number of registers that can be used simultaneously.</p>
<h2 id="max_number_logs"><a class="header" href="#max_number_logs">max_number_logs</a></h2>
<p>`type: u64</p>
<p>Maximum number of log entries.</p>
<h2 id="max_log_len"><a class="header" href="#max_log_len">max_log_len</a></h2>
<p>`type: u64</p>
<p>Maximum length of a single log, in bytes.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="staterecord"><a class="header" href="#staterecord">StateRecord</a></h1>
<p><code>type: Enum</code></p>
<p>Enum that describes one of the records in the state storage.</p>
<h2 id="account-1"><a class="header" href="#account-1">Account</a></h2>
<p><code>type: Unnamed struct</code></p>
<p>Record that contains account information for a given account ID.</p>
<h3 id="account_id"><a class="header" href="#account_id">account_id</a></h3>
<p><code>type: AccountId</code></p>
<p>The account ID of the account.</p>
<h3 id="account-2"><a class="header" href="#account-2">account</a></h3>
<p><code>type:</code> <a href="GenesisConfig/../DataStructures/Account.html">Account</a></p>
<p>The account structure. Serialized to JSON. U128 types are serialized to strings.</p>
<h2 id="data-1"><a class="header" href="#data-1">Data</a></h2>
<p><code>type: Unnamed struct</code></p>
<p>Record that contains key-value data record for a contract at the given account ID.</p>
<h3 id="account_id-1"><a class="header" href="#account_id-1">account_id</a></h3>
<p><code>type: AccountId</code></p>
<p>The account ID of the contract that contains this data record.</p>
<h3 id="data_key"><a class="header" href="#data_key">data_key</a></h3>
<p><code>type: Vec&lt;u8&gt;</code></p>
<p>Data Key serialized in Base64 format.</p>
<p><em>NOTE: Key doesn't contain the data separator.</em></p>
<h3 id="value"><a class="header" href="#value">value</a></h3>
<p><code>type: Vec&lt;u8&gt;</code></p>
<p>Value serialized in Base64 format.</p>
<h2 id="contract"><a class="header" href="#contract">Contract</a></h2>
<p><code>type: Unnamed struct</code></p>
<p>Record that contains a contract code for a given account ID.</p>
<h3 id="account_id-2"><a class="header" href="#account_id-2">account_id</a></h3>
<p><code>type: AccountId</code></p>
<p>The account ID of that has the contract.</p>
<h3 id="code"><a class="header" href="#code">code</a></h3>
<p><code>type: Vec&lt;u8&gt;</code></p>
<p>WASM Binary contract code serialized in Base64 format.</p>
<h2 id="accesskey"><a class="header" href="#accesskey">AccessKey</a></h2>
<p><code>type: Unnamed struct</code></p>
<p>Record that contains an access key for a given account ID.</p>
<h3 id="account_id-3"><a class="header" href="#account_id-3">account_id</a></h3>
<p><code>type: AccountId</code></p>
<p>The account ID of the access key owner.</p>
<h3 id="public_key"><a class="header" href="#public_key">public_key</a></h3>
<p><code>type: PublicKey</code></p>
<p>The public key for the access key in JSON-friendly string format. E.g. <code>ed25519:5JFfXMziKaotyFM1t4hfzuwh8GZMYCiKHfqw1gTEWMYT</code></p>
<h3 id="access_key"><a class="header" href="#access_key">access_key</a></h3>
<p><code>type:</code> <a href="GenesisConfig/../DataStructures/AccessKey.html">AccessKey</a></p>
<p>The access key serialized in JSON format.</p>
<h2 id="postponedreceipt"><a class="header" href="#postponedreceipt">PostponedReceipt</a></h2>
<p><code>type: Box&lt;Receipt&gt;</code> <a href="GenesisConfig/../RuntimeSpec/Receipts.html">Receipt</a></p>
<p>Record that contains a receipt that was postponed on a shard (e.g. it's waiting for incoming data).
The receipt is in JSON-friendly format. The receipt can only be an <code>ActionReceipt</code>.</p>
<p>NOTE: Box is used to decrease fixed size of the entire enum.</p>
<h2 id="receiveddata"><a class="header" href="#receiveddata">ReceivedData</a></h2>
<p><code>type: Unnamed struct</code></p>
<p>Record that contains information about received data for some action receipt, that is not yet received or processed for a given account ID.
The data is received using <code>DataReceipt</code> before. See <a href="GenesisConfig/../RuntimeSpec/Receipts.html">Receipts</a> for details.</p>
<h3 id="account_id-4"><a class="header" href="#account_id-4">account_id</a></h3>
<p><code>type: AccountId</code></p>
<p>The account ID of the receiver of the data.</p>
<h3 id="data_id-1"><a class="header" href="#data_id-1">data_id</a></h3>
<p><code>type: CryptoHash</code></p>
<p>Data ID of the data in base58 format.</p>
<h3 id="data-2"><a class="header" href="#data-2">data</a></h3>
<p><code>type: Option&lt;Vec&lt;u8&gt;&gt;</code></p>
<p>Optional data encoded as base64 format or null in JSON.</p>
<h2 id="delayedreceipt"><a class="header" href="#delayedreceipt">DelayedReceipt</a></h2>
<p><code>type: Box&lt;Receipt&gt;</code> <a href="GenesisConfig/../RuntimeSpec/Receipts.html">Receipt</a></p>
<p>Record that contains a receipt that was delayed on a shard. It means the shard was overwhelmed with receipts and it processes receipts from backlog.
The receipt is in JSON-friendly format.  See <a href="GenesisConfig/../RuntimeSpec/Components/RuntimeCrate.html#delayed-receipts">Delayed Receipts</a> for details.</p>
<p>NOTE: Box is used to decrease fixed size of the entire enum.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="runtimeconfig"><a class="header" href="#runtimeconfig">RuntimeConfig</a></h1>
<p>The structure that holds the parameters of the runtime, mostly economics.</p>
<h2 id="storage_cost_byte_per_block"><a class="header" href="#storage_cost_byte_per_block">storage_cost_byte_per_block</a></h2>
<p><code>type: Balance</code></p>
<p>The cost to store one byte of storage per block.</p>
<h3 id="storage_cost_byte_per_block-1"><a class="header" href="#storage_cost_byte_per_block-1">storage_cost_byte_per_block</a></h3>
<p><code>type: Balance</code></p>
<p>Costs of different actions that need to be performed when sending and processing transaction
and receipts.</p>
<h2 id="poke_threshold"><a class="header" href="#poke_threshold">poke_threshold</a></h2>
<p><code>type: BlockIndex</code></p>
<p>The minimum number of blocks of storage rent an account has to maintain to prevent forced deletion.</p>
<h2 id="transaction_costs"><a class="header" href="#transaction_costs">transaction_costs</a></h2>
<p><code>type: RuntimeFeesConfig</code> <a href="GenesisConfig/RuntimeFeeConfig.html">RuntimeFeesConfig</a></p>
<p>Costs of different actions that need to be performed when sending and processing transaction and receipts.</p>
<h2 id="wasm_config"><a class="header" href="#wasm_config">wasm_config</a></h2>
<p><code>type: VMConfig</code> <a href="GenesisConfig/VMConfig.html">VMConfig</a></p>
<p>Config of wasm operations.</p>
<h2 id="account_length_baseline_cost_per_block"><a class="header" href="#account_length_baseline_cost_per_block">account_length_baseline_cost_per_block</a></h2>
<p><code>type: Balance</code></p>
<p>The baseline cost to store account_id of short length per block.
The original formula in NEP#0006 is <code>1,000 / (3 ^ (account_id.length - 2))</code> for cost per year.
This value represents <code>1,000</code> above adjusted to use per block</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="runtimefeesconfig"><a class="header" href="#runtimefeesconfig">RuntimeFeesConfig</a></h1>
<p>Economic parameters for runtime</p>
<h2 id="action_receipt_creation_config"><a class="header" href="#action_receipt_creation_config">action_receipt_creation_config</a></h2>
<p><code>type: Fee</code></p>
<p>Describes the cost of creating an action receipt, <code>ActionReceipt</code>, excluding the actual cost
of actions.</p>
<h2 id="data_receipt_creation_config"><a class="header" href="#data_receipt_creation_config">data_receipt_creation_config</a></h2>
<p><code>type:</code> <a href="GenesisConfig/RuntimeFeeConfig/DataReceiptCreationConfig.html">DataReceiptCreationConfig</a></p>
<p>Describes the cost of creating a data receipt, <code>DataReceipt</code>.</p>
<h2 id="action_creation_config"><a class="header" href="#action_creation_config">action_creation_config</a></h2>
<p><code>type:</code> <a href="GenesisConfig/RuntimeFeeConfig/ActionCreationConfig.html">ActionCreationConfig</a></p>
<p>Describes the cost of creating a certain action, <code>Action</code>. Includes all variants.</p>
<h2 id="storage_usage_config"><a class="header" href="#storage_usage_config">storage_usage_config</a></h2>
<p><code>type:</code> <a href="GenesisConfig/RuntimeFeeConfig/StorageUsageConfig.html">StorageUsageConfig</a></p>
<p>Describes fees for storage rent</p>
<h2 id="burnt_gas_reward"><a class="header" href="#burnt_gas_reward">burnt_gas_reward</a></h2>
<p><code>type:</code> <a href="GenesisConfig/RuntimeFeeConfig/Fraction.html">Fraction</a></p>
<p>Fraction of the burnt gas to reward to the contract account for execution.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="accesskeycreationconfig"><a class="header" href="#accesskeycreationconfig">AccessKeyCreationConfig</a></h1>
<p>Describes the cost of creating an access key.</p>
<h2 id="full_access_cost"><a class="header" href="#full_access_cost">full_access_cost</a></h2>
<p><em>type: Fee</em>
Base cost of creating a full access access-key.</p>
<h2 id="function_call_cost"><a class="header" href="#function_call_cost">function_call_cost</a></h2>
<p><em>type: Fee</em>
Base cost of creating an access-key restricted to specific functions.</p>
<h2 id="function_call_cost_per_byte"><a class="header" href="#function_call_cost_per_byte">function_call_cost_per_byte</a></h2>
<p><em>type: Fee</em>
Cost per byte of method_names of creating a restricted access-key.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="action_creation_config-1"><a class="header" href="#action_creation_config-1">action_creation_config</a></h1>
<p>Describes the cost of creating a specific action, <code>Action</code>. Includes all variants.</p>
<h2 id="create_account_cost"><a class="header" href="#create_account_cost">create_account_cost</a></h2>
<p><code>type: Fee</code></p>
<p>Base cost of creating an account.</p>
<h2 id="deploy_contract_cost"><a class="header" href="#deploy_contract_cost">deploy_contract_cost</a></h2>
<p><code>type: Fee</code></p>
<p>Base cost of deploying a contract.</p>
<h2 id="deploy_contract_cost_per_byte"><a class="header" href="#deploy_contract_cost_per_byte">deploy_contract_cost_per_byte</a></h2>
<p><code>type: Fee</code></p>
<p>Cost per byte of deploying a contract.</p>
<h2 id="function_call_cost-1"><a class="header" href="#function_call_cost-1">function_call_cost</a></h2>
<p><code>type: Fee</code></p>
<p>Base cost of calling a function.</p>
<h2 id="function_call_cost_per_byte-1"><a class="header" href="#function_call_cost_per_byte-1">function_call_cost_per_byte</a></h2>
<p><code>type: Fee</code></p>
<p>Cost per byte of method name and arguments of calling a function.</p>
<h2 id="transfer_cost"><a class="header" href="#transfer_cost">transfer_cost</a></h2>
<p><code>type: Fee</code></p>
<p>Base cost of making a transfer.</p>
<p>NOTE: If the account ID is an implicit account ID (64-length hex account ID), then the cost of the transfer fee
will be <code>transfer_cost + create_account_cost + add_key_cost.full_access_cost</code>.
This is needed to account for the implicit account creation costs.</p>
<h2 id="stake_cost"><a class="header" href="#stake_cost">stake_cost</a></h2>
<p><code>type: Fee</code></p>
<p>Base cost of staking.</p>
<h2 id="add_key_cost"><a class="header" href="#add_key_cost">add_key_cost</a></h2>
<p><em>type: <a href="GenesisConfig/RuntimeFeeConfig/AccessKeyCreationConfig.html">AccessKeyCreationConfig</a></em>
Base cost of adding a key.</p>
<h2 id="delete_key_cost"><a class="header" href="#delete_key_cost">delete_key_cost</a></h2>
<p><code>type: Fee</code></p>
<p>Base cost of deleting a key.</p>
<h2 id="delete_account_cost"><a class="header" href="#delete_account_cost">delete_account_cost</a></h2>
<p><code>type: Fee</code></p>
<p>Base cost of deleting an account.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="datareceiptcreationconfig"><a class="header" href="#datareceiptcreationconfig">DataReceiptCreationConfig</a></h1>
<p>Describes the cost of creating a data receipt, <code>DataReceipt</code>.</p>
<h2 id="base_cost"><a class="header" href="#base_cost">base_cost</a></h2>
<p><em>type: Fee</em>
Base cost of creating a data receipt.</p>
<h2 id="cost_per_byte"><a class="header" href="#cost_per_byte">cost_per_byte</a></h2>
<p><em>type: Fee</em>
Additional cost per byte sent.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="fee"><a class="header" href="#fee">Fee</a></h1>
<p>Costs associated with an object that can only be sent over the network (and executed by the receiver).</p>
<h2 id="send_sir"><a class="header" href="#send_sir">send_sir</a></h2>
<p>Fee for sending an object from the sender to itself, guaranteeing that it does not leave (SIR = signer is receiver, which guarantees the receipt is local).</p>
<h2 id="send_not_sir"><a class="header" href="#send_not_sir">send_not_sir</a></h2>
<p>Fee for sending an object potentially across the shards.</p>
<h2 id="execution-1"><a class="header" href="#execution-1">execution</a></h2>
<p>Fee for executing the object.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="fraction"><a class="header" href="#fraction">Fraction</a></h1>
<h2 id="numerator"><a class="header" href="#numerator">numerator</a></h2>
<p><code>type: u64</code></p>
<h2 id="denominator"><a class="header" href="#denominator">denominator</a></h2>
<p><code>type: u64</code></p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="storageusageconfig"><a class="header" href="#storageusageconfig">StorageUsageConfig</a></h1>
<p>Describes cost of storage per block</p>
<h2 id="account_cost"><a class="header" href="#account_cost">account_cost</a></h2>
<p><em>type: Gas</em>
Base storage usage for an account</p>
<h2 id="data_record_cost"><a class="header" href="#data_record_cost">data_record_cost</a></h2>
<p><em>type: Gas</em>
Base cost for a k/v record</p>
<h2 id="key_cost_per_byte"><a class="header" href="#key_cost_per_byte">key_cost_per_byte</a></h2>
<p><em>type: Gas</em>
Cost per byte of key</p>
<h2 id="value_cost_per_byte-gas"><a class="header" href="#value_cost_per_byte-gas">value_cost_per_byte: Gas</a></h2>
<p><em>type: Gas</em>
Cost per byte of value</p>
<h2 id="code_cost_per_byte-gas"><a class="header" href="#code_cost_per_byte-gas">code_cost_per_byte: Gas</a></h2>
<p><em>type: Gas</em>
Cost per byte of contract code</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="overview-3"><a class="header" href="#overview-3">Overview</a></h1>
<p>This document describes the high-level architecture of nearcore. The focus here
is on the implementation of the blockchain protocol, not the protocol itself.
For reference documentation of the protocol, please refer to
<a href="https://nomicon.io/">nomicon</a></p>
<p>Some parts of our architecture are also covered in this <a href="https://www.youtube.com/playlist?list=PL9tzQn_TEuFV4qlts0tVgndnytFs4QSYo">video series on YouTube</a>.</p>
<h2 id="birds-eye-view"><a class="header" href="#birds-eye-view">Bird's Eye View</a></h2>
<p>If we put the entirety of nearcore onto one picture, we get something like this:</p>
<p><img src="architecture/../images/architecture.svg" alt="" /></p>
<p>Don't worry if this doesn't yet make a lot of sense: hopefully, by the end of
this document the above picture would become much clearer!</p>
<h2 id="overall-operation"><a class="header" href="#overall-operation">Overall Operation</a></h2>
<p><code>nearcore</code> is a blockchain node -- it's a single binary (<code>neard</code>) which runs on
some machine and talks to other similar binaries running elsewhere. Together,
the nodes agree (using a distributed consensus algorithm) on a particular
sequence of transactions. Once transaction sequence is established, each node
applies transactions to the current state. Because transactions are fully
deterministic, each node in the network ends up with identical state. To allow
greater scalability, NEAR protocol uses sharding, which allows a node to hold
only a small subset (shard) of the whole state.</p>
<p><code>neard</code> is a stateful, restartable process. When <code>neard</code> starts, the node
connects to the network and starts processing blocks (block is a batch of
transactions, processed together; transactions are batched into blocks for
greater efficiency). The results of processing are persisted in the database.
RocksDB is used for storage. Usually, the node's data is found in the <code>~/.near</code>
directory. The node can be stopped at any moment and be restarted later. While
the node is offline it misses the block, so, after a restart, the sync process
kicks in which brings the node up-to-speed with the network by downloading the
missing bits of history from more up-to-date peer nodes.</p>
<p>Major components of nearcore:</p>
<ul>
<li>
<p><strong>JSON RPC</strong>. This HTTP RPC interface is how <code>neard</code> communicates with
non-blockchain outside world. For example, to submit a transaction, some
client sends an RPC request with it to some node in the network. From that
node, the transaction propagates through the network, until it is included in
some block. Similarly, a client can send an HTTP request to a node to learn
about current state of the blockchain. The <strong>JSON RPC</strong> interface is documented
<a href="https://docs.near.org/api/rpc/introduction">here</a>.</p>
</li>
<li>
<p><strong>Network</strong>. If RPC is aimed &quot;outside&quot; the blockchain, &quot;network&quot; is how peer
<code>neard</code> nodes communicate with each other within the blockchain. RPC carries
requests from users of the blockchain, while network carries various messages
needed to implement consensus. Two directly connected nodes communicate by
sending protobuf-encoded messages over TCP. A node also includes logic to
route messages for indirect peers through intermediaries. Oversimplifying a
lot, it's enough for a new node to know an IP address of just one other
network participant. From this bootstrap connection, the node learns how to
communicate with any other node in the network.</p>
</li>
<li>
<p><strong>Client</strong>. Somewhat confusingly named, <strong>client</strong> is the logical state of the
blockchain. After receiving and decoding a request, both <strong>RPC</strong> and <strong>network</strong>
usually forward it in the parsed form to the <strong>client</strong>. Internally, <strong>client</strong> is
split in two somewhat independent components: <strong>chain</strong> and <strong>runtime</strong>.</p>
</li>
<li>
<p><strong>Chain</strong>. The job of <strong>chain</strong>, in a nutshell, is to determine a global order of
transactions. <strong>Chain</strong> builds and maintains the blockchain data structure. This
includes block and chunk production and processing, consensus, and validator
selection. However, <strong>chain</strong> is not responsible for actually applying
transactions and receipts.</p>
</li>
<li>
<p><strong>Runtime</strong>. If <strong>chain</strong> selects the <em>order</em> of transactions, <strong>Runtime</strong> applies
transaction to the state. <strong>Chain</strong> guarantees that everyone agrees on the order
and content of transactions, and <strong>Runtime</strong> guarantees that each transaction is
fully deterministic. It follows that everyone agrees on the &quot;current state&quot; of
the blockchain. Some transactions are as simple as &quot;transfer X tokens from
Alice to Bob&quot;. But a much more powerful class of transactions is supported:
&quot;run this arbitrary WebAssembly code in the context of the current state of
the chain&quot;. Running such &quot;smart contract&quot; transactions securely and
efficiently is a major part of what <strong>Runtime</strong> does. Today, <strong>Runtime</strong> uses a JIT
compiler to do that.</p>
</li>
<li>
<p><strong>Storage</strong>. <strong>Storage</strong> is more of a cross-cutting concern, than an isolated
component. Many parts of a node want to durably persist various bits of state
to disk. One notable case is the logical state of the blockchain, and, in
particular, data associated with each account. Logically, the state of an account
on a chain is a key-value map: <code>HashMap&lt;Vec&lt;u8&gt;, Vec&lt;u8&gt;&gt;</code>. But there is a
twist: it should be possible to provide a succinct proof that a particular key
indeed holds a particular value. To allow that internally the state is
implemented as a persistent (in both senses, &quot;functional&quot; and &quot;on disk&quot;)
merkle-patricia trie.</p>
</li>
<li>
<p><strong>Parameter Estimator</strong>. One kind of transaction we support is &quot;run this
arbitrary, Turing-complete computation&quot;. To protect from a <code>loop {}</code>
transaction halting the whole network, <strong>Runtime</strong> implements resource limiting:
each transaction runs with a certain finite amount of &quot;gas&quot;, and each
operation costs a certain amount of gas to perform. <strong>Parameter estimator</strong> is
essentially a set of benchmarks used to estimate relative gas costs of
various operations.</p>
</li>
</ul>
<h2 id="entry-points"><a class="header" href="#entry-points">Entry Points</a></h2>
<p><code>neard/src/main.rs</code> contains the main function that starts a blockchain node.
However, this file mostly only contains the logic to parse arguments and
dispatch different commands. <code>start_with_config</code> in <code>nearcore/src/lib.rs</code> is the
actual entry point and it starts all the actors.</p>
<p><code>JsonRpcHandler::process</code> in the <code>jsonrpc</code> crate is the RPC entry point. It
implements the public API of a node, which is documented
<a href="https://docs.near.org/api/rpc/introduction">here</a>.</p>
<p><code>PeerManagerActor::spawn</code> in the <code>network</code> is an entry for the other point of
contract with the outside world -- the peer-to-peer network.</p>
<p><code>Runtime::apply</code> in the <code>runtime</code> crate is the entry point for transaction
processing logic. This is where state transitions actually happen, after chain
decided, according to distributed consensus, which transitions need  to
happen.</p>
<h2 id="code-map"><a class="header" href="#code-map">Code Map</a></h2>
<p>This section contains some high-level overview of important crates and data
structures.</p>
<h3 id="coreprimitives"><a class="header" href="#coreprimitives"><code>core/primitives</code></a></h3>
<p>This crate contains most of the types that are shared across different crates.</p>
<h3 id="coreprimitives-core"><a class="header" href="#coreprimitives-core"><code>core/primitives-core</code></a></h3>
<p>This crate contains types needed for runtime.</p>
<h3 id="corestoretrie"><a class="header" href="#corestoretrie"><code>core/store/trie</code></a></h3>
<p>This directory contains the MPT state implementation. Note that we usually use
<code>TrieUpdate</code> to interact with the state.</p>
<h3 id="chainchain"><a class="header" href="#chainchain"><code>chain/chain</code></a></h3>
<p>This crate contains most of the chain logic (consensus, block processing, etc).
<code>ChainUpdate::process_block</code> is where most of the block processing logic
happens.</p>
<p><strong>State update</strong></p>
<p>The blockchain state of a node can be changed in the following two ways:</p>
<ul>
<li>Applying a chunk. This is how the state is normally updated: through
<code>Runtime::apply</code>.</li>
<li>State sync. State sync can happen in two cases:
<ul>
<li>A node is far enough behind the most recent block and triggers state sync to
fast forward to the state of a very recent block without having to apply
blocks in the middle.</li>
<li>A node is about to become validator for some shard in the next epoch, but it
does not yet have the state for that shard. In this case, it would run state
sync through the <code>catchup</code> routine.</li>
</ul>
</li>
</ul>
<h3 id="chainchunks"><a class="header" href="#chainchunks"><code>chain/chunks</code></a></h3>
<p>This crate contains most of the sharding logic which includes chunk creation,
distribution, and processing. <code>ShardsManager</code> is the main struct that
orchestrates everything here.</p>
<h3 id="chainclient"><a class="header" href="#chainclient"><code>chain/client</code></a></h3>
<p>This crate defines two important structs, <code>Client</code> and <code>ViewClient</code>. <code>Client</code>
includes everything necessary for the chain (without network and runtime) to
function and runs in a single thread. <code>ViewClient</code> is a &quot;read-only&quot; client that
answers queries without interfering with the operations of <code>Client</code>.
<code>ViewClient</code> runs in multiple threads.</p>
<h3 id="chainnetwork"><a class="header" href="#chainnetwork"><code>chain/network</code></a></h3>
<p>This crate contains the entire implementation of the p2p network used by NEAR
blockchain nodes.</p>
<p>Two important structs here: <code>PeerManagerActor</code> and <code>Peer</code>. Peer manager
orchestrates all the communications from network to other components and from
other components to network. <code>Peer</code> is responsible for low-level network
communications from and to a given peer (more details in
<a href="architecture/./network.html#23-peeractor">this article</a>). Peer manager runs in one thread while each
<code>Peer</code> runs in its own thread.</p>
<p><strong>Architecture Invariant:</strong> Network communicates to <code>Client</code> through
<code>NetworkClientMessages</code> and to <code>ViewClient</code> through <code>NetworkViewClientMessages</code>.
Conversely, <code>Client</code> and <code>ViewClient</code> communicates to network through
<code>NetworkRequests</code>.</p>
<h3 id="chainepoch_manager"><a class="header" href="#chainepoch_manager"><code>chain/epoch_manager</code></a></h3>
<p>This crate is responsible for determining validators and other epoch related
information such as epoch id for each epoch.</p>
<p><strong>Note:</strong> <code>EpochManager</code> is constructed in <code>NightshadeRuntime</code> rather than in
<code>Chain</code>, partially because we had this idea of making epoch manager a smart
contract.</p>
<h3 id="chainjsonrpc"><a class="header" href="#chainjsonrpc"><code>chain/jsonrpc</code></a></h3>
<p>This crate implements <a href="https://www.jsonrpc.org/">JSON-RPC</a> API server to enable
submission of new transactions and inspection of the blockchain data, the
network state, and the node status. When a request is processed, it generates a
message to either <code>ClientActor</code> or <code>ViewClientActor</code> to interact with the
blockchain. For queries of blockchain data, such as block, chunk, account, etc,
the request usually generates a message to <code>ViewClientActor</code>. Transactions, on
the other hand, are sent to <code>ClientActor</code> for further processing.</p>
<h3 id="runtimeruntime"><a class="header" href="#runtimeruntime"><code>runtime/runtime</code></a></h3>
<p>This crate contains the main entry point to runtime -- <code>Runtime::apply</code>. This
function takes <code>ApplyState</code>, which contains necessary information passed from
chain to runtime, a list of <code>SignedTransaction</code> and a list of <code>Receipt</code>, and
returns an <code>ApplyResult</code>, which includes state changes, execution outcomes, etc.</p>
<p><strong>Architecture Invariant:</strong> The state update is only finalized at the end of
<code>apply</code>. During all intermediate steps state changes can be reverted.</p>
<h3 id="runtimenear-vm-logic"><a class="header" href="#runtimenear-vm-logic"><code>runtime/near-vm-logic</code></a></h3>
<p><code>VMLogic</code> contains all the implementations of host functions and is the
interface between runtime and wasm. <code>VMLogic</code> is constructed when runtime
applies function call actions. In <code>VMLogic</code>, interaction with NEAR blockchain
happens in the following two ways:</p>
<ul>
<li><code>VMContext</code>, which contains lightweight information such as current block
hash, current block height, epoch id, etc.</li>
<li><code>External</code>, which is a trait that contains functions to interact with
blockchain by either reading some nontrivial data, or writing to the
blockchain.</li>
</ul>
<h3 id="runtimenear-vm-runner"><a class="header" href="#runtimenear-vm-runner"><code>runtime/near-vm-runner</code></a></h3>
<p><code>run</code> function in <code>runner.rs</code> is the entry point to the vm runner. This function essentially spins
up the vm and executes some function in a contract. It supports different wasm compilers including
near-vm and wasmtime through compile-time feature flags. Currently we use near-vm in production.
The <code>imports</code> module exposes host functions defined in <code>near-vm-logic</code> to WASM code. In other
words, it defines the ABI of the contracts on NEAR.</p>
<h3 id="neard"><a class="header" href="#neard"><code>neard</code></a></h3>
<p>As mentioned before, <code>neard</code> is the crate that contains that main entry points.
All the actors are spawned in <code>start_with_config</code>. It is also worth noting that
<code>NightshadeRuntime</code> is the struct that implements <code>RuntimeAdapter</code>.</p>
<!-- TODO: Maybe add RuntimeAdapter mention or explanation in runtime/runtime chapter? -->
<h3 id="corestoresrcdbrs"><a class="header" href="#corestoresrcdbrs"><code>core/store/src/db.rs</code></a></h3>
<p>This file contains the schema (DBCol) of our internal RocksDB storage - a good
starting point when reading the code base.</p>
<h2 id="cross-cutting-concerns"><a class="header" href="#cross-cutting-concerns">Cross Cutting Concerns</a></h2>
<h3 id="observability"><a class="header" href="#observability">Observability</a></h3>
<p>The <a href="https://tracing.rs">tracing</a> crate is used for structured, hierarchical
event output and logging. We also integrate <a href="https://prometheus.io">Prometheus</a>
for light-weight metric output. See the <a href="architecture/../practices/style.html">style</a> documentation for
more information on the usage.</p>
<h3 id="testing"><a class="header" href="#testing">Testing</a></h3>
<p>Rust has built-in support for writing unit tests by marking functions
with the <code>#[test]</code> directive.  Take full advantage of that!  Testing not
only confirms that what was written works the way it was intended to but
also helps during refactoring since it catches unintended behavior
changes.</p>
<p>Not all tests are created equal though and while some may only need
milliseconds to run, others may run for several seconds or even
minutes.  Tests that take a long time should be marked as such by
prefixing their name with <code>slow_test_</code> or <code>ultra_slow_test_</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[test]
fn ultra_slow_test_catchup_random_single_part_sync() {
    test_catchup_random_single_part_sync_common(false, false, 13)
}
<span class="boring">}
</span></code></pre></pre>
<p>During local development both slow and ultra-slow tests will not run
with a typical <code>just nextest</code> invocation. You can run them with <code>just nextest-slow</code> or <code>just nextest-all</code> locally. CI will run the slow
tests and the <code>ultra_slow</code> ones are left to run on Nayduck.</p>
<p>Because <code>ultra_slow</code> tests are run on nayduck, they need to be explicitly
included in <code>nightly/expensive.txt</code> file; for example:</p>
<pre><code class="language-text">expensive --timeout=1800 near-client near_client tests::catching_up::ultra_slow_test_catchup_random_single_part_sync
expensive --timeout=1800 near-client near_client tests::catching_up::ultra_slow_test_catchup_random_single_part_sync --features nightly
expensive --timeout=1800 near-client near_client tests::catching_up::ultra_slow_test_catchup_random_single_part_sync --features nightly,protocol_feature_spice
</code></pre>
<p>For more details regarding nightly tests see <code>nightly/README.md</code>.</p>
<p>Note that what counts as a slow test is defined in
<code>.config/nextest.toml</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="how-neard-works"><a class="header" href="#how-neard-works">How neard works</a></h1>
<p>This chapter describes how neard works with a focus on implementation details
and practical scenarios. To get a better understanding of how the protocol
works, please refer to <a href="https://nomicon.io">nomicon</a>. For a high-level code map
of nearcore, please refer to this <a href="architecture/how/../">document</a>.</p>
<h2 id="high-level-overview-1"><a class="header" href="#high-level-overview-1">High level overview</a></h2>
<p>On the high level, neard is a daemon that periodically receives messages from
the network and sends messages to peers based on different triggers. Neard is
implemented using an actor framework provided by near-async.</p>
<p>There are several important actors in neard:</p>
<ul>
<li>
<p><code>PeerActor</code> - Each peer is represented by one peer actor and runs in a separate
thread. It is responsible for sending messages to and receiving messages from
a given peer. After <code>PeerActor</code> receives a message, it will route it to
<code>ClientActor</code>, <code>ViewClientActor</code>, or <code>PeerManagerActor</code> depending on the type
of the message.</p>
</li>
<li>
<p><code>PeerManagerActor</code> - Peer Manager is responsible for receiving messages to send
to the network from either <code>ClientActor</code> or <code>ViewClientActor</code> and routing them to
the right <code>PeerActor</code> to send the bytes over the wire. It is also responsible for
handling some types of network messages received and routed through <code>PeerActor</code>.
For the purpose of this document, we only need to know that <code>PeerManagerActor</code>
handles <code>RoutedMessage</code>s. Peer manager would decide whether the <code>RoutedMessage</code>s
should be routed to <code>ClientActor</code> or <code>ViewClientActor</code>.</p>
</li>
<li>
<p><code>ClientActor</code> - Client actor is the â€œcoreâ€ of neard. It contains all the main
logic including consensus, block and chunk processing, state transition, garbage
collection, etc. Client actor is single-threaded.</p>
</li>
<li>
<p><code>ViewClientActor</code> - View client actor can be thought of as a read-only interface
to <strong>client</strong>. It only accesses data stored in a nodeâ€™s storage and does not mutate
any state. It is used for two purposes:</p>
<ul>
<li>Answering RPC requests by fetching the relevant piece of data from storage.</li>
<li>Handling some network requests that do not require any changes to the
storage, such as header sync, state sync, and block sync requests.</li>
</ul>
<p><code>ViewClientActor</code> runs in four threads by default but this number is configurable.</p>
</li>
</ul>
<h2 id="data-flow-within-neard"><a class="header" href="#data-flow-within-neard">Data flow within <code>neard</code></a></h2>
<p>Flow for incoming messages:</p>
<p><img src="https://user-images.githubusercontent.com/1711539/195619986-25798cde-8a91-4721-86bd-93fa924b483a.png" alt="" /></p>
<p>Flow for outgoing messages:</p>
<p><img src="https://user-images.githubusercontent.com/1711539/195626792-7697129b-7f9c-4953-b939-0b9bcacaf72c.png" alt="" /></p>
<h2 id="how-neard-operates-when-it-is-fully-synced"><a class="header" href="#how-neard-operates-when-it-is-fully-synced">How neard operates when it is fully synced</a></h2>
<p>When a node is fully synced, the main logic of the node operates in the
following way (the node is assumed to track all shards, as most nodes on mainnet
do today):</p>
<ol>
<li>A block is produced by some block producer and sent to the node through
broadcasting.</li>
<li>The node receives a block and tries to process it. If the node is synced it
presumably has the previous block and the state before the current block to
apply. It then checks whether it has all the chunks available. If the node is
not a validator node, it wonâ€™t have any chunk parts and therefore wonâ€™t have
the chunks available. If the node is a validator node, it may already have
chunk parts through chunk parts forwarding from other nodes and therefore may
have already reconstructed some chunks. Regardless, if the node doesnâ€™t have all
chunks for all shards, it will request them from peers by parts.</li>
<li>The chunk requests are sent and the node waits for enough chunk parts to be
received to reconstruct the chunks. For each chunk, 1/3 of all the parts<!-- TODO: Is 100 the number of all the parts or one third of all the parts? -->
(100) is sufficient to reconstruct a chunk. If new blocks arrive while waiting
for chunk parts, they will be put into an <code>OrphanPool</code>, waiting to be processed.
If a chunk part request is not responded to within <code>chunk_request_retry_period</code>,
which is set to 400ms by default, then a request for the same chunk part
would be sent again.</li>
<li>After all chunks are reconstructed, the node processes the current block by
applying transactions and receipts from the chunks. Afterwards, it will
update the head according to the fork choice rule, which only looks at block
height. In other words, if the newly processed block is of higher height than
the current head of the node, the head is updated.</li>
<li>The node checks whether any blocks in the <code>OrphanPool</code> are ready to be
processed in a BFS order and processes all of them until none can be
processed anymore. Note that a block is put into the <code>OrphanPool</code> if and
only if its previous block is not accepted.</li>
<li>Upon acceptance of a block, the node would check whether it needs to run
garbage collection. If it needs to, it would garbage collect two blocks worth
of data at a time. The logic of garbage collection is complicated and could
be found <a href="architecture/how/./gc.html">here</a>.</li>
<li>If the node is a validator node, it would start a timer after the current
block is accepted. After <code>min_block_production_delay</code> which is currently
configured to be 1.3s on mainnet, it would send an approval to the block
producer of the next block (current block height + 1).</li>
</ol>
<p>The main logic is illustrated below:</p>
<p><img src="https://user-images.githubusercontent.com/1711539/195635652-f0c7ebae-a2e5-423f-8e62-b853b815fcec.png" alt="" /></p>
<h2 id="how-neard-works-when-it-is-synchronizing"><a class="header" href="#how-neard-works-when-it-is-synchronizing">How neard works when it is synchronizing</a></h2>
<p><code>PeerManagerActor</code> periodically sends a <code>NetworkInfo</code> message to <code>ClientActor</code>
to update it on the latest peer information, which includes the height of each
peer. Once <code>ClientActor</code> realizes that it is more than <code>sync_height_threshold</code>
(which by default is set to 1) behind the highest height among peers, it starts
to sync. The synchronization process is done in three steps:</p>
<ol>
<li>
<p>Header sync. The node first identifies the headers it needs to sync through a
<a href="https://github.com/near/nearcore/blob/279044f09a7e6e5e3f26db4898af3655dae6eda6/chain/client/src/sync.rs#L332"><code>get_locator</code></a>
calculation. This is essentially an exponential backoff computation that
tries to identify commonly known headers between the node and its peers. Then
it would request headers from different peers, at most
<code>MAX_BLOCK_HEADER_HASHES</code> (which is 512) headers at a time.</p>
</li>
<li>
<p>After the headers are synced, the node would determine whether it needs to
run state sync. The exact condition can be found
<a href="https://github.com/near/nearcore/blob/279044f09a7e6e5e3f26db4898af3655dae6eda6/chain/client/src/sync.rs#L458">here</a>
but basically a node would do state sync if it is more than 2 epochs behind
the head of the network. State sync is a very complex process and warrants
its own section. We will give a high level overview here.</p>
<ol>
<li>First, the node computes <code>sync_hash</code> which is the hash of the block that
identifies the state that the node wants to sync. This is guaranteed to be
the first block of the most recent epoch. In fact, there is a
<a href="https://github.com/near/nearcore/blob/279044f09a7e6e5e3f26db4898af3655dae6eda6/chain/chain/src/chain.rs#L4292">check</a>
on the receiver side that this is indeed the case. The node would also
request the block whose hash is <code>sync_hash</code></li>
<li>The node <a href="https://github.com/near/nearcore/blob/279044f09a7e6e5e3f26db4898af3655dae6eda6/chain/chain/src/chain.rs#L1809">deletes basically all data (blocks, chunks, state) from its
storage</a>.
This is not an optimal solution, but it makes the implementation for
combining state easier when there is no stale data in storage.</li>
<li>For the state of each shard that the node needs to download, it first
requests a
<a href="https://github.com/near/nearcore/blob/279044f09a7e6e5e3f26db4898af3655dae6eda6/core/primitives/src/syncing.rs#L40">header</a>
that contains some metadata the node needs to know about. Then the node
computes the number of state parts it needs to download and requests those
parts from different peers who track the shard.</li>
<li>After all parts are downloaded, the node <a href="https://github.com/near/nearcore/blob/279044f09a7e6e5e3f26db4898af3655dae6eda6/chain/client/src/client_actor.rs#L1877">combines those state
parts</a>
and then
<a href="https://github.com/near/nearcore/blob/279044f09a7e6e5e3f26db4898af3655dae6eda6/chain/chain/src/chain.rs#L3065">finalizes</a>
the state sync by applying the last chunk included in or before the sync
block so that the node has the state after applying sync block to be able
to apply the next block.</li>
<li>The node <a href="https://github.com/near/nearcore/blob/279044f09a7e6e5e3f26db4898af3655dae6eda6/chain/chain/src/chain.rs#L1874">resets
heads</a>
properly after state sync.</li>
</ol>
</li>
<li>
<p>Block Sync. The node first gets the block with highest height that is on the
canonical chain and request from there <code>MAX_BLOCK_REQUESTS</code> (which is set to 5)
blocks from different peers in a round robin order. The block sync routine
runs again if head has changed (progress is made) or if a timeout (which is
set to 2s) has happened.</p>
</li>
</ol>
<p><strong>Note:</strong> when a block is received and its height is no more than 500 + the
nodeâ€™s current head height, then the node would request its previous block
automatically. This is called orphan sync and helps to speed up the syncing
process. If, on the other hand, the height is more than 500 + the nodeâ€™s current
head height, the block is simply dropped.</p>
<!-- TODO: Either this note is incorrect or the block processing diagram is. -->
<h2 id="how-clientactor-works"><a class="header" href="#how-clientactor-works">How <code>ClientActor</code> works</a></h2>
<p>ClientActor has some periodically running routines that are worth noting:</p>
<ul>
<li><a href="https://github.com/near/nearcore/blob/fa78002a1b4119e5efe277c3073b3f333f451ffc/chain/client/src/client_actor.rs#L1198">Doomslug
timer</a> -
This routine runs every <code>doomslug_step_period</code> (set to 100ms by default) and
updates consensus information. If the node is a validator node, it also sends
approvals when necessary.</li>
<li><a href="https://github.com/near/nearcore/blob/fa78002a1b4119e5efe277c3073b3f333f451ffc/chain/client/src/client_actor.rs#L991">Block
production</a> -
This routine runs every <code>block_production_tracking_delay</code> (which is set to
100ms by default) and checks if the node should produce a block.</li>
<li><a href="https://github.com/near/nearcore/blob/fa78002a1b4119e5efe277c3073b3f333f451ffc/chain/client/src/client_actor.rs#L1790">Log
summary</a> -
Prints a log line that summarizes block rate, average gas used, the height of
the node, etc. every 10 seconds.</li>
<li><a href="https://github.com/near/nearcore/blob/fa78002a1b4119e5efe277c3073b3f333f451ffc/chain/chunks/src/lib.rs#L910">Resend chunk
requests</a> -
This routine runs every <code>chunk_request_retry_period</code> (which is set to 400ms).
It resend the chunk part requests for those that are not yet responded to.</li>
<li><a href="https://github.com/near/nearcore/blob/fa78002a1b4119e5efe277c3073b3f333f451ffc/chain/client/src/client_actor.rs#L1629">Sync</a> -
This routine runs every <code>sync_step_period</code> (which is set to 10ms by default)
and checks whether the node needs to sync from its peers and, if needed, also
starts the syncing process.</li>
<li><a href="https://github.com/near/nearcore/blob/fa78002a1b4119e5efe277c3073b3f333f451ffc/chain/client/src/client_actor.rs#L1581">Catch
up</a> -
This routine runs every <code>catchup_step_period</code> (which is set to 100ms by
default) and runs the catch up process. This only applies if a node validates
shard A in epoch X and is going to validate a different shard B in epoch X+1.
In this case, the node would start downloading the state for shard B at the
beginning of epoch X. After the state downloading is complete, it would apply
all blocks in the current epoch (epoch X) for shard B to ensure that the node
has the state needed to validate shard B when epoch X+1 starts.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="how-sync-works"><a class="header" href="#how-sync-works">How Sync Works</a></h1>
<h2 id="basics"><a class="header" href="#basics">Basics</a></h2>
<p>While Sync and Catchup sounds similar - they are actually describing two
completely different things.</p>
<p><strong>Sync</strong> - is used when your node falls â€˜behindâ€™ other nodes in the network (for
example because it was down for some time or it took longer to process some
blocks etc).</p>
<p><strong>Catchup</strong> - is used when you want (or have to) start caring about (a.k.a.
tracking) additional shards in the future epochs. Currently it should be a no-op
for 99% of nodes (see below).</p>
<p><strong>Tracking shards:</strong> as you know our system has multiple shards (currently 4).
Currently 99% of nodes are tracking all the shards: validators have to - as they
have to validate the chunks from all the shards, and normal nodes mostly also
track all the shards as this is default.</p>
<p>But in the future - we will have more and more people tracking only a subset of
the shards, so the catchup will be increasingly important.</p>
<h2 id="sync"><a class="header" href="#sync">Sync</a></h2>
<p>If your node is behind the head - it will start the sync process (this code is
running periodically in the client_actor and if youâ€™re behind for more than
<code>sync_height_threshold</code> (currently 50) blocks - it will enable the sync.</p>
<p>The Sync behavior differs depending on whether youâ€™re an archival node (which
means you care about the state of each block) or â€˜normalâ€™ node - where you care
mostly about the Tip of the network.</p>
<h3 id="step-1-header-sync-archival-node--normal-node-downloading-headers"><a class="header" href="#step-1-header-sync-archival-node--normal-node-downloading-headers">Step 1: Header Sync [archival node &amp; normal node*] (â€œdownloading headersâ€)</a></h3>
<p>The goal of the header sync is to get all the block headers from your current
HEAD all the way to the top of the chain.</p>
<p>As headers are quite small, we try to request multiple of them in a single call
(currently we ask for 512 headers at once).</p>
<p><img src="https://user-images.githubusercontent.com/1711539/195892312-2fbd8241-87ce-4241-a44d-ff3056b12bab.png" alt="image" /></p>
<h3 id="step-1a-epoch-sync-normal-node"><a class="header" href="#step-1a-epoch-sync-normal-node">Step 1a: Epoch Sync [normal node*]</a></h3>
<p>While currently normal nodes are using Header sync, we could actually allow them
to do something faster - â€œlight client syncâ€ a.k.a â€œepoch syncâ€.</p>
<p>The idea of the epoch sync, is to read â€œjustâ€ a single block header from each
epoch - that has to contain additional information about validators.</p>
<p>This way it would drastically reduce both the time needed for the sync and the
db resources.</p>
<p>Implementation is complete with <a href="https://github.com/near/nearcore/releases/tag/2.4.0">2.4 release</a>.</p>
<p><img src="https://user-images.githubusercontent.com/1711539/195892336-cc117c08-d3ad-43f7-9304-3233b25e8bb1.png" alt="image" /></p>
<p>Notice that in the image above - it is enough to only get the â€˜lastâ€™ header from
each epoch. For the â€˜currentâ€™ epoch, we still need to get all the headers.</p>
<h3 id="step-2-state-sync-normal-node"><a class="header" href="#step-2-state-sync-normal-node">Step 2: State sync [normal node]</a></h3>
<p>After header sync - if you notice that youâ€™re too far behind, i.e. the chain
head is at least two epochs ahead of your local head - the node will try to do
the â€˜state syncâ€™.</p>
<p>The idea of the state sync is - rather than trying to process all the blocks -
try to â€˜jumpâ€™ ahead by downloading the freshest state instead - and continue
processing blocks from that place in the chain. As a side effect, it is going to
create a â€˜gapâ€™ in the chunks/state on this node (which is fine - as the data
will be garbage collected after 5 epochs anyway). State sync will ONLY sync to
the beginning of the epoch - it cannot sync to any random block.</p>
<p>This step is never run on the archival nodes - as these nodes want to have whole
history and cannot have any gaps.</p>
<p><img src="https://user-images.githubusercontent.com/1711539/195892354-cf2befed-98e9-40a2-9b81-b5cf738406e0.png" alt="image" /></p>
<p>In this case, we can skip processing transactions that are in the blocks 124 - 128, and start from 129 (after sync state finishes)</p>
<p>See <a href="architecture/how/../../misc/state_sync_from_external_storage.html">how-to</a> to learn how to configure your node to state sync.</p>
<h3 id="step-3-block-sync-archival-node-normal-node-downloading-blocks"><a class="header" href="#step-3-block-sync-archival-node-normal-node-downloading-blocks">Step 3: Block sync [archival node, normal node] (â€œdownloading blocksâ€)</a></h3>
<p>The final step is to start requesting and processing blocks as soon as possible,
hoping to catch up with the chain.</p>
<p>Block sync will request up to 5  (<code>MAX_BLOCK_REQUESTS</code>) blocks at a time - sending
explicit Network BlockRequests for each one.</p>
<p>After the response (Block) is received - the code will execute the â€˜standardâ€™ path
that tries to add this block to the chain (see section below).</p>
<p><img src="https://user-images.githubusercontent.com/1711539/195892370-b177228b-2520-486a-94fc-67a91978cb58.png" alt="image" /></p>
<p>In this case, we are processing each transaction for each block - until we catch
up with the chain.</p>
<h2 id="side-topic-how-blocks-are-added-to-the-chain"><a class="header" href="#side-topic-how-blocks-are-added-to-the-chain">Side topic: how blocks are added to the chain?</a></h2>
<p>A node can receive a Block in two ways:</p>
<ul>
<li>Either by broadcasting - when a new block is produced, its contents are
broadcasted within the network by the nodes</li>
<li>Or by explicitly sending a BlockRequest to another peer - and getting a Block
in return.</li>
</ul>
<p>(in case of broadcasting, the node will automatically reject any Blocks that are
more than 500 (<code>BLOCK_HORIZON</code>) blocks away from the current HEAD).</p>
<p>When a given block is received, the node checks if it can be added to the
current chain.</p>
<p>If blockâ€™s â€œparentâ€ (<code>prev_block</code>) is not in the chain yet - the block gets added
to the orphan list.</p>
<p>If the parent is already in the chain - we can try to add the block as the head
of the chain.</p>
<p>Before adding the block, we want to download the chunks for the shards that we
are tracking - so in many cases, weâ€™ll call <code>missing_chunks</code> functions that will
try to go ahead and request those chunks.</p>
<p><strong>Note:</strong> as an optimization, weâ€™re also sometimes trying to fetch chunks for
the blocks that are in the orphan pool â€“ but only if they are not more than 3
(<code>NUM_ORPHAN_ANCESTORS_CHECK</code>) blocks away from our head.</p>
<p>We also keep a separate job in client_actor that keeps retrying chunk fetching
from other nodes if the original request fails.</p>
<p>After all the chunks for a given block are received (we have a separate HashMap
that checks how many chunks are missing for each block) - weâ€™re ready to
process the block and attach it to the chain.</p>
<p>Afterwards, we look at other entries in the orphan pool to see if any of them
are a direct descendant of the block that we just added - and if yes, we repeat
the process.</p>
<h2 id="catchup-1"><a class="header" href="#catchup-1">Catchup</a></h2>
<h3 id="the-goal-of-catchup"><a class="header" href="#the-goal-of-catchup">The goal of catchup</a></h3>
<p>Catchup is needed when not all nodes in the network track all shards and nodes
can change the shard they are tracking during different epochs.</p>
<p>For example, if a node tracks shard 0 at epoch T and tracks shard 1 at epoch T+1,
it actually needs to have the state of shard 1 ready before the beginning of
epoch T+1. We make sure this happens by making the node start downloading
the state for shard 1 at the beginning of epoch T and applying blocks during
epoch T to shard 1â€™s state. Because downloading state can take time, the
node may have already processed some blocks (for shard 0 at this epoch), so when
the state finishes downloading, the node needs to â€œcatch upâ€ processing these
blocks for shard 1.</p>
<p>Right now, all nodes do track all shards, so technically we shouldnâ€™t need the
catchup process, but it is still implemented for the future.</p>
<p>Image below: Example of the node, that tracked only shard 0 in epoch T-1, and
will start tracking shard 0 &amp; 1 in epoch T+1.</p>
<p>At the beginning of the epoch T, it will initiate the state download (green) and
afterwards will try to â€˜catchupâ€™ the blocks (orange). After blocks are caught
up, it will continue processing as normal.</p>
<p><img src="https://user-images.githubusercontent.com/1711539/195892395-2e12808e-002b-4c04-9505-611288386dc8.png" alt="image" /></p>
<h3 id="how-catchup-interact-with-normal-block-processing"><a class="header" href="#how-catchup-interact-with-normal-block-processing">How catchup interact with normal block processing</a></h3>
<p>The catchup process has two phases: downloading states for shards that we are
going to care about in epoch T+1 and catching up blocks that have already been
applied.</p>
<p>When epoch T starts, the node will start downloading states of shards that it
will track for epoch T+1, which it doesn't track already. Downloading happens in
a different thread so <code>ClientActor</code> can still process new blocks. Before the
shard states for epoch T+1 are ready, processing new blocks only applies chunks
for the shards that the node is tracking in epoch T. When the shard states for
epoch T+1 finish downloading, the catchup process needs to reprocess the
blocks that have already been processed in epoch T to apply the chunks for the
shards in epoch T+1. We assume that it will be faster than regular block
processing, because blocks are not full and block production has its own delays,
so catchup can finish within an epoch.</p>
<p>In other words, there are three modes for applying chunks and two code paths,
either through the normal <code>process_block</code> (blue) or through <code>catchup_blocks</code>
(orange). When <code>process_block</code>, either that the shard states for the next epoch
are ready, corresponding to <code>IsCaughtUp</code> and all shards the node is tracking in
this, or will be tracking in the next, epoch will be applied, or when the
states are not ready, corresponding to <code>NotCaughtUp</code>, then only the shards for
this epoch will be applied. When <code>catchup_blocks</code>, shards for the next epoch
will be applied.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>enum ApplyChunksMode {
    IsCaughtUp,
    CatchingUp,
    NotCaughtUp,
}
<span class="boring">}
</span></code></pre></pre>
<h3 id="how-catchup-works"><a class="header" href="#how-catchup-works">How catchup works</a></h3>
<p>The catchup process is initiated by <code>process_block</code>, where we check if the block
is caught up and if we need to download states. The logic works as follows:</p>
<ul>
<li>For the first block in an epoch T, we check if the previous block is caught
up, which signifies if the state of the new epoch is ready. If the previous
block is not caught up, the block will be orphaned and not processed for now
because it is not ready to be processed yet. Ideally, this case should never
happen, because the node will appear stalled until the blocks in the previous
epoch are catching up.</li>
<li>Otherwise, we start processing blocks for the new epoch T. For the first
block, we always mark it as not caught up and will initiate the process
for downloading states for shards that we are going to care about in epoch
T+1. Info about downloading states is persisted in <code>DBCol::StateDlInfos</code>.</li>
<li>For other blocks, we mark them as not caught up if the previous block is not
caught up. This info is persisted in <code>DBCol::BlocksToCatchup</code> which stores
mapping from previous block to vector of all child blocks to catch up.</li>
<li>Chunks for already tracked shards will be applied during <code>process_block</code>, as
we said before mentioning <code>ApplyChunksMode</code>.</li>
<li>Once we downloaded state, we start catchup. It will take blocks from
<code>DBCol::BlocksToCatchup</code> in breadth-first search order and apply chunks for
shards which have to be tracked in the next epoch.</li>
<li>When catchup doesn't see any more blocks to process, <code>DBCol::BlocksToCatchup</code>
is cleared, which means that catchup process is finished.</li>
</ul>
<p>The catchup process is implemented through the function <code>Client::run_catchup</code>.
<code>ClientActor</code> schedules a call to <code>run_catchup</code> every 100ms. However, the call
can be delayed if ClientActor has a lot of messages in its actor queue.</p>
<p>Every time <code>run_catchup</code> is called, it checks <code>DBCol::StateDlInfos</code> to see
if there are any shard states that should be downloaded. If so, it
initiates the syncing process for these shards. After the state is downloaded,
<code>run_catchup</code> will start to apply blocks that need to be caught up.</p>
<p>One thing to note is that <code>run_catchup</code> is located at <code>ClientActor</code>, but
intensive work such as applying state parts and applying blocks is actually
offloaded to <code>SyncJobsActor</code> in another thread, because we donâ€™t want
<code>ClientActor</code> to be blocked by this. <code>run_catchup</code> is simply responsible for
scheduling <code>SyncJobsActor</code> to do the intensive job. Note that <code>SyncJobsActor</code> is
state-less, it doesnâ€™t have write access to the chain. It will return the changes
that need to be made as part of the response to <code>ClientActor</code>, and <code>ClientActor</code>
is responsible for applying these changes. This is to ensure only one thread
(<code>ClientActor</code>) has write access to the chain state. However, this also adds a
lot of limits, for example, <code>SyncJobsActor</code> can only be scheduled to apply one
block at a time. Because <code>run_catchup</code> is only scheduled to run every 100ms, the
speed of catching up blocks is limited to 100ms per block, even when blocks
applying can be faster. Similar constraints happen to apply state parts.</p>
<h3 id="improvements"><a class="header" href="#improvements">Improvements</a></h3>
<p>There are three improvements we can make to the current code.</p>
<p>First, currently we always initiate the state downloading process at the first
block of an epoch, even when there are no new states to be downloaded for the
new epoch. This is unnecessary.</p>
<p>Second, even though <code>run_catchup</code> is scheduled to run every 100ms, the call can
be delayed if ClientActor has messages in its actor queue. A better way to do
this is to move the scheduling of <code>run_catchup</code> to <code>check_triggers</code>.</p>
<p>Third, because of how <code>run_catchup</code> interacts with <code>SyncJobsActor</code>, <code>run_catchup</code>
can catch up at most one block every 100 ms. This is because we donâ€™t want to
write to <code>ChainStore</code> in multiple threads. However, the changes that catching up
blocks make do not interfere with regular block processing and they can be
processed at the same time. However, to restructure this, we will need to
re-implement <code>ChainStore</code> to separate the parts that can be shared among threads
and the part that canâ€™t.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="garbage-collection"><a class="header" href="#garbage-collection">Garbage Collection</a></h1>
<p>This document covers the basics of Chain garbage collection.</p>
<p>Currently we run garbage collection only in non-archival nodes,  to keep the
size of the storage under control. Therefore, we remove blocks, chunks and state
that is â€˜oldâ€™ enough  - which in current configuration means 5 epochs ago.</p>
<p>We run a single â€˜roundâ€™ of GC after a new block is accepted to the chain - and
in order not to delay the chain too much, we make sure that each round removes
at most 2 blocks from the chain.</p>
<p>For more details look at function <code>clear_data()</code> in file <code>chain/chain/src/chain.rs</code></p>
<h2 id="how-it-works"><a class="header" href="#how-it-works">How it works</a></h2>
<p>Imagine the following chain (with 2 forks)</p>
<p><img src="https://user-images.githubusercontent.com/1711539/195649805-e7997192-be3a-4bf0-992d-d35b2ad80847.png" alt="" /></p>
<p>In the pictures below, letâ€™s assume that epoch length is 5 and we keep only 3
epochs (rather than 5 that is currently set in production) - otherwise the image
becomes too large ðŸ˜‰.</p>
<p>If head is in the middle of the epoch, the <code>gc_stop</code> will be set to the first
block of epoch T-2, and <code>tail</code> &amp; <code>fork_tail</code> will be sitting at the last block of
epoch T-3.</p>
<p>(and no GC is happening in this round - as tail is next to <code>gc_stop</code>).</p>
<p><img src="https://user-images.githubusercontent.com/1711539/195649850-95dee667-b88b-4ef6-b08c-77a17b8d4ae2.png" alt="" /></p>
<p>Next block was accepted on the chain (head jumped ahead), but still no GC
happening in this round:</p>
<p><img src="https://user-images.githubusercontent.com/1711539/195649879-e29cc826-dfd8-4cbc-a66d-72e42202d26a.png" alt="" /></p>
<p>Now interesting things will start happening once head â€˜crossesâ€™ over to the
next epoch.</p>
<p>First, the <code>gc_stop</code> will jump to the beginning of the next epoch.</p>
<p><img src="https://user-images.githubusercontent.com/1711539/195649928-0401b221-b6b3-4986-8931-54fbdd1adda0.png" alt="" /></p>
<p>Then weâ€™ll start the GC of the forks: by first moving the <code>fork_tail</code> to match
the <code>gc_stop</code> and going backwards from there.</p>
<p><img src="https://user-images.githubusercontent.com/1711539/195649966-dac6a4dd-f04b-4131-887a-58efe89d456a.png" alt="" /></p>
<p>It will start removing all the blocks that donâ€™t have a successor (a.k.a the tip
of the fork). And then it will proceed to lower height.</p>
<p><img src="https://user-images.githubusercontent.com/1711539/195650003-90e1fde7-18a6-4343-b0dd-9a10a596f136.png" alt="" /></p>
<p>Will keep going until it â€˜hitsâ€™ the tail.</p>
<p><img src="https://user-images.githubusercontent.com/1711539/195650059-dd6b3d30-7dd5-4324-8e65-80f955960c47.png" alt="" /></p>
<p>In order not to do too much in one go, weâ€™d only remove up to 2 block in each
run  (that happens after each head update).</p>
<p>Now, the forks are gone, so we can proceed with GCing of the blocks from
the canonical chain:</p>
<p><img src="https://user-images.githubusercontent.com/1711539/195650101-dc6953a7-0d55-4db8-a78b-6a52310410b2.png" alt="" /></p>
<p>Same as before, weâ€™d remove up to 2 blocks in each run:</p>
<p><img src="https://user-images.githubusercontent.com/1711539/195650127-b30865e1-d9c1-4950-8607-67d82a185b76.png" alt="" /></p>
<p>Until we catch up to the <code>gc_stop</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="how-epoch-works"><a class="header" href="#how-epoch-works">How Epoch Works</a></h1>
<p>This short document will tell you all you need to know about Epochs in NEAR
protocol.</p>
<p>You can also find additional information about epochs in
<a href="https://nomicon.io/BlockchainLayer/EpochManager/">nomicon</a>.</p>
<h2 id="what-is-an-epoch"><a class="header" href="#what-is-an-epoch">What is an Epoch?</a></h2>
<p>Epoch is a sequence of consecutive blocks.
Within one epoch, the set of validators is fixed, and validator rotation
happens at epoch boundaries.</p>
<p>Basically almost all the changes that we do are happening at epoch boundaries:</p>
<ul>
<li>sharding changes</li>
<li>protocol version changes</li>
<li>validator changes</li>
<li>changing tracking shards</li>
<li>state sync</li>
</ul>
<h2 id="where-does-the-epoch-id-come-from"><a class="header" href="#where-does-the-epoch-id-come-from">Where does the Epoch Id come from?</a></h2>
<p><code>EpochId</code> for epoch T+2 is the last hash of the block of epoch T.</p>
<p><img src="https://user-images.githubusercontent.com/1711539/195907256-c4b1d956-632c-4c11-aa38-17603b1fcc40.png" alt="image" /></p>
<p>Situation at genesis is interesting. We have three blocks:</p>
<p>dummy â† genesis â† first-block</p>
<h2 id="where-do-we-set-the-epoch-length"><a class="header" href="#where-do-we-set-the-epoch-length">Where do we set the epoch length?</a></h2>
<p>Epoch length is set in the genesis config. Currently in mainnet it is set to 43200 blocks:</p>
<pre><code class="language-json">  &quot;epoch_length&quot;: 43200
</code></pre>
<p>See <a href="https://s3-us-west-1.amazonaws.com/build.nearprotocol.com/nearcore-deploy/mainnet/genesis.json">the mainnet genesis</a> for more details.</p>
<p>This means that each epoch lasts around 15 hours.</p>
<p><strong>Important:</strong> sometimes there might be â€˜troublesâ€™ on the network, that might result
in epoch lasting a little bit longer (if we cannot get enough signatures on the
last blocks of the previous epoch).</p>
<p>You can read specific details on our
<a href="https://nomicon.io/ChainSpec/EpochAndStaking/Epoch.html">nomicon page</a>.</p>
<h2 id="how-do-we-pick-the-next-validators"><a class="header" href="#how-do-we-pick-the-next-validators">How do we pick the next validators?</a></h2>
<p><strong>TL;DR:</strong> in the last block of the epoch T, we look at the accounts that have
highest stake and we pick them to become validators in <strong>T+2</strong>.</p>
<p>We are deciding on validators for T+2 (and not T+1) as we want to make sure that
validators have enough time to prepare for block production and validation (they
have to download the state of shards etc).</p>
<p>For more info on how we pick validators please look at
<a href="https://nomicon.io/Economics/Economics.html#validator-selection">nomicon</a>.</p>
<h2 id="epoch-and-sharding"><a class="header" href="#epoch-and-sharding">Epoch and Sharding</a></h2>
<p>Sharding changes happen only on epoch boundary - thatâ€™s why many of the requests
(like which shard does my account belong to), require also an <code>epoch_id</code> as a
parameter.</p>
<p>As of April 2022 we donâ€™t have dynamic sharding yet, so the whole chain is
simply using 4 shards.</p>
<h3 id="how-can-i-get-more-information-about-currentprevious-epochs"><a class="header" href="#how-can-i-get-more-information-about-currentprevious-epochs">How can I get more information about current/previous epochs?</a></h3>
<p>We donâ€™t show much information about Epochs in Explorer. Today, you can use
<code>state_viewer</code> (if you have access to the network database).</p>
<p>At the same time, weâ€™re working on a small debug dashboard, to show you the
basic information about past epochs - stay tuned.</p>
<h2 id="technical-details"><a class="header" href="#technical-details">Technical details</a></h2>
<h3 id="where-do-we-store-epoch-info"><a class="header" href="#where-do-we-store-epoch-info">Where do we store epoch info?</a></h3>
<p>We use a couple of columns in the database to store epoch information:</p>
<ul>
<li><strong>ColEpochInfo = 11</strong> - is storing the mapping from EpochId to EpochInfo
structure that contains all the details.</li>
<li><strong>ColEpochStart = 23</strong> - has a mapping from EpochId to the first block height
of that epoch.</li>
<li><strong>ColEpochValidatorInfo = 47</strong> - contains validator statistics (blocks
produced etc.) for each epoch.</li>
</ul>
<h3 id="how-does-epoch-info-look-like"><a class="header" href="#how-does-epoch-info-look-like">How does epoch info look like?</a></h3>
<p>Hereâ€™s the example epoch info from a localnet node. As you can see below,
EpochInfo mostly contains information about who is the validator and in which
order should they produce the blocks.</p>
<pre><code>EpochInfo.V3(
  epoch_height=7,
  validators=ListContainer([
    validator_stake.V1(account_id='node0', public_key=public_key.ED25519(tuple_data=ListContainer([b'7PGseFbWxvYVgZ89K1uTJKYoKetWs7BJtbyXDzfbAcqX'])), stake=51084320187874404740382878961615),
    validator_stake.V1(account_id='node2', public_key=public_key.ED25519(tuple_data=ListContainer([b'GkDv7nSMS3xcqA45cpMvFmfV1o4fRF6zYo1JRR6mNqg5'])), stake=51084320187874404740382878961615),
    validator_stake.V1(account_id='node1', public_key=public_key.ED25519(tuple_data=ListContainer([b'6DSjZ8mvsRZDvFqFxo8tCKePG96omXW7eVYVSySmDk8e'])), stake=50569171534262067815663761517574)]),

  validator_to_index={'node0': 0, 'node1': 2, 'node2': 1},

  block_producers_settlement=ListContainer([0, 1, 2]),
  chunk_producers_settlement=ListContainer([ListContainer([0, 1, 2]), ListContainer([0, 1, 2]), ListContainer([0, 1, 2]), ListContainer([0, 1, 2]), ListContainer([0, 1, 2])]),

  hidden_validators_settlement=ListContainer([]),
  fishermen=ListContainer([]),
  fishermen_to_index={},
  stake_change={'node0': 51084320187874404740382878961615, 'node1': 50569171534262067815663761517574, 'node2': 51084320187874404740382878961615},
  validator_reward={'near': 37059603312899067633082436, 'node0': 111553789870214657675206177, 'node1': 110428850075662293347329569, 'node2': 111553789870214657675206177},
  validator_kickout={},
  minted_amount=370596033128990676330824359,
  seat_price=24438049905601740367428723111,
  protocol_version=52
)
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="transaction-routing"><a class="header" href="#transaction-routing">Transaction Routing</a></h1>
<p>We all know that transactions are â€˜addedâ€™ to the chain - but how do they get
there?</p>
<p>Hopefully by the end of this article, the image below should make total sense.</p>
<p><img src="https://user-images.githubusercontent.com/1711539/196204937-d6828382-16df-42bd-b59b-50eb2e6f07af.png" alt="image" /></p>
<h2 id="step-1-transaction-creatorauthor"><a class="header" href="#step-1-transaction-creatorauthor">Step 1: Transaction creator/author</a></h2>
<p>The journey starts with the author of the transaction - who creates the
transaction object (basically list of commands) - and signs them with their
private key.</p>
<p>Basically, they prepare the payload that looks like this:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct SignedTransaction {
    pub transaction: Transaction,
    pub signature: Signature,
}
<span class="boring">}
</span></code></pre></pre>
<p>With such a payload, they can go ahead and send it as a JSON-RPC request to ANY
node in the system (they can choose between using â€˜syncâ€™ or â€˜asyncâ€™ options).</p>
<p>From now on, theyâ€™ll also be able to query the status of the transaction - by
using the hash of this object.</p>
<p><strong>Fun fact:</strong> the <code>Transaction</code> object also contains some fields to prevent
attacks: like <code>nonce</code> to prevent replay attack, and <code>block_hash</code> to limit the
validity of the transaction (it must be added within
<code>transaction_validity_period</code> (defined in genesis) blocks of <code>block_hash</code>).</p>
<h2 id="step-2-inside-the-node"><a class="header" href="#step-2-inside-the-node">Step 2: Inside the node</a></h2>
<p>Our transaction has made it to a node in the system - but most of the nodes
are not validators - which means that they cannot mutate the chain.</p>
<p>Thatâ€™s why the node has to forward it to someone who can - the upcoming
validator.</p>
<p>The node, roughly, does the following steps:</p>
<ul>
<li>verify transactionâ€™s metadata - check signatures etc. (we want to make sure
that we donâ€™t forward bogus data)</li>
<li>forward it to the â€˜upcomingâ€™ validator - currently we pick the validators that
would be a chunk creator in +2, +3, +4 and +8 blocks (this is controlled by
<code>TX_ROUTING_HEIGHT_HORIZON</code>) - and send the transaction to all of them.</li>
</ul>
<h2 id="step-3-en-route-to-validatorproducer"><a class="header" href="#step-3-en-route-to-validatorproducer">Step 3: En-route to validator/producer</a></h2>
<p>Great, the node knows to send (forward) the transaction to the validator, but
how does the routing work? How do we know which peer is hosting a validator?</p>
<p>Each validator is regularly (every <code>config.ttl_account_id_router</code>/2 seconds == 30
minutes in production) broadcasting so called <code>AnnounceAccount</code>, which is
basically a pair of <code>(account_id, peer_id)</code>, to the whole network. This way each
node knows which <code>peer_id</code> to send the message to.</p>
<p>Then it asks the routing table about the shortest path to the peer, and sends
the <code>ForwardTx</code> message to the peer.</p>
<h2 id="step-4-chunk-producer"><a class="header" href="#step-4-chunk-producer">Step 4: Chunk producer</a></h2>
<p>When a validator receives such a forwarded transaction, it double-checks that it is
about to produce the block, and if so, it adds the transaction to the mempool
(<code>TransactionPool</code>) for this shard, where it waits to be picked up when the chunk
is produced.</p>
<p>What happens afterwards will be covered in future episodes/articles.</p>
<h2 id="additional-notes"><a class="header" href="#additional-notes">Additional notes</a></h2>
<h3 id="transaction-being-added-multiple-times"><a class="header" href="#transaction-being-added-multiple-times">Transaction being added multiple times</a></h3>
<p>But such an approach means, that weâ€™re forwarding the same transaction to multiple
validators (currently 4) - so can it be added multiple times?</p>
<p>No. Remember that a transaction has a concrete hash which is used as a global
identifier. If the validator sees that the transaction is present in the chain,
it removes it from its local mempool.</p>
<h3 id="can-transaction-get-lost"><a class="header" href="#can-transaction-get-lost">Can transaction get lost?</a></h3>
<p>Yes - they can and they do. Sometimes a node doesnâ€™t have a path to a given
validator or it didnâ€™t receive an <code>AnnounceAccount</code> for it, so it doesnâ€™t know
where to forward the message. And if this happens to all 4 validators that we
try to send to, then the message can be silently dropped.</p>
<p>Weâ€™re working on adding some monitoring to see how often this happens.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="transactions-receipts-and-chunk-surprises"><a class="header" href="#transactions-receipts-and-chunk-surprises">Transactions, Receipts and Chunk Surprises</a></h1>
<p>We finished the previous article (<a href="architecture/how/./tx_routing.html">Transaction routing</a>)
where a transaction was successfully added to the soon-to-be block
producerâ€™s mempool.</p>
<p>In this article, weâ€™ll cover what happens next:
How it is changed into a receipt and executed, potentially creating even
more receipts in the process.</p>
<p>First, letâ€™s look at the â€˜high-level viewâ€™:</p>
<p><img src="https://user-images.githubusercontent.com/1711539/198282472-3883dcc1-77ca-452c-b21e-0a7af1435ede.png" alt="image" /></p>
<h2 id="transaction-vs-receipt"><a class="header" href="#transaction-vs-receipt">Transaction vs Receipt</a></h2>
<p>As you can see from the image above:</p>
<p><strong>Transactions</strong> are â€˜externalâ€™ communication - they are coming from the
outside.</p>
<p><strong>Receipts</strong> are used for â€˜internalâ€™ communication (cross shard, cross
contract) - they are created by the block/chunk producers.</p>
<h2 id="life-of-a-transaction"><a class="header" href="#life-of-a-transaction">Life of a Transaction</a></h2>
<p>If we â€˜zoom-inâ€˜, the chunk producer's work looks like this:</p>
<p><img src="https://user-images.githubusercontent.com/1711539/198282518-cdeb375e-8f1c-4634-842c-6490020ad9c0.png" alt="image" /></p>
<h3 id="step-1-process-transaction-into-receipt"><a class="header" href="#step-1-process-transaction-into-receipt">Step 1: Process Transaction into receipt</a></h3>
<p>Once a chunk producer is ready to produce a chunk, it will fetch the
transactions from its mempool, check that they are valid, and if so, prepare to
process them into receipts.</p>
<p><strong>Note:</strong> There are additional restrictions (e.g. making sure that we take them in
the right order, that we donâ€™t take too many, etc.) - that you can see in
nomiconâ€™s <a href="https://nomicon.io/ChainSpec/Transactions">transaction page</a>.</p>
<p>You can see this part in explorer:</p>
<p><img src="https://user-images.githubusercontent.com/1711539/198282561-c97235a1-93a1-4dc8-b6bc-ee9983376b2c.png" alt="image" /></p>
<h3 id="step-2-sending-receipt-to-the-proper-destination"><a class="header" href="#step-2-sending-receipt-to-the-proper-destination">Step 2: Sending receipt to the proper destination</a></h3>
<p>Once we have a receipt, we have to send it to the proper destination - by adding
it to the <code>outgoing_receipt</code> list, which will be forwarded to the chunk
producers from the next block.</p>
<p><strong>Note:</strong> There is a special case here - if the sender of the receipt is the
same as the receiver, then the receipt will be added to the <code>local_receipts</code>
queue and executed in the same block.</p>
<h3 id="step-3-when-an-incoming-receipt-arrives"><a class="header" href="#step-3-when-an-incoming-receipt-arrives">Step 3: When an incoming receipt arrives</a></h3>
<p>(<strong>Note:</strong> this happens in the â€˜nextâ€™ block)</p>
<p>When a chunk producer receives an incoming receipt, it will try to execute its
actions (creating accounts, executing function calls etc).</p>
<p>Such actions might generate additional receipts (for example a contract might
want to call other contracts). All these outputs are added to the outgoing
receipt queue to be executed in the next block.</p>
<p>If the incoming receipt queue is too large to execute in the current chunk,
the producer will put the remaining receipts onto the â€˜delayedâ€™ queue.</p>
<h3 id="step-4-profit"><a class="header" href="#step-4-profit">Step 4: Profit</a></h3>
<p>When all the â€˜dependantâ€™ receipts are executed for a given transaction, we can
consider the transaction to be successful.</p>
<h3 id="advanced-but-reality-is-more-complex"><a class="header" href="#advanced-but-reality-is-more-complex">[Advanced] But reality is more complex</a></h3>
<p><strong>Caution:</strong> In the section below, some things are simplified and do not match exactly
how the current code works.</p>
<p>Letâ€™s quickly also check whatâ€™s inside a Chunk:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct ShardChunkV2 {
    pub chunk_hash: ChunkHash,
    pub header: ShardChunkHeader,
    pub transactions: Vec&lt;SignedTransaction&gt;,
    pub receipts: Vec&lt;Receipt&gt;, // outgoing receipts from 'previous' block
}
<span class="boring">}
</span></code></pre></pre>
<p>Yes, it is a little bit confusing, that receipts here are NOT the â€˜incomingâ€™
ones for this chunk, but instead the â€˜outgoingâ€™ ones from the previous block, i.e. all receipts from shard 0, block B are actually found in shard 0, block B+1.  Why?!?!</p>
<p>This has to do with performance.</p>
<p>The steps usually followed for producing a block are as follows</p>
<ol>
<li>Chunk producer executes the receipts and creates a chunk. It sends the chunk to other validators. Note that it's the execution/processing of the receipts that usually takes the most time.</li>
<li>Validators receive the chunk and validate it before signing the chunk. Validation involves executing/processing of the receipts in the chunk.</li>
<li>Once the next block chunk producer receives the validation (signature), only then can it start producing the next chunk.</li>
</ol>
<h4 id="simple-approach"><a class="header" href="#simple-approach">Simple approach</a></h4>
<p>First, letâ€™s imagine how the system would look like, if chunks contained things
that weâ€™d expect:</p>
<ul>
<li>list of transactions</li>
<li>list of incoming receipts</li>
<li>list of outgoing receipts</li>
<li>hash of the final state</li>
</ul>
<p>This means, that the chunk producer has to compute all this information first,
before sending the chunk to other validators.</p>
<p><img src="https://user-images.githubusercontent.com/1711539/198282601-383977f1-08dd-45fe-aa19-70556d585034.png" alt="image" /></p>
<p>Once the other validators receive the chunk, they can start their own processing to
verify those outgoing receipts/final state - and then do the signing. Only then,
can the next chunk producer start creating the next chunk.</p>
<p>While this approach does work, we can do it faster.</p>
<h4 id="faster-approach"><a class="header" href="#faster-approach">Faster approach</a></h4>
<p>What if the chunk didnâ€™t contain the â€˜outputâ€™ state? This changes our â€˜mentalâ€™ model
a little bit, as now when weâ€™re singing the chunk, weâ€™d actually be
verifying the previous chunk - but thatâ€™s the topic for the next article (to be added).</p>
<!-- TODO: add future link to article about signatures and verification -->
<p>For now, imagine if the chunk only had:</p>
<ul>
<li>a list of transactions</li>
<li>a list of incoming receipts</li>
</ul>
<p>In this case, the chunk producer could send the chunk a lot earlier, and
validators (and chunk producer) could do their processing at the same time:</p>
<p><img src="https://user-images.githubusercontent.com/1711539/198282641-1e728088-6f2b-4cb9-90c9-5eb09304e72a.png" alt="image" /></p>
<p>Now the last mystery:
Why do we have â€˜outgoingâ€™ receipts from previous chunks rather than incoming
to the current one?</p>
<p>This is yet another optimization. This way the chunk producer can send out the
chunk a little bit earlier - without having to wait for all the other shards.</p>
<p>But thatâ€™s a topic for another article (to be added).</p>
<!-- TODO: add future link to article about chunk fragments etc. -->
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="cross-shard-transactions---deep-dive"><a class="header" href="#cross-shard-transactions---deep-dive">Cross shard transactions - deep dive</a></h1>
<p>In this article, we'll look deeper into how cross-shard transactions are working
on the simple example of user <code>shard0</code> transferring money to user <code>shard1</code>.</p>
<p>These users are on separate shards (<code>shard0</code> is on shard 0 and <code>shard1</code> is on
shard 1).</p>
<p>Imagine, we run the following command in the command line:</p>
<pre><code class="language-console">NEAR_ENV=local near send shard0 shard1 500
</code></pre>
<p>What happens under the hood? How is this transaction changed into receipts and
processed by near?</p>
<h2 id="from-explorer-perspective"><a class="header" href="#from-explorer-perspective">From Explorer perspective</a></h2>
<p>If you look at a simple token transfer in explorer
(<a href="https://explorer.near.org/transactions/79gPsyYRG2xghr6oNLpMbdjP2jpafjVT35no9atS6zUf">example</a>),
you can see that it is broken into three separate sections:</p>
<ul>
<li>convert transaction into receipt ( executed in block B )</li>
<li>receipt that transfers tokens ( executed in block B+1 )</li>
<li>receipt that refunds gas ( executed in block B+2 )</li>
</ul>
<p>But under the hood, the situation is a little bit more complex, as there is
actually one more receipt (that is created after converting the transaction).
Let's take a deeper look.</p>
<h2 id="internal-perspective-transactions--receipts"><a class="header" href="#internal-perspective-transactions--receipts">Internal perspective (Transactions &amp; Receipts)</a></h2>
<p>One important thing to remember is that NEAR is sharded - so in all our
designs, we have to assume that each account is on a separate shard. So that the
fact that some of them are colocated doesn't give any advantage.</p>
<h3 id="step-1---transaction"><a class="header" href="#step-1---transaction">Step 1 - Transaction</a></h3>
<p>This is the part which we receive from the user (<code>SignedTransaction</code>) - it has 3
parts:</p>
<ul>
<li>signer (account + key) who signed the transaction</li>
<li>receiver (in which account context should we execute this)</li>
<li>payload - a.k.a Actions to execute.</li>
</ul>
<p>As the first step, we want to change this transaction into a Receipt (a.k.a
'internal' message) - but before doing that, we must verify that:</p>
<ul>
<li>the message signature matches (that is - that this message was actually signed
by this key)</li>
<li>that this key is authorized to act on behalf of that account (so it is a full
access key to this account - or a valid function key).</li>
</ul>
<p>The last point above means, that we MUST execute this (Transaction to Receipt)
transition within the shard that the <code>signer</code> belongs to (as other shards don't
know the state that belongs to signer - so they don't know which keys it has).</p>
<p>So actually if we look inside the chunk 0 (where <code>shard0</code> belongs) at block
B, we'll see the transaction:</p>
<pre><code>Chunk: Ok(
    V2(
        ShardChunkV2 {
            chunk_hash: ChunkHash(
                8mgtzxNxPeEKfvDcNdFisVq8TdeqpCcwfPMVk219zRfV,
            ),
            header: V3(
                ShardChunkHeaderV3 {
                    inner: V2(
                        ShardChunkHeaderInnerV2 {
                            prev_block_hash: CgTJ7FFwmawjffrMNsJ5XhvoxRtQPXdrtAjrQjG91gkQ,
                            prev_state_root: 99pXnYjQbKE7bEf277urcxzG3TaN79t2NgFJXU5NQVHv,
                            outcome_root: 11111111111111111111111111111111,
                            encoded_merkle_root: 67zdyWTvN7kB61EgTqecaNgU5MzJaCiRnstynerRbmct,
                            encoded_length: 187,
                            height_created: 1676,
                            shard_id: 0,
                            gas_used: 0,
                            gas_limit: 1000000000000000,
                            balance_burnt: 0,
                            outgoing_receipts_root: 8s41rye686T2ronWmFE38ji19vgeb6uPxjYMPt8y8pSV,
                            tx_root: HyS6YfQbfBRniVSbWRnxsxEZi9FtLqHwyzNivrF6aNAM,
                            validator_proposals: [],
                        },
                    ),
                    height_included: 0,
                    signature: ed25519:uUvmvDV2cRVf1XW93wxDU8zkYqeKRmjpat4UUrHesJ81mmr27X43gFvFuoiJHWXz47czgX68eyBN38ejwL1qQTD,
                    hash: ChunkHash(
                        8mgtzxNxPeEKfvDcNdFisVq8TdeqpCcwfPMVk219zRfV,
                    ),
                },
            ),
            transactions: [
                SignedTransaction {
                    transaction: Transaction {
                        signer_id: AccountId(
                            &quot;shard0&quot;,
                        ),
                        public_key: ed25519:Ht8EqXGUnY8B8x7YvARE1LRMEpragRinqA6wy5xSyfj5,
                        nonce: 11,
                        receiver_id: AccountId(
                            &quot;shard1&quot;,
                        ),
                        block_hash: 6d5L1Vru2c4Cwzmbskm23WoUP4PKFxBHSP9AKNHbfwps,
                        actions: [
                            Transfer(
                                TransferAction {
                                    deposit: 500000000000000000000000000,
                                },
                            ),
                        ],
                    },
                    signature: ed25519:63ssFeMyS2N1khzNFyDqiwSELFaUqMFtAkRwwwUgrPbd1DU5tYKxz9YL2sg1NiSjaA71aG8xSB7aLy5VdwgpvfjR,
                    hash: 6NSJFsTTEQB4EKNKoCmvB1nLuQy4wgSKD51rfXhmgjLm,
                    size: 114,
                },
            ],
            receipts: [],
        },
    ),
)
</code></pre>
<p><strong>Side note:</strong> When we're converting the transaction into a receipt, we also use
this moment to deduct prepaid gas fees and transferred tokens from the 'signer'
account. The details on how much gas is charged can be found at <a href="https://nomicon.io/RuntimeSpec/Fees/">https://nomicon.io/RuntimeSpec/Fees/</a>.</p>
<h2 id="step-2---cross-shard-receipt"><a class="header" href="#step-2---cross-shard-receipt">Step 2 - cross shard receipt</a></h2>
<p>After transaction was changed into a receipt, this receipt must now be sent to
the shard where the <code>receiver</code> is (in our example <code>shard1</code> is on shard 1).</p>
<p>We can actually see this in the chunk of the next block:</p>
<pre><code>Chunk: Ok(
    V2(
        ShardChunkV2 {
            chunk_hash: ChunkHash(
                DoF7yoCzyBSNzB8R7anWwx6vrimYqz9ZbEmok4eqHZ3m,
            ),
            header: V3(
                ShardChunkHeaderV3 {
                    inner: V2(
                        ShardChunkHeaderInnerV2 {
                            prev_block_hash: 82dKeRnE262qeVf31DXaxHvbYEugPUDvjGGiPkjm9Rbp,
                            prev_state_root: DpsigPFeVJDenQWVueGKyTLVYkQuQjeQ6e7bzNSC7JVN,
                            outcome_root: H34BZknAfWrPCcppcHSqbXwFvAiD9gknG8Vnrzhcc4w,
                            encoded_merkle_root: 3NDvQBrcRSAsWVPWkUTTrBomwdwEpHhJ9ofEGGaWsBv9,
                            encoded_length: 149,
                            height_created: 1677,
                            shard_id: 0,
                            gas_used: 223182562500,
                            gas_limit: 1000000000000000,
                            balance_burnt: 22318256250000000000,
                            outgoing_receipts_root: Co1UNMcKnuhXaHZz8ozMnSfgBKPqyTKLoC2oBtoSeKAy,
                            tx_root: 11111111111111111111111111111111,
                            validator_proposals: [],
                        },
                    ),
                    height_included: 0,
                    signature: ed25519:32hozA7GMqNqJzscEWzYBXsTrJ9RDhW5Ly4sp7FXP1bmxoCsma8Usxry3cjvSuywzMYSD8HvGntVtJh34G2dKJpE,
                    hash: ChunkHash(
                        DoF7yoCzyBSNzB8R7anWwx6vrimYqz9ZbEmok4eqHZ3m,
                    ),
                },
            ),
            transactions: [],
            receipts: [
                Receipt {
                    predecessor_id: AccountId(
                        &quot;shard0&quot;,
                    ),
                    receiver_id: AccountId(
                        &quot;shard1&quot;,
                    ),
                    receipt_id: 3EtEcg7QSc2CYzuv67i9xyZTyxBD3Dvx6X5yf2QgH83g,
                    receipt: Action(
                        ActionReceipt {
                            signer_id: AccountId(
                                &quot;shard0&quot;,
                            ),
                            signer_public_key: ed25519:Ht8EqXGUnY8B8x7YvARE1LRMEpragRinqA6wy5xSyfj5,
                            gas_price: 103000000,
                            output_data_receivers: [],
                            input_data_ids: [],
                            actions: [
                                Transfer(
                                    TransferAction {
                                        deposit: 500000000000000000000000000,
                                    },
                                ),
                            ],
                        },
                    ),
                },
            ],
        },
    ),
)
</code></pre>
<p><strong>Side comment:</strong> notice that the receipt itself no longer has a <code>signer</code> field, but
a <code>predecessor_id</code> one.</p>
<p>Such a receipt is sent to the destination shard (we'll explain this process in a
separate article) where it can be executed.</p>
<!-- TODO: maybe add the link to that article here? -->
<h2 id="3-gas-refund"><a class="header" href="#3-gas-refund">3. Gas refund</a></h2>
<p>When shard 1 processes the receipt above, it is then ready to refund the unused
gas to the original account (<code>shard0</code>). So it also creates the receipt, and puts
it inside the chunk. This time it is in shard 1 (as that's where it was
executed).</p>
<pre><code>Chunk: Ok(
    V2(
        ShardChunkV2 {
            chunk_hash: ChunkHash(
                8sPHYmBFp7cfnXDAKdcATFYfh9UqjpAyqJSBKAngQQxL,
            ),
            header: V3(
                ShardChunkHeaderV3 {
                    inner: V2(
                        ShardChunkHeaderInnerV2 {
                            prev_block_hash: Fj7iu26Yy9t5e9k9n1fSSjh6ZoTafWyxcL2TgHHHskjd,
                            prev_state_root: 4y6VL9BoMJg92Z9a83iqKSfVUDGyaMaVU1RNvcBmvs8V,
                            outcome_root: 7V3xRUeWgQa7D9c8s5jTq4dwdRcyTuY4BENRmbWaHiS5,
                            encoded_merkle_root: BnCE9LZgnFEjhQv1fSYpxPNw56vpcLQW8zxNmoMS8H4u,
                            encoded_length: 149,
                            height_created: 1678,
                            shard_id: 1,
                            gas_used: 223182562500,
                            gas_limit: 1000000000000000,
                            balance_burnt: 22318256250000000000,
                            outgoing_receipts_root: HYjZzyTL5JBfe1Ar4C4qPKc5E6Vbo9xnLHBKLVAqsqG2,
                            tx_root: 11111111111111111111111111111111,
                            validator_proposals: [],
                        },
                    ),
                    height_included: 0,
                    signature: ed25519:4FzcDw2ay2gAGosNpFdTyEwABJhhCwsi9g47uffi77N21EqEaamCg9p2tALbDt5fNeCXXoKxjWbHsZ1YezT2cL94,
                    hash: ChunkHash(
                        8sPHYmBFp7cfnXDAKdcATFYfh9UqjpAyqJSBKAngQQxL,
                    ),
                },
            ),
            transactions: [],
            receipts: [
                Receipt {
                    predecessor_id: AccountId(
                        &quot;system&quot;,
                    ),
                    receiver_id: AccountId(
                        &quot;shard0&quot;,
                    ),
                    receipt_id: 6eei79WLYHGfv5RTaee4kCmzFx79fKsX71vzeMjCe6rL,
                    receipt: Action(
                        ActionReceipt {
                            signer_id: AccountId(
                                &quot;shard0&quot;,
                            ),
                            signer_public_key: ed25519:Ht8EqXGUnY8B8x7YvARE1LRMEpragRinqA6wy5xSyfj5,
                            gas_price: 0,
                            output_data_receivers: [],
                            input_data_ids: [],
                            actions: [
                                Transfer(
                                    TransferAction {
                                        deposit: 669547687500000000,
                                    },
                                ),
                            ],
                        },
                    ),
                },
            ],
        },
    ),
)
</code></pre>
<p>Such gas refund receipts are a little bit special - as we'll set the
<code>predecessor_id</code> to be <code>system</code> - but the receiver is what we expect (<code>shard0</code>
account).</p>
<p><strong>Note:</strong> <code>system</code> is a special account that doesn't really belong to any shard.
As you can see in this example, the receipt was created within shard 1.</p>
<p>So putting it all together would look like this:</p>
<p><img src="https://user-images.githubusercontent.com/91919554/200617392-00b9fa0c-2f15-40ad-9802-137ca9a5a15d.png" alt="image" /></p>
<p>But wait - NEAR was saying that transfers are happening with 2 blocks - but here
I see that it took 3 blocks. What's wrong?</p>
<p>The image above is a simplification, and reality is a little bit trickier -
especially as receipts in a given chunks are actually receipts received as a
result from running a PREVIOUS chunk from this shard.</p>
<p>We'll explain it more in the next section.</p>
<h1 id="advanced-whats-actually-going-on"><a class="header" href="#advanced-whats-actually-going-on">Advanced: What's actually going on?</a></h1>
<p>As you could have read in <a href="architecture/how/./tx_receipts.html">Transactions And Receipts</a> - the
'receipts' field in the chunk is actually representing 'outgoing' receipts
from the previous block.</p>
<p>So our image should look more like this:</p>
<p><img src="https://user-images.githubusercontent.com/91919554/200621066-a5d06f2d-ff43-44ce-a52b-47dc44d6f8ab.png" alt="image" /></p>
<p>In this example, the black boxes are representing the 'processing' of the chunk,
and red arrows are cross-shard communication.</p>
<p>So when we process Shard 0 from block 1676, we read the transaction, and output
the receipt - which later becomes the input for shard 1 in block 1677.</p>
<p>But you might still be wondering - so why didn't we add the Receipt (transfer)
to the list of receipts of shard0 1676?</p>
<p>That's because the shards &amp; blocks are set BEFORE we do any computation. So the
more correct image would look like this:</p>
<p><img src="https://user-images.githubusercontent.com/91919554/200621808-1ce78047-6968-4af5-9c2a-805a0f1643fc.png" alt="image" /></p>
<p>Here you can clearly see that chunk processing (black box), is happening AFTER
the chunk is set.</p>
<p>In this example, the blue arrows are showing the part where we persist the
result (receipt) into next block's chunk.</p>
<!-- TODO: maybe add the link to that article here? -->
<p>In a future article, we'll discuss how the actual cross-shard communication
works (red arrows) in the picture, and how we could guarantee that a given shard
really gets all the red arrows, before it starts processing.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="gas"><a class="header" href="#gas">Gas</a></h1>
<p>This page describes the technical details around gas during the lifecycle of a
<em>transaction</em>(*) while giving an intuition for why things are the way they are
from a technical perspective. For a more practical, user-oriented angle, please
refer to the <a href="https://docs.near.org/concepts/basics/transactions/gas">gas section in the official protocol
documentation</a>.</p>
<p>(*) <em>For this page, a transaction shall refer to the set of all recursively
generated receipts by a <code>SignedTransaction</code>. When referring to only the original
transaction object, we write <code>SignedTransaction</code>.</em></p>
<p>The topic is split into several sections.</p>
<ol>
<li><a href="architecture/how/gas.html#gas-flow">Gas Flow</a>
<ul>
<li><a href="architecture/how/gas.html#buying-gas-for-a-transaction">Buying Gas</a>: How are NEAR tokens converted to gas?</li>
<li><a href="architecture/how/gas.html#burning-gas">Burning Gas</a>: Who receives burnt tokens?</li>
<li><a href="architecture/how/gas.html#gas-in-contract-calls">Gas in Contract Calls</a>: How is gas attached to calls?</li>
<li><a href="architecture/how/gas.html#contract-reward">Contract Reward</a>: How smart contract earn a reward.</li>
</ul>
</li>
<li><a href="architecture/how/gas.html#gas-price">Gas Price</a>:
<ul>
<li><a href="architecture/how/gas.html#block-level-gas-price">Block-Level Gas Price</a>: How the block-level gas price is determined.</li>
<li><a href="architecture/how/gas.html#pessimistic-gas-price">Pessimistic Gas Price</a>: How worst-case gas pricing is estimated.</li>
<li><a href="architecture/how/gas.html#gas-refund-fee">Gas Refund Fee</a>: The cost paid for a gas refund receipt.</li>
</ul>
</li>
<li><a href="architecture/how/gas.html#tracking-gas-in-receipts">Tracking Gas</a>: How the system keeps track of purchased gas during the transaction execution.</li>
</ol>
<h2 id="gas-flow"><a class="header" href="#gas-flow">Gas Flow</a></h2>
<p>On the highest level, gas is bought by the signer, burnt during execution, and
contracts receive a part of the burnt gas as a reward. We will discuss each step
in more details.</p>
<h3 id="buying-gas-for-a-transaction"><a class="header" href="#buying-gas-for-a-transaction">Buying Gas for a Transaction</a></h3>
<p>A signer pays all the gas required for a transaction upfront. However, there is
no explicit act of buying gas. Instead, the fee is subtracted directly in NEAR
tokens from the balance of the signer's account. The fee is calculated as <code>gas amount</code> * <code>gas price</code>. The gas amount for actions included in a <code>SignedTransaction</code>
are all fixed, except for function calls where the user needs to specify the attached
gas amount for the dynamic execution part.
(See <a href="https://docs.near.org/protocol/gas#cost-for-common-actions">here</a> for more details.)</p>
<p>If the account has insufficient balance to pay for this, it will fail with a
<code>NotEnoughBalance</code> error, with the required balance included in the error message.</p>
<p>The <code>gas amount</code> is not a field of <code>SignedTransaction</code>, nor is it something the
signer can choose. It is only a virtual field that is computed on-chain following
the protocol's rules.</p>
<p>The <code>gas price</code> is a variable that may change during the execution of the
transaction. The way it is implemented today, a single transaction can be
charged a different gas price for different receipts.</p>
<p>Already we can see a fundamental problem: Gas is bought once at the beginning
but the gas price may change during execution. To solve this incompatibility,
the protocol used to calculate a pessimistic gas price for the initial purchase.
Later on, the delta between real and pessimistic gas prices would be refunded at
the end of every receipt execution.</p>
<p>Generating a refund receipts for every executed function call has become a
non-trivial overhead, limiting total throughput. Therefore, with the adoption of
<a href="https://github.com/near/NEPs/pull/536">NEP-536</a> the model was changed.</p>
<p>With version 78 and onward, the protocol simply ignores gas price changes
between time of purchase and time of use. A transaction buys gas at one price
and burns it at the same price. While this avoids the need for refunds due to
price changes, it also means that transactions with deep receipt calls can end
up with a cheaper gas price competing for the same chunk space. The community
took note of this trade-off and agreed to take it.</p>
<h3 id="burning-gas"><a class="header" href="#burning-gas">Burning Gas</a></h3>
<p>Buying gas immediately removes a part of the signer's tokens from the total
supply. However, the equivalent value in gas still exists in the form of the
receipt and the unused gas will be converted back to tokens as a refund after
subtracting a small gas refund fee. (More on the fee further down.)</p>
<p>The gas spent on execution on the other hand is burnt and removed from total
supply forever. Unlike gas in other chains, none of it goes to validators. This
is roughly equivalent to the base fee burning mechanism which Ethereum added in
<a href="https://eips.ethereum.org/EIPS/eip-1559">EIP-1559</a>. But in Near Protocol, the
entire fee is burnt, whereas in Ethereum the <a href="https://ethereum.org/en/developers/docs/gas/#priority-fee">priority
fee</a> goes to
validators.</p>
<p>The following diagram shows how gas flows through the execution of a
transaction. The transaction consists of a function call performing a cross
contract call, hence two function calls in sequence. (Note: This diagram is
slightly simplified, more accurate diagrams are further down.)</p>
<p><img src="https://github.com/near/nearcore/assets/6342444/f52c6e4b-6fca-4f61-8e6e-ac786076aa65" alt="Very Simplified Gas Flow Diagram" /></p>
<!-- Editable source: https://github.com/near/nearcore/issues/7821#issuecomment-1705672850 -->
<h3 id="gas-in-contract-calls"><a class="header" href="#gas-in-contract-calls">Gas in Contract Calls</a></h3>
<p>A function call has a fixed gas cost to be initiated. Then the execution itself
draws gas from the <code>attached_gas</code>, sometimes also called <code>prepaid_gas</code>, until it
reaches zero, at which point the function call aborts with a <code>GasExceeded</code>
error. No changes are persisted on chain.</p>
<p>(<em>Note on naming: If you see <code>prepaid_fee: Balance</code> in the nearcore code base,
this is NOT only the fee for <code>prepaid_gas</code>. It also includes prepaid fees for
other gas costs. However, <code>prepaid_gas: Gas</code> is used the same in the code base
as described in this document.</em>)</p>
<p>Attaching gas to function calls is the primary way for end-users and contract
developers to interact with gas. All other gas fees are implicitly computed and
are hidden from the users except for the fact that the equivalent in tokens is
removed from their account balance.</p>
<p>To attach gas, the signer sets the gas field of the function call action.
Wallets and CLI tools expose this to the users in different ways. Usually just
as a <code>gas</code> field, which makes users believe this is the maximum gas the
transaction will consume. Which is not true, the maximum is the specified number
plus the fixed base cost.</p>
<p>Contract developers also have to pick the attached gas values when their
contract calls another contract. They cannot buy additional gas, they have to
work with the unspent gas attached to the current call. They can check how much
gas is left by subtracting the <code>used_gas()</code> from the <code>prepaid_gas()</code> host
function results. But they cannot use all the available gas, since that would
prevent the current function call from executing to the end.</p>
<p>The gas attached to a function can be at most <code>max_total_prepaid_gas</code>, which is
300 Tgas since the mainnet launch. Note that this limit is per
<code>SignedTransaction</code>, not per function call. In other words, batched function
calls share this limit.</p>
<p>There is also a limit to how much single call can burn, <code>max_gas_burnt</code>, which
used to be 200 Tgas but has been increased to 300 Tgas in protocol version 52.
(Note: When attaching gas to an outgoing function call, this is not counted as
gas burnt.) However, given a call can never burn more than was attached anyway,
this second limit is obsolete with the current configuration where the two limits
are equal.</p>
<p>Since protocol version 53, with the stabilization of
<a href="https://github.com/near/NEPs/blob/master/neps/nep-0264.md">NEP-264</a>, contract
developers do not have to specify the absolute amount of gas to attach to calls.
<code>promise_batch_action_function_call_weight</code> allows to specify a ratio of unspent
gas that is computed after the current call has finished. This allows attaching
100% of unspent gas to a call. If there are multiple calls, this allows
attaching an equal fraction to each, or any other split as defined by the weight
per call.</p>
<h3 id="contract-reward"><a class="header" href="#contract-reward">Contract Reward</a></h3>
<p>A rather unique property of Near Protocol is that a part of the gas fee goes to
the contract owner. This &quot;smart contract gets paid&quot; model is pretty much the
opposite design choice from the &quot;smart contract pays&quot; model that for example
<a href="https://internetcomputer.org/docs/current/developer-docs/gas-cost#details-cost-of-compute-and-storage-transactions-on-the-internet-computer">Cycles in the Internet
Computer</a>
implement.</p>
<p>The idea is that it gives contract developers a source of income and hence an
incentive to create useful contracts that are commonly used. But there are also
downsides, such as when implementing a free meta-transaction relayer one has to
be careful not to be susceptible to faucet-draining attacks where an attacker
extracts funds from the relayer by making calls to a contract they own.</p>
<p>How much contracts receive from execution depends on two things.</p>
<ol>
<li>How much gas is burnt on the function call execution itself. That is, only
the gas taken from the <code>attached_gas</code> of a function call is considered for
contract rewards. The base fees paid for creating the receipt, including the
<code>action_function_call</code> fee, are burnt 100%.</li>
<li>The remainder of the burnt gas is multiplied by the runtime configuration
parameter
<a href="architecture/how/../../../core/parameters/res/runtime_configs/parameters.snap#L5C5-L5C5"><code>burnt_gas_reward</code></a>
which currently is at 30%.</li>
</ol>
<p>During receipt execution, nearcore code tracks the <code>gas_burnt_for_function_call</code>
separately from other gas burning to enable this contract reward calculations.</p>
<p>In the (still slightly simplified) flow diagram, the contract reward looks like this.
For brevity, <code>gas_burnt_for_function_call</code> in the diagram is denoted as <code>wasm fee</code>.</p>
<p><img src="https://github.com/near/nearcore/assets/6342444/32600ef0-1475-43af-b196-576317787578" alt="Slightly Simplified Gas Flow Diagram" /></p>
<!-- Editable source: https://github.com/near/nearcore/issues/7821#issuecomment-1705673349 -->
<h2 id="gas-price"><a class="header" href="#gas-price">Gas Price</a></h2>
<p>Gas pricing is a surprisingly deep and complicated topic. Usually, we only think
about the value of the <code>gas_price</code> field in the block header. However, to
understand the internals, this is not enough.</p>
<h3 id="block-level-gas-price"><a class="header" href="#block-level-gas-price">Block-Level Gas Price</a></h3>
<p><code>gas_price</code> is a field in the block header. It determines how much it costs to
buy gas at the given block height.</p>
<p>The price is measured in NEAR tokens per unit of gas. It dynamically changes in
the range between 0.1 NEAR per Pgas and 2 NEAR per Pgas, based on demand. (1
Pgas = 1000 Tgas corresponds to a full chunk.)</p>
<p>The block producer has to set this field following the exact formula as defined
by the protocol. Otherwise, the produced block is invalid.</p>
<p>Intuitively, the formula checks how much gas was used compared to the total
capacity. If it exceeds 50%, the gas price increases exponentially within the
limits. When the demand is below 50%, it decreases exponentially. In practice,
it stays at the bottom most of the time.</p>
<p>Note that all shards share the same gas price. Hence, if one out of four shards
is at 100% capacity, this will not cause the price to increase. The 50% capacity
is calculated as an average across all shards.</p>
<p>Going slightly off-topic, it should also be mentioned that chunk capacity is not
constant. Chunk producers can change it by 0.1% per chunk. The nearcore client
does not currently make use of this option, so it really is a nitpick only
relevant in theory. However, any client implementation such as nearcore must
compute the total capacity as the sum of gas limits stored in the chunk headers
to be compliant. Using a hard-coded <code>1000 Tgas * num_shards</code> would lead to
incorrect block header validation.</p>
<h3 id="pessimistic-gas-price"><a class="header" href="#pessimistic-gas-price">Pessimistic Gas Price</a></h3>
<p>The pessimistic gas price features was removed with protocol version 78 and
<a href="https://github.com/near/NEPs/pull/536">NEP-536</a>.</p>
<h3 id="gas-refund-fee"><a class="header" href="#gas-refund-fee">Gas Refund Fee</a></h3>
<p>After executing the transaction, there might be unspent gas left. For function
calls, this is the normal case, since attaching exactly the right amount of gas
is tricky. Additionally, in case of receipt failure, some actions that did not
start execution will have the execution gas unspent. This gas is converted back
to NEAR tokens and sent as a refund transfer to the original signer.</p>
<p>Before protocol version 78, the full gas amount would be refunded and the refund
transfer action was executed for free. With <a href="https://github.com/near/NEPs/pull/536">NEP-536</a>
which was implemented in version 78, the plan was to have the network charge a
fee of 5% of unspent gas or a minimum of 1 Tgas. This often removes the need to
send a refund, which avoids additional load on the network, and it compensates
for the load of the refund receipt when it needs to be issued. This is intended
to discourage users from attaching more gas than needed to their transactions.
In the nearcore code, you will find this fee under the name <code>gas_refund_penalty</code>.</p>
<p>However, due to existing projects that need to attach more gas than they
actually use, the introduction of the new fee has been postponed. The code is
still in place but the parameters were set to 0 in PR
<a href="https://github.com/near/nearcore/pull/13579">#13579</a>. Among other problems, in
the reference FT implementation, <code>ft_transfer_call</code> requires at least 30 TGas
even if most of the time only a fraction of that is burnt. Once all known
problems are resolved, the plan is to try and introduce the 5% / 1 Tgas parameters.</p>
<p>Technically, even when the parameters are increased again, the refund transfer
is still executed for free, since the gas price is set to 0. This keeps it in
line with balance refunds. However, when the gas refund is produced, at least 1
Tgas has been burnt on receipt execution, which more than covers for a transfer.</p>
<p>Finally, we can have a complete diagram, including the gas refund penalty.</p>
<p><img src="https://github.com/user-attachments/assets/28aea744-979d-4e1b-88b5-541b38ce58ca" alt="Complete Gas Flow Diagram" /></p>
<!-- Editable source: https://github.com/near/nearcore/issues/7821#issuecomment-2867060321 -->
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="receipt-congestion"><a class="header" href="#receipt-congestion">Receipt Congestion</a></h1>
<p>Near Protocol executes transactions in multiple steps, or receipts. Once a
transaction is accepted, the system has committed to finish all those receipts
even if it does not know ahead of time how many receipts there will be or on
which shards they will execute.</p>
<p>This naturally leads to the problem that if shards just keep accepting more
transactions, we might accept workload at a higher rate than we can execute.</p>
<h2 id="cross-shard-congestion-as-flow-problem"><a class="header" href="#cross-shard-congestion-as-flow-problem">Cross-shard congestion as flow problem</a></h2>
<p>For a quick formalized discussion on congestion, let us model the Near Protocol
transaction execution as a <a href="https://en.wikipedia.org/wiki/Flow_network">flow
network</a>.</p>
<p>Each shard has a source that accepts new transactions and a sink for burning
receipts. The flow is measured in gas. Edges to sinks have a capacity of 1000
Tgas. (Technically, it should be 1300 but let's keep it simple for this
discussion.)</p>
<p><img src="architecture/how/../../images/congestion/base_flow_network.svg" alt="graph" /></p>
<p>The edges between shards are not limited in this model. In reality, we are
eventually limited by the receipt sizes and what we can send within a block time
through the network links. But if we only look at that limit, we can send very
many receipts with a lot of gas attached to them. Thus, the model considers it
unlimited.</p>
<p>Okay, we have the capacities of the network modeled. Now let's look at how a
receipt execution maps onto it.</p>
<p>Let's say a receipt starts at shard 1 with 300 Tgas. While executing, it burns 100 Tgas and
creates an outgoing receipts with 200 Tgas to another shard. We can represent this in the flow network with
100 Tgas to the sink of shard 1 and 200 Tgas to shard 2.</p>
<p><img src="architecture/how/../../images/congestion/receipt_flow_example_0.svg" alt="graph" /></p>
<p>Note: The graph includes the execution of the next block with the 200 Tgas to the
sink of shard 2. This should be interpreted as if we continue sending the exact
same workload on all shards every block. Then we reach this steady state where
we continue to have these gas assignments per edge.</p>
<p>Now we can do some flow analysis. It is immediately obvious that the total
outflow per is limited to N * 1000 Tgas but the incoming flow is unlimited.</p>
<p>For a finite amount of time, we can accept more inflow than outflow, we just have to add buffers to store what we cannot execute, yet. But to stay within finite memory requirements, we need to fall back to a flow diagram where outflows are greater or equal to inflows within a finite time frame.</p>
<p>Next, we look at ideas one at a time before combining some of them into the
cross-shard congestion design proposed in
<a href="https://github.com/near/NEPs/blob/master/neps/nep-0539.md">NEP-539</a>.</p>
<h2 id="idea-1-compute-the-minimum-max-flow-and-stay-below-that-limit"><a class="header" href="#idea-1-compute-the-minimum-max-flow-and-stay-below-that-limit">Idea 1: Compute the minimum max-flow and stay below that limit</a></h2>
<p>One approach to solve congestion would be to never allow more work into the
system than we can execute.</p>
<p>But this is not ideal. Just consider this example where everybody tries to access
a contract on the same shard.</p>
<p><img src="architecture/how/../../images/congestion/receipt_flow_example_1.svg" alt="graph" /></p>
<p>In this workload where everyone want to use the capacity of the same shard, the
max-flow of the system is essentially the 1000 Tgas that shard 3 can execute. No
matter how many additional shards we add, this 1000 Tgas does not increase.</p>
<p>Consequently, if we want to limit inflow to be the same or lower than the
outflow, we cannot accept more than <code>1000 Tgas / NUM_SHARDS</code> of new transactions
per chunk.</p>
<p><img src="architecture/how/../../images/congestion/receipt_flow_example_1_1.svg" alt="graph" /></p>
<p>So, can we just put a constant limit on sources that's <code>1000 Tgas / NUM_SHARDS</code>? Not
really, as this limit is hardly practical. It means we limit global throughput
to that of a single shard. Then why would we do sharding in the first place?</p>
<p>The sad thing is, there is no way around it in the most general case. A
congestion control strategy that does not apply this limit to this workload will
always have infinitely sized queues.</p>
<p>Of course, we won't give up. We are not limited to a constant capacity limit, we
can instead adjust it dynamically. We simply have to find a strategy that
detects such workload and eventually applies the required limit.</p>
<p>Most of these strategies can be gamed by malicious actors and probably that
means we eventually fall back to the minimum of <code>1000 Tgas / NUM_SHARDS</code>. But at
this stage our ambition isn't to have 100% utilization under all malicious
cases. We are instead trying to find a solution that can give 100% utilization
for normal operation and then falls back to <code>1000 Tgas / NUM_SHARDS</code> when it has
to, in order to prevent out-of-memory crashes.</p>
<h2 id="idea-2-limit-transactions-when-we-use-too-much-memory"><a class="header" href="#idea-2-limit-transactions-when-we-use-too-much-memory">Idea 2: Limit transactions when we use too much memory</a></h2>
<p>What if we have no limit at the source until we notice we are above the memory
threshold we are comfortable with? Then we can reduce the source capacity in
steps, potentially down to 0, until buffers are getting emptier and we use less
memory again.</p>
<p>If we do that, we can decide between either applying a global limit on all
sources (allow only <code>1000 Tgas / NUM_SHARDS</code> new transactions on all shards like
in idea 1) or applying the limit only to transactions that go to the shard with
the congestion problem.</p>
<p>The first choice is certainly safe. But it means that a single congested shard
leads to all shards slowing down, even if they could keep working faster without
ever sending receipts to the congested shard. This is a hit to utilization we
want to avoid. So let's try the second way.</p>
<p>In that case we filter transactions by receiver and keep accepting transactions
that go to non-congested shards. This would work fine, if all transactions would
only have depth 1.</p>
<p>But receipts produced by an accepted transaction can produce more receipts to
any other shard. Therefore, we might end up accepting more inflow that
indirectly requires bandwidth on the congested shard.</p>
<p><img src="architecture/how/../../images/congestion/receipt_flow_example_2.svg" alt="graph" /></p>
<p>Crucially, when accepting a transaction, we don't know ahead of time which
shards will be affected by the full directed graph of receipts in a transaction.
We only know the first step. For multi-hop transactions, there is no easy way out.</p>
<p>But it is worth mentioning, that in practice the single-hop function call is the
most common case. And this case can be handled nicely by rejecting incoming
transactions to congested shards.</p>
<h2 id="idea-3-apply-backpressure-to-stop-all-flows-to-a-congested-shard"><a class="header" href="#idea-3-apply-backpressure-to-stop-all-flows-to-a-congested-shard">Idea 3: Apply backpressure to stop all flows to a congested shard</a></h2>
<p>On top of stopping transactions to congested shards, we can also stop receipts if they have a congested shard as the receiver.
We simply put them in a buffer of the sending shard and keep them there until
the congested shard has space again for the receipts.</p>
<p><img src="architecture/how/../../images/congestion/receipt_flow_example_3.svg" alt="graph" /></p>
<p>The problem with this idea is that it leads to deadlocks where all receipts in
the system are waiting in outgoing buffers but cannot make progress because the
receiving shard already has too high memory usage.</p>
<p><img src="architecture/how/../../images/congestion/receipt_flow_example_3_1.svg" alt="graph" /></p>
<h2 id="idea-4-keep-minimum-incoming-queue-length-to-avoid-deadlocks"><a class="header" href="#idea-4-keep-minimum-incoming-queue-length-to-avoid-deadlocks">Idea 4: Keep minimum incoming queue length to avoid deadlocks</a></h2>
<p>This is the final idea we need. To avoid deadlocks, we ensure that we can always
send receipts to a shard that does not have enough work in the delayed receipts queue
already.</p>
<p>Basically, the backpressure limits from idea 3 are only applied to incoming
receipts but not for the total size. This guarantees that in the congested
scenario that previously caused a deadlock, we always have something in the
incoming queue to work on, otherwise there wouldn't be backpressure at all.</p>
<p><img src="architecture/how/../../images/congestion/receipt_flow_example_4.svg" alt="graph" /></p>
<p>We decided to measure the incoming congestion level using gas rather than
bytes, because it is here to maximize utilization, not to minimize memory
consumption. And utilization is best measured in gas. If we have a queue of
10_000 Tgas waiting, even if only 10% of that is burnt in this step of the
transaction, we still have 1000 Tgas of useful work we can contribute to the
total flow. Thus under the assumption that at least 10% of gas is being burnt,
we have 100% utilization.</p>
<p>A limit in bytes would be better to argue how much memory we need exactly. But
in some sense, the two are equivalent, as producing large receipts should cost a
linear amount of gas. What exactly the conversion rate is, is rather complicated
and warrants its own investigation with potential protocol changes to lower the
ratio in the most extreme cases. And this is important regardless of how
congestion is handled, given that network bandwidth is becoming more and more
important as we add more shards. Issue
<a href="https://github.com/near/nearcore/issues/8214">#8214</a> tracks our effort on
estimating what that cost should be and
<a href="https://github.com/near/nearcore/issues/9378">#9378</a> tracks our best progress
on calculating what it is today.</p>
<p>Of course, we can increase the queue to have even better utility guarantees. But
it comes at the cost of longer delays for every transaction or receipt that goes
through a congested shard.</p>
<p>This strategy also preserves the backpressure property in the sense that all
shards on a path from sources to sinks that contribute to congestion will
eventually end up with full buffers. Combined with idea 2, eventually all
transactions to those shards are rejected. All of this without affecting shards
that are not on the critical path.</p>
<h2 id="putting-it-all-together"><a class="header" href="#putting-it-all-together">Putting it all together</a></h2>
<p>The proposal in <a href="https://github.com/near/NEPs/blob/master/neps/nep-0539.md">NEP-539</a> combines all
ideas 2, 3, and 4.</p>
<p>We have a limit of how much memory we consider to be normal operations (for
example 500 MB). Then we stop new transaction coming in to that shard but still
allow more incoming transactions to other shards if those are not congested.
That alone already solves all problems with single-hop transactions.</p>
<p>In the congested shard itself, we also keep accepting transactions to other
shards. But we heavily reduce the gas allocated for new transactions, in order
to have more capacity to work on finishing the waiting receipts. This is
technically not necessary for any specific property, but it should make sense
intuitively that this helps to reduce congestion quicker and therefore lead to a
better user experience. This is why we added this feature. And our simulations
also support this intuition.</p>
<p>Then we apply backpressure for multi-hop receipts and avoid deadlocks by only
applying the backpressure when we still have enough work queued up that holding
it back cannot lead to a slowed down global throughput.</p>
<p>Another design decision was to linearly interpolate the limits, as opposed to
binary on and off states. This way, we don't have to be too precise in finding
the right parameters, as the system should balance itself around a specific
limit that works for each workload.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="meta-transactions"><a class="header" href="#meta-transactions">Meta Transactions</a></h1>
<p><a href="https://github.com/near/NEPs/blob/master/neps/nep-0366.md">NEP-366</a> introduced the concept of meta
transactions to Near Protocol. This feature allows users to execute transactions
on NEAR without owning any gas or tokens. In order to enable this, users
construct and sign transactions off-chain. A third party (the relayer) is used
to cover the fees of submitting and executing the transaction.</p>
<p>The MVP for meta transactions is currently in the stabilization process.
Naturally, the MVP has some limitations, which are discussed in separate
sections below. Future iterations have the potential to make meta transactions
more flexible.</p>
<h2 id="overview-4"><a class="header" href="#overview-4">Overview</a></h2>
<!-- cspell:ignore Egor Fadeev Uleyskiy -->
<p><img src="https://raw.githubusercontent.com/near/NEPs/003e589e6aba24fc70dd91c9cf7ef0007ca50735/neps/assets/nep-0366/NEP-DelegateAction.png" alt="Flow chart of meta transactions" />
<em>Credits for the diagram go to the NEP authors Alexander Fadeev and Egor
Uleyskiy.</em></p>
<p>The graphic shows an example use case for meta transactions. Alice owns an
amount of the fungible token $FT. She wants to transfer some to John. To do
that, she needs to call <code>ft_transfer(&quot;john&quot;, 10)</code> on an account named <code>FT</code>.</p>
<p>In technical terms, ownership of $FT is an entry in the <code>FT</code> contract's storage
that tracks the balance for her account. Note that this is on the application
layer and thus not a part of Near Protocol itself. But <code>FT</code> relies on the
protocol to verify that the <code>ft_transfer</code> call actually comes from Alice. The
contract code checks that <code>predecessor_id</code> is <code>&quot;Alice&quot;</code> and if that is the case
then the call is legitimately from Alice, as only she could create such a
receipt according to the Near Protocol specification.</p>
<p>The problem is, Alice has no NEAR tokens. She only has a NEAR account that
someone else funded for her and she owns the private keys. She could create a
signed transaction that would make the <code>ft_transfer(&quot;john&quot;, 10)</code> call. But
validator nodes will not accept it, because she does not have the necessary Near
token balance to purchase the gas.</p>
<p>With meta transactions, Alice can create a <code>DelegateAction</code>, which is very
similar to a transaction. It also contains a list of actions to execute and a
single receiver for those actions. She signs the <code>DelegateAction</code> and forwards
it (off-chain) to a relayer. The relayer wraps it in a transaction, of which the
relayer is the signer and therefore pays the gas costs. If the inner actions
have an attached token balance, this is also paid for by the relayer.</p>
<p>On chain, the <code>SignedDelegateAction</code> inside the transaction is converted to an
action receipt with the same <code>SignedDelegateAction</code> on the relayer's shard. The
receipt is forwarded to the account from <code>Alice</code>, which will unpacked the
<code>SignedDelegateAction</code> and verify that it is signed by Alice with a valid Nonce
etc. If all checks are successful, a new action receipt with the inner actions
as body is sent to <code>FT</code>. There, the <code>ft_transfer</code> call finally executes.</p>
<h2 id="relayer"><a class="header" href="#relayer">Relayer</a></h2>
<p>Meta transactions only work with a relayer. This is an application layer
concept, implemented off-chain. Think of it as a server that accepts a
<code>SignedDelegateAction</code>, does some checks on them and eventually forwards it
inside a transaction to the blockchain network.</p>
<p>A relayer may choose to offer their service for free but that's not going to be
financially viable long-term. But they could easily have the user pay using
other means, outside of Near blockchain. And with some tricks, it can even be
paid using fungible tokens on Near.</p>
<p>In the example visualized above, the payment is done using $FT. Together with
the transfer to John, Alice also adds an action to pay 0.1 $FT to the relayer.
The relayer checks the content of the <code>SignedDelegateAction</code> and only processes
it if this payment is included as the first action. In this way, the relayer
will be paid in the same transaction as John.</p>
<p>Note that the payment to the relayer is still not guaranteed. It could be that
Alice does not have sufficient <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">FT</span><span class="mord mathnormal">an</span><span class="mord mathnormal">d</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">an</span><span class="mord mathnormal">s</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal" style="margin-right:0.02778em;">er</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">ai</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">s</span><span class="mord">.</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal">o</span><span class="mord mathnormal">mi</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span><span class="mord mathnormal">ere</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">a</span><span class="mord mathnormal">yers</span><span class="mord mathnormal">h</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">d</span><span class="mord mathnormal">c</span><span class="mord mathnormal">h</span><span class="mord mathnormal">ec</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span></span></span></span>FT balance of Alice first.</p>
<p>Unfortunately, this still does not guarantee that the balance will be high
enough once the meta transaction executes. The relayer could waste NEAR gas
without compensation if Alice somehow reduces her $FT balance in just the right
moment. Some level of trust between the relayer and its user is therefore
required.</p>
<p>The vision here is that there will be mostly application-specific relayers. A
general-purpose relayer is difficult to implement with just the MVP. See
limitations below.</p>
<h2 id="limitation-single-receiver"><a class="header" href="#limitation-single-receiver">Limitation: Single receiver</a></h2>
<p>A meta transaction, like a normal transaction, can only have one receiver. It's
possible to chain additional receipts afterwards. But crucially, there is no
atomicity guarantee and no roll-back mechanism.</p>
<p>For normal transactions, this has been widely accepted as a fact for how Near
Protocol works. For meta transactions, there was a discussion around allowing
multiple receivers with separate lists of actions per receiver. While this could
be implemented, it would only create a false sense of atomicity. Since each
receiver would require a separate action receipt, there is no atomicity, the
same as with chains of receipts.</p>
<p>Unfortunately, this means the trick to compensate the relayer in the same meta
transaction as the serviced actions only works if both happen on the same
receiver. In the example, both happen on <code>FT</code> and this case works well. But it
would not be possible to send $FT1 and pay the relayer in $FT2. Nor could one
deploy a contract code on <code>Alice</code> and pay in $FT in one meta transaction. It
would require two separate meta transactions to do that. Due to timing problems,
this again requires some level of trust between the relayer and Alice.</p>
<p>A potential solution could involve linear dependencies between the action
receipts spawned from a single meta transaction. Only if the first succeeds,
will the second start executing, and so on. But this quickly gets too complicated
for the MVP and is therefore left open for future improvements.</p>
<h2 id="constraints-on-the-actions-inside-a-meta-transaction"><a class="header" href="#constraints-on-the-actions-inside-a-meta-transaction">Constraints on the actions inside a meta transaction</a></h2>
<p>A transaction is only allowed to contain one single delegate action. Nested
delegate actions are disallowed and so are delegate actions next to each other
in the same receipt.</p>
<p>Nested delegate actions have no known use case and it would be complicated to
implement. Consequently, it was omitted.</p>
<p>For delegate actions beside each other, there was a bit of back and forth during
the NEP-366 design phase. The potential use case here is essentially the same as
having multiple receivers in a delegate action. Naturally, it runs into all the
same complications (false sense of atomicity) and ends with the same conclusion:
Omitted from the MVP and left open for future improvement.</p>
<h2 id="limitation-accounts-must-be-initialized"><a class="header" href="#limitation-accounts-must-be-initialized">Limitation: Accounts must be initialized</a></h2>
<p>Any transaction, including meta transactions, must use NONCEs to avoid replay
attacks. The NONCE must be chosen by Alice and compared to a NONCE stored on
chain. This NONCE is stored on the access key information that gets initialized
when creating an account.</p>
<p>Implicit accounts don't need to be initialized in order to receive NEAR tokens,
or even <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">FT</span><span class="mord">.</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal">hi</span><span class="mord mathnormal">s</span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">an</span><span class="mord mathnormal">s</span><span class="mord mathnormal">u</span><span class="mord mathnormal">sersco</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">d</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">n</span></span></span></span>FT but no NONCE is stored on chain for
them. This is problematic because we want to enable this exact use case with
meta transactions, but we have no NONCE to create a meta transaction.</p>
<p>For the MVP, the proposed solution, or work-around, is that the relayer will
have to initialize the account of Alice once if it does not exist. Note that
this cannot be done as part of the meta transaction. Instead, it will be a
separate transaction that executes first. Only then can Alice even create a
<code>SignedDelegateAction</code> with a valid NONCE.</p>
<p>Once again, some trust is required. If Alice wanted to abuse the relayer's
helpful service, she could ask the relayer to initialize her account.
Afterwards, she does not sign a meta transaction, instead she deletes her
account and cashes in the small token balance reserved for storage. If this
attack is repeated, a significant amount of tokens could be stolen from the
relayer.</p>
<p>One partial solution suggested here was to remove the storage staking cost from
accounts. This means there is no financial incentive for Alice to delete her
account. But it does not solve the problem that the relayer has to pay for the
account creation and Alice can simply refuse to send a meta transaction
afterwards. In particular, anyone creating an account would have financial
incentive to let a relayer create it for them instead of paying out of their own
pockets. This would still be better than Alice stealing tokens but
fundamentally, there still needs to be some trust.</p>
<p>An alternative solution discussed is to do NONCE checks on the relayer's access
key. This prevents replay attacks and allows implicit accounts to be used in
meta transactions without even initializing them. The downside is that meta
transactions share the same NONCE counter(s). That means, a meta transaction
sent by Bob may invalidate a meta transaction signed by Alice that was created
and sent to the relayer at the same time. Multiple access keys by the relayer
and coordination between relayer and user could potentially alleviate this
problem. But for the MVP, nothing along those lines has been approved.</p>
<h2 id="gas-costs-for-meta-transactions"><a class="header" href="#gas-costs-for-meta-transactions">Gas costs for meta transactions</a></h2>
<p>Meta transactions challenge the traditional ways of charging gas for actions. To
see why, let's first list the normal flow of gas, outside of meta transactions.</p>
<ol>
<li>Gas is purchased (by deducting NEAR from the transaction signer account),
when the transaction is converted into a receipt. The amount of gas is
implicitly defined by the content of the receipt. For function calls, the
caller decides explicitly how much gas is attached on top of the minimum
required amount. The NEAR token price per gas unit is dynamically adjusted on
the blockchain. In today's nearcore code base, this happens as part of
<a href="https://github.com/near/nearcore/blob/4510472d69c059644bb2d2579837c6bd6d94f190/runtime/runtime/src/verifier.rs#L69"><code>verify_and_charge_transaction</code></a>
which gets called in
<a href="https://github.com/near/nearcore/blob/4510472d69c059644bb2d2579837c6bd6d94f190/runtime/runtime/src/lib.rs#L218"><code>process_transaction</code></a>.</li>
<li>For all actions listed inside the transaction, the <code>SEND</code> cost is burned
immediately. Depending on the condition <code>sender == receiver</code>, one of two
possible <code>SEND</code> costs is chosen. The <code>EXEC</code> cost is not burned, yet. But it
is implicitly part of the transaction cost. The third and last part of the
transaction cost is the gas attached to function calls. The attached gas is
also called prepaid gas. (Not to be confused with <code>total_prepaid_exec_fees</code>
which is the implicitly prepaid gas for <code>EXEC</code> action costs.)</li>
<li>On the receiver shard, <code>EXEC</code> costs are burned before the execution of an
action starts. Should the execution fail and abort the transaction, the
remaining gas will be refunded to the signer of the transaction.</li>
</ol>
<p>Ok, now adapt for meta transactions. Let's assume Alice uses a relayer to
execute actions with Bob as the receiver.</p>
<ol>
<li>The relayer purchases the gas for all inner actions, plus the gas for the
delegate action wrapping them.</li>
<li>The cost of sending the inner actions and the delegate action from the
relayer to Alice's shard will be burned immediately. The condition <code>relayer == Alice</code> determines which action <code>SEND</code> cost is taken (<code>sir</code> or <code>not_sir</code>).
Let's call this <code>SEND(1)</code>.</li>
<li>On Alice's shard, the delegate action is executed, thus the <code>EXEC</code> gas cost
for it is burned. Alice sends the inner actions to Bob's shard. Therefore, we
burn the <code>SEND</code> fee again. This time based on <code>Alice == Bob</code> to figure out
<code>sir</code> or <code>not_sir</code>. Let's call this <code>SEND(2)</code>.</li>
<li>On Bob's shard, we execute all inner actions and burn their <code>EXEC</code> cost.</li>
</ol>
<p>Each of these steps should make sense and not be too surprising. But the
consequence is that the implicit costs paid at the relayer's shard are
<code>SEND(1)</code> + <code>SEND(2)</code> + <code>EXEC</code> for all inner actions plus <code>SEND(1)</code> + <code>EXEC</code> for
the delegate action. This might be surprising but hopefully with this
explanation it makes sense now!</p>
<h2 id="gas-refunds-in-meta-transactions"><a class="header" href="#gas-refunds-in-meta-transactions">Gas refunds in meta transactions</a></h2>
<p>Gas refund receipts work exactly like for normal transaction. At every step, the
difference between the pessimistic gas price and the actual gas price at that
height is computed and refunded. At the end of the last step, additionally all
remaining gas is also refunded at the original purchasing price. The gas refunds
go to the signer of the original transaction, in this case the relayer. This is
only fair, since the relayer also paid for it.</p>
<h2 id="balance-refunds-in-meta-transactions"><a class="header" href="#balance-refunds-in-meta-transactions">Balance refunds in meta transactions</a></h2>
<p>Unlike gas refunds, the protocol sends balance refunds to the predecessor
(a.k.a. sender) of the receipt. This makes sense, as we deposit the attached
balance to the receiver, who has to explicitly reattach a new balance to new
receipts they might spawn.</p>
<p>In the world of meta transactions, this assumption is also challenged. If an
inner action requires an attached balance (for example a transfer action) then
this balance is taken from the relayer.</p>
<p>The relayer can see what the cost will be before submitting the meta transaction
and agrees to pay for it, so nothing wrong so far. But what if the transaction
fails execution on Bob's shard? At this point, the predecessor is <code>Alice</code> and
therefore she receives the token balance refunded, not the relayer. This is
something relayer implementations must be aware of since there is a financial
incentive for Alice to submit meta transactions that have high balances attached
but will fail on Bob's shard.</p>
<h2 id="function-access-keys-in-meta-transactions"><a class="header" href="#function-access-keys-in-meta-transactions">Function access keys in meta transactions</a></h2>
<p>Assume alice sends a meta transaction and signs with a function access key.
How exactly are permissions applied in this case?</p>
<p>Function access keys can limit the allowance, the receiving contract, and the
contract methods. The allowance limitation acts slightly strange with meta
transactions.</p>
<p>But first, both the methods and the receiver will be checked as expected. That
is, when the delegate action is unwrapped on Alice's shard, the access key is
loaded from the DB and compared to the function call. If the receiver or method
is not allowed, the function call action fails.</p>
<p>For allowance, however, there is no check. All costs have been covered by the
relayer. Hence, even if the allowance of the key is insufficient to make the call
directly, indirectly through meta transaction it will still work.</p>
<p>This behavior is in the spirit of allowance limiting how much financial
resources the user can use from a given account. But if someone were to limit a
function access key to one trivial action by setting a very small allowance,
that is circumventable by going through a relayer. An interesting twist that
comes with the addition of meta transactions.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="serialization-borsh-json-protobuf"><a class="header" href="#serialization-borsh-json-protobuf">Serialization: Borsh, Json, ProtoBuf</a></h1>
<p>If you spent some time looking at NEAR code, youâ€™ll notice that we have
different methods of serializing structures into strings. So in this article,
weâ€™ll compare these different approaches, and explain how and where weâ€™re using
them.</p>
<h2 id="protocolschema"><a class="header" href="#protocolschema">ProtocolSchema</a></h2>
<p>All structs which need to be persisted or sent over the network must derive the
ProtocolSchema trait:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// First, the schema checksums (hashes) are calculated at compile time and
// require `TypeId` for cross-navigation. However, it is a nightly feature,
// so we enable it manually by putting this in lib.rs:

#![cfg_attr(enable_const_type_id, feature(const_type_id))]

// Then, import schema calculation functionality by putting in Cargo.toml:
// near-schema-checker-lib.workspace = true

[features]
protocol_schema = [
  &quot;near-schema-checker-lib/protocol_schema&quot;,
  ...the same feature in all dependent crates...
]
 
// Then, mark your struct with `#[derive(ProtocolSchema)]`:

use near_schema_checker_lib::ProtocolSchema;

#[derive(ProtocolSchema)]
pub struct BlockHeader {
  pub hash: CryptoHash,
  pub height: BlockHeight,
}

// Lastly, mark your crate in `tools/protocol-schema-check/Cargo.toml`
// as dependency with `protocol_schema` feature enabled.

<span class="boring">}
</span></code></pre></pre>
<p>This is done to protect structures from accidental changes that could corrupt the
database or disrupt the protocol. Dedicated CI check is responsible to check the
consistency of the schema. See <a href="architecture/how/../../../tools/protocol-schema-check/README.html">README</a> for more details.</p>
<p>All these structures are likely to implement BorshSerialize and BorshDeserialize (see below).</p>
<h2 id="borsh"><a class="header" href="#borsh">Borsh</a></h2>
<p>Borsh is our custom serializer (<a href="https://github.com/near/borsh">link</a>), that we use
mostly for things that have to be hashed.</p>
<p>The main feature of Borsh is that, there are no two binary representations that
deserialize into the same object.</p>
<p>You can read more on how Borsh serializes the data, by looking at the Specification
tab on <a href="https://borsh.io">borsh.io</a>.</p>
<p>The biggest pitfall/risk of Borsh, is that any change to the structure, might
cause previous data to no longer be parsable.</p>
<p>For example, inserting a new enum â€˜in the middleâ€™:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum MyCar {
  Bmw,
  Ford,
}

If we change our enum to this:

pub enum MyCar {
  Bmw,
  Citroen,
  Ford, // !! WRONG - Ford objects cannot be deserialized anymore
}
<span class="boring">}
</span></code></pre></pre>
<p>This is especially tricky if we have conditional compilation:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum MyCar {
  Bmw,
  #[cfg(feature = &quot;french_cars&quot;)]
  Citroen,
  Ford,
}
<span class="boring">}
</span></code></pre></pre>
<p>Is such a scenario - some of the objects created by binaries with this feature
enabled, will not be parsable by binaries without this feature.</p>
<p>Removing and adding fields to structures is also dangerous.</p>
<p>Basically - the only â€˜safeâ€™ thing that you can do with Borsh - is add a new Enum
value at the end.</p>
<h2 id="json"><a class="header" href="#json">JSON</a></h2>
<p>JSON doesnâ€™t need much introduction. Weâ€™re using it for external APIs (jsonrpc)
and configuration. It is a very popular, flexible and human-readable format.</p>
<h2 id="proto-protocol-buffers"><a class="header" href="#proto-protocol-buffers">Proto (Protocol Buffers)</a></h2>
<p>We started using proto recently - and we plan to use it mostly for our network
communication. Protocol buffers are strongly typed - they require you to create
a .proto file, where you describe the contents of your message.</p>
<p>For example:</p>
<pre><code class="language-proto">message HandshakeFailure {
  // Reason for rejecting the Handshake.
  Reason reason = 1;

  // Data about the peer.
  PeerInfo peer_info = 2;
  // GenesisId of the NEAR chain that the peer belongs to.
  GenesisId genesis_id = 3;
}
</code></pre>
<!-- cspell:words protoc -->
<p>Afterwards, such a proto file is fed to protoc â€˜compilerâ€™ that returns
auto-generated code (in our case Rust code) - that can be directly imported into
your library.</p>
<p>The main benefit of protocol buffers is their backwards compatibility (as long
as you adhere to the rules and donâ€™t reuse the same field ids).</p>
<h2 id="summary-1"><a class="header" href="#summary-1">Summary</a></h2>
<p>So to recap what weâ€™ve learned:</p>
<p>JSON - mostly used for external APIs - look for serde::Serialize/Deserialize</p>
<p>Proto - currently being developed to be used for network connections - objects
have to be specified in proto file.</p>
<p>Borsh - for things that we hash (and currently also for all the things that we
store on disk - but we might move to proto with this in the future). Look for
BorshSerialize/BorshDeserialize</p>
<h2 id="questions"><a class="header" href="#questions">Questions</a></h2>
<h3 id="why-dont-you-use-json-for-everything"><a class="header" href="#why-dont-you-use-json-for-everything">Why donâ€™t you use JSON for everything?</a></h3>
<p>While this is a tempting option, JSON has a few drawbacks:</p>
<ul>
<li>size (json is self-describing, so all the field names etc are included every time)</li>
<li>non-canonical: JSON doesnâ€™t specify strict ordering of the fields, so weâ€™d
have to do additional restrictions/rules on that - otherwise the same
â€˜conceptualâ€™ message would end up with different hashes.</li>
</ul>
<h3 id="ok---so-how-about-proto-for-everything"><a class="header" href="#ok---so-how-about-proto-for-everything">Ok - so how about proto for everything?</a></h3>
<p>There are couple risks related with using proto for things that have to be
hashed. A Serialized protocol buffer can contain additional data (for example
fields with tag ids that youâ€™re not using) and still successfully parse (thatâ€™s
how it achieves backward compatibility).</p>
<p>For example, in this proto:</p>
<pre><code class="language-proto">message First {
  string foo = 1;
  string bar = 2;
}
message Second {
  string foo = 1;
}
</code></pre>
<p>Every â€˜Firstâ€™ message will be successfully parsed as â€˜Secondâ€™ message - which
could lead to some programmatic bugs.</p>
<h2 id="advanced-section---rawtrienode"><a class="header" href="#advanced-section---rawtrienode">Advanced section - RawTrieNode</a></h2>
<p>There is one more place in the code where we use a â€˜customâ€™ encoding:
RawTrieNodeWithSize defined in store/src/trie/raw_node.rs.  While the format
uses Borsh derives and API, there is a difference in how branch children
(<code>[Option&lt;CryptoHash&gt;; 16]</code>) are encoded.  Standard Borsh encoding would
encode <code>Option&lt;CryptoHash&gt;</code> sixteen times.  Instead, RawTrieNodeWithSize uses
a bitmap to indicate which elements are set resulting in a different layout.</p>
<p>Imagine a children vector like this:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>[Some(0x11), None, Some(0x12), None, None, â€¦]
<span class="boring">}
</span></code></pre></pre>
<p>Here, we have children at index 0 and 2 which has a bitmap of <code>101</code></p>
<p>Custom encoder:</p>
<pre><code>// Number of children determined by the bitmask
[16 bits bitmask][32 bytes child][32 bytes child]
[5][0x11][0x12]
// Total size: 2 + 32 + 32 = 68 bytes
</code></pre>
<p>Borsh:</p>
<pre><code>[8 bits - 0 or 1][32 bytes child][8 bits 0 or 1][8 bits ]
[1][0x11][0][1][0x11][0][0]...
// Total size: 16 + 32 + 32 = 80 bytes
</code></pre>
<p>Code for encoding children is given in BorshSerialize implementation for
ChildrenRef type and code for decoding in BorshDeserialize implementation for
Children.  All of that is in aforementioned store/src/trie/raw_node.rs file.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="proofs"><a class="header" href="#proofs">Proofs</a></h1>
<p>â€œDonâ€™t trust, but verifyâ€ - letâ€™s talk about proofs</p>
<h2 id="was-your-transaction-included"><a class="header" href="#was-your-transaction-included">Was your transaction included?</a></h2>
<p>How do you know that your transaction was actually included in the blockchain?
Sure, you can â€œsimplyâ€ ask the RPC node, and it might say â€œyesâ€, but is it
enough?</p>
<p>The other option would be to ask many nodes - hoping that at least one of them
would be telling the truth. But what if that is not enough?</p>
<p>The final solution would be to run your own node - this way youâ€™d check all the
transactions yourself, and then you could be sure - but this can become a quite
expensive endeavor - especially when many shards are involved.</p>
<p>But there is actually a better solution - that doesnâ€™t require you to trust the
single (or many) RPC nodes, and to verify, by yourself, that your transaction was
actually executed.</p>
<h2 id="lets-talk-about-proofs-merkelization"><a class="header" href="#lets-talk-about-proofs-merkelization">Letâ€™s talk about proofs (merkelization)</a></h2>
<p>Imagine you have 4 values that youâ€™d like to store, in such a way, that you can
easily prove that a given value is present.</p>
<p><img src="https://user-images.githubusercontent.com/1711539/198579560-923f1f97-a8df-486d-b68e-8796c6aaa300.png" alt="image" /></p>
<p>One way to do it, would be to create a binary tree, where each node would hold a
hash:</p>
<ul>
<li>leaves would hold the hashes that represent the hash of the respective value.</li>
<li>internal nodes would hold the hash of â€œconcatenation of hashes of their childrenâ€</li>
<li>the top node would be called a root node (in this image it is the node n7)</li>
</ul>
<p>With such a setup, you can prove that a given value exists in this tree, by
providing a â€œpathâ€ from the corresponding leaf to the root, and including all
the siblings.</p>
<p>For example to prove that value v[1] exists, we have to provide all the nodes
marked as green, with the information about which sibling (left or right) they
are:</p>
<p><img src="https://user-images.githubusercontent.com/1711539/198579596-488c540b-cd24-4d38-bc07-4dc3378c53d0.png" alt="image" /></p>
<pre><code># information needed to verify that node v[1] is present in a tree
# with a given root (n7)
[(Left, n0), (Right, n6)]

# Verification
assert_eq!(root, hash(hash(n0, hash(v[1])), n6))
</code></pre>
<p>We use the technique above (called merkelization) in a couple of places in our
protocol, but for todayâ€™s article, Iâ€™d like to focus on receipts &amp; outcome
roots.</p>
<h2 id="merkelization-receipts-and-outcomes"><a class="header" href="#merkelization-receipts-and-outcomes">Merkelization, receipts and outcomes</a></h2>
<p>In order to prove that a given receipt belongs to a given block, we will need to
fetch some additional information.</p>
<p>As NEAR is sharded, the receipts actually belong to â€œChunksâ€ not Blocks
themselves, so the first step is to find the correct chunk and fetch its
<code>ChunkHeader</code>.</p>
<pre><code>ShardChunkHeaderV3 {
    inner: V2(
        ShardChunkHeaderInnerV2 {
            prev_block_hash: `C9WnNCbNvkQvnS7jdpaSGrqGvgM7Wwk5nQvkNC9aZFBH`,
            prev_state_root: `5uExpfRqAoZv2dpkdTxp1ZMcids1cVDCEYAQwAD58Yev`,
            outcome_root: `DBM4ZsoDE4rH5N1AvCWRXFE9WW7kDKmvcpUjmUppZVdS`,
            encoded_merkle_root: `2WavX3DLzMCnUaqfKPE17S1YhwMUntYhAUHLksevGGfM`,
            encoded_length: 425,
            height_created: 417,
            shard_id: 0,
            gas_used: 118427363779280,
            gas_limit: 1000000000000000,
            balance_burnt: 85084341232595000000000,
            outgoing_receipts_root: `4VczEwV9rryiVSmFhxALw5nCe9gSohtRpxP2rskP3m1s`,
            tx_root: `11111111111111111111111111111111`,
            validator_proposals: [],
        },
    ),
}
</code></pre>
<p>The field that we care about is called <code>outcome_root</code>. This value represents the
root of the binary merkle tree, that is created based on all the receipts that
were processed in this chunk.</p>
<p><strong>Note:</strong> You can notice that we also have a field here called
<code>encoded_merkle_root</code> - this is another case where we use merkelization in our
chain - this field is a root of a tree that holds hashes of all the &quot;partial
chunks&quot; into which we split the chunk to be distributed over the network.</p>
<p>So, in order to verify that a given receipt/transaction was really included, we
have to compute its hash (see details below), get the path to the root, and
voila, we can confirm that it was really included.</p>
<p>But how do we get the siblings on the path to the root? This is actually
something that RPC nodes do return in their responses.</p>
<p>If you ever looked closely at NEARâ€™s tx-status response, you can notice a
&quot;proof&quot; section there. For every receipt, you'd see something like this:</p>
<pre><code>proof: [
    {
        direction: 'Right',
        hash: '2wTFCh2phFfANicngrhMV7Po7nV7pr6gfjDfPJ2QVwCN'
    },
    {
        direction: 'Right',
        hash: '43ei4uFk8Big6Ce6LTQ8rotsMzh9tXZrjsrGTd6aa5o6'
    },
    {
        direction: 'Left',
        hash: '3fhptxeChNrxWWCg8woTWuzdS277u8cWC9TnVgFviu3n'
    },
    {
        direction: 'Left',
        hash: '7NTMqx5ydMkdYDFyNH9fxPNEkpgskgoW56Y8qLoVYZf7'
    }
]
</code></pre>
<p>And the values in there are exactly the siblings (plus info on which side of the
tree the sibling is), on the path to the root.</p>
<p><strong>Note:</strong> proof section doesnâ€™t contain the root itself and also doesnâ€™t include
the hash of the receipt.</p>
<h2 id="advanced-section-lets-look-at-a-concrete-example"><a class="header" href="#advanced-section-lets-look-at-a-concrete-example">[Advanced section]: Letâ€™s look at a concrete example</a></h2>
<p>Imagine that we have the following receipt:</p>
<pre><code>{
  block_hash: '7FtuLHR3VSNhVTDJ8HmrzTffFWoWPAxBusipYa2UfrND',
  id: '6bdKUtGbybhYEQ2hb2BFCTDMrtPBw8YDnFpANZHGt5im',
  outcome: {
    executor_id: 'node0',
    gas_burnt: 223182562500,
    logs: [],
    metadata: { gas_profile: [], version: 1 },
    receipt_ids: [],
    status: { SuccessValue: '' },
    tokens_burnt: '0'
  },
  proof: [
    {
      direction: 'Right',
      hash: 'BWwZ4wHuzaUxdDSrhAEPjFQtDgwzb8K4zoNzfX9A3SkK'
    },
    {
      direction: 'Left',
      hash: 'Dpg4nQQwbkBZMmdNYcZiDPiihZPpsyviSTdDZgBRAn2z'
    },
    {
      direction: 'Right',
      hash: 'BruTLiGx8f71ufoMKzD4H4MbAvWGd3FLL5JoJS3XJS3c'
    }
  ]
}
</code></pre>
<p>Remember that the outcomes of the execution will be added to the NEXT block, so
letâ€™s find the next block hash, and the proper chunk.</p>
<p>(in this example, Iâ€™ve used the <code>view-state chain</code> from neard)</p>
<pre><code>417 7FtuLHR3VSNhVTDJ8HmrzTffFWoWPAxBusipYa2UfrND |      node0 | parent: 416 C9WnNCbNvkQvnS7jdpaSGrqGvgM7Wwk5nQvkNC9aZFBH | .... 0: E6pfD84bvHmEWgEAaA8USCn2X3XUJAbFfKLmYez8TgZ8 107 Tgas |1: Ch1zr9TECSjDVaCjupNogLcNfnt6fidtevvKGCx8c9aC 104 Tgas |2: 87CmpU6y7soLJGTVHNo4XDHyUdy5aj9Qqy4V7muF5LyF   0 Tgas |3: CtaPWEvtbV4pWem9Kr7Ex3gFMtPcKL4sxDdXD4Pc7wah   0 Tgas
418 J9WQV9iRJHG1shNwGaZYLEGwCEdTtCEEDUTHjboTLLmf |      node0 | parent: 417 7FtuLHR3VSNhVTDJ8HmrzTffFWoWPAxBusipYa2UfrND | .... 0: 7APjALaoxc8ymqwHiozB5BS6mb3LjTgv4ofRkKx2hMZZ   0 Tgas |1: BoVf3mzDLLSvfvsZ2apPSAKjmqNEHz4MtPkmz9ajSUT6   0 Tgas |2: Auz4FzUCVgnM7RsQ2noXsHW8wuPPrFxZToyLaYq6froT   0 Tgas |3: 5ub8CZMQmzmZYQcJU76hDC3BsajJfryjyShxGF9rzpck   1 Tgas
</code></pre>
<p>I know that the receipt should belong to Shard 3 <!-- TODO: how? :) --> so letâ€™s fetch
the chunk header:</p>
<pre><code class="language-console">neard view-state chunks --chunk-hash 5ub8CZMQmzmZYQcJU76hDC3BsajJfryjyShxGF9rzpck
</code></pre>
<pre><code>ShardChunkHeaderV3 {
  inner: V2(
      ShardChunkHeaderInnerV2 {
          prev_block_hash: `7FtuLHR3VSNhVTDJ8HmrzTffFWoWPAxBusipYa2UfrND`,
          prev_state_root: `6rtfqVEXx5STLv5v4zwLVqAfq1aRAvLGXJzZPK84CPpa`,
          outcome_root: `2sZ81kLj2cw5UHTjdTeMxmaWn2zFeyr5pFunxn6aGTNB`,
          encoded_merkle_root: `6xxoqYzsgrudgaVRsTV29KvdTstNYVUxis55KNLg6XtX`,
          encoded_length: 8,
          height_created: 418,
          shard_id: 3,
          gas_used: 1115912812500,
          gas_limit: 1000000000000000,
          balance_burnt: 0,
          outgoing_receipts_root: `8s41rye686T2ronWmFE38ji19vgeb6uPxjYMPt8y8pSV`,
          tx_root: `11111111111111111111111111111111`,
          validator_proposals: [],
      },
  ),
  height_included: 0,
  signature: ed25519:492i57ZAPggqWEjuGcHQFZTh9tAKuQadMXLW7h5CoYBdMRnfY4g7A749YNXPfm6yXnJ3UaG1ahzcSePBGm74Uvz3,
  hash: ChunkHash(
      `5ub8CZMQmzmZYQcJU76hDC3BsajJfryjyShxGF9rzpck`,
  ),
}
</code></pre>
<p>So the <code>outcome_root</code> is <code>2sZ81kLj2cw5UHTjdTeMxmaWn2zFeyr5pFunxn6aGTNB</code> - letâ€™s
verify it then.</p>
<p>Our first step is to compute the hash of the receipt, which is equal to
<code>hash([receipt_id, hash(borsh(receipt_payload)])</code></p>
<pre><code class="language-python"># this is a borsh serialized ExecutionOutcome struct.
# computing this, we leave as an exercise for the reader :-)
receipt_payload_hash = &quot;7PeGiDjssz65GMCS2tYPHUm6jYDeBCzpuPRZPmLNKSy7&quot;

receipt_hash = base58.b58encode(hashlib.sha256(struct.pack(&quot;&lt;I&quot;, 2) + base58.b58decode(&quot;6bdKUtGbybhYEQ2hb2BFCTDMrtPBw8YDnFpANZHGt5im&quot;) + base58.b58decode(receipt_payload_hash)).digest())
</code></pre>
<p>And then we can start reconstructing the tree:</p>
<pre><code class="language-python">def combine(a, b):
   return hashlib.sha256(a + b).digest()

# one node example
# combine(receipt_hash, &quot;BWwZ4wHuzaUxdDSrhAEPjFQtDgwzb8K4zoNzfX9A3SkK&quot;)
# whole tree
combine(combine(&quot;Dpg4nQQwbkBZMmdNYcZiDPiihZPpsyviSTdDZgBRAn2z&quot;, combine(receipt_hash, &quot;BWwZ4wHuzaUxdDSrhAEPjFQtDgwzb8K4zoNzfX9A3SkK&quot;)), &quot;BruTLiGx8f71ufoMKzD4H4MbAvWGd3FLL5JoJS3XJS3c&quot;)
# result == 2sZ81kLj2cw5UHTjdTeMxmaWn2zFeyr5pFunxn6aGTNB
</code></pre>
<p>And success - our result is matching the outcome root, so it means that our
receipt was indeed processed by the blockchain.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="resharding-v2"><a class="header" href="#resharding-v2">Resharding V2</a></h1>
<p><strong>DISCLAIMER</strong>: This document describes Resharding V2 and it may not be up to date with recent changes to <code>nearcore</code>.</p>
<h2 id="resharding"><a class="header" href="#resharding">Resharding</a></h2>
<p>Resharding is the process in which the shard layout changes. The primary purpose
of resharding is to keep the shards small so that a node meeting minimum hardware
requirements can safely keep up with the network while tracking some set minimum
number of shards.</p>
<h2 id="specification-1"><a class="header" href="#specification-1">Specification</a></h2>
<p>The resharding is described in more detail in the following NEPs:</p>
<ul>
<li><a href="https://github.com/near/NEPs/blob/master/neps/archive/0040-split-states.md">NEP-0040</a></li>
<li><a href="https://github.com/near/NEPs/blob/master/neps/nep-0508.md">NEP-0508</a></li>
</ul>
<h2 id="shard-layout"><a class="header" href="#shard-layout">Shard layout</a></h2>
<p>The shard layout determines the number of shards and the assignment of accounts
to shards (as single account cannot be split between shards).</p>
<p>There are two versions of the ShardLayout enum.</p>
<ul>
<li>v0 - maps the account to a shard taking hash of the account id modulo number of shards</li>
<li>v1 - maps the account to a shard by looking at a set of predefined boundary accounts
and selecting the shard where the accounts fits by using alphabetical order</li>
</ul>
<p>At the time of writing there are three pre-defined shard layouts but more can
be added in the future.</p>
<ul>
<li>v0 - The first shard layout that contains only a single shard encompassing all the accounts.</li>
<li>simple nightshade - Splits the accounts into 4 shards.</li>
<li>simple nightshade v2 - Splits the accounts into 5 shards.</li>
</ul>
<p><strong>IMPORTANT</strong>: Using alphabetical order applies to the full account name, so <code>a.near</code> could belong to
shard 0, while <code>z.a.near</code> to shard 3.</p>
<p>Currently in mainnet &amp; testnet, we use the fixed shard split (which is defined in <code>get_simple_nightshade_layout</code>):</p>
<p><code>vec![&quot;aurora&quot;, &quot;aurora-0&quot;, &quot;kkuuue2akv_1630967379.near&quot;]</code></p>
<p>In the near future we are planning on switching to simple nightshade v2 (which is defined in <code>get_simple_nightshade_layout_v2</code>)</p>
<p><code>vec![&quot;aurora&quot;, &quot;aurora-0&quot;, &quot;kkuuue2akv_1630967379.near&quot;, &quot;tge-lockup.sweat&quot;]</code></p>
<h2 id="shard-layout-changes"><a class="header" href="#shard-layout-changes">Shard layout changes</a></h2>
<p>Shard Layout is determined at epoch level in the AllEpochConfig based on the protocol version of the epoch.</p>
<p>The shard layout can change at the epoch boundary. Currently in order to change the
shard layout it is necessary to manually determine the new shard layout and setting it
for the desired protocol version in the <code>AllEpochConfig</code>.</p>
<h3 id="deeper-technical-details"><a class="header" href="#deeper-technical-details">Deeper technical details</a></h3>
<p>It all starts in <code>preprocess_block</code> - if the node sees, that the block it is
about to preprocess is the first block of the epoch (X+1)  - it calls
<code>get_state_sync_info</code>, which is responsible for figuring out which shards will
be needed in next epoch (X+2).</p>
<p>This is the moment, when node can request new shards that it didn't track before (using StateSync) - and if it detects that the shard layout would change in the next epoch, it also involves the StateSync - but skips the download part (as it already has the data) - and starts from resharding.</p>
<p>StateSync in this phase would send the <code>ReshardingRequest</code> to the <code>SyncJobsActor</code> (you can think about the <code>SyncJobsActor</code> as a background thread).</p>
<p>We'd use the background thread to perform resharding: the goal is to change the one trie (that represents the state of the current shard) - to multiple tries (one for each of the new shards).</p>
<p>In order to split a trie into children tries we use a snapshot of the flat storage. We iterate over all of the entries in the flat storage and we build the children tries by inserting the parent entry into either of the children tries.</p>
<p>Extracting of the account from the key happens in <code>parse_account_id_from_raw_key</code> - and we do it for all types of data that we store in the trie (contract code, keys, account info etc) EXCEPT for Delayed receipts. Then, we figure out the shard that this account is going to belong to, and we add this key/value to that new trie.</p>
<p>This way, after going over all the key/values from the original trie, we end up with X new tries (one for each new shard).</p>
<p>IMPORTANT: in the current code, we only support such 'splitting' (so a new shard can have just one parent).</p>
<h3 id="why-delayed-receipts-are-special"><a class="header" href="#why-delayed-receipts-are-special">Why delayed receipts are special?</a></h3>
<p>For all the other columns, there is no dependency between entries, but in case of delayed receipts - we are forming a 'queue'. We store the information about the first index and the last index (in DelayedReceiptIndices struct).</p>
<p>Then, when receipt arrives, we add it as the 'DELAYED_RECEIPT + last_index' key (and increment last_index by 1).</p>
<p>That is why we cannot move this trie entry type in the same way as others where account id is part of the key. Instead we do it by iterating over this queue and inserting entries to the queue of the relevant child shard.</p>
<h2 id="constraints"><a class="header" href="#constraints">Constraints</a></h2>
<p>The state sync of the parent shard, the resharding and the catchup of the children shards must all complete within a single epoch.</p>
<h2 id="rollout"><a class="header" href="#rollout">Rollout</a></h2>
<h3 id="flow"><a class="header" href="#flow">Flow</a></h3>
<p>The resharding will be initiated by having it included in a dedicated protocol version together with neard. Here is the expected flow of events:</p>
<ul>
<li>A new neard release is published and protocol version upgrade date is set to D, roughly a week from the release.</li>
<li>All node operators upgrade their binaries to the newly released version within the given time frame, ideally as soon as possible but no later than D.</li>
<li>The protocol version upgrade voting takes place at D in an epoch E and nodes vote in favour of switching to the new protocol version in epoch E+2.</li>
<li>The resharding begins at the beginning of epoch E+1.</li>
<li>The network switches to the new shard layout in the first block of epoch E+2.</li>
</ul>
<h3 id="monitoring"><a class="header" href="#monitoring">Monitoring</a></h3>
<p>Resharding exposes a number of metrics and logs that allow for monitoring the resharding process as it is happening. Resharding requires manual recovery in case anything goes wrong and should be monitored in order to ensure smooth node operation.</p>
<ul>
<li>near_resharding_status is the primary metric that should be used for tracking the progress of resharding. It's tagged with a shard_uid label of the parent shard. It's set to corresponding ReshardingStatus enum and can take one of the following values
<ul>
<li>0 - Scheduled - resharding is scheduled and waiting to be executed.</li>
<li>1 - Building - resharding is running. Only one shard at a time can be in that state while the rest will be either finished or waiting in the Scheduled state.</li>
<li>2 - Finished - resharding is finished.</li>
<li>-1 - Failed - resharding failed and manual recovery action is required. The node will operate as usual until the end of the epoch but will then stop being able to process blocks.</li>
</ul>
</li>
<li>near_resharding_batch_size and near_resharding_batch_count - those two metrics show how much data has been resharded. Both metrics should progress with the near_resharding_status as follows.
<ul>
<li>While in the Scheduled state both metrics should remain 0.</li>
<li>While in the Building state both metrics should be gradually increasing.</li>
<li>While in the Finished state both metrics should remain at the same value.</li>
</ul>
</li>
<li>near_resharding_batch_prepare_time_bucket, near_resharding_batch_apply_time_bucket and near_resharding_batch_commit_time_bucket - those three metrics can be used to track the performance of resharding and fine tune throttling if needed. As a rule of thumb the combined time of prepare, apply and commit for a batch should remain at the 100ms-200ms level on average. Higher batch processing time may lead to disruptions in block processing, missing chunks and blocks.</li>
</ul>
<p>Here are some example metric values when finished for different shards and networks. The duration column reflects the duration of the building phase. Those were captured in production like environment in November 2023 and actual times at the time of resharding in production may be slightly higher.</p>
<div class="table-wrapper"><table><thead><tr><th>mainnet</th><th>duration</th><th>batch count</th><th>batch size</th></tr></thead><tbody>
<tr><td>total</td><td>2h23min</td><td></td><td></td></tr>
<tr><td>shard 0</td><td>32min</td><td>12,510</td><td>6.6GB</td></tr>
<tr><td>shard 1</td><td>30min</td><td>12,203</td><td>6.1GB</td></tr>
<tr><td>shard 2</td><td>26min</td><td>10,619</td><td>6.0GB</td></tr>
<tr><td>shard 3</td><td>55min</td><td>21,070</td><td>11.5GB</td></tr>
</tbody></table>
</div><div class="table-wrapper"><table><thead><tr><th>testnet</th><th>duration</th><th>batch count</th><th>batch size</th></tr></thead><tbody>
<tr><td>total</td><td>5h32min</td><td></td><td></td></tr>
<tr><td>shard 0</td><td>21min</td><td>10,259</td><td>10.9GB</td></tr>
<tr><td>shard 1</td><td>18min</td><td>7,034</td><td>3.5GB</td></tr>
<tr><td>shard 2</td><td>2h31min</td><td>75,529</td><td>75.6GB</td></tr>
<tr><td>shard 3</td><td>2h22min</td><td>63,621</td><td>49.2GB</td></tr>
</tbody></table>
</div>
<p>Here is an example of what that may look like in a grafana dashboard. Please keep in mind that the values and duration is not representative as the sample data below is captured in a testing environment with different configuration.</p>
<img width="941" alt="Screenshot 2023-12-01 at 10 10 20" src="https://github.com/near/nearcore/assets/1555986/42824d5a-af16-4a06-9727-a04b1b9d7c03">
<img width="941" alt="Screenshot 2023-12-01 at 10 10 50" src="https://github.com/near/nearcore/assets/1555986/06a2c6f1-1daf-4220-b3fe-e21992e2d62c">
<img width="941" alt="Screenshot 2023-12-01 at 10 10 42" src="https://github.com/near/nearcore/assets/1555986/fea2ad6b-2fa4-4862-875e-a3ca5d61d849">
<h3 id="throttling"><a class="header" href="#throttling">Throttling</a></h3>
<p>The resharding process can be quite resource intensive and affect the regular operation of a node. In order to mitigate that as well as limit any need for increasing hardware specifications of the nodes throttling was added. Throttling slows down resharding to not have it impact other node operations. Throttling can be configured by adjusting the resharding_config in the node config file.</p>
<ul>
<li>batch_size - controls the size of batches in which resharding moves data around. Setting a smaller batch size will slow down the resharding process and make it less resource-consuming.</li>
<li>batch_delay - controls the delay between processing of batches. Setting a smaller batch delay will speed up the resharding process and make it more resource-consuming.</li>
</ul>
<p>The remaining fields in the ReshardingConfig are only intended for testing purposes and should remain set to their default values.</p>
<p>The default configuration for ReshardingConfig should provide a good and safe setting for resharding in the production networks. There is no need for node operators to make any changes to it unless they observe issues.</p>
<p>The resharding config can be adjusted at runtime, without restarting the node. The config needs to be updated first and then a SIGHUP signal should be sent to the neard process. When received the signal neard will update the config and print a log message showing what fields were changed. It's recommended to check the log to make sure the relevant config change was correctly picked up.</p>
<h2 id="future-possibilities"><a class="header" href="#future-possibilities">Future possibilities</a></h2>
<h3 id="localize-resharding-to-a-single-shard"><a class="header" href="#localize-resharding-to-a-single-shard">Localize resharding to a single shard</a></h3>
<p>Currently when resharding we need to move the data for all shards even if only a single shard is being split. That is due to having the version field in the storage key that needs to be updated when changing shard layout version.</p>
<p>This can be improved by changing how ShardUId works e.g. removing the version and instead using globally unique shard ids.</p>
<h3 id="dynamic-resharding"><a class="header" href="#dynamic-resharding">Dynamic resharding</a></h3>
<p>The current implementation relies on having the shard layout determined offline and manually added to the node implementation.</p>
<p>The dynamic resharding would mean that the network itself can automatically determine that resharding is needed, what should be the new shard layout and schedule the resharding.</p>
<h3 id="support-different-changes-to-shard-layout"><a class="header" href="#support-different-changes-to-shard-layout">Support different changes to shard layout</a></h3>
<p>The current implementation only supports splitting a shard. In the future we can consider adding support for other operations such as merging two shards or moving an existing boundary account.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="optimistic-block"><a class="header" href="#optimistic-block">Optimistic block</a></h1>
<p>This short document will tell you about what optimistic block is and why it was introduced with protocol version 77.</p>
<h2 id="improving-stateless-validation-latency-with-optimistic-block"><a class="header" href="#improving-stateless-validation-latency-with-optimistic-block">Improving Stateless Validation Latency with Optimistic Block</a></h2>
<h3 id="why-2-latency-existed-before-v77--and-how-the-idea-of-optimistic-block-emerged"><a class="header" href="#why-2-latency-existed-before-v77--and-how-the-idea-of-optimistic-block-emerged">Why 2Ã— Latency Existed Before v77 â€” and How the Idea of Optimistic Block Emerged</a></h3>
<p><img src="https://raw.githubusercontent.com/near/nearcore/7f0299041e3c3c9241a8a300900ec9a8d07fd7c1/docs/images/optimistic_block_before.png" alt="image" /></p>
<p>In this diagram: yellow = data; rectangle = process. Arrow = dependency on a process; dashed arrow = production and dependency on data.</p>
<p>This was the critical path between two consecutive blocks. The two red blocks are the slow parts. It's better to have only one of them on the critical path.</p>
<ul>
<li>Chunk production could be skipped and as validation of the state witness can be done as soon as the chunk producer finishes applying the chunk. But that doesnâ€™t help with 2x latency.</li>
<li>Chunk validation necessarily depend on chunk application to produce the state witness, so thereâ€™s no way to parallelize chunk application with the chunk validation of the next chunk
<ul>
<li>The best you can do is stream that data, but thatâ€™s complicated.</li>
</ul>
</li>
<li>If they cannot be stacked this way, only option is to stack them the other way: apply a chunk while validating the same chunk.</li>
<li>But now the challenge is: chunk application requires the block, and block production is the only way to have the block, but block production depends on chunk endorsement which depends on chunk validation, so how do we break this chain?</li>
</ul>
<h3 id="introduction-to-optimistic-block"><a class="header" href="#introduction-to-optimistic-block">Introduction to Optimistic Block</a></h3>
<p><img src="https://raw.githubusercontent.com/near/nearcore/7f0299041e3c3c9241a8a300900ec9a8d07fd7c1/docs/images/optimistic_block_after.png" alt="image" /></p>
<p>Optimistic Block accelerates chunk execution by speculatively applying chunks before the actual block is finalized. Here's how it works:</p>
<ul>
<li><strong>Block production:</strong> as soon as the previous block producer produces a block, the new block producer produces an optimistic block.
<ul>
<li>The optimistic block contains all parts of the block except those that depend on chunks. That means no chunk headers, no chunk endorsements, but everything else including block height, timestamp, vrf, etc.</li>
</ul>
</li>
<li><strong>Chunk execution:</strong> The chunk producer who is responsible for producing the next chunk and needs to apply the just produced chunk of the same shard, listens to the ShardsManager for other chunks with the same parent. As soon as it receives chunks from all other shards (if it happens before the new block is received), and it also receives the optimistic block, it starts applying the chunk optimistically.
<ul>
<li>As a reminder, applying a chunk requires the block that the chunk is in, for two reasons:
<ul>
<li>The runtime requires several fields from the block: block height, timestamp, and VRF. These can be obtained from the optimistic block.</li>
<li>A chunk does not contain the incoming receipts of that shard; rather it contains the outgoing receipts of the previous chunk of that shard. In order to collect the incoming receipts, other chunks in the same block are needed. During optimistic execution, these are obtained from the other chunks that are received via ShardsManager.</li>
</ul>
</li>
<li>The optimistic chunk application should produce the exact same result as the real chunk application as long as the optimistic block matches all of the real blockâ€™s fields, and the chunks used for optimistic application are exactly the chunks included in the real block (in other words, no chunk producer double-signed, and no chunks were missed).</li>
</ul>
</li>
<li><strong>Fallback and safety:</strong> It is possible for the optimistic chunk application to incorrectly predict the actual block produced. Therefore, the original chunk application logic still needs to be executed in that case.
<ul>
<li>To implement cleanly, the optimistic chunk application shall serve only as a cache for the actual chunk application. It should not write any data or do anything else other than acting as a cache. The actual chunk application always happens except it may be skipped if the inputs match exactly.</li>
</ul>
</li>
<li><strong>Changes to block timestamp:</strong> Note that the way validators choose the block timestamp must be changed, as it needs to be predicted by the time the block producer produces the optimistic block.
<ul>
<li>The timestamp is not a critical field; it only needs to be reasonable (tethered to real world time) and monotonically increasing.</li>
<li>In the current implementation, the current timestamp is used when producing the optimistic block.</li>
<li>This is not a protocol change as the block producer has freedom in picking this value.</li>
<li>If optimistic block was produced, the block and optimistic block timestamp must be the same. Otherwise, the optimistic chunk application will be invalidated. </li>
</ul>
</li>
<li><strong>Backward compatibility:</strong> Optimistic block itself is also not a protocol change. It is also very safe as long as the optimistic chunk applicationâ€™s implementation is consistent with the actual.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="how-neard-will-work"><a class="header" href="#how-neard-will-work">How neard will work</a></h1>
<p>The documents under this chapter are talking about the future of NEAR - what we're planning on improving and how.</p>
<p>(This also means that they can get out of date quickly :-).</p>
<p>If you have comments, suggestions or want to help us designing and implementing some of these things here - please reach out on Zulip or github.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<p>This document is still a DRAFT.</p>
<p>This document covers our improvement plans for state sync and catchup.
<strong>Before reading this doc, you should take a look at <a href="architecture/next/../how/sync.html">How sync works</a></strong></p>
<p>State sync is used in two situations:</p>
<ul>
<li>when your node is behind for more than 2 epochs (and it is not an archival node) - then rather than trying to apply block by block (that can take hours) - you 'give up' and download the fresh state (a.k.a state sync) and apply blocks from there.</li>
<li>when you're a block (or chunk) producer - and in the upcoming epoch, you'll have to track a shard that you are not currently tracking.</li>
</ul>
<p>In the past (and currently) - the state sync was mostly used in the first scenario (as all block &amp; chunk producers had to track all the shards for security reasons - so they didn't actually have to do catchup at all).</p>
<p>As we progress towards phase 2 and keep increasing number of shards - the catchup part starts being a lot more critical. When we're running a network with a 100 shards, the single machine is simply not capable of tracking (a.k.a applying all transactions) of all shards - so it will have to track just a subset. And it will have to change this subset almost every epoch (as protocol rebalances the shard-to-producer assignment based on the stakes).</p>
<p>This means that we have to do some larger changes to the state sync design, as requirements start to differ a lot:</p>
<ul>
<li>catchups are high priority (the validator MUST catchup within 1 epoch - otherwise it will not be able to produce blocks for the new shards in the next epoch - and therefore it will not earn rewards).</li>
<li>a lot more catchups in progress (with lots of shards basically every validator would have to catchup at least one shard at each epoch boundary) - this leads to a lot more potential traffic on the network</li>
<li>malicious attacks &amp; incentives - the state data can be large and can cause a lot of network traffic. At the same time it is quite critical (see point above), so we'll have to make sure that the nodes are incentivize to provide the state parts upon request.</li>
<li>only a subset of peers will be available to request the state sync from (as not everyone from our peers will be tracking the shard that we're interested in).</li>
</ul>
<h2 id="things-that-were-actively-analyzing"><a class="header" href="#things-that-were-actively-analyzing">Things that we're actively analyzing</a></h2>
<h3 id="performance-of-state-sync-on-the-receiver-side"><a class="header" href="#performance-of-state-sync-on-the-receiver-side">Performance of state sync on the receiver side</a></h3>
<p>We're looking at the performance of state sync:</p>
<ul>
<li>how long does it take to create the parts,</li>
<li>pro-actively creating the parts as soon as epoch starts</li>
<li>creating them in parallel</li>
<li>allowing user to ask for many at once</li>
<li>allowing user to provide a bitmask of parts that are required (therefore allowing the server to return only the ones that it already cached).</li>
</ul>
<h3 id="better-performance-on-the-requestor-side"><a class="header" href="#better-performance-on-the-requestor-side">Better performance on the requestor side</a></h3>
<p>Currently the parts are applied only once all of them are downloaded - instead we should try to apply them in parallel - after each part is received.</p>
<p>When we receive a part, we should announce this information to our peers - so that they know that they can request it from us if they need it.</p>
<h2 id="ideas---not-actively-working-on-them-yet"><a class="header" href="#ideas---not-actively-working-on-them-yet">Ideas - not actively working on them yet</a></h2>
<h3 id="better-networking-aka-tier-3"><a class="header" href="#better-networking-aka-tier-3">Better networking (a.k.a Tier 3)</a></h3>
<p>Currently our networking code is picking the peers to connect at random (as most of them are tracking all the shards). With phase2 it will no longer be the case, so we should work on improvements of our peer-selection mechanism.</p>
<p>In general - we should make sure that we have direct connection to at least a few nodes that are tracking the same shards that we're tracking right now (or that we'll want to track in the near future).</p>
<h3 id="dedicated-nodes-optimized-towards-state-sync-responses"><a class="header" href="#dedicated-nodes-optimized-towards-state-sync-responses">Dedicated nodes optimized towards state sync responses</a></h3>
<p>The idea is to create a set of nodes that would specialize in state sync responses (similar to how we have archival nodes today).</p>
<p>The sub-idea of this, is to store such data on one of the cloud providers (AWS, GCP).</p>
<h3 id="sending-deltas-instead-of-full-state-syncs"><a class="header" href="#sending-deltas-instead-of-full-state-syncs">Sending deltas instead of full state syncs</a></h3>
<p>In case of catchup, the requesting node might have tracked that shard in the past. So we could consider just sending a delta of the state rather than the whole state.</p>
<p>While this helps with the amount of data being sent - it might require the receiver to do a lot more work (as the data that it is about to send cannot be easily cached).</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="malicious-producers-in-phase-2-of-sharding"><a class="header" href="#malicious-producers-in-phase-2-of-sharding">Malicious producers in phase 2 of sharding</a></h1>
<p>In this document, we'll compare the impact of the hypothetical malicious producer on the NEAR system (both in the current setup and how it will work when phase2 is implemented).</p>
<h2 id="current-state-phase-1"><a class="header" href="#current-state-phase-1">Current state (Phase 1)</a></h2>
<p>Let's assume that a malicious chunk producer <code>C1</code> has produced a bad chunk
and sent it to the block producer at this height <code>B1</code>.</p>
<p>The block producer IS going to add the chunk to the block (as we don't validate
the chunks before adding to blocks - but only when signing the block - see
<a href="architecture/next/./../how/tx_receipts.html">Transactions and receipts - last section</a>).</p>
<p>After this block is produced, it is sent to all the validators to get the
signatures.</p>
<p>As currently all the validators are tracking all the shards - they will quickly
notice that the chunk is invalid, so they will not sign the block.</p>
<p>Therefore the next block producer <code>B2</code> is going to ignore <code>B1</code>'s block, and
select block from <code>B0</code> as a parent instead.</p>
<p>So TL;DR - <strong>a bad chunk would not be added to the chain.</strong></p>
<h2 id="phase-2-and-sharding"><a class="header" href="#phase-2-and-sharding">Phase 2 and sharding</a></h2>
<p>Unfortunately things get a lot more complicated, once we scale.</p>
<p>Let's assume the same setup as above (a single chunk producer <code>C1</code> being
malicious). But this time, we have 100 shards - each validator is tracking just
a few (they cannot track all - as today - as they would have to run super
powerful machines with &gt; 100 cores).</p>
<p>So in the similar scenario as above - <code>C1</code> creates a malicious chunks, and
sends it to <code>B1</code>, which includes it in the block.</p>
<p>And here's where the complexity starts - as most of the validators will NOT
track the shard which <code>C1</code> was producing - so they will still sign the block.</p>
<p>The validators that do track that shard will of course (assuming that they are non-malicious) refuse the sign. But overall, they will be a small majority - so the block is going to get enough signatures and be added to the chain.</p>
<h3 id="challenges-slashing-and-rollbacks"><a class="header" href="#challenges-slashing-and-rollbacks">Challenges, Slashing and Rollbacks</a></h3>
<p>So we're in a pickle - as a malicious chunk was just added to the chain. And
that's why need to have mechanisms to automatically recover from such situations:
Challenges, Slashing and Rollbacks.</p>
<h4 id="challenge"><a class="header" href="#challenge">Challenge</a></h4>
<p>Challenge is a self-contained proof, that something went wrong in the chunk
processing. It must contain all the inputs (with their merkle proof), the code
that was executed, and the outputs (also with merkle proofs).</p>
<p>Such a challenge allows anyone (even nodes that don't track that shard or have
any state) to verify the validity of the challenge.</p>
<p>When anyone notices that a current chain contains a wrong transition - they
submit such challenge to the next block producer, which can easily verify it
and it to the next block.</p>
<p>Then the validators do the verification themselves, and if successful, they
sign the block.</p>
<p>When such block is successfully signed, the protocol automatically slashes
malicious nodes (more details below) and initiates the rollback to bring the
state back to the state before the bad chunk (so in our case, back to the block
produced by <code>B0</code>).</p>
<h4 id="slashing-2"><a class="header" href="#slashing-2">Slashing</a></h4>
<p>Slashing is the process of taking away the part of the stake from validators
that are considered malicious.</p>
<p>In the example above, we'll definitely need to slash the <code>C1</code> - and potentially also any validators that were tracking that shard and did sign the bad block.</p>
<p>Things that we'll have to figure out in the future:</p>
<ul>
<li>how much do we slash? all of the stake? some part?</li>
<li>what happens to the slashed stake? is it burned? does it go to some pool?</li>
</ul>
<h4 id="state-rollbacks"><a class="header" href="#state-rollbacks">State rollbacks</a></h4>
<p>// TODO: add</p>
<h2 id="problems-with-the-current-phase-2-design"><a class="header" href="#problems-with-the-current-phase-2-design">Problems with the current Phase 2 design</a></h2>
<h3 id="is-slashing-painful-enough"><a class="header" href="#is-slashing-painful-enough">Is slashing painful enough?</a></h3>
<p>In the example above, we'd successfully slash the <code>C1</code> producer - but was it<br />
enough?</p>
<p>Currently (with 4 shards) you need around 20k NEAR to become a chunk producer.
If we increase the number of shards to 100, it would drop the minimum stake to
around 1k NEAR.</p>
<p>In such scenario, by sacrificing 1k NEAR, the malicious node can cause the
system to rollback a couple blocks (potentially having bad impact on the bridge
contracts etc).</p>
<p>On the other side, you could be a non-malicious chunk producer with a corrupted
database (or a nasty bug in the code) - and the effect would be the same - the
chunk that you produced would be marked as malicious, and you'd lose your stake
(which will be a super-scary even for any legitimate validator).</p>
<p>So the open question is - can we do something 'smarter' in the protocol to
detect the case, where there is 'just a single' malicious (or buggy) chunk
producer and avoid the expensive rollback?</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="storage-1"><a class="header" href="#storage-1">Storage</a></h1>
<p>This is our work-in-progress storage documentation. Things are raw and
incomplete. You are encouraged to help improve it, in any capacity you can!</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="flow-1"><a class="header" href="#flow-1">Flow</a></h1>
<p>Here we present the flow of a single read or write request from the transaction runtime
all the way to the OS. As you can see, there are many layers of read-caching and
write-buffering involved.</p>
<p>Blue arrow means a call triggered by read.</p>
<p>Red arrow means a call triggered by write.</p>
<p>Black arrow means a non-trivial data dependency. For example:</p>
<ul>
<li>Nodes which are read on TrieStorage go to TrieRecorder to generate proof, so they
are connected with black arrow.</li>
<li>Memtrie lookup needs current state of accounting cache to compute costs. When
query completes, accounting cache is updated with memtrie nodes. So they are connected
with bidirectional black arrow.</li>
</ul>
<!-- Editable source: https://docs.google.com/presentation/d/1_iU5GfznFDUMUNi_7szBRd5hDrjqBxr8ap7eTCK-lZA/edit#slide=id.p  -->
<p><img src="https://github.com/user-attachments/assets/232ae746-3f86-4a15-8a3a-08a544a88834" alt="Diagram with read and write request flow" /></p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="trie"><a class="header" href="#trie">Trie</a></h1>
<p>We use Merkle-Patricia Trie to store blockchain state. Trie is persistent, which
means that insertion of new node actually leads to creation of a new path to this
node, and thus root of Trie after insertion will also be represented by a new
object.</p>
<p>Here we describe its implementation details which are closely related to
Runtime.</p>
<h2 id="main-structures"><a class="header" href="#main-structures">Main structures</a></h2>
<h3 id="trie-1"><a class="header" href="#trie-1">Trie</a></h3>
<p>Trie stores the state - accounts, contract codes, access keys, etc. Each state
item corresponds to the unique trie key. You can read more about this structure on
<a href="https://en.wikipedia.org/wiki/Trie">Wikipedia</a>.</p>
<p>There are two ways to access trie - from memory and from disk. The first one is
currently the main one, where only the loading stage requires disk, and the
operations are fully done in memory. The latter one relies only on disk with
several layers of caching. Here we describe the disk trie.</p>
<p>Disk trie is stored in the RocksDB, which is persistent across node restarts. Trie
communicates with database using <code>TrieStorage</code>. On the database level, data is
stored in key-value format in <code>DBCol::State</code> column. There are two kinds of
records:</p>
<ul>
<li>trie nodes, for the which key is constructed from shard id and
<code>RawTrieNodeWithSize</code> hash, and value is a <code>RawTrieNodeWithSize</code> serialized by
a custom algorithm;</li>
<li>values (encoded contract codes, postponed receipts, etc.), for which the key is
constructed from shard id and the hash of value, which maps to the encoded value.</li>
</ul>
<p>So, value can be obtained from <code>TrieKey</code> as follows:</p>
<ul>
<li>start from the hash of <code>RawTrieNodeWithSize</code> corresponding to the root;</li>
<li>descend to the needed node using nibbles from <code>TrieKey</code>;</li>
<li>extract underlying <code>RawTrieNode</code>;</li>
<li>if it is a <code>Leaf</code> or <code>Branch</code>, it should contain the hash of the value;</li>
<li>get value from storage by its hash and shard id.</li>
</ul>
<p>Note that <code>Trie</code> is almost never called directly from <code>Runtime</code>, modifications
are made using <code>TrieUpdate</code>.</p>
<h3 id="trieupdate"><a class="header" href="#trieupdate">TrieUpdate</a></h3>
<p>Provides a way to access storage and record changes to commit in the future.
Update is prepared as follows:</p>
<ul>
<li>changes are made using <code>set</code> and <code>remove</code> methods, which are added to
<code>prospective</code> field,</li>
<li>call <code>commit</code> method which moves <code>prospective</code> changes to <code>committed</code>,</li>
<li>call <code>finalize</code> method which prepares <code>TrieChanges</code> and state changes based on
<code>committed</code> field.</li>
</ul>
<p>Prospective changes correspond to intermediate state updates, which can be
discarded if the transaction is considered invalid (because of insufficient
balance, invalidity, etc.). While they can't be applied yet, they must be cached
this way if the updated keys are accessed again in the same transaction.</p>
<p>Committed changes are stored in memory across transactions and receipts.
Similarly, they must be cached if the updated keys are accessed across
transactions. They can be discarded only if the chunk is discarded.</p>
<p>Note that <code>finalize</code>, <code>Trie::insert</code> and <code>Trie::update</code> do not update the
database storage. These functions only modify trie nodes in memory. Instead,
these functions prepare the <code>TrieChanges</code> object, and <code>Trie</code> is actually updated
when <code>ShardTries::apply_insertions</code> is called, which puts new values to
<code>DBCol::State</code> part of the key-value database.</p>
<h3 id="triestorage"><a class="header" href="#triestorage">TrieStorage</a></h3>
<p>Stores all <code>Trie</code> nodes and allows to get serialized nodes by <code>TrieKey</code> hash
using the <code>retrieve_raw_bytes</code> method.</p>
<p>There are two major implementations of <code>TrieStorage</code>:</p>
<ul>
<li><code>TrieCachingStorage</code> - caches all big values ever read by <code>retrieve_raw_bytes</code>.</li>
<li><code>TrieMemoryPartialStorage</code> - used for validating recorded partial storage.</li>
</ul>
<p>Note that these storages use database keys, which are retrieved using hashes of
trie nodes using the <code>get_key_from_shard_id_and_hash</code> method.</p>
<h3 id="shardtries"><a class="header" href="#shardtries">ShardTries</a></h3>
<p>This is the main struct that is used to access all Tries. There's usually only a single instance of this and it contains stores and caches. We use this to gain access to the <code>Trie</code> for a single shard by calling the <code>get_trie_for_shard</code> or equivalent methods.</p>
<p>Each shard within <code>ShardTries</code> has their own <code>cache</code> and <code>view_cache</code>. The <code>cache</code> stores the most frequently accessed nodes and is usually used during block production. The <code>view_cache</code> is used to serve user request to get data, which usually come in via network. It is a good idea to have an independent cache for this as we can have patterns in accessing user data independent of block production.</p>
<h2 id="primitives"><a class="header" href="#primitives">Primitives</a></h2>
<h3 id="triechanges"><a class="header" href="#triechanges">TrieChanges</a></h3>
<p>Stores result of updating <code>Trie</code>.</p>
<ul>
<li><code>old_root</code>: root before updating <code>Trie</code>, i.e. inserting new nodes and deleting
old ones,</li>
<li><code>new_root</code>: root after updating <code>Trie</code>,</li>
<li><code>insertions</code>, <code>deletions</code>: vectors of <code>TrieRefcountChange</code>, describing all
inserted and deleted nodes.</li>
</ul>
<p>This way to update trie allows to add new nodes to storage and remove old ones
separately. The former corresponds to saving new block, the latter - to garbage
collection of old block data which is no longer needed.</p>
<h3 id="trierefcountchange"><a class="header" href="#trierefcountchange">TrieRefcountChange</a></h3>
<p>Because we remove unused nodes during garbage collection, we need to track
the reference count (<code>rc</code>) for each node. Another reason is that we can dedup
values. If the same contract is deployed 1000 times, we only store one contract
binary in storage and track its count.</p>
<p>This structure is used to update <code>rc</code> in the database:</p>
<ul>
<li><code>trie_node_or_value_hash</code> - hash of the trie node or value, used for uniting
with shard id to get DB key,</li>
<li><code>trie_node_or_value</code> - serialized trie node or value,</li>
<li><code>rc</code> - change of reference count.</li>
</ul>
<p>Note that for all reference-counted records, the actual value stored in DB is
the concatenation of <code>trie_node_or_value</code> and <code>rc</code>. The reference count is
updated using a custom merge operation <code>refcount_merge</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="on-disk-database-format"><a class="header" href="#on-disk-database-format">On-Disk Database Format</a></h1>
<p>We store the database in RocksDB. This document is an attempt to give hints about how to navigate it.</p>
<h2 id="rocksdb"><a class="header" href="#rocksdb">RocksDB</a></h2>
<ul>
<li>The column families are defined in <code>DBCol</code>, defined in <code>core/store/src/columns.rs</code></li>
<li>The column families are seen on the rocksdb side as per the <code>col_name</code> function defined in <code>core/store/src/db/rocksdb.rs</code></li>
</ul>
<h2 id="the-trie-col5"><a class="header" href="#the-trie-col5">The Trie (col5)</a></h2>
<ul>
<li>The trie is stored in column family <code>State</code>, number 5</li>
<li>In this family, each key is of the form <code>ShardUId | CryptoHash</code> where <code>ShardUId: u64</code> and <code>CryptoHash: [u8; 32]</code></li>
</ul>
<h2 id="all-historical-state-changes-col35"><a class="header" href="#all-historical-state-changes-col35">All Historical State Changes (col35)</a></h2>
<ul>
<li>The state changes are stored in column family <code>StateChanges</code>, number 35</li>
<li>In this family, each key is of the form <code>BlockHash | Column | AdditionalInfo</code> where:
<ul>
<li><code>BlockHash: [u8; 32]</code> is the block hash for this change</li>
<li><code>Column: u8</code> is defined near the top of <code>core/primitives/src/trie_key.rs</code></li>
<li><code>AdditionalInfo</code> depends on <code>Column</code> and it can be found in the code for the <code>TrieKey</code> struct, same file as <code>Column</code></li>
</ul>
</li>
</ul>
<h3 id="contract-deployments"><a class="header" href="#contract-deployments">Contract Deployments</a></h3>
<ul>
<li>
<p>Contract deployments happen with <code>Column = 0x01</code></p>
</li>
<li>
<p><code>AdditionalInfo</code> is the account id for which the contract is being deployed</p>
</li>
<li>
<p>The key value contains the contract code alongside other pieces of data. It is possible to extract the contract code by removing everything until the wasm magic number, 0061736D01000000</p>
</li>
<li>
<p>As such, it is possible to dump all the contracts that were ever deployed on-chain using this command on an archival node:</p>
<pre><code>ldb --db=~/.near/data scan --column_family=col35 --hex | \
    grep -E '^0x.{64}01' | \
    sed 's/0061736D01000000/x/' | \
    sed 's/^.*x/0061736D01000000/' | \
    grep -v ' : '
</code></pre>
<p>(Note that the last grep is required because not every such value appears to contain contract code)
We should implement a feature to state-viewer thatâ€™d allow better visualization of this data, but in the meantime this seems to work.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="high-level-overview-2"><a class="header" href="#high-level-overview-2">High level overview</a></h1>
<p>When mainnet launched, the neard client stored all the chain's state in a single
RocksDB column <code>DBCol::State</code>. This column embeds the entire <a href="architecture/storage/./trie_storage.html">NEAR state
trie</a> directly in the key-value database, using roughly
<code>hash(borsh_encode(trie_node))</code> as the key to store a <code>trie_node</code>. This gives a
content-addressed storage system that can easily self-verify.</p>
<p>Flat storage is a bit like a database index for the values stored in the trie.
It stores a copy of the data in a more accessible way to speed up the lookup
time.</p>
<p>Drastically oversimplified, flat storage uses a hashmap instead of a trie. This
reduces the lookup time from <code>O(d)</code> to <code>O(1)</code> where <code>d</code> is the tree depth of the
value.</p>
<p>But the devil is in the detail. Below is a high-level summary of implementation
challenges, which are the reasons why the above description is an
oversimplification.</p>
<h2 id="time-dimension-of-the-state"><a class="header" href="#time-dimension-of-the-state">Time dimension of the state</a></h2>
<p>The blockchain state is modified with every chunk. Neard must be able to travel
back in time and resolve key lookups for older versions, as well as travel to
alternative universes to resolve requests for chunks that belong to a different
fork.</p>
<p>Using the full trie embedding in RocksDB, this is almost trivial. We only need
to know the state root for a chunk and we can start traversing from the root to
any key. As long as we do not delete (garbage collect) unused trie nodes, the
data remains available. The overhead is minimal, too, since all the trie nodes
that have not been changed are shared between tries.</p>
<p>Enter flat storage territory: A simple hashmap only stores a snapshot. When we
write a new value to the same key, the old value is overwritten and no longer
accessible. A solution to access different versions on each shard is required.</p>
<p>The minimal solution only tracks the final head and all forks building on top. A
full implementation would also allow replaying older chunks and doing view
calls. But even this minimal solution pulls in all complicated details regarding
consensus and multiplies them with all the problems listed below.</p>
<h2 id="fear-of-data-corruption"><a class="header" href="#fear-of-data-corruption">Fear of data corruption</a></h2>
<p>State and FlatState keep a copy of the same data and need to be in sync at all
times. This is a source for errors which any implementation needs to test
properly. Ideally, there are also tools to quickly compare the two and verify
which is correct.</p>
<p>Note: The trie storage is verifiable by construction of the hashes. The flat
state is not directly verifiable. But it is possible to reconstruct the full
trie just from the leaf values and use that for verification.</p>
<h2 id="gas-accounting-requires-a-protocol-change"><a class="header" href="#gas-accounting-requires-a-protocol-change">Gas accounting requires a protocol change</a></h2>
<p>The trie path we take in a trie lookup affects the gas costs, and hence the
balance subtracted from the user. In other words, the lookup algorithm leaks
into the protocol. Hence, we cannot switch between different ways of looking up
state without a protocol change.</p>
<p>This makes things a whole lot more complicated. We have to do the data migration
and prepare flat storage, while still using trie storage. Keeping flat storage
up to date at this point is pure overhead. And then, at the epoch switch where
the new protocol version begins, we have to start using the new storage in all
clients simultaneously. Anyone that has not finished migration, yet, will fail
to produce a chunk due to invalid gas results.</p>
<p>In an ideal future, we want to make gas costs independent of the position in the
trie and then this would no longer be a problem.</p>
<h2 id="performance-reality-check"><a class="header" href="#performance-reality-check">Performance reality check</a></h2>
<p>Going from <code>O(d)</code> to <code>O(1)</code> sounds great. But let's look at actual numbers.</p>
<p>A flat state lookup requires exactly 2 database requests. One for finding the
<code>ValueRef</code> and one for dereferencing the value. (Dereferencing only happens if
the value is present and if enough gas was paid to cover reading the potentially
large value, otherwise we short-circuit.)</p>
<p>A trie lookup requires exactly <code>d</code> trie node lookups where <code>d</code> is the depth in
the trie, plus one more for dereferencing the final value.</p>
<p>Clearly, <code>d + 1</code> is worse than <code>1 + 1</code>, right? Well, as it turns out, we can
cache the trie nodes with surprisingly high effectiveness. In mainnet
workloads (which were often optimized to work well with the trie shape) we
observe a 99% cache hit rate in many cases.</p>
<p>Combine that with the fact that a typical value for <code>d</code> is somewhere between 10
and 20. Then we may conclude that, in expectation, a trie lookup (<code>d * 0.01 + 1</code>
requests) requires less DB requests than a flat state lookup (<code>1 + 1</code> requests).</p>
<p>In practice, however, flat state still has an edge over accessing trie storage
directly. And that is due to two reasons.</p>
<ol>
<li>DB keys are in better order, leading to more cache hits in RocksDB's block cache.</li>
<li>The flat state column is much smaller than the state column.</li>
</ol>
<p>We observed a speedup of 100x and beyond for reading a single value from
<code>DBCol::FlatState</code> compared to reading it from <code>DBCol::State</code>. So that is
clearly a win. But one that is due to the data layout inside RocksDB, not due to
algorithmic improvements.</p>
<h2 id="updating-the-merkle-tree"><a class="header" href="#updating-the-merkle-tree">Updating the Merkle tree</a></h2>
<p>When we update a value in the blockchain state, all ancestor nodes change their
value due to the recursive nature of Merkle trees.</p>
<p>Updating flat state is easy enough but then we would not know the new state
root. Annoyingly, it is rather important to have the state root in due time, as
it is included in the chunk header.</p>
<p>To update the state root, we need to read all nodes between the root and all
changed values. At which point, we are doing all the same reads we were trying
to avoid in the first place.</p>
<p>This makes flat state for writes algorithmically useless, as we still have to do
<code>O(d)</code> requests, no matter what. But there are potential benefits from data
locality, as flat state stores values sorted by a trie key instead of a
perfectly random hash.</p>
<p>For that, we would need a fast index not only for the state value but also for
all intermediate trie nodes. At this point, we would be back to a full embedding
of the trie in a key-value store / hashmap. Just changing the keys we use for
the database.</p>
<p>Note that we can enjoy the benefits of read-only flat storage to improve read
heavy contracts. But a read-modify-write pattern using this hybrid solution is
strictly worse than the original implementation without flat storage.</p>
<h1 id="implementation-status-and-future-ideas"><a class="header" href="#implementation-status-and-future-ideas">Implementation status and future ideas</a></h1>
<p>As of March 2023, we have implemented a read-only flat storage that only works
for the frontier of non-final blocks and the final block itself. Archival calls
and view calls still use the trie directly.</p>
<h2 id="things-we-have-solved"><a class="header" href="#things-we-have-solved">Things we have solved</a></h2>
<p>We are fairly confident we have solved the time-travel issues, the data
migration / protocol upgrade problems, and got a decent handle on avoiding
accidental data corruption.</p>
<p>This improves the worst case (no cache hits) for reads dramatically. And it
paves the way for further improvements, as we have now a good understanding of
all these seemingly-simple but actually-really-hard problems.</p>
<h2 id="flat-state-for-writes"><a class="header" href="#flat-state-for-writes">Flat state for writes</a></h2>
<p>How to use flat storage for writes is not fully designed, yet, but we have some
rough ideas on how to do it. But we don't know the performance we should expect.
Algorithmically, it can only get worse but the speedup on RocksDB we found with
the read-only flat storage is promising. But one has to wonder if there are not
also simpler ways to achieve better data locality in RocksDB.</p>
<h2 id="inlining-values"><a class="header" href="#inlining-values">Inlining values</a></h2>
<p>We hope to get a jump in performance by avoiding dereferencing <code>ValueRef</code> after
the flat state lookup. At least for small values  we could store the value
itself also in flat state. (to be defined what small means)</p>
<p>This seems very promising because the value dereferencing still happens in the
much slower <code>DBCol::State</code>. If we assume small values are the common case, we
would thus expect huge performance improvements for the average case.</p>
<p>It is not clear yet, if we can also optimize large lookups somehow. If not, we
could at least charge them at a higher rate than we do today, to reflect the
real DB cost better.</p>
<h1 id="code-guide"><a class="header" href="#code-guide">Code guide</a></h1>
<p>Here we describe structures used for flat storage implementation.</p>
<h2 id="flatstorage"><a class="header" href="#flatstorage">FlatStorage</a></h2>
<p>This is the main structure which owns information about ValueRefs for all keys from some fixed
shard for some set of blocks. It is shared by multiple threads, so it is guarded by RwLock:</p>
<ul>
<li>Chain thread, because it sends queries like:
<ul>
<li>&quot;new block B was processed by chain&quot; - supported by add_block</li>
<li>&quot;flat storage head can be moved forward to block B&quot; - supported by update_flat_head</li>
</ul>
</li>
<li>Thread that applies a chunk, because it sends read queries &quot;what is the ValueRef for key for block B&quot;</li>
<li>View client (not fully decided)</li>
</ul>
<p>Requires ChainAccessForFlatStorage on creation because it needs to know the tree of blocks after
the flat storage head, to support getting queries correctly.</p>
<h2 id="flatstoragemanager"><a class="header" href="#flatstoragemanager">FlatStorageManager</a></h2>
<p>It holds all FlatStorages which NightshadeRuntime knows about and:</p>
<ul>
<li>provides views for flat storage for some fixed block - supported by new_flat_state_for_shard</li>
<li>sets initial flat storage state for genesis block - set_flat_storage_for_genesis</li>
<li>adds/removes/gets flat storage if we started/stopped tracking a shard or need to create a view - create_flat_storage_for_shard, etc.</li>
</ul>
<h2 id="flatstoragechunkview"><a class="header" href="#flatstoragechunkview">FlatStorageChunkView</a></h2>
<p>Interface for getting ValueRefs from flat storage for some shard for some fixed block, supported
by get_ref method.</p>
<h2 id="other-notes"><a class="header" href="#other-notes">Other notes</a></h2>
<h3 id="chain-dependency"><a class="header" href="#chain-dependency">Chain dependency</a></h3>
<p>If storage is fully empty, then we need to create flat storage from scratch. FlatStorage is stored
inside NightshadeRuntime, and it itself is stored inside Chain, so we need to create them in the same order
and dependency hierarchy should be the same. But at the same time, we parse genesis file only during Chain
creation. Thatâ€™s why FlatStorageManager has set_flat_storage_for_genesis method which is called
during Chain creation.</p>
<h3 id="regular-block-processing-vs-catchups"><a class="header" href="#regular-block-processing-vs-catchups">Regular block processing vs. catchups</a></h3>
<p>For these two use cases we have two different flows: first one is handled in Chain.postprocess_block,
the second one in Chain.block_catch_up_postprocess. Both, when results of applying chunk are ready,
should call Chain.process_apply_chunk_result â†’ RuntimeAdapter.get_flat_storage_for_shard â†’
FlatStorage.add_block, and when results of applying ALL processed/postprocessed chunks are ready,
should call RuntimeAdapter.get_flat_storage_for_shard â†’ FlatStorage.update_flat_head.</p>
<p>(because applying some chunk may result in error and we may need to exit there without updating flat head - ?)</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<p>This document describes how our network works. At this moment, it is known to be
somewhat outdated, as we are in the process of refactoring the network protocol
somewhat significantly.</p>
<h1 id="1-overview"><a class="header" href="#1-overview">1. Overview</a></h1>
<p>Near Protocol uses its own implementation of a custom peer-to-peer network. Peers
who join the network are represented by nodes and connections between them by edges.</p>
<p>The purpose of this document is to describe the inner workings of the <code>near-network</code>
package; and to be used as reference by future engineers to understand the network
code without any prior knowledge.</p>
<h1 id="2-code-structure"><a class="header" href="#2-code-structure">2. Code structure</a></h1>
<p><code>near-network</code> runs on top of an <code>actor</code> framework provided by near-async.
Code structure is split between 4 actors
<code>PeerManagerActor</code>, <code>PeerActor</code>, <code>RoutingTableActor</code>, <code>EdgeValidatorActor</code></p>
<h3 id="21-edgevalidatoractor-currently-called-edgeverifieractor-in-the-code"><a class="header" href="#21-edgevalidatoractor-currently-called-edgeverifieractor-in-the-code">2.1 <code>EdgeValidatorActor</code> (currently called <code>EdgeVerifierActor</code> in the code<!-- TODO: rename -->)</a></h3>
<p><code>EdgeValidatorActor</code> runs on separate thread. The purpose of this <code>actor</code> is to
validate <code>edges</code>, where each <code>edge</code> represents a connection between two peers,
and it's signed with a cryptographic signature of both parties. The process of
edge validation involves verifying cryptographic signatures, which can be quite
expensive, and therefore was moved to another thread.</p>
<p>Responsibilities:</p>
<ul>
<li>Validating edges by checking whenever cryptographic signatures match.</li>
</ul>
<h3 id="22-routingtableactor"><a class="header" href="#22-routingtableactor">2.2 <code>RoutingTableActor</code></a></h3>
<p><code>RoutingTableActor</code> maintains a view of the <code>P2P network</code> represented by a set of
nodes and edges.</p>
<p>In case a message needs to be sent between two nodes, that can be done directly
through a <code>TCP connection</code>. Otherwise, <code>RoutingTableActor</code> is responsible for pinging
the best path between them.</p>
<p>Responsibilities:</p>
<ul>
<li>Keep set of all edges of <code>P2P network</code> called routing table.</li>
<li>Connects to <code>EdgeValidatorActor</code>, and asks for edges to be validated, when
needed.</li>
<li>Has logic related to exchanging edges between peers.</li>
</ul>
<h3 id="23-peeractor"><a class="header" href="#23-peeractor">2.3 <code>PeerActor</code></a></h3>
<p>Whenever a new connection gets accepted, an instance of <code>PeerActor</code> gets
created. Each <code>PeerActor</code> keeps a physical <code>TCP connection</code> to exactly one
peer.</p>
<p>Responsibilities:</p>
<ul>
<li>Maintaining physical connection.</li>
<li>Reading messages from peers, decoding them, and then forwarding them to the
right place.</li>
<li>Encoding messages, sending them to peers on physical layer.</li>
<li>Routing messages between <code>PeerManagerActor</code> and other peers.</li>
</ul>
<h3 id="24-peermanageractor"><a class="header" href="#24-peermanageractor">2.4 <code>PeerManagerActor</code></a></h3>
<p><code>PeerManagerActor</code> is the main actor of <code>near-network</code> crate. It acts as a
bridge connecting to the world outside, the other peers, and <code>ClientActor</code> and
<code>ClientViewActor</code>, which handle processing any operations on the chain.
<code>PeerManagerActor</code> maintains information about p2p network via <code>RoutingTableActor</code>,
and indirectly, through <code>PeerActor</code>, connections to all nodes on the network.
All messages going to other nodes, or coming from other nodes will be routed
through this <code>Actor</code>. <code>PeerManagerActor</code> is responsible for accepting incoming
connections from the outside world and creating <code>PeerActors</code> to manage them.</p>
<p>Responsibilities:</p>
<ul>
<li>Accepting new connections.</li>
<li>Maintaining the list of <code>PeerActors</code>, creating, deleting them.</li>
<li>Routing information about new edges between <code>PeerActors</code> and
<code>RoutingTableManager</code>.</li>
<li>Routing messages between <code>ViewClient</code>, <code>ViewClientActor</code> and <code>PeerActors</code>, and
consequently other peers.</li>
<li>Maintains <code>RouteBack</code> structure, which has information on how to send replies to messages.</li>
</ul>
<h1 id="3-code-flow---initialization"><a class="header" href="#3-code-flow---initialization">3. Code flow - initialization</a></h1>
<p>First, the <code>PeerManagerActor</code> actor gets started. <code>PeerManagerActor</code> opens the
TCP server, which listens to incoming connections. It starts the
<code>RoutingTableActor</code>, which then starts the <code>EdgeValidatorActor</code>. When
an incoming connection gets accepted, it starts a new <code>PeerActor</code>
on its own thread.</p>
<h1 id="4-networkconfig"><a class="header" href="#4-networkconfig">4. NetworkConfig</a></h1>
<p><code>near-network</code> reads configuration from <code>NetworkConfig</code>, which is a part of <code>client config</code>.</p>
<p>Here is a list of features read from config:</p>
<ul>
<li><code>boot_nodes</code> - list of nodes to connect to on start.</li>
<li><code>addr</code> - listening address.</li>
<li><code>max_num_peers</code> - by default we connect up to 40 peers, current implementation
supports up to 128.</li>
</ul>
<h1 id="5-connecting-to-other-peers"><a class="header" href="#5-connecting-to-other-peers">5. Connecting to other peers</a></h1>
<p>Each peer maintains a list of known peers. They are stored in the database. If
the database is empty, the list of peers, called boot nodes, will be read from
the <code>boot_nodes</code> option in the config. The peer to connect to is chosen at
random from a list of known nodes by the <code>PeerManagerActor::sample_random_peer</code>
method.</p>
<h1 id="6-edges--network---in-code-representation"><a class="header" href="#6-edges--network---in-code-representation">6. Edges &amp; network - in code representation</a></h1>
<p><code>P2P network</code> is represented by a list of <code>peers</code>, where each <code>peer</code> is
represented by a structure <code>PeerId</code>, which is defined by the <code>peer</code>'s public key
<code>PublicKey</code>, and a list of edges, where each edge is represented by the
structure <code>Edge</code>.</p>
<p>Both are defined below.</p>
<h1 id="61-publickey"><a class="header" href="#61-publickey">6.1 PublicKey</a></h1>
<p>We use two types of public keys:</p>
<ul>
<li>a 256 bit <code>ED25519</code> public key.</li>
<li>a 512 bit <code>Secp256K1</code> public key.</li>
</ul>
<p>Public keys are defined in the <code>PublicKey</code> enum, which consists of those two
variants.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct ED25519PublicKey(pub [u8; 32]);
pub struct Secp256K1PublicKey([u8; 64]);
pub enum PublicKey {
    ED25519(ED25519PublicKey),
    SECP256K1(Secp256K1PublicKey),
}
<span class="boring">}
</span></code></pre></pre>
<h1 id="62-peerid"><a class="header" href="#62-peerid">6.2 PeerId</a></h1>
<p>Each <code>peer</code> is uniquely defined by its <code>PublicKey</code>, and represented by <code>PeerId</code>
struct.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct PeerId(PublicKey);
<span class="boring">}
</span></code></pre></pre>
<h1 id="63-edge"><a class="header" href="#63-edge">6.3 Edge</a></h1>
<p>Each <code>edge</code> is represented by the <code>Edge</code> structure. It contains the following:</p>
<ul>
<li>pair of nodes represented by their public keys.</li>
<li><code>nonce</code> - a unique number representing the state of an edge. Starting with <code>1</code>.
Odd numbers represent an active edge. Even numbers represent an edge in which
one of the nodes, confirmed that the edge is removed.</li>
<li>Signatures from both peers for active edges.</li>
<li>Signature from one peer in case an edge got removed.</li>
</ul>
<h1 id="64-graph-representation"><a class="header" href="#64-graph-representation">6.4 Graph representation</a></h1>
<p><code>RoutingTableActor</code> is responsible for storing and maintaining the set of all edges.
They are kept in the <code>edge_info</code> data structure of the type <code>HashSet&lt;Edge&gt;</code>.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct RoutingTableActor {
    /// Collection of edges representing P2P network.
    /// It's indexed by `Edge::key()` key and can be search through by calling `get()` function
    /// with `(PeerId, PeerId)` as argument.
    pub edges_info: HashSet&lt;Edge&gt;,
    /// ...
}
<span class="boring">}
</span></code></pre></pre>
<h1 id="7-code-flow---connecting-to-a-peer---handshake"><a class="header" href="#7-code-flow---connecting-to-a-peer---handshake">7. Code flow - connecting to a peer - handshake</a></h1>
<p>When <code>PeerManagerActor</code> starts, it starts to listen to a specific port.</p>
<h2 id="71---step-1---monitor_peers_trigger-runs"><a class="header" href="#71---step-1---monitor_peers_trigger-runs">7.1 - Step 1 - <code>monitor_peers_trigger</code> runs</a></h2>
<p><code>PeerManager</code> checks if we need to connect to another peer by running the
<code>PeerManager::is_outbound_bootstrap_needed</code> method. If <code>true</code> we will try to
connect to a new node. Let's call the current node, node <code>A</code>.</p>
<h2 id="72---step-2---choosing-the-node-to-connect-to"><a class="header" href="#72---step-2---choosing-the-node-to-connect-to">7.2 - Step 2 - choosing the node to connect to</a></h2>
<p>Method <code>PeerManager::sample_random_peer</code> will be called, and it returns node <code>B</code>
that we will try to connect to.</p>
<h2 id="73---step-3---outboundtcpconnect-message"><a class="header" href="#73---step-3---outboundtcpconnect-message">7.3 - Step 3 - <code>OutboundTcpConnect</code> message</a></h2>
<p><code>PeerManagerActor</code> will send itself a message <code>OutboundTcpConnect</code> in order
to connect to node <code>B</code>.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct OutboundTcpConnect {
    /// Peer information of the outbound connection
    pub target_peer_info: PeerInfo,
}
<span class="boring">}
</span></code></pre></pre>
<h2 id="74---step-4---outboundtcpconnect-message"><a class="header" href="#74---step-4---outboundtcpconnect-message">7.4 - Step 4 - <code>OutboundTcpConnect</code> message</a></h2>
<p>On receiving the message the <code>handle_msg_outbound_tcp_connect</code> method will be
called, which calls <code>TcpStream::connect</code> to create a new connection.</p>
<h2 id="75---step-5---connection-gets-established"><a class="header" href="#75---step-5---connection-gets-established">7.5 - Step 5 - Connection gets established</a></h2>
<p>Once connection with the outgoing peer gets established. The <code>try_connect_peer</code>
method will be called. And then a new <code>PeerActor</code> will be created and started. Once
the <code>PeerActor</code> starts it will send a <code>Handshake</code> message to the outgoing node <code>B</code>
over a tcp connection.</p>
<p>This message contains <code>protocol_version</code>, node <code>A</code>'s metadata, as well as all
information necessary to create an <code>Edge</code>.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct Handshake {
    /// Current protocol version.
    pub(crate) protocol_version: u32,
    /// Oldest supported protocol version.
    pub(crate) oldest_supported_version: u32,
    /// Sender's peer id.
    pub(crate) sender_peer_id: PeerId,
    /// Receiver's peer id.
    pub(crate) target_peer_id: PeerId,
    /// Sender's listening addr.
    pub(crate) sender_listen_port: Option&lt;u16&gt;,
    /// Peer's chain information.
    pub(crate) sender_chain_info: PeerChainInfoV2,
    /// Represents new `edge`. Contains only `none` and `Signature` from the sender.
    pub(crate) partial_edge_info: PartialEdgeInfo,
}
<span class="boring">}
</span></code></pre></pre>
<h2 id="76---step-6---handshake-arrives-at-node-b"><a class="header" href="#76---step-6---handshake-arrives-at-node-b">7.6 - Step 6 - <code>Handshake</code> arrives at node <code>B</code></a></h2>
<p>Node <code>B</code> receives a <code>Handshake</code> message. Then it performs various validation
checks. That includes:</p>
<ul>
<li>Check signature of edge from the other peer.</li>
<li>Whenever <code>nonce</code> is the edge, send matches.</li>
<li>Check whether the protocol is above the minimum
<code>OLDEST_BACKWARD_COMPATIBLE_PROTOCOL_VERSION</code>.</li>
<li>Other node <code>view of chain</code> state.</li>
</ul>
<p>If everything is successful, <code>PeerActor</code> will send a <code>RegisterPeer</code> message to
<code>PeerManagerActor</code>. This message contains everything needed to add <code>PeerActor</code>
to the list of active connections in <code>PeerManagerActor</code>.</p>
<p>Otherwise, <code>PeerActor</code> will be stopped immediately or after some timeout.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct RegisterPeer {
    pub(crate) actor: Addr&lt;PeerActor&gt;,
    pub(crate) peer_info: PeerInfo,
    pub(crate) peer_type: PeerType,
    pub(crate) chain_info: PeerChainInfoV2,
    // Edge information from this node.
    // If this is None it implies we are outbound connection, so we need to create our
    // EdgeInfo part and send it to the other peer.
    pub(crate) this_edge_info: Option&lt;EdgeInfo&gt;,
    // Edge information from other node.
    pub(crate) other_edge_info: EdgeInfo,
    // Protocol version of new peer. May be higher than ours.
    pub(crate) peer_protocol_version: ProtocolVersion,
}
<span class="boring">}
</span></code></pre></pre>
<h2 id="77---step-7---peermanageractor-receives-registerpeer-message---node-b"><a class="header" href="#77---step-7---peermanageractor-receives-registerpeer-message---node-b">7.7 - Step 7 - <code>PeerManagerActor</code> receives <code>RegisterPeer</code> message - node <code>B</code></a></h2>
<p>In the <code>handle_msg_consolidate</code> method, the <code>RegisterPeer</code> message will be validated.
If successful, the <code>register_peer</code> method will be called, which adds the <code>PeerActor</code>
to the list of connected peers.</p>
<p>Each connected peer is represented in <code>PeerActorManager</code> in <code>ActivePeer</code> the data
structure.</p>
<!-- TODO: Rename `ActivePeer` to `RegisterPeer` -->
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Contains information relevant to an active peer.
struct ActivePeer { // will be renamed to `ConnectedPeer` see #5428
    addr: Addr&lt;PeerActor&gt;,
    full_peer_info: FullPeerInfo,
    /// Number of bytes we've received from the peer.
    received_bytes_per_sec: u64,
    /// Number of bytes we've sent to the peer.
    sent_bytes_per_sec: u64,
    /// Last time requested peers.
    last_time_peer_requested: Instant,
    /// Last time we received a message from this peer.
    last_time_received_message: Instant,
    /// Time where the connection was established.
    connection_established_time: Instant,
    /// Who started connection. Inbound (other) or Outbound (us).
    peer_type: PeerType,
}
<span class="boring">}
</span></code></pre></pre>
<h2 id="78---step-8---exchange-routing-table-part-1---node-b"><a class="header" href="#78---step-8---exchange-routing-table-part-1---node-b">7.8 - Step 8 - Exchange routing table part 1 - node <code>B</code></a></h2>
<p>At the end of the <code>register_peer</code> method node <code>B</code> will perform a
<code>RoutingTableSync</code> sync. Sending the list of known <code>edges</code> representing a
full graph, and a list of known <code>AnnounceAccount</code>. Those will be
covered later, in their dedicated sections see sections (to be added). <!-- TODO: TODO1, TODO2 --></p>
<pre><code class="language-rust  ignore">message: PeerMessage::RoutingTableSync(SyncData::edge(new_edge)),
</code></pre>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Contains metadata used for routing messages to particular `PeerId` or `AccountId`.
pub struct RoutingTableSync { // also known as `SyncData` (#5489)
    /// List of known edges from `RoutingTableActor::edges_info`.
    pub(crate) edges: Vec&lt;Edge&gt;,
    /// List of known `account_id` to `PeerId` mappings.
    /// Useful for `send_message_to_account` method, to route message to particular account.
    pub(crate) accounts: Vec&lt;AnnounceAccount&gt;,
}
<span class="boring">}
</span></code></pre></pre>
<h2 id="79---step-9----exchange-routing-table-part-2---node-a"><a class="header" href="#79---step-9----exchange-routing-table-part-2---node-a">7.9 - Step 9 -  Exchange routing table part 2 - node <code>A</code></a></h2>
<p>Upon receiving a <code>RoutingTableSync</code> message. Node <code>A</code> will reply with its own
<code>RoutingTableSync</code> message.</p>
<h2 id="710---step-10----exchange-routing-table-part-2---node-b"><a class="header" href="#710---step-10----exchange-routing-table-part-2---node-b">7.10 - Step 10 -  Exchange routing table part 2 - node <code>B</code></a></h2>
<p>Node <code>B</code> will get the message from <code>A</code> and update its routing table.</p>
<h1 id="8-adding-new-edges-to-routing-tables"><a class="header" href="#8-adding-new-edges-to-routing-tables">8. Adding new edges to routing tables</a></h1>
<p>This section covers the process of adding new edges, received from another
node, to the routing table. It consists of several steps covered below.</p>
<h2 id="81-step-1"><a class="header" href="#81-step-1">8.1 Step 1</a></h2>
<p><code>PeerManagerActor</code> receives <code>RoutingTableSync</code> message containing list of new
<code>edges</code> to add. <code>RoutingTableSync</code> contains list of edges of the P2P network.
This message is then forwarded to <code>RoutingTableActor</code>.</p>
<h2 id="82-step-2"><a class="header" href="#82-step-2">8.2 Step 2</a></h2>
<p><code>PeerManagerActor</code> forwards those edges to <code>RoutingTableActor</code> inside of
the <code>ValidateEdgeList</code> struct.</p>
<p><code>ValidateEdgeList</code> contains:</p>
<ul>
<li>list of edges to verify.</li>
<li>peer who sent us the edges.</li>
</ul>
<h2 id="83-step-3"><a class="header" href="#83-step-3">8.3 Step 3</a></h2>
<p><code>RoutingTableActor</code> gets the <code>ValidateEdgeList</code> message. Filters out <code>edges</code>
that have already been verified, those that are already in
<code>RoutingTableActor::edges_info</code>.</p>
<p>Then, it updates <code>edge_verifier_requests_in_progress</code> to mark that edge
verifications are in progress, and edges shouldn't be pruned from Routing Table
(see section (to be added)<!-- TODO: add section link -->).</p>
<p>Then, after removing already validated edges, the modified message is forwarded
to <code>EdgeValidatorActor</code>.</p>
<h2 id="84-step-4"><a class="header" href="#84-step-4">8.4 Step 4</a></h2>
<p><code>EdgeValidatorActor</code> goes through the list of all edges. It checks whether all edges
are valid (their cryptographic signatures match, etc.).</p>
<p>If any edge is not valid, the peer will be banned.</p>
<p>Edges that are validated are written to a concurrent queue
<code>ValidateEdgeList::sender</code>. This queue is used to transfer edges from
<code>EdgeValidatorActor</code> back to <code>PeerManagerActor</code>.</p>
<h2 id="85-step-5"><a class="header" href="#85-step-5">8.5 Step 5</a></h2>
<p><code>broadcast_validated_edges_trigger</code> runs, and gets validated edges from
<code>EdgeVerifierActor</code>.</p>
<p>Every new edge will be broadcast to all connected peers.</p>
<p>And then, all validated edges received from <code>EdgeVerifierActor</code> will be sent
again to <code>RoutingTableActor</code> inside <code>AddVerifiedEdges</code>.</p>
<h2 id="85-step-6"><a class="header" href="#85-step-6">8.5 Step 6</a></h2>
<p>When <code>RoutingTableActor</code> receives <code>RoutingTableMessages::AddVerifiedEdges</code>, the
method <code>add_verified_edges_to_routing_table</code> will be called. It will add edges to
<code>RoutingTableActor::edges_info</code> struct, and mark routing table, that it needs
a recalculation (see <code>RoutingTableActor::needs_routing_table_recalculation</code>).</p>
<h1 id="9-routing-table-computation"><a class="header" href="#9-routing-table-computation">9 Routing table computation</a></h1>
<p>Routing table computation does a few things:</p>
<ul>
<li>For each peer <code>B</code>, calculates set of peers <code>|C_b|</code>, such that each peer is on
the shortest path to <code>B</code>.</li>
<li>Removes unreachable edges from memory and stores them to disk.</li>
<li>The distance is calculated as the minimum number of nodes on the path from
given node <code>A</code>, to each other node on the network. That is, <code>A</code> has a distance
of <code>0</code> to itself. Its neighbors will have a distance of <code>1</code>. The neighbors of
their neighbors will have a distance of <code>2</code>, etc.</li>
</ul>
<h2 id="91-step-1"><a class="header" href="#91-step-1">9.1 Step 1</a></h2>
<p><code>PeerManagerActor</code> runs a <code>update_routing_table_trigger</code> every
<code>UPDATE_ROUTING_TABLE_INTERVAL</code> seconds.</p>
<p><code>RoutingTableMessages::RoutingTableUpdate</code> message is sent to
<code>RoutingTableActor</code> to request routing table re-computation.</p>
<h2 id="92-step-2"><a class="header" href="#92-step-2">9.2 Step 2</a></h2>
<p><code>RoutingTableActor</code> receives the message, and then:</p>
<ul>
<li>calls <code>recalculate_routing_table</code> method, which computes
<code>RoutingTableActor::peer_forwarding: HashMap&lt;PeerId, Vec&lt;PeerId&gt;&gt;</code>. For each
<code>PeerId</code> on the network, gives a list of connected peers, which are on the
shortest path to the destination. It marks reachable peers in the
<code>peer_last_time_reachable</code> struct.</li>
<li>calls <code>prune_edges</code> which removes from memory all the edges that were not
reachable for at least 1 hour, based on the <code>peer_last_time_reachable</code> data
structure. Those edges are then stored to disk.</li>
</ul>
<h2 id="93-step-3"><a class="header" href="#93-step-3">9.3 Step 3</a></h2>
<p><code>RoutingTableActor</code> sends a <code>RoutingTableUpdateResponse</code> message back to
<code>PeerManagerActor</code>.</p>
<p><code>PeerManagerActor</code> keeps a local copy of <code>edges_info</code>, called <code>local_edges_info</code>
containing only edges adjacent to current node.</p>
<ul>
<li><code>RoutingTableUpdateResponse</code> contains a list of local edges, which
<code>PeerManagerActor</code> should remove.</li>
<li><code>peer_forwarding</code> which represents how to route messages in the P2P network</li>
<li><code>peers_to_ban</code> represents a list of peers to ban for sending us edges, which failed
validation in <code>EdgeVerifierActor</code>.</li>
</ul>
<h2 id="94-step-4"><a class="header" href="#94-step-4">9.4 Step 4</a></h2>
<p><code>PeerManagerActor</code> receives <code>RoutingTableUpdateResponse</code> and then:</p>
<ul>
<li>updates local copy of <code>peer_forwarding</code>, used for routing messages.</li>
<li>removes <code>local_edges_to_remove</code> from <code>local_edges_info</code>.</li>
<li>bans peers, who sent us invalid edges.</li>
</ul>
<h1 id="10-message-transportation-layers"><a class="header" href="#10-message-transportation-layers">10. Message transportation layers</a></h1>
<p>This section describes different protocols of sending messages currently used in
<code>Near</code>.</p>
<h2 id="101-messages-between-actors"><a class="header" href="#101-messages-between-actors">10.1 Messages between Actors</a></h2>
<p><code>Near</code> is built on an <code>actor</code>framework provided by near-async. Usually each actor
runs on its own dedicated thread. Some, like <code>PeerActor</code> have one thread per
each instance. Only messages implementing <code>Message</code>, can be sent
using between threads. Each actor has its own queue; Processing of messages
happens asynchronously.</p>
<p>We should not leak implementation details into the spec.</p>
<p>Actor messages can be found by looking for structs used with the async messaging helpers (for
example types that appear in <code>Handler&lt;...&gt;</code> implementations or multi-sender definitions).</p>
<h2 id="102-messages-sent-through-tcp"><a class="header" href="#102-messages-sent-through-tcp">10.2 Messages sent through TCP</a></h2>
<p>Near is using <code>borsh</code> serialization to exchange messages between nodes (See
<a href="https://borsh.io/">borsh.io</a>). We should be careful when making changes to
them. We have to maintain backward compatibility. Only messages implementing
<code>BorshSerialize</code>, <code>BorshDeserialize</code> can be sent. We also use <code>borsh</code> for
database storage.</p>
<h2 id="103-messages-sentreceived-through-chainjsonrpc"><a class="header" href="#103-messages-sentreceived-through-chainjsonrpc">10.3 Messages sent/received through <code>chain/jsonrpc</code></a></h2>
<p>Near runs a <code>json REST server</code> using the axum framework. All messages sent
and received must implement <code>serde::Serialize</code> and <code>serde::Deserialize</code>.</p>
<h1 id="11-code-flow---routing-a-message"><a class="header" href="#11-code-flow---routing-a-message">11. Code flow - routing a message</a></h1>
<p>This is the example of the message that is being sent between nodes
<a href="https://github.com/near/nearcore/blob/fa8749dc60fe0de8e94c3046571731c622326e9f/chain/network-primitives/src/types.rs#L362"><code>RawRoutedMessage</code></a>.</p>
<p>Each of these methods have a <code>target</code> - that is either the <code>account_id</code> or <code>peer_id</code>
or hash (which seems to be used only for route back...). If target is the
account - it will be converted using <code>routing_table.account_owner</code> to the peer.</p>
<p>Upon receiving the message, the <code>PeerManagerActor</code>
<a href="https://github.com/near/nearcore/blob/cadf11d5851be7611011b4e89542e11f41f3d827/chain/network/src/peer_manager/peer_manager_actor.rs">will sign it</a>
and convert into RoutedMessage (which also have things like TTL etc.).</p>
<p>Then it will use the <code>routing_table</code>, to find the route to the target peer (add
<code>route_back</code> if needed) and then send the message over the network as
<code>PeerMessage::Routed</code>. Details about routing table computations are covered in
<a href="architecture/network.html#8-adding-new-edges-to-routing-tables">section 8</a>.</p>
<p>When Peer receives this message (as <code>PeerMessage::Routed</code>), it will pass it to
PeerManager (as <code>RoutedMessageFrom</code>), which would then check if the message is
for the current <code>PeerActor</code>. (if yes, it would pass it to the client) and if
not - it would pass it along the network.</p>
<p>All these messages are handled by <code>receive_client_message</code> in Peer.
(<code>NetworkClientMessages</code>) - and transferred to <code>ClientActor</code> in
(<code>chain/client/src/client_actor.rs</code>)</p>
<p><code>NetworkRequests</code> to <code>PeerManager</code> actor trigger the <code>RawRoutedMessage</code> for
messages that are meant to be sent to another <code>peer</code>.</p>
<p><code>lib.rs</code> (<code>ShardsManager</code>) has a <code>network_adapter</code> - coming from the clientâ€™s
<code>network_adapter</code> that comes from <code>ClientActor</code> that comes from the <code>start_client</code> call
that comes from <code>start_with_config</code> (that creates <code>PeerManagerActor</code> - that is
passed as target to <code>network_recipient</code>).</p>
<h1 id="12-database"><a class="header" href="#12-database">12. Database</a></h1>
<h3 id="121-storage-of-deleted-edges"><a class="header" href="#121-storage-of-deleted-edges">12.1 Storage of deleted edges</a></h3>
<p>Every time a group of peers becomes unreachable at the same time; We store edges
belonging to them in components. We remove all of those edges from memory, and
save them to the database. If any of them were to be reachable again, we would
re-add them. This is useful in case there is a network split, to recover edges
if needed.</p>
<p>Each component is assigned a unique <code>nonce</code>, where first one is assigned nonce
0. Each new component gets assigned a consecutive integer.</p>
<p>To store components, we have the following columns in the DB.</p>
<ul>
<li><code>DBCol::LastComponentNonce</code> Stores <code>component_nonce: u64</code>, which is the last
used nonce.</li>
<li><code>DBCol::ComponentEdges</code> Mapping from <code>component_nonce</code> to a list of edges.</li>
<li><code>DBCol::PeerComponent</code> Mapping from <code>peer_id</code> to the last component <code>nonce</code> it belongs to.</li>
</ul>
<h3 id="122-storage-of-account_id-to-peer_id-mapping"><a class="header" href="#122-storage-of-account_id-to-peer_id-mapping">12.2 Storage of <code>account_id</code> to <code>peer_id</code> mapping</a></h3>
<p><code>ColAccountAnnouncements</code> -&gt; Stores a mapping from <code>account_id</code> to a tuple
(<code>account_id</code>, <code>peer_id</code>, <code>epoch_id</code>, <code>signature</code>).</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="gas-cost-parameters"><a class="header" href="#gas-cost-parameters">Gas Cost Parameters</a></h1>
<p>Gas in NEAR Protocol solves two problems.</p>
<ol>
<li>To avoid spam, validator nodes only perform work if a user's tokens are
burned. Tokens are automatically converted to gas using the current gas
price.</li>
<li>To synchronize shards, they must all produce chunks following a strict
schedule of 1 second execution time. Gas is used to measure how heavy the
workload of a transaction is, so that the number of transactions that fit in
a block can be deterministically computed by all nodes.</li>
</ol>
<p>In other words, each transaction costs a fixed amount of gas. This gas cost
determines how much a user has to pay and how much time nearcore has to execute
the transaction.</p>
<p>What happens if nearcore executes a transaction too slowly? Chunk production for
the shard gets delayed, which delays block production for the entire blockchain,
increasing latency and reducing throughput for everybody. If the chunk is really
late, the block producer will decide to not include the chunk at all and inserts
an empty chunk. The chunk may be included in the next block.</p>
<p>By now, you probably wonder how we can know the time it takes to execute a
transaction, given that validators use hardware of their choice. Getting these
timings right is indeed a difficult problem. Or flipping the problem, assuming
the timings are already known, then we must implement nearcore such that it
guarantees to operate within the given time constraints. How we tackle this is
the topic of this chapter.</p>
<p>If you want to learn more about Gas from a user perspective, 
<a href="https://docs.near.org/concepts/basics/transactions/gas">Gas basic concepts</a>,
<a href="https://docs.near.org/concepts/basics/transactions/gas-advanced">Gas advanced concepts</a>,
and <a href="https://nomicon.io/RuntimeSpec/Fees/">the runtime fee specification</a> are
good places to dig deeper.</p>
<h2 id="hardware-and-timing-assumptions"><a class="header" href="#hardware-and-timing-assumptions">Hardware and Timing Assumptions</a></h2>
<p>For timing to make sense at all, we must first define hardware constraints. The
official hardware requirements for a validator are published on
<a href="https://near-nodes.io/validator/hardware-validator">near-nodes.io/validator/hardware-validator</a>. They
may change over time but the main principle is that a moderately configured,
cloud-hosted virtual machine suffices.</p>
<p>For our gas computation, we assume the minimum required hardware. Then we define
10<sup>15</sup> gas to be executed in at most 1s. We commonly use 1 Tgas (=
10<sup>12</sup> gas) in conversation, which corresponds to 1ms execution time.</p>
<p>Obviously, this definition means that a validator running more powerful hardware
will execute the transactions faster. That is perfectly okay, as far as the
protocol is concerned we just need to make sure the chunk is available in time.
If it is ready in even less time, no problem.</p>
<p>Less obviously, this means that even a minimally configured validator is often
idle. Why is that? Well, the hardware must be prepared to execute chunks that
are always full. But that is rarely the case, as the gas price increases
exponentially when chunks are full, which would cause traffic to go back
eventually.</p>
<p>Furthermore, the hardware has to be ready for transactions of all types,
including transactions chosen by a malicious actor selecting only the most
complex transactions. Those transactions can also be unbalanced in what
bottlenecks they hit. For example, a chunk can be filled with transactions that
fully utilize the CPU's floating point units. Or they could be using all the
available disk IO bandwidth.</p>
<p>Because the minimum required hardware needs to meet the timing requirements for
any of those scenarios, the typical, more balanced case is usually computed
faster than the gas rule states.</p>
<h2 id="transaction-gas-cost-model"><a class="header" href="#transaction-gas-cost-model">Transaction Gas Cost Model</a></h2>
<p>A transaction is essentially just a list of actions to be executed on the same
account. For example it could be <code>CreateAccount</code> combined with
<code>FunctionCall(&quot;hello_world&quot;)</code>.</p>
<p>The <a href="https://nomicon.io/RuntimeSpec/Actions">reference for available actions</a>
shows the conclusive list of possible actions. The protocol defines fixed fees
for each of them. More details on <a href="architecture/gas/index.html#action-costs">actions fees</a> follow below.</p>
<p>Fixed fees are an important design decision. It means that a given action will
always cost the exact same amount of gas, no matter on what hardware it
executes. But the content of the action can impact the cost, for example a
<code>DeployContract</code> action's cost scales with the size of the contract code.</p>
<p>So, to be more precise, the protocol defines fixed gas cost <em>parameters</em> for
each action, together with a formula to compute the gas cost for the action. All
actions today either use a single fixed gas cost or they use a base cost and a
linear scaling parameter. With one important exception, <code>FunctionCall</code>, which
shall be discussed <a href="architecture/gas/index.html#fn-call-costs">further below</a>.</p>
<p>There is an entire section on <a href="architecture/gas/./parameter_definition.html">Parameter Definitions</a>
that explains how to find the source of truth for parameter values in the
nearcore repository, how they can be referenced in code, and what steps are
necessary to add a new parameter.</p>
<p>Let us dwell a bit more on the linear scaling factors. The fact that contract
deployment cost, which includes code compilation, scales linearly limits the
compiler to use only algorithms of linear complexity. Either that, or the
parameters must be set to match the 1ms = 1Tgas rule at the largest possible
contract size. Today, we limit ourselves to linear-time algorithms in the
compiler.</p>
<p>Likewise, an action that has no scaling parameters must only use constant time
to execute. Taking the <code>CreateAccount</code> action as an example, with a cost of 0.1
Tgas, it has to execute within 0.1ms. Technically, the execution time depends
ever so slightly on the account name length. But there is a fairly low upper
limit on that length and it makes sense to absorb all the cost in the constant
base cost.</p>
<p>This concept of picking parameters according to algorithmic complexity is key.
If you understand this, you know how to think about gas as a nearcore developer.
This should be enough background to understand what the estimator does.</p>
<p>The <a href="architecture/gas/./estimator.html">runtime parameter estimator</a> is a separate binary within
the nearcore repository. It contains benchmarking-like code used to validate
existing parameter values against the 1ms = 1 Tgas rule. When implementing new
features, code should be added there to estimate the safe values of the new
parameters. This section is for you if you are adding new features such as a new
pre-compiled method or other host functions.</p>
<p>Next up are more details on the specific costs that occur when executing NEAR
transactions, which help to understand existing parameters and how they are
organized.</p>
<h2 id="action-costs"><a class="header" href="#action-costs">Action Costs</a></h2>
<p>Actions are executed in two steps. First, an action is verified and inserted to
an action receipt, which is sent to the receiver of the action. The <code>send</code> fee
is paid for this. It is charged either in <code>fn process_transaction(..)</code> if the
action is part of a fresh transaction, or inside
<a href="https://github.com/near/nearcore/blob/14b8ae2c7465444c9b672a23b044c00be98f6e34/runtime/near-vm-logic/src/logic.rs">logic.rs</a>
through <code>fn pay_action_base(..)</code> if the action is generated by a function call.
The send fee is meant to cover the cost to validate an action and transmit it
over the network.</p>
<p>The second step is action execution. It is charged in <code>fn apply_action(..)</code>.
The execution cost has to cover everything required to apply the action to the
blockchain's state.</p>
<p>These two steps are done on the same shard for local receipts. Local receipts
are defined as those where the sender account is also the receiver, abbreviated
as <code>sir</code> which stands for &quot;sender is receiver&quot;.</p>
<p>For remote receipts, which is any receipt where the sender and receiver accounts
are different, we charge a different fee since sending between shards is extra
work. Notably, we charge that extra work even if the accounts are on the same
shard. In terms of gas costs, each account is conceptually its own shard. This
makes dynamic resharding possible without user-observable impact.</p>
<p>When the send step is performed, the minimum required gas to start execution of
that action is known. Thus, if the receipt does not have enough gas, it can be aborted
instead of forwarding it. Here we have to introduce the concept of used gas.</p>
<p><code>gas_used</code> is different from <code>gas_burnt</code>. The former includes the gas that needs
to be reserved for the execution step whereas the latter only includes the gas
that has been burnt in the current chunk. The difference between the two is
sometimes also called prepaid gas, as this amount of gas is paid for during the
send step and it is available in the execution step for free.</p>
<p>If execution fails, the prepaid cost that has not been burned will be refunded.
But this is not the reason why it must burn on the receiver shard instead of the
sender shard. The reason is that we want to properly compute the gas limits on
the chunk that does the execution work.</p>
<p>In conclusion, each action parameter is split into three costs, <code>send_sir</code>,
<code>send_not_sir</code>, and <code>execution</code>. Local receipts charge the first and last
parameters, remote receipts charge the second and third. They should be
estimated, defined, and charged separately. But the reality is that today almost
all actions are estimated as a whole and the parameters are split 50/50 between
send and execution cost, without discrimination on local vs remote receipts
i.e. <code>send_sir</code> cost is the same as <code>send_not_sir</code>.</p>
<p>The <a href="architecture/gas/./gas_profile.html">Gas Profile</a> section goes into more details on how gas
costs of a transaction are tracked in nearcore.</p>
<h2 id="dynamic-function-call-costs"><a class="header" href="#dynamic-function-call-costs">Dynamic Function Call Costs</a></h2>
<p><a name="fn-call-costs"></a></p>
<p>Costs that occur while executing a function call on a deployed WASM app (a.k.a.
smart contract) are charged only at the receiver. Thus, they have only one value
to define them, in contrast to action costs.</p>
<p>The most fundamental dynamic gas cost is <code>wasm_regular_op_cost</code>. It is
multiplied by the exact number of WASM operations executed. You can read about
<a href="https://nomicon.io/RuntimeSpec/Preparation#gas-instrumentation">Gas Instrumentation</a>
if you are curious how we count WASM ops.</p>
<p>Currently, all operations are charged the same, although it could be more
efficient to charge less for opcodes like <code>i32.add</code> compared to <code>f64.sqrt</code>.</p>
<p>The remaining dynamic costs are for work done during host function calls. Each
host function charges a base cost. Either the general <code>wasm_base</code> cost, or a
specific cost such as <code>wasm_utf8_decoding_base</code>, or sometimes both. New host
function calls should define a separate base cost and not charge <code>wasm_base</code>.</p>
<p>Additional host-side costs can be scaled per input byte, such as
<code>wasm_sha256_byte</code>, or costs related to moving data between host and guest, or
any other cost that is specific to the host function. Each host function must
clearly define what its costs are and how they depend on the input.</p>
<h2 id="non-gas-parameters"><a class="header" href="#non-gas-parameters">Non-gas parameters</a></h2>
<p>Not all runtime parameters are directly related to gas costs. Here is a brief
overview.</p>
<ul>
<li><strong>Gas economics config:</strong> Defines the conversion rate when purchasing gas with
NEAR tokens and how gas rewards are split.</li>
<li><strong>Storage usage config:</strong> Costs in tokens, not gas, for storing data on chain.</li>
<li><strong>Account creation config:</strong> Rules for account creation.</li>
<li><strong>Smart contract limits:</strong> Rules for WASM execution.</li>
</ul>
<p>None of the above define any gas costs directly. But there can be interplay
between those parameters and gas costs. For example, the limits on smart
contracts changes the assumptions for how slow a contract compilation could be,
hence it affects the deploy action costs.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="parameter-definitions"><a class="header" href="#parameter-definitions">Parameter Definitions</a></h1>
<p>Gas parameters are a subset of runtime parameters that are defined in
<a href="architecture/gas/../../../core/parameters/res/runtime_configs/parameters.yaml">runtime_configs/parameters.yaml</a>.
<strong>IMPORTANT:</strong> This is not the final list of parameters, it contains the base
values which can be overwritten per protocol version. For example,
<a href="architecture/gas/../../../core/parameters/res/runtime_configs/53.yaml">53.yaml</a>
changes several parameters starting from version 53. You can see the final list
of parameters in
<a href="architecture/gas/../../../core/parameters/res/runtime_configs/parameters.snap">runtime_configs/parameters.snap</a>.
This file is automatically updated whenever any of the parameters changes. To
see all parameter values for a specific version, check out the list of JSON
snapshots generated in this directory:
<a href="architecture/gas/../../../core/parameters/src/snapshots">parameters/src/snapshots</a>.</p>
<h2 id="using-parameters-in-code"><a class="header" href="#using-parameters-in-code">Using Parameters in Code</a></h2>
<p>As the introduction on this page already hints at it, parameter values are
versioned. In other words, they can change if the protocol version changes. A
nearcore binary has to support multiple versions and choose the correct
parameter value at runtime.</p>
<p>To make this easy, there is
<a href="https://github.com/near/nearcore/blob/a8964d200b3938a63d389263bc39c1bcd75b1de4/core/primitives/src/runtime/config_store.rs#L43"><code>RuntimeConfigStore</code></a>.
It contains a sparse map from protocol versions to complete runtime
configurations (<code>BTreeMap&lt;ProtocolVersion, Arc&lt;RuntimeConfig&gt;&gt;</code>).
The runtime then uses <code>store.get_config(protocol_version)</code> to access a runtime
configuration for a specific version.</p>
<p>It is crucial to always use this runtime config store. Never hard-code parameter
values. Never look them up in a different way.</p>
<p>In practice, this usually translates to a <code>&amp;RuntimeConfig</code> argument for any
function that depends on parameter values. This config object implicitly defines
the protocol version. It should therefore not be cached. It should be read from
the store once per chunk and then passed down to all functions that need it.</p>
<h2 id="how-to-add-a-new-parameter"><a class="header" href="#how-to-add-a-new-parameter">How to Add a New Parameter</a></h2>
<p>First and foremost, if you are feeling lost, open a topic in our Zulip chat
(<a href="https://near.zulipchat.com/#narrow/stream/295306-pagoda.2Fcontract-runtime">pagoda/contract-runtime</a>).
We are here to help.</p>
<h3 id="principles"><a class="header" href="#principles">Principles</a></h3>
<p>Before adding anything, please review the basic principles for gas parameters.</p>
<ul>
<li>A parameter must correspond to a clearly defined workload.</li>
<li>When the workload is scalable by a factor <code>N</code> that depends on user input,
it will likely require a base parameter and a second parameter that is
multiplied by <code>N</code>. (Example: <code>N</code> = number of bytes when reading a value from
storage.)</li>
<li>Charge gas before executing the workload.</li>
<li>Parameters should be independent of specific implementation choices in
nearcore.</li>
<li>Ideally, contract developers can easily understand what the cost is simply by
reading the name in a gas profile.</li>
</ul>
<p>The section on <a href="architecture/gas/./gas_profile.html#charging-gas">Gas Profiles</a> explains how to
charge gas, please also consider that when defining a new parameter.</p>
<h3 id="necessary-code-changes"><a class="header" href="#necessary-code-changes">Necessary Code Changes</a></h3>
<p>Adding the parameter in code involves several steps.</p>
<ol>
<li>Define the parameter by adding it to the list in <code>core/primitives/res/runtime_configs/parameters.yaml.</code></li>
<li>Update the Rust view of parameters by adding a variant to <code>enum Parameter</code>
in <code>core/primitives-core/src/parameter.rs</code>. In the same file, update
<code>enum FeeParameter</code> if you add an action cost or update <code>ext_costs()</code>
if you add a cost inside function calls.</li>
<li>Update <code>RuntimeConfig</code>, the configuration used to reference parameters in
code. Depending on the type of parameter, you will need to update
<code>RuntimeFeesConfig</code> (for action costs) or <code>ExtCostsConfig</code> (for gas costs).</li>
<li>Update the list used for gas profiles. This is defined by <code>enum Cost</code> in
<code>core/primitives-core/src/profile.rs</code>. You need to add a variant to either
<code>enum ActionCosts</code> or <code>enum ExtCost</code>. Please also update <code>fn index()</code> that
maps each profile entry to a unique position in serialized gas profiles.</li>
<li>The parameter should be available to use in the code section you need it in.
Now is a good time to ensure <code>cargo check</code> and <code>cargo test --no-run</code> pass.
Most likely you have to update some testing code, such as
<code>ExtCostsConfig::test()</code>.</li>
<li>To merge your changes into nearcore, you will have to hide your parameter
behind a feature flag. Add the feature to the <code>Cargo.toml</code> of each crate
touched in steps 3 and 4 and hide the code behind <code>#[cfg(feature = &quot;protocol_feature_MY_NEW_FEATURE&quot;)]</code>. Do not hide code in step 2 so that
non-nightly builds can still read <code>parameters.yaml</code>. Also, add your feature as
a dependency on <code>nightly</code> in <code>core/primitives/Cargo.toml</code> to make sure it
gets included when compiling for nightly. After that, check <code>cargo check</code> and
<code>cargo test --no-run</code> with and without <code>features=nightly</code>.</li>
</ol>
<h3 id="what-gas-value-should-the-parameter-have"><a class="header" href="#what-gas-value-should-the-parameter-have">What Gas Value Should the Parameter Have?</a></h3>
<p>For a first draft, the exact gas value used in the parameter is not crucial.
Make sure the right set of parameters exists and try to set a number that roughly
makes sense. This should be enough to enable discussions on the NEP around the
feasibility and usefulness of the proposed feature. If you are not sure, a good
rule of thumb is 0.1 Tgas for each disk operation and at least 1 Tgas for each
ms of CPU time. Then round it up generously.</p>
<p>The value will have to be refined later. This is usually the last step after
the implementation is complete and reviewed. Have a look at the section on
<a href="architecture/gas/./estimator.html">estimating gas parameters</a> in the book.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="gas-profile"><a class="header" href="#gas-profile">Gas Profile</a></h1>
<p>What if you want to understand the exact gas spending of a smart contract call?
It would be very complicated to predict exactly how much gas executing a piece
of WASM code will require, including all host function calls and actions. An
easier approach is to just run the code on testnet and see how much gas it
burns. Gas profiles allow one to dig deeper and understand the breakdown of the
gas costs per parameter.</p>
<p><strong>Gas profiles are not very reliable</strong>, in that they are often incomplete and the
details of how they are computed can change without a protocol version bump.</p>
<h2 id="example-transaction-gas-profile"><a class="header" href="#example-transaction-gas-profile">Example Transaction Gas Profile</a></h2>
<p>You can query the gas profile of a transaction with
<a href="https://docs.near.org/tools/near-cli">NEAR CLI</a>.</p>
<pre><code class="language-bash">NEAR_ENV=mainnet near tx-status 8vYxsqYp5Kkfe8j9LsTqZRsEupNkAs1WvgcGcUE4MUUw  \
  --accountId app.nearcrowd.near  \
  --nodeUrl https://archival-rpc.mainnet.near.org  # Allows to retrieve older transactions.
</code></pre>
<!-- cspell:ignore evgeniya -->
<pre><code>Transaction app.nearcrowd.near:8vYxsqYp5Kkfe8j9LsTqZRsEupNkAs1WvgcGcUE4MUUw
{
  receipts_outcome: [
    {
      block_hash: '2UVQKpxH6PhEqiKr6zMggqux4hwMrqqjpsbKrJG3vFXW',
      id: '14bwmJF21PXY9YWGYN1jpjF3BRuyCKzgVWfhXhZBKH4u',
      outcome: {
        executor_id: 'app.nearcrowd.near',
        gas_burnt: 5302170867180,
        logs: [],
        metadata: {
          gas_profile: [
            {
              cost: 'BASE',
              cost_category: 'WASM_HOST_COST',
              gas_used: '15091782327'
            },
            {
              cost: 'CONTRACT_LOADING_BASE',
              cost_category: 'WASM_HOST_COST',
              gas_used: '35445963'
            },
            {
              cost: 'CONTRACT_LOADING_BYTES',
              cost_category: 'WASM_HOST_COST',
              gas_used: '117474381750'
            },
            {
              cost: 'READ_CACHED_TRIE_NODE',
              cost_category: 'WASM_HOST_COST',
              gas_used: '615600000000'
            },
            # ...
            # skipping entries for presentation brevity
            # ...
            {
              cost: 'WRITE_REGISTER_BASE',
              cost_category: 'WASM_HOST_COST',
              gas_used: '48713882262'
            },
            {
              cost: 'WRITE_REGISTER_BYTE',
              cost_category: 'WASM_HOST_COST',
              gas_used: '4797573768'
            }
          ],
          version: 2
        },
        receipt_ids: [ '46Qsorkr6hy36ZzWmjPkjbgG28ko1iwz1NT25gvia51G' ],
        status: { SuccessValue: 'ZmFsc2U=' },
        tokens_burnt: '530217086718000000000'
      },
      proof: [ ... ]
    },
    { ... }
  ],
  status: { SuccessValue: 'ZmFsc2U=' },
  transaction: { ... },
  transaction_outcome: {
    block_hash: '7MgTTVi3aMG9LiGV8ezrNvoorUwQ7TwkJ4Wkbk3Fq5Uq',
    id: '8vYxsqYp5Kkfe8j9LsTqZRsEupNkAs1WvgcGcUE4MUUw',
    outcome: {
      executor_id: 'evgeniya.near',
      gas_burnt: 2428068571644,
      ...
      tokens_burnt: '242806857164400000000'
    },
  }
}
</code></pre>
<p>The gas profile is in <code>receipts_outcome.outcome.metadata.gas_profile</code>. It shows
gas costs per parameter and with associated categories such as <code>WASM_HOST_COST</code>
or <code>ACTION_COST</code>. In the example, all costs are of the former category, which is
gas expended on smart contract execution. The latter is for gas spent on
actions.</p>
<p>To be complete, the output above should also have a gas profile entry for the
function call action. But currently this is not included since gas profiles only
work properly on function call receipts. Improving this is planned, see
<a href="https://github.com/near/nearcore/issues/8261">nearcore#8261</a>.</p>
<p>The <code>tx-status</code> query returns one gas profile for each receipt. The output above
contains a single gas profile because the transaction only spawned one receipt.
If there was a chain of cross contract calls, there would be multiple profiles.</p>
<p>Besides receipts, also note the <code>transaction_outcome</code> in the output. It contains
the gas cost for converting the transaction into a receipt. To calculate the
full gas cost, add up the transaction cost with all receipt costs.</p>
<p>The transaction outcome currently does not have a gas profile, it only shows the
total gas spent converting the transaction. Arguably, it is not necessary to
provide the gas profile since the costs only depend on the list of actions. With
sufficient understanding of the protocol, one could reverse-engineer the exact
breakdown simply by looking at the action list. But adding the profile would
still make sense to make it easier to understand.</p>
<h2 id="gas-profile-versions"><a class="header" href="#gas-profile-versions">Gas Profile Versions</a></h2>
<p>Depending on the version in <code>receipts_outcome.outcome.metadata.version</code>, you
should expect a different format of the gas profile. Version 1 has no profile
data at all. Version 2 has a detailed profile but some parameters are conflated,
so you cannot extract the exact gas spending in some cases. Version 3 will have
the cost exactly per parameter.</p>
<p>Which version of the profile an RPC node returns depends on the version it had
when it first processed the transaction. The profiles are stored in the database
with one version and never updated. Therefore, older transactions will usually
only have old profiles. However, one could replay the chain from genesis with a
new nearcore client and generate the newest profile for all transactions in this
way.</p>
<p>Note: Due to bugs, some nodes will claim they send version 1 but actually
send version 2. (Did I mention that profiles are unreliable?)</p>
<h2 id="how-gas-profiles-are-created"><a class="header" href="#how-gas-profiles-are-created">How Gas Profiles are Created</a></h2>
<p>The transaction runtime charges gas in various places around the code.
<code>ActionResult</code> keeps a summary of all costs for an action. The <code>gas_burnt</code> and
<code>gas_used</code> fields track the total gas burned and reserved for spawned receipts.
These two fields are crucial for the protocol to function correctly, as they are
used to determine when execution runs out of gas.</p>
<p>Additionally, <code>ActionResult</code> also has a <code>profile</code> field which keeps a detailed
breakdown of the gas spending per parameter. Profiles are not stored on chain
but RPC nodes and archival nodes keep them in their databases. This is mostly a
debug tool and has no direct impact on the correct functioning of the protocol.</p>
<h2 id="charging-gas"><a class="header" href="#charging-gas">Charging Gas</a></h2>
<p>Generally speaking, gas is charged right before the computation that it pays for
is executed. It has to be before to avoid cheap resource exhaustion attacks.
Imagine the user has only 1 gas unit left, but if we start executing an expensive
step, we would waste a significant duration of computation on all validators
without anyone paying for it.</p>
<p>When charging gas for an action, the <code>ActionResult</code> can be updated directly. But
when charging WASM costs, it would be too slow to do a context switch each time,
Therefore, a fast gas counter exists that can be updated from within the VM.
(See
<a href="https://github.com/near/nearcore/blob/06711f8460f946b8d2042aa1df6abe03c5184767/runtime/near-vm-logic/src/gas_counter.rs">gas_counter.rs</a>)
At the end of a function call execution, the gas counter is read by the host and
merged into the <code>ActionResult</code>.</p>
<!-- 
TODO: We can expand a bit more on how profiles are created and how it interacts 
with gas charging after merging https://github.com/near/nearcore/issues/8033
-->
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="runtime-parameter-estimator"><a class="header" href="#runtime-parameter-estimator">Runtime Parameter Estimator</a></h1>
<p>The runtime parameter estimator is a byzantine benchmarking suite. Byzantine
benchmarking is not a commonly used term but I feel it describes it quite
well. It measures the performance assuming that up to a third of validators and
all users collude to make the system as slow as possible.</p>
<p>This benchmarking suite is used to check that the gas parameters defined in the
protocol are correct. Correct in this context means, a chunk filled with 1 Pgas
(<strong>P</strong>eta gas) will take at most 1 second to be applied. Or more generally,
per 1 Tgas of execution, we spend no more than 1ms wall-clock time.</p>
<p>For now, nearcore timing is the only one that matters. Things will become more
complicated once there are multiple client implementations. But knowing that
nearcore can serve requests fast enough proves that it is possible to be at
least as fast. However, we should be careful not to couple costs too tightly
with the specific implementation of nearcore to allow for innovation in new
clients.</p>
<p>The estimator code is part of the nearcore repository in the directory
<a href="https://github.com/near/nearcore/tree/master/runtime/runtime-params-estimator">runtime/runtime-params-estimator</a>.</p>
<p>For a practical guide on how to run the estimator, please take a look at
<a href="architecture/gas/../../practices/workflows/gas_estimations.html">Running the Estimator</a> in the
workflows chapter.</p>
<h2 id="code-structure"><a class="header" href="#code-structure">Code Structure</a></h2>
<p>The estimator contains a binary and a library module. The
<a href="https://github.com/near/nearcore/blob/e40863c9ba61a0de140c869583b2113358605771/runtime/runtime-params-estimator/src/main.rs">main.rs</a>
contains the CLI arguments parsing code and logic to fill the test database.</p>
<p>The interesting code lives in
<a href="https://github.com/near/nearcore/blob/e40863c9ba61a0de140c869583b2113358605771/runtime/runtime-params-estimator/src/lib.rs">lib.rs</a>
and its submodules. The comments at the top of that file provide a
high-level overview of how estimations work. More details on specific
estimations are available as comments on the enum variants of <code>Cost</code> in
<a href="https://github.com/near/nearcore/blob/e40863c9ba61a0de140c869583b2113358605771/runtime/runtime-params-estimator/src/cost.rs#L9">costs.rs</a>.</p>
<p>If you roughly understand the three files above, you already have a great
overview of the estimator.
<a href="https://github.com/near/nearcore/blob/e40863c9ba61a0de140c869583b2113358605771/runtime/runtime-params-estimator/src/estimator_context.rs">estimator_context.rs</a>
is another central file. A full estimation run creates a single
<code>EstimatorContext</code>. Each estimation will use it to spawn a new <code>Testbed</code>
with a fresh database that contains the same data as the setup in the
estimator context.</p>
<p>Most estimations fill blocks with transactions to be executed and hand them to
<code>Testbed::measure_blocks</code>. To allow for easy repetitions, the block is usually
filled by an instance of the
<a href="https://github.com/near/nearcore/blob/e40863c9ba61a0de140c869583b2113358605771/runtime/runtime-params-estimator/src/transaction_builder.rs"><code>TransactionBuilder</code></a>,
which can be retrieved from a testbed.</p>
<p>But even filling blocks with transactions becomes repetitive since many
parameters are estimated similarly.
<a href="https://github.com/near/nearcore/blob/master/runtime/runtime-params-estimator/src/utils.rs">utils.rs</a>
has a collection of helpful functions that let you write estimations very
quickly.</p>
<h2 id="estimation-metrics"><a class="header" href="#estimation-metrics">Estimation Metrics</a></h2>
<p>The estimation code is generally not concerned with the metric used to estimate
gas. We use <code>let clock = GasCost::measure();</code> and <code>clock.elapsed()</code> to measure
the cost in whatever metric has been specified in the CLI argument <code>--metric</code>.
But when you run estimations and especially when you want to interpret the
results, you want to understand the metric used. Available metrics are <code>time</code>
and <code>icount</code>.</p>
<!-- cspell:words DVFS -->
<p>Starting with <code>time</code>, this is a simple wall-clock time measurement. At the end
of the day, this is what counts in a validator setup. But unfortunately, this
metric is very dependent on the specific hardware and what else is running on
that hardware right now. Dynamic voltage and frequency scaling (DVFS) also plays
a role here. To a certain degree, all these factors can be controlled. But it
requires full control over a system (often not the case when running on
cloud-hosted VMs) and manual labor to set it up.</p>
<p>The other supported metric <code>icount</code> is much more stable. It uses
<a href="https://www.qemu.org/">qemu</a> to emulate an x86 CPU. We then insert a custom
<a href="https://www.qemu.org/docs/master/devel/tcg-plugins.html">TCG plugin</a>
(<a href="https://github.com/near/nearcore/blob/08c4a1bd4b16847eb1c2fccee36bf16f6efb71fd/runtime/runtime-params-estimator/emu-cost/counter_plugin/counter.c">counter.c</a>)
that counts the number of executed x86 instructions. It also intercepts system
calls and counts the number of bytes seen in <code>sys_read</code>, <code>sys_write</code> and their
variations. This gives an approximation for IO bytes, as seen on the interface
between the operating system and nearcore. To convert to gas, we use three
constants to multiply with instruction count, read bytes, and write bytes.</p>
<p>We run qemu inside a Docker container using the Podman runtime, to make sure the qemu and qemu
plugin versions match with system libraries. Make sure to add <code>--containerize</code> when running with
<code>--metric icount</code>.</p>
<p>The great thing about <code>icount</code> is that you can run it on different machines and
it will always return the same result. It is not 100% deterministic but very
close, so it can usually detect code changes that degrade performance in major
ways.</p>
<p>The problem with <code>icount</code> is how unrepresentative it is for real-life
performance. First, <code>x86</code> instructions are not all equally complex. Second, how
many of them are executed per cycle depends on instruction level pipelining,
branch prediction, memory prefetching, and more CPU features like that which are
just not captured by an emulator like qemu. Third, the time it takes to serve
bytes in system calls depends less on the sum of all bytes and more on data
locality and how it can be cached in the OS page cache. But regardless of all
these inaccuracies, it can still be useful to compare different implementations
both measured using <code>icount</code>.</p>
<h2 id="from-estimations-to-parameter-values"><a class="header" href="#from-estimations-to-parameter-values">From Estimations to Parameter Values</a></h2>
<p>To calculate the final gas parameter values, there is more to be done than just
running a single command. After all, these parameters are part of the protocol
specification. They cannot be changed easily. And setting them to a wrong value
can cause severe system instability.</p>
<p>Our current strategy is to run estimations with two different metrics and do so
on standardized cloud hardware. The output is then sanity checked manually by
several people. Based on that, the final gas parameter value is determined.
Usually, it will be the higher output of the two metrics rounded up.</p>
<p>The PR <a href="https://github.com/near/nearcore/pull/8031">#8031</a> to set the ed25519
verification gas parameters is a good example of how such an analysis and
report could look like.</p>
<p>More details on the process will be added to this document
in due time.</p>
<!-- TODO: how to add a new host function estimation -->
<!-- TODO: state of IO estimations -->
<!-- TODO: CE and Warehouse -->
<!-- TODO: ... -->
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="overview-5"><a class="header" href="#overview-5">Overview</a></h1>
<p>This chapter describes various development processes and best practices employed
at nearcore.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="rust-"><a class="header" href="#rust-">Rust ðŸ¦€</a></h1>
<p>This short chapter collects various useful general resources about the Rust
programming language. If you are already familiar with Rust, skip this
chapter. Otherwise, this chapter is for you!</p>
<h2 id="getting-help"><a class="header" href="#getting-help">Getting Help</a></h2>
<p>Rust community actively encourages beginners to ask questions, take advantage of that!</p>
<p>We have a dedicated stream for Rust questions on our Zulip: <a href="https://near.zulipchat.com/#narrow/stream/300659-Rust-.F0.9F.A6.80">Rust
ðŸ¦€</a>.</p>
<p>There's a general Rust forum at <a href="https://users.rust-lang.org">https://users.rust-lang.org</a>.</p>
<p>For a more interactive chat, take a look at Discord:
<a href="https://discord.com/invite/rust-lang">https://discord.com/invite/rust-lang</a>.</p>
<h2 id="reference-material"><a class="header" href="#reference-material">Reference Material</a></h2>
<p>Rust is <em>very</em> well documented. It's possible to learn the whole language and
most of the idioms by just reading the official docs. Starting points are</p>
<ul>
<li><a href="https://doc.rust-lang.org/book/">The Rust Book</a> (any resemblance to &quot;Guide to
Nearcore Development&quot; is purely coincidental)</li>
<li><a href="https://doc.rust-lang.org/stable/std/">Standard Library API</a></li>
</ul>
<p>Alternatives are:</p>
<ul>
<li><a href="https://www.amazon.com/Programming-Rust-Fast-Systems-Development/dp/1491927283">Programming
Rust</a>
is an alternative book that moves a bit faster.</li>
<li><a href="https://doc.rust-lang.org/rust-by-example/">Rust By Example</a> is a great
resource for learning by doing.</li>
</ul>
<p>Rust has some great tooling, which is also documented:</p>
<ul>
<li><a href="https://doc.rust-lang.org/cargo/">Cargo</a>, the build system. Worth at least skimming through!</li>
<li>For IDE support, see <a href="https://www.jetbrains.com/rust/">IntelliJ Rust</a> if you
like JetBrains products or
<a href="https://rust-analyzer.github.io/manual.html">rust-analyzer</a> if you use any
other editor (fun fact: NEAR was one of the sponsors of rust-analyzer!).</li>
<li><a href="https://rust-lang.github.io/rustup/">Rustup</a> manages versions of Rust
itself. It's unobtrusive, so feel free to skip this.</li>
</ul>
<h2 id="cheat-sheet"><a class="header" href="#cheat-sheet">Cheat Sheet</a></h2>
<p>This is a thing in its category, do check it out:</p>
<p><a href="https://cheats.rs">https://cheats.rs</a></p>
<h2 id="language-mastery"><a class="header" href="#language-mastery">Language Mastery</a></h2>
<!-- cspell:ignore Rustaceans Rustonomicon -->
<ul>
<li><a href="https://nostarch.com/rust-rustaceans">Rust for Rustaceans</a> â€” the book to read
after &quot;The Book&quot;.</li>
<li><a href="https://tokio.rs/tokio/tutorial">Tokio docs</a> explain asynchronous programming
in Rust (async/await).</li>
<li><a href="https://rust-lang.github.io/api-guidelines/about.html">Rust API Guidelines</a>
codify rules for idiomatic Rust APIs. Note that guidelines apply to <em>semver
surface</em> of libraries, and most of the code in nearcore is not on the semver
boundary. Still, a lot of insight there!</li>
<li><a href="https://doc.rust-lang.org/nomicon/">Rustonomicon</a> explains <code>unsafe</code>. (any
resemblance to <a href="https://nomicon.io">https://nomicon.io</a> is purely coincidental)</li>
</ul>
<h2 id="selected-blog-posts"><a class="header" href="#selected-blog-posts">Selected Blog Posts</a></h2>
<p>A lot of finer knowledge is hidden away in various dusty corners of Web-2.0.
Here are some favorites:</p>
<ul>
<li><a href="https://docs.rs/dtolnay/latest/dtolnay/macro._02__reference_types.html">https://docs.rs/dtolnay/latest/dtolnay/macro._02__reference_types.html</a></li>
<li><a href="https://limpet.net/mbrubeck/2019/02/07/rust-a-unique-perspective.html">https://limpet.net/mbrubeck/2019/02/07/rust-a-unique-perspective.html</a></li>
<li><a href="https://smallcultfollowing.com/babysteps/blog/2018/02/01/in-rust-ordinary-vectors-are-values/">https://smallcultfollowing.com/babysteps/blog/2018/02/01/in-rust-ordinary-vectors-are-values/</a></li>
<li><a href="https://smallcultfollowing.com/babysteps/blog/2016/10/02/observational-equivalence-and-unsafe-code/">https://smallcultfollowing.com/babysteps/blog/2016/10/02/observational-equivalence-and-unsafe-code/</a></li>
<li><a href="https://matklad.github.io/2021/09/05/Rust100k.html">https://matklad.github.io/2021/09/05/Rust100k.html</a></li>
</ul>
<p>And on the easiest topic of error handling specifically:</p>
<ul>
<li><a href="http://sled.rs/errors.html">http://sled.rs/errors.html</a></li>
<li><a href="https://kazlauskas.me/entries/errors">https://kazlauskas.me/entries/errors</a></li>
<li><a href="http://joeduffyblog.com/2016/02/07/the-error-model/">http://joeduffyblog.com/2016/02/07/the-error-model/</a></li>
<li><a href="https://blog.burntsushi.net/rust-error-handling/">https://blog.burntsushi.net/rust-error-handling/</a></li>
</ul>
<p>Finally, as a dessert, the first rust slide deck:
<a href="http://venge.net/graydon/talks/rust-2012.pdf">http://venge.net/graydon/talks/rust-2012.pdf</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="workflows"><a class="header" href="#workflows">Workflows</a></h1>
<p>This chapter documents various ways you can run <code>neard</code> during development:
running a local net, joining a test net, doing benchmarking and load testing.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="run-a-node"><a class="header" href="#run-a-node">Run a Node</a></h1>
<p>This chapter focuses on the basics of running a node you've just built from
source. It tries to explain how the thing works under the hood and pays
relatively little attention to the various shortcuts we have.</p>
<h2 id="building-the-node"><a class="header" href="#building-the-node">Building the Node</a></h2>
<p>Start with the following command:</p>
<pre><code class="language-console">cargo run --profile dev-release -p neard -- --help
</code></pre>
<p>This command builds <code>neard</code> and asks it to show <code>--help</code>. Building <code>neard</code> takes
a while, take a look at <a href="practices/workflows/../fast_builds.html">Fast Builds</a> chapter to learn how to
speed it up.</p>
<p>Let's dissect the command:</p>
<ul>
<li><code>cargo run</code> asks <code>Cargo</code>, the package manager/build tool, to run our
application. If you don't have <code>cargo</code>, install it via <a href="https://rustup.rs">https://rustup.rs</a></li>
<li><code>--profile dev-release</code> is our
<a href="https://doc.rust-lang.org/cargo/reference/profiles.html#custom-profiles">custom profile</a>
to build a somewhat optimized version of the code. The default debug
profile is faster to compile, but produces a node that is too slow to
participate in a real network. The <code>--release</code> profile produces a fully
optimized node, but that's very slow to compile. So <code>--dev-release</code>
is a sweet spot for us! However, never use it for actual production nodes.</li>
<li><code>-p neard</code> asks to build the <code>neard</code> package. We use
<a href="https://doc.rust-lang.org/cargo/reference/workspaces.html">cargo workspaces</a>
to organize our code. The <code>neard</code> package in the top-level <code>/neard</code> directory
is the final binary that ties everything together.</li>
<li><code>--</code> tells cargo to pass the rest of the arguments through to <code>neard</code>.</li>
<li><code>--help</code> instructs <code>neard</code> to list available CLI arguments and subcommands.</li>
</ul>
<p><strong>Note:</strong> Building <code>neard</code> might fail with an openssl or CC error. This means
that you lack some non-rust dependencies we use (openssl and rocksdb mainly). We
currently don't have docs on how to install those, but (basically) you want to
<code>sudo apt install</code> (or whichever distro/package manager you use) missing bits.</p>
<h2 id="preparing-tiny-network"><a class="header" href="#preparing-tiny-network">Preparing Tiny Network</a></h2>
<p>Typically, you want <code>neard</code> to connect to some network, like <code>mainnet</code> or
<code>testnet</code>. We'll get there in time, but we'll start small. For the current
chapter, we will run a network consisting of just a single node -- our own.</p>
<p>The first step there is creating the required configuration. Run the <code>init</code>
command to create config files:</p>
<pre><code class="language-console">$ cargo run --profile dev-release -p neard -- init
INFO neard: version=&quot;trunk&quot; build=&quot;1.1.0-3091-ga8964d200-modified&quot; latest_protocol=57
INFO near: Using key ed25519:B41GMfqE2jWHVwrPLbD7YmjZxxeQE9WA9Ua2jffP5dVQ for test.near
INFO near: Using key ed25519:34d4aFJEmc2A96UXMa9kQCF8g2EfzZG9gCkBAPcsVZaz for node
INFO near: Generated node key, validator key, genesis file in ~/.near
</code></pre>
<p>As the log output says, we are just generating <em>some things</em> in <code>~/.near</code>.
Let's take a look:</p>
<pre><code class="language-console">$ ls ~/.near
config.json
genesis.json
node_key.json
validator_key.json
</code></pre>
<p>The most interesting file here is perhaps <code>genesis.json</code> -- it specifies the
initial state of our blockchain. There are a bunch of hugely important fields
there, which we'll ignore here. The part we'll look at is the <code>.records</code>, which
contains the actual initial data:</p>
<pre><code class="language-console">$ cat ~/.near/genesis.json | jq '.records'
[
  {
    &quot;Account&quot;: {
      &quot;account_id&quot;: &quot;test.near&quot;,
      &quot;account&quot;: {
        &quot;amount&quot;: &quot;1000000000000000000000000000000000&quot;,
        &quot;locked&quot;: &quot;50000000000000000000000000000000&quot;,
        &quot;code_hash&quot;: &quot;11111111111111111111111111111111&quot;,
        &quot;storage_usage&quot;: 0,
        &quot;version&quot;: &quot;V1&quot;
      }
    }
  },
  {
    &quot;AccessKey&quot;: {
      &quot;account_id&quot;: &quot;test.near&quot;,
      &quot;public_key&quot;: &quot;ed25519:B41GMfqE2jWHVwrPLbD7YmjZxxeQE9WA9Ua2jffP5dVQ&quot;,
      &quot;access_key&quot;: {
        &quot;nonce&quot;: 0,
        &quot;permission&quot;: &quot;FullAccess&quot;
      }
    }
  },
  {
    &quot;Account&quot;: {
      &quot;account_id&quot;: &quot;near&quot;,
      &quot;account&quot;: {
        &quot;amount&quot;: &quot;1000000000000000000000000000000000&quot;,
        &quot;locked&quot;: &quot;0&quot;,
        &quot;code_hash&quot;: &quot;11111111111111111111111111111111&quot;,
        &quot;storage_usage&quot;: 0,
        &quot;version&quot;: &quot;V1&quot;
      }
    }
  },
  {
    &quot;AccessKey&quot;: {
      &quot;account_id&quot;: &quot;near&quot;,
      &quot;public_key&quot;: &quot;ed25519:546XB2oHhj7PzUKHiH9Xve3Ze5q1JiW2WTh6abXFED3c&quot;,
      &quot;access_key&quot;: {
        &quot;nonce&quot;: 0,
        &quot;permission&quot;: &quot;FullAccess&quot;
      }
    }
  }
</code></pre>
<p>(I am using the <a href="https://stedolan.github.io/jq/">jq</a> utility here)</p>
<p>We see that we have two accounts here, and we also see their public keys (but
not the private ones).</p>
<p>One of these accounts is a validator:</p>
<pre><code>$ cat ~/.near/genesis.json | jq '.validators'
[
  {
    &quot;account_id&quot;: &quot;test.near&quot;,
    &quot;public_key&quot;: &quot;ed25519:B41GMfqE2jWHVwrPLbD7YmjZxxeQE9WA9Ua2jffP5dVQ&quot;,
    &quot;amount&quot;: &quot;50000000000000000000000000000000&quot;
  }
]
</code></pre>
<p>Now, if we</p>
<pre><code class="language-console">cat ~/.near/validator_key.json
</code></pre>
<p>we'll see</p>
<pre><code class="language-json">{
  &quot;account_id&quot;: &quot;test.near&quot;,
  &quot;public_key&quot;: &quot;ed25519:B41GMfqE2jWHVwrPLbD7YmjZxxeQE9WA9Ua2jffP5dVQ&quot;,
  &quot;secret_key&quot;: &quot;ed25519:3x2dUQgBoEqNvKwPjfDE8zDVJgM8ysqb641PYHV28mGPu61WWv332p8keMDKHUEdf7GVBm4f6z4D1XRgBxnGPd7L&quot;
}
</code></pre>
<p>That is, we have a secret key for the sole validator in our network, how
convenient.</p>
<p>To recap, <code>neard init</code> without arguments creates a config for a new network
that starts with a single validator, for which we have the keys.</p>
<p>You might be wondering what <code>~/.near/node_key.json</code> is. That's not too
important, but, in our network, there's no 1-1 correspondence between machines
participating in the peer-to-peer network and accounts on the blockchain. So the
<code>node_key</code> specifies the keypair we'll use when signing network packets. These
packets internally will contain messages signed with the validator's key, and
these internal messages will drive the evolution of the blockchain state.</p>
<p>Finally, <code>~/.near/config.json</code> contains various configs for the node itself.
These are configs that don't affect the rules guiding the evolution of the
blockchain state, but rather things like timeouts, database settings and
such.</p>
<p>The only field we'll look at is <code>boot_nodes</code>:</p>
<pre><code class="language-console">$ cat ~/.near/config.json | jq '.network.boot_nodes'
&quot;&quot;
</code></pre>
<p>It's empty! The <code>boot_nodes</code> specify IPs of the initial nodes our node will
try to connect to on startup. As we are looking into running a single-node
network, we want to leave it empty. But, if you would like to connect to
mainnet, you'd have to set this to some nodes from the mainnet you already know.
You'd also have to ensure that you use the same genesis as the mainnet though
-- if the node tries to connect to a network with a different genesis, it
is rejected.</p>
<h2 id="running-the-network"><a class="header" href="#running-the-network">Running the Network</a></h2>
<p>Finally,</p>
<!-- cspell:ignore matklad -->
<pre><code class="language-console">$ cargo run --profile dev-release -p neard -- run
INFO neard: version=&quot;trunk&quot; build=&quot;1.1.0-3091-ga8964d200-modified&quot; latest_protocol=57
INFO near: Creating a new RocksDB database path=/home/matklad/.near/data
INFO db: Created a new RocksDB instance. num_instances=1
INFO stats: #       0 4xecSHqTKx2q8JNQNapVEi5jxzewjxAnVFhMd4v5LqNh Validator | 1 validator 0 peers â¬‡ 0 B/s â¬† 0 B/s NaN bps 0 gas/s CPU: 0%, Mem: 50.8 MB
INFO near_chain::doomslug: ready to produce block @ 1, has enough approvals for 59.907Âµs, has enough chunks
INFO near_chain::doomslug: ready to produce block @ 2, has enough approvals for 40.732Âµs, has enough chunks
INFO near_chain::doomslug: ready to produce block @ 3, has enough approvals for 65.341Âµs, has enough chunks
INFO near_chain::doomslug: ready to produce block @ 4, has enough approvals for 51.916Âµs, has enough chunks
INFO near_chain::doomslug: ready to produce block @ 5, has enough approvals for 37.155Âµs, has enough chunks
...
</code></pre>
<p>ðŸŽ‰ it's alive!</p>
<p>So, what's going on here?</p>
<p>Our node is running a single-node network. As the network only has a single
validator, and the node has the keys for the validator, the node can produce
blocks by itself. Note the increasing <code>@ 1</code>, <code>@ 2</code>, ... numbers. That
means that our network grows.</p>
<p>Let's stop the node with <code>^C</code> and look around</p>
<pre><code class="language-console">INFO near_chain::doomslug: ready to produce block @ 42, has enough approvals for 56.759Âµs, has enough chunks
^C WARN neard: SIGINT, stopping... this may take a few minutes.
INFO neard: Waiting for RocksDB to gracefully shutdown
INFO db: Waiting for remaining RocksDB instances to shut down num_instances=1
INFO db: All RocksDB instances shut down
$
</code></pre>
<p>The main change now is that we have a <code>~/.near/data</code> directory which holds the
state of the network in various rocksdb tables:</p>
<pre><code class="language-console">$ ls ~/.near/data
 000004.log
 CURRENT
 IDENTITY
 LOCK
 LOG
 MANIFEST-000005
 OPTIONS-000107
 OPTIONS-000109
</code></pre>
<p>It doesn't matter what those are, &quot;rocksdb stuff&quot; is a fine level of understanding
here. The important bit here is that the node remembers the state of the network,
so, when we restart it, it continues from around the last block:</p>
<pre><code class="language-console">$ cargo run --profile dev-release -p neard -- run
INFO neard: version=&quot;trunk&quot; build=&quot;1.1.0-3091-ga8964d200-modified&quot; latest_protocol=57
INFO db: Created a new RocksDB instance. num_instances=1
INFO db: Dropped a RocksDB instance. num_instances=0
INFO near: Opening an existing RocksDB database path=/home/matklad/.near/data
INFO db: Created a new RocksDB instance. num_instances=1
INFO stats: #       5 Cfba39eH7cyNfKn9GoKTyRg8YrhoY1nQxQs66tLBYwRH Validator | 1 validator 0 peers â¬‡ 0 B/s â¬† 0 B/s NaN bps 0 gas/s CPU: 0%, Mem: 49.4 MB
INFO near_chain::doomslug: not ready to produce block @ 43, need to wait 366.58789ms, has enough approvals for 78.776Âµs
INFO near_chain::doomslug: not ready to produce block @ 43, need to wait 265.547148ms, has enough approvals for 101.119518ms
INFO near_chain::doomslug: not ready to produce block @ 43, need to wait 164.509153ms, has enough approvals for 202.157513ms
INFO near_chain::doomslug: not ready to produce block @ 43, need to wait 63.176926ms, has enough approvals for 303.48974ms
INFO near_chain::doomslug: ready to produce block @ 43, has enough approvals for 404.41498ms, does not have enough chunks
INFO near_chain::doomslug: ready to produce block @ 44, has enough approvals for 50.07Âµs, has enough chunks
INFO near_chain::doomslug: ready to produce block @ 45, has enough approvals for 45.093Âµs, has enough chunks
</code></pre>
<h2 id="interacting-with-the-node"><a class="header" href="#interacting-with-the-node">Interacting With the Node</a></h2>
<p>Ok, now our node is running, let's poke it! The node exposes a JSON RPC interface
which can be used to interact with the node itself (to, e.g., do a health check)
or with the blockchain (to query information about the blockchain state or to
submit a transaction).</p>
<pre><code class="language-console">$ http get http://localhost:3030/status
HTTP/1.1 200 OK
access-control-allow-credentials: true
access-control-expose-headers: accept-encoding, accept, connection, host, user-agent
content-length: 1010
content-type: application/json
date: Tue, 15 Nov 2022 13:58:13 GMT
vary: Origin, Access-Control-Request-Method, Access-Control-Request-Headers

{
    &quot;chain_id&quot;: &quot;test-chain-rR8Ct&quot;,
    &quot;latest_protocol_version&quot;: 57,
    &quot;node_key&quot;: &quot;ed25519:71QRP9qKcYRUYXTLNnrmRc1NZSdBaBo9nKZ88DK5USNf&quot;,
    &quot;node_public_key&quot;: &quot;ed25519:5A5QHyLayA9zksJZGBzveTgBRecpsVS4ohuxujMAFLLa&quot;,
    &quot;protocol_version&quot;: 57,
    &quot;rpc_addr&quot;: &quot;0.0.0.0:3030&quot;,
    &quot;sync_info&quot;: {
        &quot;earliest_block_hash&quot;: &quot;6gJLCnThQENYFbnFQeqQvFvRsTS5w87bf3xf8WN1CMUX&quot;,
        &quot;earliest_block_height&quot;: 0,
        &quot;earliest_block_time&quot;: &quot;2022-11-15T13:45:53.062613669Z&quot;,
        &quot;epoch_id&quot;: &quot;6gJLCnThQENYFbnFQeqQvFvRsTS5w87bf3xf8WN1CMUX&quot;,
        &quot;epoch_start_height&quot;: 501,
        &quot;latest_block_hash&quot;: &quot;9JC9o3rZrDLubNxVr91qMYvaDiumzwtQybj1ZZR9dhbK&quot;,
        &quot;latest_block_height&quot;: 952,
        &quot;latest_block_time&quot;: &quot;2022-11-15T13:58:13.185721125Z&quot;,
        &quot;latest_state_root&quot;: &quot;9kEYQtWczrdzKCCuFzPDX3Vtar1pFPXMdLU5HJyF8Ght&quot;,
        &quot;syncing&quot;: false
    },
    &quot;uptime_sec&quot;: 570,
    &quot;validator_account_id&quot;: &quot;test.near&quot;,
    &quot;validator_public_key&quot;: &quot;ed25519:71QRP9qKcYRUYXTLNnrmRc1NZSdBaBo9nKZ88DK5USNf&quot;,
    &quot;validators&quot;: [
        {
            &quot;account_id&quot;: &quot;test.near&quot;,
            &quot;is_slashed&quot;: false
        }
    ],
    &quot;version&quot;: {
        &quot;build&quot;: &quot;1.1.0-3091-ga8964d200-modified&quot;,
        &quot;rustc_version&quot;: &quot;1.65.0&quot;,
        &quot;version&quot;: &quot;trunk&quot;
    }
}
</code></pre>
<p>(I am using <a href="https://httpie.io/cli">HTTPie here</a>)</p>
<p>Note how <code>&quot;latest_block_height&quot;: 952</code> corresponds to <code>@ 952</code> we see in the logs.</p>
<p>Let's query the blockchain state:</p>
<pre><code>$ http post http://localhost:3030/ method=query jsonrpc=2.0 id=1 \
     params:='{&quot;request_type&quot;: &quot;view_account&quot;, &quot;finality&quot;: &quot;final&quot;, &quot;account_id&quot;: &quot;test.near&quot;}'
Î» http post http://localhost:3030/ method=query jsonrpc=2.0 id=1 \
           params:='{&quot;request_type&quot;: &quot;view_account&quot;, &quot;finality&quot;: &quot;final&quot;, &quot;account_id&quot;: &quot;test.near&quot;}'

HTTP/1.1 200 OK
access-control-allow-credentials: true
access-control-expose-headers: content-length, accept, connection, user-agent, accept-encoding, content-type, host
content-length: 294
content-type: application/json
date: Tue, 15 Nov 2022 14:04:54 GMT
vary: Origin, Access-Control-Request-Method, Access-Control-Request-Headers

{
    &quot;id&quot;: &quot;1&quot;,
    &quot;jsonrpc&quot;: &quot;2.0&quot;,
    &quot;result&quot;: {
        &quot;amount&quot;: &quot;1000000000000000000000000000000000&quot;,
        &quot;block_hash&quot;: &quot;Hn4v5CpfWf141AJi166gdDK3e3khCxgfeDJ9dSXGpAVi&quot;,
        &quot;block_height&quot;: 1611,
        &quot;code_hash&quot;: &quot;11111111111111111111111111111111&quot;,
        &quot;locked&quot;: &quot;50003138579594550524246699058859&quot;,
        &quot;storage_paid_at&quot;: 0,
        &quot;storage_usage&quot;: 182
    }
}
</code></pre>
<p>Note how we use an HTTP <code>post</code> method when we interact with the blockchain RPC.
The full set of RPC endpoints is documented at</p>
<p><a href="https://docs.near.org/api/rpc/introduction">https://docs.near.org/api/rpc/introduction</a></p>
<h2 id="sending-transactions"><a class="header" href="#sending-transactions">Sending Transactions</a></h2>
<p>Transactions are submitted via RPC as well. Submitting a transaction manually
with <code>http</code> is going to be cumbersome though â€” transactions are borsh encoded
to bytes, then signed, then encoded in base64 for JSON.</p>
<p>So we will use the official <a href="https://docs.near.org/tools/near-cli">NEAR CLI</a> utility.</p>
<p>Install it via <code>npm</code>:</p>
<pre><code class="language-console">$ npm install -g near-cli@3.4.2
$ near -h
Usage: near &lt;command&gt; [options]

Commands:
  near create-account &lt;accountId&gt;    create a new developer account
....
</code></pre>
<p>Note that, although you install <code>near-cli</code>, the name of the utility is <code>near</code>.</p>
<p>As a first step, let's redo the <code>view_account</code> call we did with raw <code>httpie</code>
with <code>near-cli</code>:</p>
<pre><code class="language-console">$ NEAR_ENV=local near state test.near
Loaded master account test.near key from ~/.near/validator_key.json with public key = ed25519:71QRP9qKcYRUYXTLNnrmRc1NZSdBaBo9nKZ88DK5USNf
Account test.near
{
  amount: '1000000000000000000000000000000000',
  block_hash: 'ESGN7H1kVLp566CTQ9zkBocooUFWNMhjKwqHg4uCh2Sg',
  block_height: 2110,
  code_hash: '11111111111111111111111111111111',
  locked: '50005124762657986708532525400812',
  storage_paid_at: 0,
  storage_usage: 182,
  formattedAmount: '1,000,000,000'
}
</code></pre>
<p><code>NEAR_ENV=local</code> tells <code>near-cli</code> to use our local network, rather than the
<code>mainnet</code>.</p>
<p>Now, let's create a couple of accounts and send tokes between them:</p>
<pre><code>$ NEAR_ENV=local near create-account alice.test.near --masterAccount test.near
NOTE: In most cases, when connected to network &quot;local&quot;, masterAccount will end in &quot;.node0&quot;
Loaded master account test.near key from /home/matklad/.near/validator_key.json with public key = ed25519:71QRP9qKcYRUYXTLNnrmRc1NZSdBaBo9nKZ88DK5USNf
Saving key to 'undefined/local/alice.test.near.json'
Account alice.test.near for network &quot;local&quot; was created.

$ NEAR_ENV=local near create-account bob.test.near --masterAccount test.near
NOTE: In most cases, when connected to network &quot;local&quot;, masterAccount will end in &quot;.node0&quot;
Loaded master account test.near key from /home/matklad/.near/validator_key.json with public key = ed25519:71QRP9qKcYRUYXTLNnrmRc1NZSdBaBo9nKZ88DK5USNf
Saving key to 'undefined/local/bob.test.near.json'
Account bob.test.near for network &quot;local&quot; was created.

$ NEAR_ENV=local near send alice.test.near bob.test.near 10
Sending 10 NEAR to bob.test.near from alice.test.near
Loaded master account test.near key from /home/matklad/.near/validator_key.json with public key = ed25519:71QRP9qKcYRUYXTLNnrmRc1NZSdBaBo9nKZ88DK5USNf
Transaction Id BBPndo6gR4X8pzoDK7UQfoUXp5J8WDxkf8Sq75tK5FFT
To see the transaction in the transaction explorer, please open this url in your browser
http://localhost:9001/transactions/BBPndo6gR4X8pzoDK7UQfoUXp5J8WDxkf8Sq75tK5FFT
</code></pre>
<p><strong>Note:</strong> You can export the variable <code>NEAR_ENV</code> in your shell if you are planning
to do multiple commands to avoid repetition:</p>
<pre><code class="language-console">export NEAR_ENV=local
</code></pre>
<p>NEAR CLI printouts are not always the most useful or accurate, but this seems to
work.</p>
<p>Note that <code>near</code> automatically creates keypairs and stores them at
<code>.near-credentials</code>:</p>
<pre><code class="language-console">$ ls ~/.near-credentials/local
  alice.test.near.json
  bob.test.near.json
</code></pre>
<p>To verify that this did work, and that <code>near-cli</code> didn't cheat us, let's
query the state of accounts manually:</p>
<pre><code class="language-console">$ http post http://localhost:3030/ method=query jsonrpc=2.0 id=1 \
    params:='{&quot;request_type&quot;: &quot;view_account&quot;, &quot;finality&quot;: &quot;final&quot;, &quot;account_id&quot;: &quot;alice.test.near&quot;}' \
    | jq '.result.amount'
&quot;89999955363487500000000000&quot;

14:30:52|~
Î» http post http://localhost:3030/ method=query jsonrpc=2.0 id=1 \
    params:='{&quot;request_type&quot;: &quot;view_account&quot;, &quot;finality&quot;: &quot;final&quot;, &quot;account_id&quot;: &quot;bob.test.near&quot;}' \
    | jq '.result.amount'
&quot;110000000000000000000000000&quot;
</code></pre>
<p>Indeed, some amount of tokes was transferred from <code>alice</code> to <code>bob</code>, and then
some amount of tokens was deducted to account for transaction fees.</p>
<h2 id="recap"><a class="header" href="#recap">Recap</a></h2>
<p>Great! So we've learned how to run our very own single-node NEAR network using a
binary we've built from source. The steps are:</p>
<ul>
<li>Create configs with <code>cargo run --profile dev-release -p neard -- init</code></li>
<li>Run the node with <code>cargo run --profile dev-release -p neard -- run</code></li>
<li>Poke the node with <code>httpie</code> or</li>
<li>Install <code>near-cli</code> via <code>npm install -g near-cli@3.4.2</code></li>
<li>Submit transactions via <code>NEAR_ENV=local near create-account ...</code></li>
</ul>
<p>In the <a href="practices/workflows/./deploy_a_contract.html">next chapter</a>, we'll learn how to deploy a simple
WASM contract.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<!-- cspell:ignore EPGUSUV Vaddhcdr cdylib matklad rodata rwxr syscalls -->
<h1 id="deploy-a-contract"><a class="header" href="#deploy-a-contract">Deploy a Contract</a></h1>
<p>In this chapter, we'll learn how to build, deploy, and call a minimal smart
contract on our local node.</p>
<h2 id="preparing-ground"><a class="header" href="#preparing-ground">Preparing Ground</a></h2>
<p>Let's start with creating a fresh local network with an account to which we'll
deploy a contract. You might want to re-read <a href="practices/workflows/./run_a_node.html">how to run a node</a>
to understand what's going on here:</p>
<pre><code class="language-console">cargo run --profile dev-release -p neard -- init
cargo run --profile dev-release -p neard -- run
NEAR_ENV=local near create-account alice.test.near --masterAccount test.near
</code></pre>
<p>As a sanity check, querying the state of <code>alice.test.near</code> account should work:</p>
<pre><code class="language-console">$ NEAR_ENV=local near state alice.test.near
Loaded master account test.near key from /home/matklad/.near/validator_key.json with public key = ed25519:7tU4NtFozPWLotcfhbT9KfBbR3TJHPfKJeCri8Me6jU7
Account alice.test.near
{
  amount: '100000000000000000000000000',
  block_hash: 'EEMiLrk4ZiRzjNJXGdhWPJfKXey667YBnSRoJZicFGy9',
  block_height: 24,
  code_hash: '11111111111111111111111111111111',
  locked: '0',
  storage_paid_at: 0,
  storage_usage: 182,
  formattedAmount: '100'
}
</code></pre>
<h2 id="minimal-contract"><a class="header" href="#minimal-contract">Minimal Contract</a></h2>
<p>NEAR contracts are <a href="https://webassembly.org">WebAssembly</a> blobs of bytes. To
create a contract, a contract developer typically uses an SDK for some
high-level programming language, such as JavaScript, which takes care of
producing the right <code>.wasm</code>.</p>
<p>In this guide, we are interested in how things work under the hood, so we'll
do everything manually, and implement a contract in Rust without any help from
SDKs.</p>
<p>As we are looking for something simple, let's create a contract with a single
&quot;method&quot;, <code>hello</code>, which returns a <code>&quot;hello world&quot;</code> string. To &quot;define a method&quot;,
a wasm module should export a function. To &quot;return a value&quot;, the contract needs
to interact with the environment to say &quot;hey, this is the value I am returning&quot;.
Such &quot;interactions&quot; are carried through host functions, which are quite a bit
like syscalls in traditional operating systems.</p>
<p>The set of host functions that the contract can import is defined in
<a href="https://github.com/near/nearcore/blob/aeccaaab334275f6d0a62deabd184675bc3c6a23/runtime/near-vm-runner/src/imports.rs#L71-L242"><code>imports.rs</code></a>.</p>
<p>In this particular case, we need the <code>value_return</code> function:</p>
<pre><code>value_return&lt;[value_len: u64, value_ptr: u64] -&gt; []&gt;
</code></pre>
<p>This means that the <code>value_return</code> function takes a pointer to a slice of bytes,
the length of the slice, and returns nothing. If the contract calls this function,
the slice would be considered a result of the function.</p>
<p>To recap, we want to produce a <code>.wasm</code> file with roughly the following content:</p>
<pre><code class="language-wasm">(module
  (import &quot;env&quot; &quot;value_return&quot; (func $value_return (param i64 i64)))
  (func (export &quot;hello&quot;) ... ))
</code></pre>
<h2 id="cargo-boilerplate"><a class="header" href="#cargo-boilerplate">Cargo Boilerplate</a></h2>
<p>Armed with this knowledge, we can write Rust code to produce the required WASM.
Before we start doing that, some amount of setup code is required.</p>
<p>Let's start with creating a new crate:</p>
<pre><code class="language-console">cargo new hello-near --lib
</code></pre>
<p>To compile to wasm, we also need to add a relevant rustup toolchain:</p>
<pre><code class="language-console">rustup toolchain add wasm32-unknown-unknown
</code></pre>
<p>Then, we need to tell Cargo that the final artifact we want to get is a
WebAssembly module.</p>
<p>This requires the following cryptic spell in Cargo.toml:</p>
<pre><code class="language-toml"># hello-near/Cargo.toml

[lib]
crate-type = [&quot;cdylib&quot;]
</code></pre>
<p>Here, we ask Cargo to build a &quot;C dynamic library&quot;. When compiling for wasm,
that'll give us a <code>.wasm</code> module. This part is a bit confusing, sorry about
that :(</p>
<p>Next, as we are aiming for minimalism here, we need to disable optional bits
of the Rust runtime. Namely, we want to make our crate <code>no_std</code> (this means
that we are not going to use the Rust standard library), set <code>panic=abort</code>
as our panic strategy and define a panic handler to abort execution.</p>
<pre><code class="language-toml"># hello-near/Cargo.toml

[package]
name = &quot;hello-near&quot;
version = &quot;0.1.0&quot;
edition = &quot;2024&quot;

[lib]
crate-type = [&quot;cdylib&quot;]

[profile.release]
panic = &quot;abort&quot;
</code></pre>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// hello-near/src/lib.rs

#![no_std]

#[panic_handler]
fn panic_handler(_info: &amp;core::panic::PanicInfo) -&gt; ! {
    core::arch::wasm32::unreachable()
}
<span class="boring">}
</span></code></pre></pre>
<p>At this point, we should be able to compile our code to wasm, and it should be
fairly small. Let's do that:</p>
<pre><code class="language-console">$ cargo b -r --target wasm32-unknown-unknown
   Compiling hello-near v0.1.0 (~/hello-near)
    Finished release [optimized] target(s) in 0.24s
$ ls target/wasm32-unknown-unknown/release/hello_near.wasm
.rwxr-xr-x 106 matklad 15 Nov 15:34 target/wasm32-unknown-unknown/release/hello_near.wasm
</code></pre>
<p>106 bytes is pretty small! Let's see what's inside. For that, we'll use
the <code>wasm-tools</code> suite of CLI utilities.</p>
<pre><code class="language-console">$ cargo install wasm-tools
Î» wasm-tools print target/wasm32-unknown-unknown/release/hello_near.wasm
(module
  (memory (;0;) 16)
  (global $__stack_pointer (;0;) (mut i32) i32.const 1048576)
  (global (;1;) i32 i32.const 1048576)
  (global (;2;) i32 i32.const 1048576)
  (export &quot;memory&quot; (memory 0))
  (export &quot;__data_end&quot; (global 1))
  (export &quot;__heap_base&quot; (global 2))
)
</code></pre>
<h2 id="rust-contract"><a class="header" href="#rust-contract">Rust Contract</a></h2>
<p>Finally, let's implement an actual contract. We'll need an <code>extern &quot;C&quot;</code> block to
declare the <code>value_return</code> import, and a <code>#[unsafe(no_mangle)] extern &quot;C&quot;</code> function to
declare the <code>hello</code> export:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// hello-near/src/lib.rs

#![no_std]

unsafe extern &quot;C&quot; {
    fn value_return(len: u64, ptr: u64);
}

#[unsafe(no_mangle)]
pub extern &quot;C&quot; fn hello() {
    let msg = &quot;hello world&quot;;
    unsafe { value_return(msg.len() as u64, msg.as_ptr() as u64) }
}

#[panic_handler]
fn panic_handler(_info: &amp;core::panic::PanicInfo) -&gt; ! {
    core::arch::wasm32::unreachable()
}
<span class="boring">}
</span></code></pre></pre>
<p>After building the contract, the output wasm shows us that it's roughly what we
want:</p>
<pre><code class="language-console">$ cargo b -r --target wasm32-unknown-unknown
   Compiling hello-near v0.1.0 (/home/matklad/hello-near)
    Finished release [optimized] target(s) in 0.05s
$ wasm-tools print target/wasm32-unknown-unknown/release/hello_near.wasm
(module
  (type (;0;) (func (param i64 i64)))
  (type (;1;) (func))
  (import &quot;env&quot; &quot;value_return&quot;        (; &lt;- Here's our import. ;)
    (func $value_return (;0;) (type 0)))
  (func $hello (;1;) (type 1)
    i64.const 11
    i32.const 1048576
    i64.extend_i32_u
    call $value_return
  )
  (memory (;0;) 17)
  (global $__stack_pointer (;0;) (mut i32) i32.const 1048576)
  (global (;1;) i32 i32.const 1048587)
  (global (;2;) i32 i32.const 1048592)
  (export &quot;memory&quot; (memory 0))
  (export &quot;hello&quot; (func $hello))      (; &lt;- And export! ;)
  (export &quot;__data_end&quot; (global 1))
  (export &quot;__heap_base&quot; (global 2))
  (data $.rodata (;0;) (i32.const 1048576) &quot;hello world&quot;)
)
</code></pre>
<h2 id="deploying-the-contract"><a class="header" href="#deploying-the-contract">Deploying the Contract</a></h2>
<p>Now that we have the WASM, let's deploy it!</p>
<pre><code class="language-console">$ NEAR_ENV=local near deploy alice.test.near \
    ./target/wasm32-unknown-unknown/release/hello_near.wasm
Loaded master account test.near key from /home/matklad/.near/validator_key.json with public key = ed25519:ChLD1qYic3G9qKyzgFG3PifrJs49CDYeERGsG58yaSoL
Starting deployment. Account id: alice.test.near, node: http://127.0.0.1:3030, helper: http://localhost:3000, file: ./target/wasm32-unknown-unknown/release/hello_near.wasm
Transaction Id GDbTLUGeVaddhcdrQScVauYvgGXxSssEPGUSUVAhMWw8
To see the transaction in the transaction explorer, please open this url in your browser
http://localhost:9001/transactions/GDbTLUGeVaddhcdrQScVauYvgGXxSssEPGUSUVAhMWw8
Done deploying to alice.test.near
</code></pre>
<p>And, finally, let's call our contract:</p>
<pre><code class="language-console">$ NEAR_ENV=local near call alice.test.near hello --accountId alice.test.near
Scheduling a call: alice.test.near.hello()
Loaded master account test.near key from /home/matklad/.near/validator_key.json with public key = ed25519:ChLD1qYic3G9qKyzgFG3PifrJs49CDYeERGsG58yaSoL
Doing account.functionCall()
Transaction Id 9WMwmTf6pnFMtj1KBqjJtkKvdFXS4kt3DHnYRnbFpJ9e
To see the transaction in the transaction explorer, please open this url in your browser
http://localhost:9001/transactions/9WMwmTf6pnFMtj1KBqjJtkKvdFXS4kt3DHnYRnbFpJ9e
'hello world'
</code></pre>
<p>Note that we pass <code>alice.test.near</code> twice: the first time to specify which contract
we are calling, the second time to determine who calls the contract. That is,
the second account is the one that spends tokens. In the following example <code>bob</code>
spends NEAR to call the contact deployed to the <code>alice</code> account:</p>
<pre><code class="language-console">$ NEAR_ENV=local near call alice.test.near hello --accountId bob.test.near
Scheduling a call: alice.test.near.hello()
Loaded master account test.near key from /home/matklad/.near/validator_key.json with public key = ed25519:ChLD1qYic3G9qKyzgFG3PifrJs49CDYeERGsG58yaSoL
Doing account.functionCall()
Transaction Id 4vQKtP6zmcR4Xaebw8NLF6L5YS96gt5mCxc5BUqUcC41
To see the transaction in the transaction explorer, please open this url in your browser
http://localhost:9001/transactions/4vQKtP6zmcR4Xaebw8NLF6L5YS96gt5mCxc5BUqUcC41
'hello world'
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="running-the-estimator"><a class="header" href="#running-the-estimator">Running the Estimator</a></h1>
<p>This workflow describes how to run the gas estimator byzantine-benchmark suite.
To learn about its background and purpose, refer to <a href="practices/workflows/../../architecture/gas/estimator.html">Runtime Parameter
Estimator</a> in the architecture chapter.</p>
<p>Type this in your console to quickly run estimations on a couple of action costs.</p>
<pre><code class="language-bash">cargo run -p runtime-params-estimator --features required -- \
    --accounts-num 20000 --additional-accounts-num 20000 \
    --iters 3 --warmup-iters 1 --metric time \
    --costs=ActionReceiptCreation,ActionTransfer,ActionCreateAccount,ActionFunctionCallBase
</code></pre>
<p>You should get an output like this.</p>
<pre><code>[elapsed 00:00:17 remaining 00:00:00] Writing into storage â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   20000/20000
ActionReceiptCreation         4_499_673_502_000 gas [  4.499674ms]    (computed in 7.22s)
ActionTransfer                  410_122_090_000 gas [   410.122Âµs]    (computed in 4.71s)
ActionCreateAccount             237_495_890_000 gas [   237.496Âµs]    (computed in 4.64s)
ActionFunctionCallBase          770_989_128_914 gas [   770.989Âµs]    (computed in 4.65s)


Finished in 40.11s, output saved to:

    /home/you/near/nearcore/costs-2022-11-11T11:11:11Z-e40863c9b.txt
</code></pre>
<p>This shows how much gas a parameter should cost to satisfy the 1ms = 1Tgas rule.
It also shows how much time that corresponds to and how long it took to compute
each of the estimations.</p>
<p>Note that the above does not produce very accurate results and it can have high
variance as well. It runs an unoptimized binary, the state is small, and the
metric used is wall-clock time which is always prone to variance in hardware and
can be affected by other processes currently running on your system.</p>
<p>Once your estimation code is ready, it is better to run it with a larger state
and an optimized binary.</p>
<pre><code class="language-bash">cargo run --release -p runtime-params-estimator --features required -- \
    --accounts-num 20000 --additional-accounts-num 2000000 \
    --iters 3 --warmup-iters 1 --metric time \
    --costs=ActionReceiptCreation,ActionTransfer,ActionCreateAccount,ActionFunctionCallBase
</code></pre>
<p>You might also want to run a hardware-agnostic estimation using the following
command. It uses <code>podman</code> and <code>qemu</code> under the hood, so it will be quite a bit
slower. You will need to install <code>podman</code> to run this command.</p>
<pre><code class="language-bash">cargo run --release -p runtime-params-estimator --features required -- \
    --accounts-num 20000 --additional-accounts-num 2000000 \
    --iters 3 --warmup-iters 1 --metric icount --containerize \
    --costs=ActionReceiptCreation,ActionTransfer,ActionCreateAccount,ActionFunctionCallBase
</code></pre>
<p>Note how the output looks a bit different now. The <code>i</code>, <code>r</code> and <code>w</code> values show
instruction count, read IO bytes, and write IO bytes respectively. The IO byte
count is known to be inaccurate.</p>
<!-- cspell:ignore libcounter Haswell -->
<pre><code>+ /host/nearcore/runtime/runtime-params-estimator/emu-cost/counter_plugin/qemu-x86_64 -plugin file=/host/nearcore/runtime/runtime-params-estimator/emu-cost/counter_plugin/libcounter.so -cpu Haswell-v4 /host/nearcore/target/release/runtime-params-estimator --home /.near --accounts-num 20000 --iters 3 --warmup-iters 1 --metric icount --costs=ActionReceiptCreation,ActionTransfer,ActionCreateAccount,ActionFunctionCallBase --skip-build-test-contract --additional-accounts-num 0 --in-memory-db
ActionReceiptCreation         214_581_685_500 gas [  1716653.48i 0.00r 0.00w]     (computed in 6.11s)
ActionTransfer                 21_528_212_916 gas [   172225.70i 0.00r 0.00w]     (computed in 4.71s)
ActionCreateAccount            26_608_336_250 gas [   212866.69i 0.00r 0.00w]     (computed in 4.67s)
ActionFunctionCallBase         12_193_364_898 gas [    97546.92i 0.00r 0.00w]     (computed in 2.39s)


Finished in 17.92s, output saved to:

    /host/nearcore/costs-2022-11-01T16:27:36Z-e40863c9b.txt
</code></pre>
<p>The difference between the metrics is discussed in the <a href="practices/workflows/../../architecture/gas/estimator.html#estimation-metrics">Estimation
Metrics</a> chapter.</p>
<p>You should now be all set up for running estimations on your local machine. Also,
check <code>cargo run -p runtime-params-estimator --features required -- --help</code> for
the list of available options.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="running-near-localnet-on-2-machines"><a class="header" href="#running-near-localnet-on-2-machines">Running near localnet on 2 machines</a></h1>
<p>Quick instructions on how to run a localnet on 2 separate machines.</p>
<h2 id="setup"><a class="header" href="#setup">Setup</a></h2>
<ul>
<li>Machine1: &quot;pc&quot; - 192.168.0.1</li>
<li>Machine2: &quot;laptop&quot; - 192.168.0.2</li>
</ul>
<p>Run on both machines (make sure that they are using the same version of the code):</p>
<pre><code>cargo build -p neard
</code></pre>
<p>Then on machine1 run the command below, which will generate the configurations:</p>
<pre><code>./target/debug/neard --home ~/.near/localnet_multi localnet --shards 3 --v 2
</code></pre>
<p>This command has generated configuration for 3 shards and 2 validators (in directories ~/.near/localnet_multi/node0 and ~/.near/localnet_multi/node1).</p>
<p>Now - copy the contents of node1 directory to the machine2</p>
<pre><code>rsync -r ~/.near/localnet_multi/node1 192.168.0.2:~/.near/localnet_multi/node1
</code></pre>
<p>Now open the config.json file on both machines (node0/config.json on machine1 and node1/config.json on machine2) and:</p>
<ul>
<li>for rpc-&gt;addr and network-&gt;addr:
<ul>
<li>Change the address from 127.0.0.1 to 0.0.0.0 (this means that the port will be accessible from other computers)</li>
<li>Remember the port numbers (they are generated randomly).</li>
</ul>
</li>
<li>Also write down the node0's node_key (it is probably: &quot;ed25519:7PGseFbWxvYVgZ89K1uTJKYoKetWs7BJtbyXDzfbAcqX&quot;)</li>
</ul>
<h2 id="running"><a class="header" href="#running">Running</a></h2>
<p>On machine1:</p>
<pre><code>./target/debug/neard --home ~/.near/localnet_multi/node0 run
</code></pre>
<p>On machine2:</p>
<pre><code>./target/debug/neard --home ~/.near/localnet_multi/node1 run --boot-nodes ed25519:7PGseFbWxvYVgZ89K1uTJKYoKetWs7BJtbyXDzfbAcqX@192.168.0.1:37665
</code></pre>
<p>The boot node address should be the IP of the machine1 + the network addr port <strong>from the node0/config.json</strong></p>
<p>And if everything goes well, the nodes should communicate and start producing blocks.</p>
<h2 id="troubleshooting"><a class="header" href="#troubleshooting">Troubleshooting</a></h2>
<p>The debug mode is enabled by default, so you should be able to see what's going on by going to <code>http://machine1:RPC_ADDR_PORT/debug</code></p>
<h3 id="if-node-keeps-saying-waiting-for-peers"><a class="header" href="#if-node-keeps-saying-waiting-for-peers">If node keeps saying &quot;waiting for peers&quot;</a></h3>
<p>See if you can see the machine1's debug page from machine2. (if not - there might be a firewall blocking the connection).</p>
<p>Make sure that you set the right ports (it should use node0's NETWORK port) and that you set the ip add there to 0.0.0.0</p>
<h3 id="resetting-the-state"><a class="header" href="#resetting-the-state">Resetting the state</a></h3>
<p>Simply stop both nodes, and remove the <code>data</code> subdirectory (~/.near/localnet_multi/node0/data and ~/.near/localnet_multi/node1/data).</p>
<p>Then after restart, the nodes will start the blockchain from scratch.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="io-tracing"><a class="header" href="#io-tracing">IO tracing</a></h1>
<h2 id="when-should-i-use-io-traces"><a class="header" href="#when-should-i-use-io-traces">When should I use IO traces?</a></h2>
<p>IO traces can be used to identify slow receipts and to understand why they
are slow. Or to detect general inefficiencies in how we use the DB.</p>
<p>The results give you counts of DB requests and some useful statistics such as
trie node cache hits. It will NOT give you time measurements, use Grafana to
observe those.</p>
<p>The main use cases in the past were to estimate the performance of new storage
features (prefetcher, flat state) and to find out why specific contracts produce
slow receipts.</p>
<h2 id="setup-1"><a class="header" href="#setup-1">Setup</a></h2>
<p>When compiling neard (or the parameter estimator) with <code>feature=io_trace</code> it
instruments the binary code with fine-grained database operations tracking.</p>
<p><em>Aside: We don't enable it by default because we are afraid the overhead could be
too much, since we store some information for very hot paths such as trie node
cache hits. Although we haven't properly evaluated if it really is a performance
problem.</em></p>
<p>This allows using the <code>--record-io-trace=/path/to/output.io_trace</code> CLI flag on
neard. Run it in combination with the subcommands <code>neard run</code>, <code>neard view-state</code>, or <code>runtime-params-estimator</code> and it will record an IO trace. Make
sure to provide the flag to <code>neard</code> itself, however, not to the subcommands.
(See examples below)</p>
<pre><code class="language-bash"># Example command for normal node
# (Careful! This will quickly fill your disk if you let it run.)
cargo build --release -p neard --features=io_trace
target/release/neard \
    --record-io-trace=/mnt/disks/some_disk_with_enough_space/my.io_trace \
    run
</code></pre>
<pre><code class="language-bash"># Example command for state viewer, applying a range of chunks in shard 0
cargo build --release -p neard --features=io_trace
target/release/neard \
    --record-io-trace=75220100-75220101.s0.io_trace \
    view-state apply-range --start-index 75220100 --end-index 75220101 \
    --shard-id 0 sequential
</code></pre>
<pre><code class="language-bash"># Example command for params estimator
cargo run --release -p runtime-params-estimator --features=required,io_trace \
-- --accounts-num 200000 --additional-accounts-num 200000 \
--iters 3 --warmup-iters 1 --metric time \
--record-io-trace=tmp.io \
--costs ActionReceiptCreation
</code></pre>
<h2 id="io-trace-content"><a class="header" href="#io-trace-content">IO trace content</a></h2>
<p>Once you have collected an IO trace, you can inspect its content manually, or
use existing tools to extract statistics. Let's start with the manual approach.</p>
<h3 id="simple-example-trace-estimator"><a class="header" href="#simple-example-trace-estimator">Simple example trace: Estimator</a></h3>
<p>An estimator trace typically starts something like this:</p>
<pre><code>commit
  SET DbVersion &quot;'VERSION'&quot; size=2
commit
  SET DbVersion &quot;'KIND'&quot; size=3
apply num_transactions=0 shard_cache_miss=7
  GET State &quot;AAAAAAAAAAB3I0MYevRcExi1ql5PSQX+fuObsPH30yswS7ytGPCgyw==&quot; size=46
  GET State &quot;AAAAAAAAAACGDsmYvNoBGZnc8PzDKoF4F2Dvw3N6XoAlRrg8ezA8FA==&quot; size=107
  GET State &quot;AAAAAAAAAAB3I0MYevRcExi1ql5PSQX+fuObsPH30yswS7ytGPCgyw==&quot; size=46
  GET State &quot;AAAAAAAAAACGDsmYvNoBGZnc8PzDKoF4F2Dvw3N6XoAlRrg8ezA8FA==&quot; size=107
  GET State &quot;AAAAAAAAAAB3I0MYevRcExi1ql5PSQX+fuObsPH30yswS7ytGPCgyw==&quot; size=46
  GET State &quot;AAAAAAAAAACGDsmYvNoBGZnc8PzDKoF4F2Dvw3N6XoAlRrg8ezA8FA==&quot; size=107
  GET State &quot;AAAAAAAAAAB3I0MYevRcExi1ql5PSQX+fuObsPH30yswS7ytGPCgyw==&quot; size=46
...
</code></pre>
<p>Depending on the source, traces look a bit different at the start. But you
should always see some setup at the beginning and per-chunk workload later on.</p>
<p>Indentation is used to display the call hierarchy. The <code>commit</code> keyword shows
when a commit starts, and all <code>SET</code> and <code>UPDATE_RC</code> commands that follow with
one level deeper indentation belong to that same database transaction commit.</p>
<p>Later, you see a group that starts with an <code>apply</code> header. It groups all IO
requests that were performed for a call to <a href="https://github.com/near/nearcore/blob/d38c94ac8e78a5a71c592125dfd47803beff58ce/runtime/runtime/src/lib.rs#L1172"><code>fn apply</code></a>
that applies transactions and receipts of a chunk to the previous state root.</p>
<p>In the example, you see a list of <code>GET</code> requests that belong to that <code>apply</code>,
each with the DB key used and the size of the value read. Further, you can read
in the trace that this specific chunk had 0 transactions and that it
cache-missed all 7 of the DB requests it performed to apply this empty chunk.</p>
<h3 id="example-trace-full-mainnet-node"><a class="header" href="#example-trace-full-mainnet-node">Example trace: Full mainnet node</a></h3>
<!-- cspell:ignore Gxlb -->
<p>Next let's look at an excerpt of an IO trace from a real node on mainnet.</p>
<pre><code>...
GET State &quot;AQAAAAMAAACm9DRx/dU8UFEfbumiRhDjbPjcyhE6CB1rv+8fnu81bw==&quot; size=9
GET State &quot;AQAAAAAAAACLFgzRCUR3inMDpkApdLxFTSxRvprJ51eMvh3WbJWe0A==&quot; size=203
GET State &quot;AQAAAAIAAACXlEo0t345S6PHsvX1BLaGw6NFDXYzeE+tlY2srjKv8w==&quot; size=299
apply_transactions shard_id=3
  process_state_update 
    apply num_transactions=3 shard_cache_hit=207
      process_transaction tx_hash=C4itKVLP5gBoAPsEXyEbi67Gg5dvQVugdMjrWBBLprzB shard_cache_hit=57
        GET FlatState &quot;AGxlb25hcmRvX2RheS12aW5jaGlrLm5lYXI=&quot; size=36
        GET FlatState &quot;Amxlb25hcmRvX2RheS12aW5jaGlrLm5lYXICANLByB1merOzxcGB1HI9/L60QvONzOE6ovF3hjYUbhA8&quot; size=36
      process_transaction tx_hash=GRSXC4QCBJHN4hmJiATAbFGt9g5PiksQDNNRaSk666WX shard_cache_miss=3 prefetch_pending=3 shard_cache_hit=35
        GET FlatState &quot;AnJlbGF5LmF1cm9yYQIA5iq407bcLgisCKxQQi47TByaFNe9FOgQg5y2gpU4lEM=&quot; size=36
      process_transaction tx_hash=6bDPeat12pGqA3KEyyg4tJ35kBtRCuFQ7HtCpWoxr8qx shard_cache_miss=2 prefetch_pending=1 shard_cache_hit=21 prefetch_hit=1
        GET FlatState &quot;AnJlbGF5LmF1cm9yYQIAyKT1vEHVesMEvbp2ICA33x6zxfmBJiLzHey0ZxauO1k=&quot; size=36
      process_receipt receipt_id=GRB3skohuShBvdGAoEoR3SdJJw7MwCxxscJHKLdPoYUC predecessor=1663adeba849fb7c26195678e1c5378278e5caa6325d4672246821d8e61bb160 receiver=token.sweat id=GRB3skohuShBvdGAoEoR3SdJJw7MwCxxscJHKLdPoYUC shard_cache_too_large=1 shard_cache_miss=1 shard_cache_hit=38
        GET FlatState &quot;AXRva2VuLnN3ZWF0&quot; size=36
        GET State &quot;AQAAAAMAAADVYp4vtlIbDoVhji22CZOEaxVWVTJKASq3iMvpNEQVDQ==&quot; size=206835
        input 
        register_len 
        read_register 
        storage_read READ key='STATE' size=70 tn_db_reads=20 tn_mem_reads=0 shard_cache_hit=21
        register_len 
        read_register 
        attached_deposit 
        predecessor_account_id 
        register_len 
        read_register 
        sha256 
        read_register 
        storage_read READ key=dAAxagYMOEb01+56sl9vOM0yHbZRPSaYSL3zBXIfCOi7ow== size=16 tn_db_reads=10 tn_mem_reads=19 shard_cache_hit=11
          GET FlatState &quot;CXRva2VuLnN3ZWF0LHQAMWoGDDhG9NfuerJfbzjNMh22UT0mmEi98wVyHwjou6M=&quot; size=36
        register_len 
        read_register 
        sha256 
        read_register 
        storage_write WRITE key=dAAxagYMOEb01+56sl9vOM0yHbZRPSaYSL3zBXIfCOi7ow== size=16 tn_db_reads=0 tn_mem_reads=30
        ...
</code></pre>
<p>Maybe that's a bit much. Let's break it down into pieces.</p>
<p>It start with a few DB get requests that are outside of applying a chunk. It's
quite common that we have these kinds of constant overhead requests that are
independent of what's inside a chunk. If we see too many such requests, we
should take a close look to see if we are wasting performance.</p>
<pre><code>GET State &quot;AQAAAAMAAACm9DRx/dU8UFEfbumiRhDjbPjcyhE6CB1rv+8fnu81bw==&quot; size=9
GET State &quot;AQAAAAAAAACLFgzRCUR3inMDpkApdLxFTSxRvprJ51eMvh3WbJWe0A==&quot; size=203
GET State &quot;AQAAAAIAAACXlEo0t345S6PHsvX1BLaGw6NFDXYzeE+tlY2srjKv8w==&quot; size=299
</code></pre>
<p>Next let's look at <code>apply_transactions</code> but limit the depth of items to 3
levels.</p>
<pre><code>apply_transactions shard_id=3
  process_state_update 
    apply num_transactions=3 shard_cache_hit=207
      process_transaction tx_hash=C4itKVLP5gBoAPsEXyEbi67Gg5dvQVugdMjrWBBLprzB shard_cache_hit=57
      process_transaction tx_hash=GRSXC4QCBJHN4hmJiATAbFGt9g5PiksQDNNRaSk666WX shard_cache_miss=3 prefetch_pending=3 shard_cache_hit=35
      process_transaction tx_hash=6bDPeat12pGqA3KEyyg4tJ35kBtRCuFQ7HtCpWoxr8qx shard_cache_miss=2 prefetch_pending=1 shard_cache_hit=21 prefetch_hit=1
      process_receipt receipt_id=GRB3skohuShBvdGAoEoR3SdJJw7MwCxxscJHKLdPoYUC predecessor=1663adeba849fb7c26195678e1c5378278e5caa6325d4672246821d8e61bb160 receiver=token.sweat id=GRB3skohuShBvdGAoEoR3SdJJw7MwCxxscJHKLdPoYUC shard_cache_too_large=1 shard_cache_miss=1 shard_cache_hit=38
</code></pre>
<p>Here you can see that before we even get to <code>apply</code>, we go through
<code>apply_transactions</code> and <code>process_state_update</code>. The excerpt does not show it
but there are DB requests listed further below that belong to these levels but
not to <code>apply</code>.</p>
<p>Inside <code>apply</code>, we see 3 transactions being converted to receipts as part of
this chunk, and one already existing action receipt getting processed.</p>
<p>Cache hit statistics for each level are also displayed. For example, the first
transaction has 57 read requests and all of them hit in the shard cache. For
the second transaction, we miss the cache 3 times but the values were already in the
process of being prefetched. This would be account data which we fetch in
parallel for all transactions in the chunk.</p>
<p>Finally, there are several <code>process_receipt</code> groups, although the excerpt was
cut to display only one. Here we see the receiving account
(<code>receiver=token.sweat</code>) and the receipt ID to potentially look it up on an
explorer, or dig deeper using state viewer commands.</p>
<p>Again, cache hit statistics are included. Here you can see one value
missed the cache because it was too large. Usually that's a contract code. We do
not include it in the shard cache because it would take up too much space.</p>
<p>Zooming in a bit further, let's look at the DB request at the start of the
receipt.</p>
<pre><code>    GET FlatState &quot;AXRva2VuLnN3ZWF0&quot; size=36
    GET State &quot;AQAAAAMAAADVYp4vtlIbDoVhji22CZOEaxVWVTJKASq3iMvpNEQVDQ==&quot; size=206835
    input 
    register_len 
    read_register 
    storage_read READ key='STATE' size=70 tn_db_reads=20 tn_mem_reads=0 shard_cache_hit=21
    register_len 
    read_register 
</code></pre>
<p><code>FlatState &quot;AXRva2VuLnN3ZWF0&quot;</code> reads the <code>ValueRef</code> of the contract code, which
is 36 bytes in its serialized format. Then, the <code>ValueRef</code> is dereferenced to
read the actual code, which happens to be 206kB in size. This happens in the
<code>State</code> column because at the time of writing, we still read the actual values
from the trie, not from flat state.</p>
<p>What follows are host function calls performed by the SDK. It uses <code>input</code> to
check the function call arguments and copies it from a register into WASM
memory.</p>
<p>Then the SDK reads the serialized contract state from the hardcoded key
<code>&quot;STATE&quot;</code>. Note that we charge 20 <code>tn_db_reads</code> for it, since we missed the
accounting cache, but we hit everything in the shard cache. Thus, there are no DB
requests. If there were DB requests for this <code>tn_db_reads</code>, you would see them
listed.</p>
<p>The returned 70 bytes are again copied into WASM memory. Knowing the SDK code a
little bit, we can guess that the data is then deserialized into the struct used
by the contract for its root state. That's not visible on the trace though, as
this happens completely inside the WASM VM.</p>
<p>Next we start executing the actual contract code, which again calls a bunch of
host functions. Apparently the code starts by reading the attached deposit and
the predecessor account id, presumably to perform some checks.</p>
<p>The <code>sha256</code> call here is used to shorten implicit account ids.
(<a href="https://github.com/sweatco/near-sdk-rs/blob/af6ba3cb75e0bbfc26e346e61aa3a0d1d7f5ac7b/near-contract-standards/src/fungible_token/core_impl.rs#L249-L259">Link to code for comparison</a>).</p>
<!-- cspell:words Sweatcoin -->
<p>Afterwards, a value with 16 bytes (a <code>u128</code>) is fetched from the trie state.
To serve this, it required reading 30 trie nodes, 19 of them were cached in the
accounting cache and were not charged the full gas cost. And the remaining 11
missed the accounting cache but they hit the shard cache. Nothing needed to be
fetched from DB because the Sweatcoin specific prefetcher has already loaded
everything into the shard cache.</p>
<p><em>Note: We see trie node requests despite flat state being used. This is because
the trace was collected with a binary that performed a read on both the trie and
flat state to do some correctness checks.</em></p>
<pre><code>    attached_deposit 
    predecessor_account_id 
    register_len 
    read_register 
    sha256 
    read_register 
    storage_read READ key=dAAxagYMOEb01+56sl9vOM0yHbZRPSaYSL3zBXIfCOi7ow== size=16 tn_db_reads=10 tn_mem_reads=19 shard_cache_hit=11
        GET FlatState &quot;CXRva2VuLnN3ZWF0LHQAMWoGDDhG9NfuerJfbzjNMh22UT0mmEi98wVyHwjou6M=&quot; size=36
</code></pre>
<p>So that is how to read these traces and dig deep. But maybe you
want aggregated statistics instead? Then please continue reading.</p>
<h2 id="evaluating-an-io-trace"><a class="header" href="#evaluating-an-io-trace">Evaluating an IO trace</a></h2>
<p>When you collect an IO trace over an hour of mainnet traffic, it can quickly be
above 1GB in uncompressed size. You might be able to sample a few receipts and
eyeball them to get a feeling for what's going on. But you can't understand the
whole trace without additional tooling.</p>
<p>The parameter estimator command <code>replay</code> can help with that. (See also <a href="https://github.com/near/nearcore/tree/master/runtime/runtime-params-estimator/README.md">this
readme</a>)
Run the following command to see an overview of available commands.</p>
<pre><code class="language-bash"># will print the help page for the IO trace replay command
cargo run --profile dev-release -p runtime-params-estimator -- \
  replay --help
</code></pre>
<p>All commands aggregate the information of a trace. Either globally, per chunk,
or per receipt. For example, below is the output that gives a list of RocksDB
columns that were accessed and how many times, aggregated by chunk.</p>
<pre><code class="language-bash">cargo run --profile dev-release -p runtime-params-estimator -- \
  replay  ./path/to/my.io_trace  chunk-db-stats
</code></pre>
<pre><code>apply_transactions shard_id=3 block=DajBgxTgV8NewTJBsR5sTgPhVZqaEv9xGAKVnCiMiDxV
  GET   12 FlatState  4 State  

apply_transactions shard_id=0 block=DajBgxTgV8NewTJBsR5sTgPhVZqaEv9xGAKVnCiMiDxV
  GET   14 FlatState  8 State  

apply_transactions shard_id=2 block=HTptJFZKGfmeWs7y229df6WjMQ3FGfhiqsmXnbL2tpz8
  GET   2 FlatState  

apply_transactions shard_id=3 block=HTptJFZKGfmeWs7y229df6WjMQ3FGfhiqsmXnbL2tpz8
  GET   6 FlatState  2 State  

apply_transactions shard_id=1 block=HTptJFZKGfmeWs7y229df6WjMQ3FGfhiqsmXnbL2tpz8
  GET   50 FlatState  5 State  

...

apply_transactions shard_id=3 block=AUcauGxisMqNmZu5Ln7LLu8Li31H1sYD7wgd7AP6nQZR
  GET   17 FlatState  3 State  

top-level:
  GET   8854 Block  981 BlockHeader  16556 BlockHeight  59155 BlockInfo  2 BlockMerkleTree  330009 BlockMisc  1 BlockOrdinal  31924 BlockPerHeight  863 BlockRefCount  1609 BlocksToCatchup  1557 ChallengedBlocks  4 ChunkExtra  5135 ChunkHashesByHeight  128788 Chunks  35 EpochInfo  1 EpochStart  98361 FlatState  1150 HeaderHashesByHeight  8113 InvalidChunks  263 NextBlockHashes  22 OutgoingReceipts  131114 PartialChunks  1116 ProcessedBlockHeights  968698 State  
  SET   865 BlockHeight  1026 BlockMerkleTree  12428 BlockMisc  1636 BlockOrdinal  865 BlockPerHeight  865 BlockRefCount  3460 ChunkExtra  3446 ChunkHashesByHeight  339142 FlatState  3460 FlatStateDeltas  3460 FlatStateMisc  865 HeaderHashesByHeight  3460 IncomingReceipts  865 NextBlockHashes  3442 OutcomeIds  3442 OutgoingReceipts  863 ProcessedBlockHeights  340093 StateChanges  3460 TrieChanges  
</code></pre>
<p>The output contains one <code>apply_transactions</code> for each chunk, with the block hash
and the shard id. Then it prints one line for each DB operations observed
(GET,SET,...) together with a list of columns and an OP count.</p>
<p>See the <code>top-level</code> output at the end? These are all the DB requests that could
not be assigned to specific chunks. The way we currently count write operations
(SET, UPDATE_RC) they are never assigned to a specific chunk and instead only
show up in the top-level list. Clearly, there is some room for improvement here.
So far we simply haven't worried about RocksDB write performance so the tooling
to debug write performance is naturally lacking.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<!-- cspell:ignore Heaptrack Jemalloc bytehound highcpu jemallocator koute kptr libbytehound myexportedfile mylittleprofile read-write rgba setcap tikv -->
<h1 id="profiling-neard"><a class="header" href="#profiling-neard">Profiling neard</a></h1>
<h2 id="sampling-performance-profiling"><a class="header" href="#sampling-performance-profiling">Sampling performance profiling</a></h2>
<p>It is a common task to need to look where <code>neard</code> is spending time. Outside of instrumentation
we've also been successfully using sampling profilers to gain an intuition over how the code works
and where it spends time. It is a very quick way to get some baseline understanding of the
performance characteristics, but due to its probabilistic nature it is also not particularly precise
when it comes to small details.</p>
<p>Linux's <code>perf</code> has been a tool of choice in most cases, although tools like Intel VTune could be
used too. In order to use either, first prepare your system:</p>
<pre><code class="language-command">sudo sysctl kernel.perf_event_paranoid=0 kernel.kptr_restrict=0
</code></pre>
<blockquote style="background: rgba(255, 200, 0, 0.1); border: 5px solid rgba(255, 200, 0, 0.4);">
<p>Beware that this gives access to certain kernel state and environment to the unprivileged user.
Once investigation is over either set these properties back to the more restricted settings or,
better yet, reboot.</p>
<p>Definitely do not run untrusted code after running these commands.</p>
</blockquote>
<p>Then collect a profile as such:</p>
<!-- cspell: ignore ecpu esyscalls epoll esched -->
<pre><code class="language-command">$ perf record -ecpu-clock -esyscalls:sys_enter_{&quot;epoll_*wait*&quot;,&quot;futex_wait*&quot;,futex_wake,io_uring_enter,nanosleep,pause,&quot;*poll&quot;,&quot;*select*&quot;,sched_yield,&quot;wait*&quot;} -esched:sched_switch -F1000 -g --call-graph dwarf,65528 [YOUR_COMMAND_HERE]
# or attach to a running process:
$ perf record -ecpu-clock -esyscalls:sys_enter_{&quot;epoll_*wait*&quot;,&quot;futex_wait*&quot;,futex_wake,io_uring_enter,nanosleep,pause,&quot;*poll&quot;,&quot;*select*&quot;,sched_yield,&quot;wait*&quot;} -esched:sched_switch -F1000 -g --call-graph dwarf,65528 -p [NEARD_PID]
# possibly with a pre-specified collection duration
$ timeout 15 perf record -ecpu-clock -esyscalls:sys_enter_{&quot;epoll_*wait*&quot;,&quot;futex_wait*&quot;,futex_wake,io_uring_enter,nanosleep,pause,&quot;*poll&quot;,&quot;*select*&quot;,sched_yield,&quot;wait*&quot;} -esched:sched_switch -F1000 -g --call-graph dwarf,65528 -p [NEARD_PID]
</code></pre>
<p>This command will use the CPU time clock to determine when to trigger a sampling process and will
do such sampling roughly 1000 times (the <code>-F</code> argument) every CPU second. It will also sample a
selection of syscall entries as well as scheduler switches. Readers are encouraged to adjust the
events they record â€“ ones in the command above are a good baseline only.</p>
<p>Once terminated, this command will produce a profile file in the current working directory.
Although you can inspect the profile already with <code>perf report</code>, we've had much better experience
with using <a href="https://profiler.firefox.com/">Firefox Profiler</a> as the viewer. Although Firefox
Profiler supports <code>perf</code> and many other different data formats, for <code>perf</code> in particular a
conversion step is necessary. For ideal results with Firefox Profiler,
<a href="https://github.com/mstange/samply"><code>samply</code></a> is recommended, as it produces a much better
rendering than the <code>perf script</code> approach previously recommended by this and <a href="https://profiler.firefox.com/docs/#/./guide-perf-profiling">Firefox Profiler
documentation</a> alike.</p>
<pre><code class="language-command">$ cargo install samply
$ samply import -P 3333 perf.data
</code></pre>
<p>This will open a local server with a profiler UI. If profiling on a cloud machine, use a SSH proxy
to access this interface (you can start another ssh session):</p>
<pre><code>$ gcloud compute ssh --ssh-flag='-L 3333:localhost:3333' [OTHER_ARGS...]
# open localhost:3333 in your browser
</code></pre>
<p>From there you can inspect the profile locally and upload it to <code>profiler.firefox.com</code> for sharing
with others.</p>
<h3 id="low-overhead-stack-frame-collection"><a class="header" href="#low-overhead-stack-frame-collection">Low overhead stack frame collection</a></h3>
<p>The command above uses <code>-g --call-graph dwarf,65528</code> parameter to instruct <code>perf</code> to collect
stack trace for each sample using DWARF unwinding metadata. This will work no matter how <code>neard</code> is
built, but is expensive and not super precise (e.g. it has trouble with JIT code.) If you have an
ability to build a profiling-tuned build of <code>neard</code>, you can use higher quality stack frame
collection.</p>
<pre><code class="language-command">cargo build --release --config .cargo/config.profiling.toml -p neard
</code></pre>
<p>Then, replace the <code>--call-graph dwarf</code> with <code>--call-graph fp</code>:</p>
<pre><code class="language-command">perf record -ecpu-clock -esyscalls:sys_enter_{&quot;epoll_*wait*&quot;,&quot;futex_wait*&quot;,futex_wake,io_uring_enter,nanosleep,pause,&quot;*poll&quot;,&quot;*select*&quot;,sched_yield,&quot;wait*&quot;} -esched:sched_switch -F1000 -g --call-graph fp,65528 [YOUR_COMMAND_HERE]
</code></pre>
<h3 id="headless-samply-use"><a class="header" href="#headless-samply-use">Headless <code>samply</code> use</a></h3>
<p>Samply instructions above require manual interaction with browsers, which makes automation
difficult. If you'd like to just get files for, headless operation is also possible. Do note that
the results produced this way lose some information that is otherwise made available with the
instructions above. Most notably â€“ kernel symbols may be lost.</p>
<!-- cspell: ignore cswitch presymbolicate -->
<pre><code>$ samply import --cswitch-markers --unstable-presymbolicate -s -n perf.data
$ ls profile.json*
</code></pre>
<p>These files can later be viewed with</p>
<pre><code>$ samply load
</code></pre>
<h3 id="lost-samples"><a class="header" href="#lost-samples">Lost samples</a></h3>
<p>In some cases <code>perf</code> may complain about lost samples. This can happen more often when profiling
<code>neard</code> with a large number threads. To mitigate sample loss, reduce the sampling rate, use <a href="practices/workflows/profiling.html#low-overhead-stack-frame-collection">low
overhead stack frame collection</a> and/or record traces to a
fast storage device (possibly <code>/tmp</code> mounted on <code>tmpfs</code>.)</p>
<h3 id="profiling-with-hardware-counters"><a class="header" href="#profiling-with-hardware-counters">Profiling with hardware counters</a></h3>
<p>As mentioned earlier, sampling profiler is probabilistic and the data it produces is only really
suitable for a broad overview. Any attempt to analyze the performance of the code at the
microarchitectural level (which you might want to do if investigating how to speed up a small but
frequently invoked function) will be severely hampered by the low quality of data.</p>
<p>For a long time now, CPUs are able to expose information about how it operates on the code at a
very fine grained level: how many cycles have passed, how many instructions have been processed,
how many branches have been taken, how many predictions were incorrect, how many cycles were spent
waiting of a memory accesses and many more. These allow a much better look at how the code behaves.</p>
<p>Until recently, use of these detailed counters was still sampling based -- the CPU would produce
some information at a certain cadence of these counters (e.g. every 1000 instructions or cycles)
which still shares a fair number of the same downsides as sampling <code>cpu-clock</code>. In order to address
this downside, recent CPUs from both Intel and AMD have implemented a list of recent branches taken
-- <a href="https://lwn.net/Articles/680985/">Last Branch Record</a> or LBR. This is available on reasonably
recent Intel architectures as well as starting with Zen 4 on the side of AMD. With LBRs profilers
are able to gather information about the cycle counts between each branch, giving an accurate and
precise evaluation of the performance at a <a href="https://en.wikipedia.org/wiki/Basic_block">basic block</a>
or function call level.</p>
<p>It all sounds really nice, so why are we not using these mechanisms all the time? That's because
GCP VMs don't allow access to these counters! In order to access them the code has to be run on
your own hardware, or a VM instance that provides direct access to the hardware, such as the (quite
expensive) <code>c3-highcpu-192-metal</code> type.</p>
<p>Once everything is set up, though, the following command can gather some interesting information
for you.</p>
<pre><code class="language-command">perf record -e cycles:u -b -g --call-graph fp,65528 YOUR_COMMAND_HERE
</code></pre>
<p>Analyzing this data is, unfortunately, not as easy as chucking it away to Firefox Profiler. I'm not
aware of any other ways to inspect the data other than using <code>perf report</code>:</p>
<pre><code class="language-command">perf report -g --branch-history
perf report -g --branch-stack
</code></pre>
<p>You may also be able to gather some interesting results if you use <code>--call-graph lbr</code> and the
relevant reporting options as well.</p>
<h2 id="memory-usage-profiling"><a class="header" href="#memory-usage-profiling">Memory usage profiling</a></h2>
<p><code>neard</code> is a pretty memory-intensive application with many allocations occurring constantly.
Although Rust makes it pretty hard to introduce memory problems, it is still possible to leak
memory or to inadvertently retain too much of it.</p>
<p>Unfortunately, â€œjustâ€ throwing a random profiler at neard does not work for many reasons. Valgrind
for example is introducing enough slowdown to significantly alter the behavior of the run, not to
mention that to run it successfully and without crashing it will be necessary to comment out
<code>neard</code>â€™s use of <code>jemalloc</code> for yet another substantial slowdown.</p>
<p>So far the only tool that worked out well out of the box was
<a href="https://github.com/koute/bytehound"><code>bytehound</code></a>. Using it is quite straightforward, but needs
Linux, and ability to execute privileged commands.</p>
<p>First, checkout and build the profiler (you will need to have nodejs <code>yarn</code> thing available as
well):</p>
<pre><code class="language-command">git clone git@github.com:koute/bytehound.git
cargo build --release -p bytehound-preload
cargo build --release -p bytehound-cli
</code></pre>
<p>You will also need a build of your <code>neard</code>, once you have that, give it some ambient capabilities
necessary for profiling:</p>
<pre><code class="language-command">sudo sysctl kernel.perf_event_paranoid=0
sudo setcap 'CAP_SYS_ADMIN+ep' /path/to/neard
sudo setcap 'CAP_SYS_ADMIN+ep' /path/to/libbytehound.so
</code></pre>
<p>And finally run the program with the profiler enabled (in this case <code>neard run</code> command is used):</p>
<pre><code class="language-command">/lib64/ld-linux-x86-64.so.2 --preload /path/to/libbytehound.so /path/to/neard run
</code></pre>
<h3 id="viewing-the-profile"><a class="header" href="#viewing-the-profile">Viewing the profile</a></h3>
<blockquote style="background: rgba(255, 200, 0, 0.1); border: 5px solid rgba(255, 200, 0, 0.4);">
<p>Do note that you will need about twice the amount of RAM as the size of the input file in order to
load it successfully.</p>
</blockquote>
<p>Once enough profiling data has been gathered, terminate the program. Use the <code>bytehound</code> CLI tool
to operate on the profile. I recommend <code>bytehound server</code> over directly converting to e.g. heaptrack
format using other subcommands as each invocation will read and parse the profile data from
scratch. This process can take quite some time. <code>server</code> parses the inputs once and makes
conversions and other introspection available as interactive steps.</p>
<p>You can use <code>server</code> interface to inspect the profile in one of the few ways, download a flamegraph
or a heaptrack file. Heaptrack in particular provides some interesting additional visualizations
and has an ability to show memory use over time from different allocation sources.</p>
<p>I personally found it a bit troublesome to figure out how to open the heaptrack file from the GUI.
However, <code>heaptrack myexportedfile</code> worked perfectly. I recommend opening the file exactly this way.</p>
<h3 id="troubleshooting-1"><a class="header" href="#troubleshooting-1">Troubleshooting</a></h3>
<h4 id="no-output-file"><a class="header" href="#no-output-file">No output file</a></h4>
<ol>
<li>Set a higher profiler logging level. Verify that the profiler gets loaded at all. If you're not
seeing any log messages, then something about your working environment is preventing the loader
from including the profiler library.</li>
<li>Try specifying an exact output file with e.g. environment variables that the profiler reads.</li>
</ol>
<h4 id="crashes"><a class="header" href="#crashes">Crashes</a></h4>
<p>If the profiled <code>neard</code> crashes in your tests, there are a couple of things you can try to get past
it. First, make sure your binary has the necessary ambient capabilities (<code>setcap</code> command above
needs to be executed every time binary is replaced!)</p>
<p>Another thing to try is disabling <code>jemalloc</code>. Comment out this code in <code>neard/src/main.rs</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[global_allocator]
static ALLOC: tikv_jemallocator::Jemalloc = tikv_jemallocator::Jemalloc;
<span class="boring">}
</span></code></pre></pre>
<p>The other thing you can try is different profilers, different versions of the profilers or
different options made available (in particular disabling the shadow stack in bytehound), although
I don't have specific recommendations here.</p>
<p>We don't know what exactly it is about neard that leads to it crashing under the profiler as easily
as it does. I have seen valgrind reporting that we have libraries that are deallocating with a
wrong size class, so that might be the reason? Do definitely look into this if you have time.</p>
<h2 id="what-to-profile"><a class="header" href="#what-to-profile">What to profile?</a></h2>
<p>This section provides some ideas on programs you could consider profiling if you are not sure where
to start.</p>
<p>First and foremost you could go shotgun and profile a full running <code>neard</code> node that's operating on
mainnet or testnet traffic. There are a couple ways to set up such a node: search for
<a href="https://docs.nearone.org/doc/my-own-mainnettestnet-MZTRLQjXCz">my-own-mainnet</a> or a forknet based
tooling.</p>
<p>From there either attach to a running <code>neard run</code> process or stop the running one and start a new
instance under the profiler.</p>
<p>This approach will give you a good overview of the entire system, but at the same time the
information might be so dense, it might be difficult to derive any signal from the noise. There are
alternatives that isolate certain components of the runtime:</p>
<h3 id="runtimeapply"><a class="header" href="#runtimeapply"><code>Runtime::apply</code></a></h3>
<p>Profiling just the <code>Runtime::apply</code> is going to include the work done by transaction runtime and
the contract runtime only. A smart use of the tools already present in the <code>neard</code> binary can
achieve that today.</p>
<p>First, make sure all deltas in flat storage are applied and written:</p>
<pre><code>neard view-state --read-write apply-range --storage flat sequential
</code></pre>
<p>You will need to do this for all shards you're interested in profiling. Then pick a block or a
range of blocks you want to re-apply and set the flat head to the specified height:</p>
<pre><code>neard flat-storage move-flat-head back --blocks 17
</code></pre>
<p>Finally the following commands will apply the block or blocks from the height in various different
ways. Experiment with the different modes and flags to find the best fit for your task. Don't
forget to run these commands under the profiler :)</p>
<pre><code># Apply blocks from current flat head to the highest known block height in sequence
# using the memtrie storage (note that after this you will need to move the flat head again)
neard view-state --read-write apply-range --storage memtrie sequential
# Same but with flat storage
neard view-state --read-write apply-range --storage flat sequential

# Repeatedly apply a single block at the flat head using the memtrie storage.
# Will not modify the storage on the disk.
neard view-state apply-range --storage memtrie benchmark
# Same but with flat storage
neard view-state apply-range --storage flat benchmark
# Same but with recorded storage
neard view-state apply-range --storage recorded benchmark
</code></pre>
<p>Note that all of these commands operate on all shards at the same time. You can specify
<code>--shard-id</code> argument to pick just one shard to operate with.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="benchmarking-neard"><a class="header" href="#benchmarking-neard">Benchmarking <code>neard</code></a></h1>
<p>At the moment there are 3 major benchmarking tools in use: </p>
<ul>
<li>Native token transactions using the RPC node</li>
<li>Native token transactions directly injecting transaction to the pool</li>
<li><code>apply-range</code> benchmarks</li>
</ul>
<p>The first two can be run either single node or multi-node setup.</p>
<h2 id="native-token-transactions"><a class="header" href="#native-token-transactions">Native token transactions</a></h2>
<h3 id="using-the-rpc-node-to-generate-the-load"><a class="header" href="#using-the-rpc-node-to-generate-the-load">Using the RPC Node to generate the load</a></h3>
<p>This one includes all major components of the network including the RPC layer.
Which makes it most representative for measuring the realistic throughput of the network while on the same time introduces some noise and makes it difficult to reason about the performance of the specific components.</p>
<p>One needs to compile the <code>benchmarks/synth-bm</code>, create the link to the <code>neard</code> executable and run the tasks from the <code>justfile</code>.
The details are available on the dedicated <a href="practices/workflows/./benchmarking_synthetic_workloads.html">page</a>.</p>
<h3 id="direct-transaction-injection"><a class="header" href="#direct-transaction-injection">Direct transaction injection</a></h3>
<p>This section closely follows (duplicates) the dedicated <code>readme.md</code> in <code>benchmarks/transaction-generator</code>.
In case of questions you may want to consult that as well.</p>
<p>This benchmark bypasses the RPC layer and injects the transactions using direct calls to the ingress handling actor.
It is representative of the performance of the <code>neard</code> excluding the RPC layer.
The single-node setup of this benchmark is a part of the CI.</p>
<h4 id="run-the-benchmark"><a class="header" href="#run-the-benchmark">Run the benchmark</a></h4>
<ul>
<li>compile the <code>neard</code> with the <code>tx_generator</code> feature</li>
</ul>
<pre><code>cargo build --release --features tx_generator
</code></pre>
<ul>
<li>create a link to the release binary of neard in the <code>benchmarks/transactions-generator</code></li>
</ul>
<pre><code>cd benchmarks/transactions-generator &amp;&amp; ln -s ../../release/neard ./
</code></pre>
<ul>
<li>run the thing</li>
</ul>
<pre><code>just do_it 20000
</code></pre>
<p>The last command will init a single-node network, apply customizations to the config, create the accounts and run the benchmark for 3m.
All of it.
For a more fine-grained control feel free to dive into the <code>justfile</code> for the commands executing the intermediate steps.</p>
<h4 id="tweaking-the-load-generation-parameters"><a class="header" href="#tweaking-the-load-generation-parameters">Tweaking the load generation parameters</a></h4>
<p>The load generation parameters are expected as a part of the <code>neard</code> <code>config.json</code>.
The node name is &quot;tx_generator&quot; and is optional. 
In case the node is missing the error message is printed out and the <code>neard</code> continues running as usually.
The node currently consists of the path to  &quot;schedule&quot; and &quot;controller&quot; sections</p>
<pre><code class="language-json">{
	&quot;tx_generator&quot;: {
		&quot;accounts_path&quot;: &quot;{{near_accounts_path}}&quot;,
		&quot;schedule&quot;: [
			{ &quot;tps&quot;: 1000, &quot;duration_s&quot;: 60 },
			{ &quot;tps&quot;: 2000, &quot;duration_s&quot;: 60 }
		],
		&quot;controller&quot;: {
			&quot;target_block_production_time_s&quot;: 1.4,
			&quot;bps_filter_window_length&quot;: 64,
			&quot;gain_proportional&quot;: 20,
			&quot;gain_integral&quot;: 0.0,
			&quot;gain_derivative&quot;: 0.0
		}
	}
}

</code></pre>
<p>The &quot;schedule&quot; section is required and defines the load applying schedule. 
After the schedule completes the <code>neard</code> will exit in case &quot;controller&quot; is not defined, or else will run the control loop defined by the parameters indefinitely.
The last scheduled TPS is than used as a starting point and the loop adjusts TPS to keep the target block production time at a desired value.
Note that the resulting production time currently tends to be slightly under the target value.</p>
<h4 id="what-you-should-see"><a class="header" href="#what-you-should-see">What you should see</a></h4>
<ul>
<li>observe the load reported in the logs</li>
</ul>
<pre><code>...
2025-02-12T16:42:37.351118Z  INFO stats: #    1584 6nxZon12xBTmARmUm3ngtgaA2K7V9dX1J13EtPZ2kEhe Validator | 1 validator 0 peers â¬‡ 0 B/s â¬† 0 B/s 1.60 bps 131 Tgas/s CPU: 70%, Mem: 2.98 GB
...
2025-02-18T13:04:29.790195Z  INFO transaction-generator: total=&quot;Stats { pool_accepted: 158247, pool_rejected: 237, included_in_chunks: 155338, failed:0 }&quot;
2025-02-18T13:04:29.790208Z  INFO transaction-generator: diff=&quot;Stats { pool_accepted: 6049, pool_rejected: 0, included_in_chunks: 6439, failed: 0 }, rate=6036&quot;
...
</code></pre>
<ul>
<li>see the number of processed transactions (<code>near_transaction_processed_successfully_total</code>) or transactions included to the chunks (<code>near_chunk_transactions_total</code>) in the metrics</li>
</ul>
<pre><code>$ curl http://localhost:3030/metrics -s | rg &quot;near_transaction_processed_successfully_total (\\d+)&quot;
near_transaction_processed_successfully_total 852883
</code></pre>
<p>The first one is prone to double-counting the transactions but may better reflect the performance of the underlying runtime.</p>
<p>[!CAUTION]
When the un-limiting settings are applied to the network config the network is prone to failing in non-obvious ways.
To notice the degradation one can monitor for missing chunks and block production times for example.
When the latter starts to grow that means the network no longer sustains the load although the reported mean rate of transaction processing may remain at a high level (reflecting the performance the runtime subsystem).</p>
<h3 id="apply-range-benchmark"><a class="header" href="#apply-range-benchmark">Apply-range benchmark</a></h3>
<p>This measures the performance of the runtime sub-system in isolation applying the block or blocks in multiple configurable ways.
The detailed description of it is provided in the <a href="practices/workflows/./profiling.html">profiling</a> section, <code>Runtime::apply</code> subsection.
To evaluate the number of rate of processing the transactions one may query the stats as described above.</p>
<h3 id="multi-node-setup"><a class="header" href="#multi-node-setup">Multi-Node setup</a></h3>
<p>For benchmarking multi-node sharded networks, there is a comprehensive toolset in the <a href="https://github.com/near/nearcore/blob/master/pytest/tests/mocknet/sharded_bm.py">sharded-bm</a>. This framework allows testing various network configurations with different numbers of shards, validators and traffic profiles.</p>
<p>The sharded benchmark framework supports both localnet testing on a single machine and forknet deployments. Forknet is particularly useful as it allows creating a network running on multiple VMs, providing real-world conditions for performance testing.</p>
<p>To run sharded benchmarks on a forknet, you'll need to:</p>
<ol>
<li>Set up the required infrastructure using terraform</li>
<li>Configure environment variables for the benchmark</li>
<li>Initialize and start the network</li>
<li>Create test accounts and run the benchmark</li>
</ol>
<p>Alternatively one may use the infra-ops <a href="https://github.com/Near-One/infra-ops/actions/workflows/benchmark.yml">workflow</a>.</p>
<p>For detailed instructions and configuration options, refer to the <a href="https://github.com/near/nearcore/tree/master/pytest/tests/mocknet/docs/sharded_bm.md">README</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="benchmarking-synthetic-workloads"><a class="header" href="#benchmarking-synthetic-workloads">Benchmarking synthetic workloads</a></h1>
<p>Benchmarking a synthetic workload starts a new network with empty state. Then state is created and afterwards transactions involving that state are generated. For example, the native token transfer workload creates <code>n</code> accounts with NEAR balance and then generates transactions to transfer the native token between accounts.</p>
<p>This approach has the following benefits:</p>
<ul>
<li>Relatively simple and quick setup, as there is no state from real work networks involved.</li>
<li>Fine grained control over traffic intensity.</li>
<li>Enabling the comparison of <code>neard</code> performance at different points in time or with different features.</li>
<li>Might expose performance bottlenecks.</li>
</ul>
<p>The main drawbacks of synthetic benchmarks are:</p>
<ul>
<li>Drawing conclusions is limited as real world traffic is not homogeneous.</li>
<li>Calibrating traffic generation parameters can be cumbersome.</li>
</ul>
<p>The tooling for synthetic benchmarks is available in <a href="practices/workflows/../../../benchmarks/synth-bm"><code>benchmarks/synth-bm</code></a>.</p>
<h2 id="workflows-1"><a class="header" href="#workflows-1">Workflows</a></h2>
<p>The tooling's <a href="practices/workflows/../../../benchmarks/synth-bm/justfile"><code>justfile</code></a> contains recipes for the most relevant workflows.</p>
<h3 id="benchmark-native-token-transfers"><a class="header" href="#benchmark-native-token-transfers">Benchmark native token transfers</a></h3>
<p>A typical workflow benchmarking the native token transfers using the above <code>justfile</code> would be something along the:</p>
<ul>
<li>set up the network</li>
</ul>
<!-- cspell:words subaccounts -->
<pre><code class="language-command">rm -rf .near &amp;&amp; just init_localnet
# Modify the configuration (see the &quot;Un-limit configuration&quot; section)
[t1]$ just run_localnet
[t1]$ just create_sub_accounts
</code></pre>
<ul>
<li>run the benchmark</li>
</ul>
<pre><code class="language-command"># set the desired tx rate (`--interval-duration-micros`) and the total volume (`--num-transfers`) in the justfile
[t2]$ just benchmark_native_transfers
</code></pre>
<p>This benchmark generates a native token transfer workload involving the accounts provided in <code>--user-data-dir</code>. Transactions are generated by iterating through these accounts and sending native tokens to a randomly chosen receiver from the same set of accounts. To view all options, run:</p>
<pre><code class="language-command">cargo run --release -- benchmark-native-transfers --help
</code></pre>
<p>For the native transfer benchmark transactions are sent with <code>wait_until: None</code>, meaning the responses the <code>near_synth_bm</code> tool receives are basically just an ACK by the RPC confirming it received the transaction.
Thus the numbers reported by the tool as if in</p>
<pre><code>[2025-01-27T14:05:12Z INFO  near_synth_bm::native_transfer] Sent 200000 txs in 6.50 seconds
[2025-01-27T14:05:12Z INFO  near_synth_bm::rpc] Received 200000 tx responses in 6.49 seconds
</code></pre>
<p>are not directly indicative of the runtime performance and transaction outcomes.
The number of transactions successfully processed may be obtained by querying the <code>near_transaction_processed_successfully_total</code> metric, e.g. with: <code>http://localhost:3030/metrics | grep transaction_processed</code>.
Automatic calculation of transactions per second (TPS) when RPC requests are sent with <code>wait_until: NONE</code> is coming up shortly.</p>
<h3 id="benchmark-calls-to-the-sign-method-of-an-mpc-contract"><a class="header" href="#benchmark-calls-to-the-sign-method-of-an-mpc-contract">Benchmark calls to the <code>sign</code> method of an MPC contract</a></h3>
<p>Assumes the accounts that send the transactions invoking <code>sign</code> have been created as described above. Transactions can be sent to a RPC of a network on which an instance of the <a href="https://github.com/near/mpc/tree/79ec50759146221e7ad8bb04520f13333b75ca07/chain-signatures/contract"><code>mpc/chain-signatures</code></a> is deployed.</p>
<p>Transactions are sent to the RPC with <code>wait_until: EXECUTED_OPTIMISTIC</code> as the throughput for <code>sign</code> is at a level at which neither the network nor the RPC are expected to be a bottleneck.</p>
<p>All options of the command can be shown with:</p>
<pre><code class="language-command">cargo run -- benchmark-mpc-sign --help
</code></pre>
<h2 id="auxiliary-steps"><a class="header" href="#auxiliary-steps">Auxiliary steps</a></h2>
<h3 id="network-setup-and-neard-configuration"><a class="header" href="#network-setup-and-neard-configuration">Network setup and <code>neard</code> configuration</a></h3>
<p>Details of bringing up and configuring a network are out of scope for this document. Instead we just give a brief overview of the setup regularly used to benchmark TPS of common workloads in a single-node with a single-shard setup.</p>
<h3 id="build-neard"><a class="header" href="#build-neard">Build <code>neard</code></a></h3>
<p>Choose the git commit and cargo features corresponding to what you want to benchmark. Most likely you will want a <code>--release</code> build to measure TPS. Place the corresponding <code>neard</code> binary in the justfile's directory or set the <code>NEARD_PATH</code> environment variable to point to it.</p>
<h3 id="create-sub-accounts"><a class="header" href="#create-sub-accounts">Create sub accounts</a></h3>
<p>Creating the state for synthetic benchmarks usually starts with creating accounts. We create sub accounts for the account specified by <code>--signer-key-path</code>. This avoids dealing with the registrar, which would be required for creating top level accounts. To view all options, run:</p>
<pre><code class="language-command">cargo run --release -- create-sub-accounts --help
</code></pre>
<h3 id="initialize-the-network"><a class="header" href="#initialize-the-network">Initialize the network</a></h3>
<pre><code class="language-command">./neard --home .near init --chain-id localnet
</code></pre>
<h3 id="enable-memtrie"><a class="header" href="#enable-memtrie">Enable memtrie</a></h3>
<p>The configuration generated by the above command does not enable memtrie. However, most benchmarks should run against a node with memtrie enabled, which can be achieved by setting the following in <code>.near/config.json</code>:</p>
<pre><code>&quot;load_mem_tries_for_tracked_shards&quot;: true
</code></pre>
<h3 id="un-limit-configuration"><a class="header" href="#un-limit-configuration">Un-limit configuration</a></h3>
<p>Following these steps so far creates a config that will throttle throughput due to various factors related to state witness size, gas/compute limits, and congestion control. In case you want to benchmark a node that fully utilizes its hardware, you can do the following modifications to effectively run with unlimited configuration:</p>
<pre><code># Modifications in .near/genesis.json

&quot;chain_id&quot;: &quot;benchmarknet&quot;
&quot;gas_limit&quot;: 20000000000000000               # increase default by x20

# Modifications in .near/config.json
&quot;view_client_threads&quot;: 8                     # increase default by x2
&quot;load_mem_tries_for_tracked_shards&quot;: true    # enable memtrie 
&quot;produce_chunk_add_transactions_time_limit&quot;: {
  &quot;secs&quot;: 0,
  &quot;nanos&quot;: 800000000                         # increase default by x4
}
</code></pre>
<p>Note that as <code>nearcore</code> evolves, these steps and <code>BENCHMARKNET</code> adjustments might need to be updated to achieve the effect of un-limiting configuration.</p>
<p>Modifications of <code>genesis.json</code> need to be applied before initializing the network with <code>just init_localnet</code>. Otherwise <code>just run_localnet</code> will fail. If you ran the node with default config and want to switch to unlimited config, the required steps are:</p>
<pre><code class="language-console"># Remove .near as you will need to initialize localnet again.
$ rm -rf .near
$ just init_localnet
# Modify the configuration
$ just run_localnet
</code></pre>
<h2 id="common-parameters"><a class="header" href="#common-parameters">Common parameters</a></h2>
<p>The following parameters are common to multiple tasks:</p>
<h3 id="rpc-url"><a class="header" href="#rpc-url"><code>rpc-url</code></a></h3>
<p>The RPC endpoint to which transactions are sent.</p>
<p>Synthetic benchmarking may create thousands of transactions per second, which can hit network limitations if the RPC is located on a separate machine. In particular sending transactions to nodes running on GCP requires care as it can cause temporary IP address bans. For that scenario it is recommended to run a separate traffic generation vm located in the same GCP zone as the RPC node and send transactions to its <code>internal IP</code>.</p>
<h3 id="interval-duration-micros"><a class="header" href="#interval-duration-micros"><code>interval-duration-micros</code></a></h3>
<p>Controls the rate at which transactions are sent. Assuming your hardware is able to send a request at every interval tick, the number of transactions sent per second equals <code>1_000_000 / interval-duration-micros</code>. The rate might be slowed down if <code>channel-buffer-size</code> becomes a bottleneck.</p>
<h3 id="channel-buffer-size"><a class="header" href="#channel-buffer-size"><code>channel-buffer-size</code></a></h3>
<p>Before an RPC request is sent, the tooling awaits capacity on a buffered channel. Thereby the number of outstanding RPC requests is limited by <code>channel-buffer-size</code>. This can slow down the rate at which transactions are sent in case the node is congested. To disable that behavior, set <code>channel-buffer-size</code> to a large value, e.g. the total number of transactions to be sent.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="benchmarking-chunk-application-on-the-native-transfers-workload"><a class="header" href="#benchmarking-chunk-application-on-the-native-transfers-workload">Benchmarking chunk application on the native transfers workload</a></h1>
<p>This doc shows how to:</p>
<ul>
<li>Run a single-node localnet with native transfer workload</li>
<li>Use the <code>view-state</code> command to benchmark applying one of the chunks created during the workload</li>
</ul>
<p>Running the workload creates ~realistic chunks and state and then we can benchmark applying one of the chunks using this.</p>
<h3 id="running-the-initial-workload"><a class="header" href="#running-the-initial-workload">Running the initial workload</a></h3>
<p>Clone nearcore and build neard with the tx_generator feature</p>
<blockquote>
<p>Note: Building <code>neard</code> with <code>--profile dev-release</code> instead of <code>--release</code> takes less time and the binary is almost as fast as the release one.</p>
</blockquote>
<blockquote>
<p>Note: If you plan to gather <code>perf</code> profiles, build with <code>--config .cargo/config.profiling.toml</code> (see <a href="practices/workflows/profiling.html">profiling docs</a>)</p>
</blockquote>
<pre><code class="language-shell">git clone https://github.com/near/nearcore
cd nearcore
cargo build -p neard --release --features tx_generator
</code></pre>
<p>Build synth-bm</p>
<pre><code class="language-shell">cd benchmarks/synth-bm
cargo build --release
</code></pre>
<p>Go to transaction-generator</p>
<pre><code class="language-shell">cd ../transactions-generator/
</code></pre>
<p>Create a link to <code>neard</code></p>
<pre><code class="language-shell">ln -s ../../target/release/neard
</code></pre>
<p>Set TPS to 4000</p>
<p>There are two files with the load schedule: <code>tx-generator-settings.json</code> and <code>tx-generator-settings.json.in</code>.
Transaction generator reads data from the <code>tx-generator-settings.json</code> file, not the one with <code>.in</code> suffix. The <code>.in</code> file is used only to store the default values for transaction generator. If <code>tx-generator-settings.json</code> doesn't exist, it's created based on <code>tx-generator-settings.json.in</code> during the first run.
This way you can modify <code>tx-generator-settings.json</code> locally without merge conflicts.</p>
<p>Create <code>tx-generator-settings.json</code>:</p>
<pre><code class="language-shell">cp tx-generator-settings.json.in tx-generator-settings.json
</code></pre>
<p>Set <code>tps = 4000</code> in <code>tx-generator-settings.json</code>. Example jq command (might not work in the future if the file structure changes):</p>
<pre><code class="language-shell">jq '.tx_generator.schedule[0].tps = 4000' tx-generator-settings.json | sponge tx-generator-settings.json
</code></pre>
<p>Run the native transfers workload (Ignore &quot;Error: tx generator idle: no schedule provided&quot;, this is normal during <code>just create-accounts</code>)</p>
<pre><code class="language-shell">just do-it
</code></pre>
<p>This will create a <code>benchmarks/transactions-generator/.near</code> directory with node state, create accounts and run the workload.
Creating accounts takes a few minutes, be patient.
Sometimes running the workload fails because the database LOCK hasn't been freed in time. If that happens run <code>just run-localnet</code> to retry.</p>
<h3 id="re-running-the-workload"><a class="header" href="#re-running-the-workload">Re-running the workload</a></h3>
<p>To re-run the workload run <code>just run-localnet</code>. It's not necessary to do <code>just do-it</code>, which would recreate the state from scratch.</p>
<p>To change TPS edit the <code>tx-generator-settings.json</code> file (without <code>.in</code> !) and run <code>just enable-tx</code></p>
<h3 id="preparing-state-for-chunk-application-benchmark"><a class="header" href="#preparing-state-for-chunk-application-benchmark">Preparing state for chunk application benchmark</a></h3>
<p>(Taken from <a href="practices/workflows/profiling.html">profiling docs</a>)</p>
<p>First, make sure all deltas in flat storage are applied and written:</p>
<pre><code class="language-shell">./neard --home .near view-state --read-write apply-range --storage flat sequential
</code></pre>
<p>Then move flat head back 32 blocks to a height that had chunks with high load</p>
<pre><code class="language-shell">./neard --home .near flat-storage move-flat-head back --blocks 32
</code></pre>
<h3 id="benchmarking-chunk-application"><a class="header" href="#benchmarking-chunk-application">Benchmarking chunk application</a></h3>
<p>Run these commands to benchmark chunk application at the height to which the flat head was moved.</p>
<pre><code class="language-shell">./neard --home .near view-state apply-range --storage flat benchmark
</code></pre>
<p>or</p>
<pre><code class="language-shell">./neard --home .near view-state apply-range --storage memtrie benchmark
</code></pre>
<p>or</p>
<pre><code class="language-shell">./neard --home .near view-state apply-range --storage recorded benchmark
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<!-- cspell:ignore nearinc pkill rgba xdwp -->
<h1 id="working-with-opentelemetry-traces"><a class="header" href="#working-with-opentelemetry-traces">Working with OpenTelemetry Traces</a></h1>
<p><code>neard</code> is instrumented in a few different ways. From the code perspective we have two major ways
of instrumenting code:</p>
<ul>
<li>Prometheus metrics â€“ by computing various metrics in code and exposing them via the <code>prometheus</code>
crate.</li>
<li>Execution tracing â€“ this shows up in the code as invocations of functionality provided by the
<code>tracing</code> crate.</li>
</ul>
<p>The focus of this document is to provide information on how to effectively work with the data
collected by the execution tracing approach to instrumentation.</p>
<h2 id="gathering-and-viewing-the-traces"><a class="header" href="#gathering-and-viewing-the-traces">Gathering and Viewing the Traces</a></h2>
<p>Tracing the execution of the code produces two distinct types of data: spans and events. These then
are exposed as either logs (representing mostly the events) seen in the standard output of the
<code>neard</code> process or sent onwards to an <a href="https://opentelemetry.io/docs/collector/">opentelemetry collector</a>.</p>
<p>When deciding how to instrument a specific part of the code, consider the following decision tree:</p>
<ol>
<li>Do I need execution timing information? If so, use a span; otherwise</li>
<li>Do I need call stack information? If so, use a span; otherwise</li>
<li>Do I need to preserve information about inputs or outputs to a specific section of the code? If
so, use key-values on a pre-existing span or an event; otherwise</li>
<li>Use an event if it represents information applicable to a single point of execution trace.</li>
</ol>
<p>As of writing (February 2024) our codebase uses spans somewhat sparsely and relies on events
heavily to expose information about the execution of the code. This is largely a historical
accident due to the fact that for a long time stdout logs were the only reasonable way to extract
information out of the running executable.</p>
<p>Today we have more tools available to us. In production environments and environments replicating
said environment (i.e. GCP environments such as mocknet) there's the ability to push this data to
Grafana Loki (for events) and <a href="https://grafana.com/oss/tempo/">Tempo</a> (for spans and events alike), so long as the amount of data
is within reason. For that reason it is critical that the event and span levels are chosen
appropriately and in consideration with the frequency of invocations. In local environments
developers can use projects like <a href="https://www.jaegertracing.io/">Jaeger</a>, or set up the Grafana stack if they wish to use a
consistent interfaces.</p>
<p>It is still more straightforward to skip all the setup necessary for tracing, but relying
exclusively on logs only increases noise for the other developers and makes it ever so slightly
harder to extract signal in the future. Keep this trade off in mind.</p>
<h3 id="spans"><a class="header" href="#spans">Spans</a></h3>
<p>We have a <a href="practices/workflows/../style.html#spans">style guide section on the use of Spans</a>, please make yourself
familiar with it.</p>
<p>Every <code>tracing::debug_span!()</code> creates a new span, and usually it is attached to its parent
automatically.</p>
<p>However, a few corner cases exist.</p>
<ul>
<li><code>do_apply_chunks()</code> starts 4 sub-tasks in parallel and waits for their completion. To make it
work, the parent span is passed explicitly to the sub-tasks.</li>
<li>Inter-process tracing is theoretically available, but I have never tested it. The plan was to
test it as soon as the Canary images get updated ðŸ˜­ Therefore it most likely doesnâ€™t work. Each
<code>PeerMessage</code> is injected with <code>TraceContext</code> (1, 2) and the receiving node extracts that context
and all spans generated in handling that message should be parented to the trace from another node.</li>
<li>Some spans are created using <code>info_span!()</code> but they are few and mostly for the logs. Exporting
only info-level spans doesnâ€™t give any useful tracing information in Grafana.</li>
</ul>
<h2 id="configuration"><a class="header" href="#configuration">Configuration</a></h2>
<p><a href="https://nearone.getoutline.com/doc/tracing-in-grafana-RgJUJZF2C0">The Tracing documentation page in nearone's
Outline</a> documents the steps
necessary to start moving the trace data from the node to Nearone's Grafana Cloud instance. Once
you set up your nodes, you can use the explore page to verify that the traces are coming through.</p>
<p><img src="practices/workflows/../../images/explore-traces.png" alt="Image displaying the Grafana explore page interacting with the grafana-nearinc-traces data source, with Service Name filter set to =~&quot;neard:mocknet-mainnet-94194484-nagisa-10402-test-vzx2.near|neard:mocknet-mainnet-94194484-nagisa-10402-test-xdwp.near&quot; and showing some traces having been found" /></p>
<p>If the traces are not coming through quite yet, consider using the ability to set logging
configuration at runtime. Create <code>$NEARD_HOME/log_config.json</code> file with the following contents:</p>
<pre><code class="language-json">{ &quot;opentelemetry&quot;: &quot;info&quot; }
</code></pre>
<p>Or optionally with <code>rust_log</code> setting to reduce logging on stdout:</p>
<pre><code class="language-json">{ &quot;opentelemetry&quot;: &quot;info&quot;, &quot;rust_log&quot;: &quot;WARN&quot; }
</code></pre>
<p>and invoke <code>sudo pkill -HUP neard</code>. Double check that the collector is running as well.</p>
<blockquote style="background: rgba(255, 200, 0, 0.1); border: 5px solid rgba(255, 200, 0, 0.4);">
<p><strong>Good to know</strong>: You can modify the event/span/log targets youâ€™re interested in just like when
setting the <code>RUST_LOG</code> environment variable, including target filters. If you're setting verbose
levels, consider selecting specific targets you're interested in too. This will help to keep trace
ingest costs down.</p>
<p>For more information about the dynamic settings refer to <code>core/dyn-configs</code> code in the repository.</p>
</blockquote>
<h3 id="local-development"><a class="header" href="#local-development">Local development</a></h3>
<blockquote style="background: rgba(255, 200, 0, 0.1); border: 5px solid rgba(255, 200, 0, 0.4);">
<p><strong>TODO</strong>: the setup is going to depend on whether one would like to use grafana stack or just
jaeger or something else. We should document setting either of these up, including the otel
collector and such for a full end-to-end setup. Success criteria: running integration tests should
allow you to see the traces in your grafana/jaeger. This may require code changes as well.</p>
</blockquote>
<p>Using the Grafana Stack here gives the benefit of all of the visualizations that are built-in. Any
dashboards you build are also portable between the local environment and the Grafana Cloud
instance. Jaeger may give a nicer interactive exploration ability. You can also set up both if you
wish.</p>
<h2 id="visualization"><a class="header" href="#visualization">Visualization</a></h2>
<p>Now that the data is arriving into the databases, it is time to visualize the data to determine
what you want to know about the node. The only general advise I have here is to check that the data
source is indeed tempo or loki.</p>
<h3 id="explore"><a class="header" href="#explore">Explore</a></h3>
<p>Initial exploration is best done with Grafana's Explore tool or some other mechanism to query and
display individual traces.</p>
<p>The query builder available in Grafana makes the process quite straightforward to start with, but
is also somewhat limited. Underlying <a href="https://grafana.com/docs/tempo/latest/traceql/">TraceQL has many more
features</a> that are not available through the
builder. For example, you can query data in somewhat of a relational manner, such as this query
below queries only spans named <code>process_receipt</code> that take 50ms when run as part of <code>new_chunk</code>
processing for shard 3!</p>
<pre><code>{ name=&quot;new_chunk&quot; &amp;&amp; span.shard_id = &quot;3&quot; } &gt;&gt; { name=&quot;process_receipt&quot; &amp;&amp; duration &gt; 50ms }
</code></pre>
<blockquote style="background: rgba(255, 200, 0, 0.1); border: 5px solid rgba(255, 200, 0, 0.4);">
<p><strong>Good to know</strong>: When querying, keep in mind the &quot;Options&quot; dropdown that allows you to specify the
limit of results and the format in which these results are presented! In particular, the
&quot;Traces/Spans&quot; toggle will affect the durations shown in the result table.</p>
</blockquote>
<p>Once you click on a span of interest, Grafana will open you a view with the trace that contains
said span, where you can inspect both the overall trace and the properties of the span:</p>
<p><img src="practices/workflows/../../images/span-details.png" alt="Image displaying a specific trace with two of the spans expanded to show their details" /></p>
<h3 id="dashboards"><a class="header" href="#dashboards">Dashboards</a></h3>
<p>Once you have arrived at an interesting query, you may be inclined to create a dashboard that
summarizes the data without having to dig into individual traces and spans.</p>
<p>As an example the author was interested in checking the execution speed before and after a change
in a component. To make the comparison visual, the span of interest was graphed using the histogram
visualization in order to obtain the following result. In this graph the Y axis displays the number
of occurrences for spans that took X-axis long to complete.</p>
<div id="image-comparison">
<img src="practices/workflows/../../images/compile-and-load-before.png" class="before" />
<img src="practices/workflows/../../images/compile-and-load-after.png" class="after" />
</div>
<style>
#image-comparison {
    position: relative;
}
#image-comparison>.before {
    position: absolute;
    top: 0;
    left: 0;
    z-index: 1;
    opacity: 0;
    transition: opacity 250ms;
}
#image-comparison>.before:hover {
    opacity: 1;
}
</style>
<p>In general most of the panels work with tracing results directly but some of the most interesting
ones do not. It is necessary to experiment with certain options and settings to have grafana panels
start showing data. Some notable examples:</p>
<ol>
<li>Time series â€“ a â€œPrepare time seriesâ€ data transformation with â€œMulti-frame time seriesâ€ has to
be added;</li>
<li>Histogram â€“ make sure to use &quot;spans&quot; table format option;</li>
<li>Heatmap - set â€œCalculate from dataâ€ option to â€œYesâ€;</li>
<li>Bar chart â€“ works out of the box, but x axis won't be readable ever.</li>
</ol>
<p>You can also add a panel that shows all the trace events in a log-like representation using the log
or table visualization.</p>
<h3 id="multiple-nodes"><a class="header" href="#multiple-nodes">Multiple nodes</a></h3>
<p>One frequently asked question is whether Grafana lets you distinguish between nodes that export
tracing information.</p>
<p>The answer is yes.</p>
<p>In addition to span attributes, each span has resource attributes. There you'll find properties
like <code>node_id</code> which uniquely identify a node.</p>
<ul>
<li><code>account_id</code> is the <code>account_id</code> from <code>validator_key.json</code>;</li>
<li><code>chain_id</code> is taken from <code>genesis.json</code>;</li>
<li><code>node_id</code> is the public key from <code>node_key.json</code>;</li>
<li><code>service.name</code> is <code>account_id</code> if that is available, otherwise it is <code>node_id</code>.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<!-- cspell:words futexes futexctn kptr libelf libbpf pgrep futexctn's msecs vtable -->
<h1 id="futex-contention"><a class="header" href="#futex-contention">Futex contention</a></h1>
<p>Futex contention occurs when multiple threads compete for access to shared resources protected by futexes (fast user-space mutexes). Futexes are efficient synchronization mechanisms in the Linux kernel, but contention can lead to performance bottlenecks in multithreaded programs.</p>
<p>Analyzing futex contention helps identify which locks are most contended and take the longest to resolve.</p>
<h2 id="setup-2"><a class="header" href="#setup-2">Setup</a></h2>
<p>The first step is to build a profiling-tuned build of <code>neard</code>:</p>
<pre><code class="language-sh">cargo build --release --config .cargo/config.profiling.toml -p neard
</code></pre>
<p>The second step involves compiling a tool designed to identify futex contention: <a href="https://github.com/iovisor/bcc/blob/master/libbpf-tools/futexctn.c">futexctn</a>. The following snippet demonstrates how to set up a <code>neard</code> node on GCP to collect lock contention data:</p>
<pre><code class="language-sh">sudo sysctl kernel.perf_event_paranoid=0 &amp;&amp; sudo sysctl kernel.kptr_restrict=0

sudo apt install -y clang llvm git libelf-dev

git clone https://github.com/iovisor/bcc.git

cd bcc/libbpf-tools/

git submodule update --init --recursive

make -j8
</code></pre>
<p>Finally, execute the <code>futexctn</code> binary for a chosen duration to gather contention statistics:</p>
<pre><code class="language-sh">sudo ./futexctn -p $(pgrep neard) -T
</code></pre>
<h2 id="understanding-futexctns-output"><a class="header" href="#understanding-futexctns-output">Understanding futexctn's output</a></h2>
<p>Below is an example section of the tool's output, illustrating the contention of a lock:</p>
<pre><code class="language-text">neard0[55783] lock 0x79a1b1dfcfb0 contended 41 times, 22 avg msecs [max: 48 msecs, min 5 msecs]
    -
    syscall
    _ZN10near_store4trie4Trie17get_optimized_ref17h8d5fd8c67e262ab1E
    _ZN10near_store4trie4Trie3get17h11d4bcd3667e3c8fE
    _ZN85_$LT$near_store..trie..update..TrieUpdate$u20$as$u20$near_store..trie..TrieAccess$GT$3get17h041c58f313ed6d6cE
    _ZN10near_store5utils11get_account17hf3071e79288206c0E
    _ZN12node_runtime8verifier25get_signer_and_access_key17hca85f102c5a0241bE
    _ZN92_$LT$near_chain..runtime..NightshadeRuntime$u20$as$u20$near_chain..types..RuntimeAdapter$GT$24can_verify_and_charge_tx17hb1907151d54f3c6bE
    _ZN11near_client11rpc_handler10RpcHandler10process_tx17h3ca7fec97c6dd01eE
    _ZN110_$LT$actix..sync..SyncContextEnvelope$LT$M$GT$$u20$as$u20$actix..address..envelope..EnvelopeProxy$LT$A$GT$$GT$6handle17h0f78e99e6ce63395E
    _ZN3std3sys9backtrace28__rust_begin_short_backtrace17hd5ed81d58d44f867E
    _ZN4core3ops8function6FnOnce40call_once$u7b$$u7b$vtable.shim$u7d$$u7d$17hc18f360a04c1b975E
    _ZN3std3sys3pal4unix6thread6Thread3new12thread_start17hcc5ed016d554f327E
    [unknown]
    -
     msecs               : count    distribution
         0 -&gt; 1          : 0        |                                        |
         2 -&gt; 3          : 0        |                                        |
         4 -&gt; 7          : 10       |***********************                 |
         8 -&gt; 15         : 10       |***********************                 |
        16 -&gt; 31         : 4        |*********                               |
        32 -&gt; 63         : 17       |****************************************|
</code></pre>
<p>Notes on the output:</p>
<ul>
<li>The first line shows the number of times the lock was contended and the average duration of contention.</li>
<li>The middle section provides the stack trace of the thread that locked the futex.</li>
<li>The bottom section contains a histogram representing the contention duration distribution.</li>
</ul>
<h3 id="things-to-watch-out-for"><a class="header" href="#things-to-watch-out-for">Things to watch out for</a></h3>
<p>Some instances of contention are not caused by locks being held for extended periods but are instead due to programmatic waits or sleeps. These can be identified either by examining the stack trace or by noticing that their durations are consistently rounded numbers.</p>
<p>Example:</p>
<pre><code class="language-text">tokio-runtime-w[56073] lock 0x79a1ae9f9fb0 contended 9 times, 1000 avg msecs [max: 1003 msecs, min 1000 msecs]
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="code-style"><a class="header" href="#code-style">Code Style</a></h1>
<p>This document specifies the code style to use in the nearcore repository. The
primary goal here is to achieve consistency, maintain it over time, and cut down
on the mental overhead related to style choices.</p>
<p>Right now, <code>nearcore</code> codebase is not perfectly consistent, and the style
acknowledges this. It guides newly written code and serves as a tie breaker for
decisions. Rewriting existing code to conform 100% to the style is not a goal.
Local consistency is more important: if new code is added to a specific file,
it's more important to be consistent with the file rather than with this style
guide.</p>
<p>This is a live document, which intentionally starts in a minimal case. When
doing code-reviews, consider if some recurring advice you give could be moved
into this document.</p>
<h2 id="formatting"><a class="header" href="#formatting">Formatting</a></h2>
<p>Use <code>rustfmt</code> for minor code formatting decisions. This rule is enforced by CI</p>
<p><strong>Rationale:</strong> <code>rustfmt</code> style is almost always good enough, even if not always
perfect. The amount of bike shedding saved by <code>rustfmt</code> far outweighs any
imperfections.</p>
<h2 id="idiomatic-rust"><a class="header" href="#idiomatic-rust">Idiomatic Rust</a></h2>
<p>While the most important thing is to solve the problem at hand, we strive to
implement the solution in idiomatic Rust, if possible. To learn what is
considered idiomatic Rust, a good start are the
<a href="https://rust-lang.github.io/api-guidelines/about.html">Rust API guidelines</a>
(but keep in mind that <code>nearcore</code> is not a library with public API, not all
advice applies literally).</p>
<p>When in doubt, ask question in the <a href="https://near.zulipchat.com/#narrow/stream/300659-Rust-.F0.9F.A6.80">Rust
ðŸ¦€</a> Zulip
stream or during code review.</p>
<p><strong>Rationale:</strong></p>
<ul>
<li><em>Consistency</em>: there's usually only one idiomatic solution amidst many
non-idiomatic ones.</li>
<li><em>Predictability</em>: you can use the APIs without consulting documentation.</li>
<li><em>Performance, ergonomics and correctness</em>: language idioms usually reflect
learned truths, which might not be immediately obvious.</li>
</ul>
<h2 id="style"><a class="header" href="#style">Style</a></h2>
<p>This section documents all micro-rules which are not otherwise enforced by
<code>rustfmt</code>.</p>
<h3 id="avoid-asrefas_ref"><a class="header" href="#avoid-asrefas_ref">Avoid <code>AsRef::as_ref</code></a></h3>
<p>When you have some concrete type, prefer <code>.as_str</code>, <code>.as_bytes</code>, <code>.as_path</code> over
generic <code>.as_ref</code>. Only use <code>.as_ref</code> when the type in question is a generic
<code>T: AsRef&lt;U&gt;</code>.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// GOOD
fn log_validator(account_id: AccountId) {
    metric_for(account_id.as_str())
       .increment()
}

// BAD
fn log_validator(account_id: AccountId) {
    metric_for(account_id.as_ref())
       .increment()
}
<span class="boring">}
</span></code></pre></pre>
<p>Note that <code>Option::as_ref</code>, <code>Result::as_ref</code> are great, do use them!</p>
<p><strong>Rationale:</strong> Readability and churn-resistance. There might be more than one
<code>AsRef&lt;U&gt;</code> implementation for a given type (with different <code>U</code>s). If a new
implementation is added, some of the <code>.as_ref()</code> calls might break. See also
this <a href="https://github.com/rust-lang/rust/issues/62586">issue</a>.</p>
<h3 id="avoid-references-to-copy-types"><a class="header" href="#avoid-references-to-copy-types">Avoid references to <code>Copy</code>-types</a></h3>
<p>Various generic APIs in Rust often return references to data (<code>&amp;T</code>). When <code>T</code> is
a small <code>Copy</code> type like <code>i32</code>, you end up with <code>&amp;i32</code> while many API expect
<code>i32</code>, so dereference has to happen <em>somewhere</em>. Prefer dereferencing as early
as possible, typically in a pattern:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// GOOD
fn compute(map: HashMap&lt;&amp;'str, i32&gt;) {
    if let Some(&amp;value) = map.get(&quot;key&quot;) {
        process(value)
    }
}
fn process(value: i32) { ... }

// BAD
fn compute(map: HashMap&lt;&amp;'str, i32&gt;) {
    if let Some(value) = map.get(&quot;key&quot;) {
        process(*value)
    }
}
fn process(value: i32) { ... }
<span class="boring">}
</span></code></pre></pre>
<p><strong>Rationale:</strong> If the value is used multiple times, dereferencing in the pattern
saves keystrokes. If the value is used exactly once, we just want to be
consistent. Additional benefit of early deref is reduced scope of borrow.</p>
<p>Note that for some <em>big</em> <code>Copy</code> types, notably <code>CryptoHash</code>, we sometimes use
references for performance reasons. As a rule of thumb, <code>T</code> is considered <em>big</em> if
<code>size_of::&lt;T&gt;() &gt; 2 * size_of::&lt;usize&gt;()</code>.</p>
<h3 id="prefer-for-loops-over-for_each-and-try_for_each-methods"><a class="header" href="#prefer-for-loops-over-for_each-and-try_for_each-methods">Prefer for loops over <code>for_each</code> and <code>try_for_each</code> methods</a></h3>
<p>Iterators offer <code>for_each</code> and <code>try_for_each</code> methods which allow executing
a closure over all items of the iterator. This is similar to using a for loop
but comes with various complications and may lead to less readable code.  Prefer
using a loop rather than those methods, for example:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// GOOD
for outcome_with_id in result? {
    *total_gas_burnt = total_gas_burnt
        .checked_add_result(outcome_with_id.outcome.gas_burnt)?;
    outcomes.push(outcome_with_id);
}

// BAD
result?.into_iter().try_for_each(
    |outcome_with_id: ExecutionOutcomeWithId| -&gt; Result&lt;(), RuntimeError&gt; {
        *total_gas_burnt = total_gas_burnt
            .checked_add_result(outcome_with_id.outcome.gas_burnt)?;
        outcomes.push(outcome_with_id);
        Ok(())
    },
)?;
<span class="boring">}
</span></code></pre></pre>
<p><strong>Rationale:</strong> The <code>for_each</code> and <code>try_for_each</code> method donâ€™t play nice with
<code>break</code> and <code>continue</code> statements nor do they mesh well with async IO (since
<code>.await</code> inside of the closure isnâ€™t possible). And while <code>try_for_each</code> allows
for the use of question mark operator, one may end up having to uses it twice:
once inside the closure and second time outside the call to <code>try_for_each</code>.
Furthermore, usage of the functions often introduce some minor syntax noise.</p>
<p>There are situations when those methods may lead to more readable code. Common
example are long call chains. Even then such code may evolve with the closure
growing and leading to less readable code. If advantages of using the methods
arenâ€™t clear cut, itâ€™s usually better to err on side of more imperative style.</p>
<p>Lastly, anecdotally the methods (e.g. when used with <code>chain</code> or <code>flat_map</code>) may
lead to faster code. This intuitively makes sense but itâ€™s worth to keep in
mind that compilers are pretty good at optimizing and in practice may generate
optimal code anyway. Furthermore, optimizing code for readability may be more
important (especially outside of hot path) than small performance gains.</p>
<h3 id="prefer-to_string-to-format"><a class="header" href="#prefer-to_string-to-format">Prefer <code>to_string</code> to <code>format!(&quot;{}&quot;)</code></a></h3>
<p>Prefer calling <code>to_string</code> method on an object rather than passing it through
<code>format!(&quot;{}&quot;)</code> if all youâ€™re doing is converting it to a <code>String</code>.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// GOOD
let hash = block_hash.to_string();
let msg = format!(&quot;{}: failed to open&quot;, path.display());

// BAD
let hash = format!(&quot;{block_hash}&quot;);
let msg = path.display() + &quot;: failed to open&quot;;
<span class="boring">}
</span></code></pre></pre>
<p><strong>Rationale:</strong> <code>to_string</code> is shorter to type and also faster.</p>
<h3 id="import-granularity"><a class="header" href="#import-granularity">Import Granularity</a></h3>
<p>Group imports by module, but not deeper:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// GOOD
use std::collections::{hash_map, BTreeSet};
use std::sync::Arc;

// BAD - nested groups.
use std::{
    collections::{hash_map, BTreeSet},
    sync::Arc,
};

// BAD - not grouped together.
use std::collections::BTreeSet;
use std::collections::hash_map;
use std::sync::Arc;
<span class="boring">}
</span></code></pre></pre>
<p>This corresponds to <code>&quot;rust-analyzer.imports.granularity.group&quot;: &quot;module&quot;</code> setting
in rust-analyzer
(<a href="https://rust-analyzer.github.io/manual.html#rust-analyzer.imports.granularity.group">docs</a>).</p>
<p><strong>Rationale:</strong> Consistency, matches existing practice.</p>
<h3 id="import-blocks"><a class="header" href="#import-blocks">Import Blocks</a></h3>
<p>Do not separate imports into groups with blank lines. Write a single block of
imports and rely on <code>rustfmt</code> to sort them.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// GOOD
use crate::types::KnownPeerState;
use borsh::BorshSerialize;
use near_primitives::utils::to_timestamp;
use near_store::{DBCol::Peers, Store};
use rand::seq::SliceRandom;
use std::collections::HashMap;
use std::net::SocketAddr;

// BAD -- several groups of imports
use std::collections::HashMap;
use std::net::SocketAddr;

use borsh::BorshSerialize;
use rand::seq::SliceRandom;

use near_primitives::utils::to_timestamp;
use near_store::{DBCol::Peers, Store};

use crate::types::KnownPeerState;
<span class="boring">}
</span></code></pre></pre>
<p><strong>Rationale:</strong> Consistency, ease of automatic enforcement. Today, stable rustfmt
can't split imports into groups automatically, and doing that manually
consistently is a chore.</p>
<h3 id="derives"><a class="header" href="#derives">Derives</a></h3>
<p>When deriving an implementation of a trait, specify a full path to the traits provided by the
external libraries:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// GOOD
#[derive(Copy, Clone, serde::Serialize, thiserror::Error, strum::Display)]
struct Grapefruit;

// BAD
use serde::Serialize;
use thiserror::Error;
use strum::Display;

#[derive(Copy, Clone, Serialize, Error, Display)]
struct Banana;
<span class="boring">}
</span></code></pre></pre>
<p>As an exception to this rule, it is okay to use either style when the derived trait already
includes the name of the library (as would be the case for <code>borsh::BorshSerialize</code>.)</p>
<p><strong>Rationale:</strong> Specifying a full path to the externally provided derivations here makes it
straightforward to differentiate between the built-in derivations and those provided by the
external crates. The surprise factor for derivations sharing a name with the standard
library traits (<code>Display</code>) is reduced and it also acts as natural mechanism to tell apart names
prone to collision (<code>Serialize</code>), all without needing to look up the list of imports.</p>
<h3 id="arithmetic-integer-operations"><a class="header" href="#arithmetic-integer-operations">Arithmetic integer operations</a></h3>
<p>Use methods with an appropriate overflow handling over plain arithmetic operators (<code>+-*/%</code>) when
dealing with integers.</p>
<pre><code>// GOOD
a.wrapping_add(b);
c.saturating_sub(2);
d.widening_mul(3);   // NB: unstable at the time of writing
e.overflowing_div(5);
f.checked_rem(7);

// BAD
a + b
c - 2
d * 3
e / 5
f % 7
</code></pre>
<p>If youâ€™re confident the arithmetic operation cannot fail,
<code>x.checked_[add|sub|mul|div](y).expect(&quot;explanation why the operation is safe&quot;)</code> is a great
alternative, as it neatly documents not just the infallibility, but also <em>why</em> that is the case.</p>
<p>This convention may be enforced by the <code>clippy::arithmetic_side_effects</code> and
<code>clippy::integer_arithmetic</code> lints.</p>
<p><strong>Rationale:</strong> By default the outcome of an overflowing computation in Rust depends on a few
factors, most notably the compilation flags used. The quick explanation is that in debug mode the
computations may panic (cause side effects) if the result has overflowed, and when built with
optimizations enabled, these computations will wrap-around instead.</p>
<p>For nearcore and neard we have opted to enable the panicking behavior regardless of the
optimization level. By doing it this we hope to prevent accidental stabilization of protocol
mis-features that depend on incorrect handling of these overflows or similarly scary silent bugs.
The downside to this approach is that any such arithmetic operation now may cause a node to crash,
much like indexing a vector with <code>a[idx]</code> may cause a crash when <code>idx</code> is out-of-bounds. Unlike
indexing, however, developers and reviewers are not used to treating integer arithmetic operations
with the due suspicion. Having to make a choice, and explicitly spell out, how an overflow case
ought to be handled will result in an easier to review and understand code and a more resilient
project overall.</p>
<h2 id="standard-naming"><a class="header" href="#standard-naming">Standard Naming</a></h2>
<ul>
<li>Use <code>-</code> rather than <code>_</code> in crate names and in corresponding folder names.</li>
<li>Avoid single-letter variable names especially in long functions.  Common <code>i</code>,
<code>j</code> etc. loop variables are somewhat of an exception but since Rust encourages
use of iterators those cases arenâ€™t that common anyway.</li>
<li>Follow standard <a href="https://rust-lang.github.io/api-guidelines/naming.html">Rust naming patterns</a> such as:
<ul>
<li>Donâ€™t use <code>get_</code> prefix for getter methods.  A getter method is one which
returns (a reference to) a field of an object.</li>
<li>Use <code>set_</code> prefix for setter methods.  An exception are builder objects
which may use different a naming style.</li>
<li>Use <code>into_</code> prefix for methods which consume <code>self</code> and <code>to_</code> prefix for
methods which donâ€™t.</li>
</ul>
</li>
<li>Use <code>get_block_header</code> rather than <code>get_header</code> for methods which return
a block header.</li>
<li>Donâ€™t use <code>_by_hash</code> suffix for methods which lookup chain objects (blocks,
chunks, block headers etc.) by their hash (i.e. their primary identifier).</li>
<li>Use <code>_by_height</code> and similar suffixes for methods which lookup chain objects
(blocks, chunks, block headers etc.) by their height or other property which
is not their hash.</li>
</ul>
<p><strong>Rationale:</strong> Consistency.</p>
<h2 id="documentation"><a class="header" href="#documentation">Documentation</a></h2>
<!-- cspell:ignore stkb -->
<p>When writing documentation in <code>.md</code> files, wrap lines at approximately 80
columns.</p>
<pre><code class="language-markdown">&lt;!-- GOOD --&gt;
Manually reflowing paragraphs is tedious. Luckily, most editors have this
functionality built in or available via extensions. For example, in Emacs you
can use `fill-paragraph` (&lt;kbd&gt;M-q&lt;/kbd&gt;), (neo)vim allows rewrapping with `gq`,
and VS Code has `stkb.rewrap` extension.

&lt;!-- BAD --&gt;
One sentence per-line is also occasionally used for technical writing.
We avoid that format though.
While convenient for editing, it may be poorly legible in unrendered form

&lt;!-- BAD --&gt;
Definitely don't use soft-wrapping. While markdown mostly ignores source level line breaks, relying on soft wrap makes the source completely unreadable, especially on modern wide displays.
</code></pre>
<h2 id="tracing"><a class="header" href="#tracing"><a href="https://tracing.rs">Tracing</a></a></h2>
<p>When emitting events and spans with <code>tracing</code>, use structured fields rather than
string formatting to include variable data. Always specify the <code>target</code>
explicitly, using the crate name or module path (e.g. <code>chain::client</code>) to group
related events.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// GOOD - structured fields with lowercase message
debug!(
    target: &quot;client&quot;,
    validator_id = self.client.validator_signer.get().map(|vs| {
        tracing::field::display(vs.validator_id())
    }),
    %hash,
    &quot;block.previous_hash&quot; = %block.header().prev_hash(),
    &quot;block.height&quot; = block.header().height(),
    %peer_id,
    was_requested,
    &quot;received block&quot;
);

// BAD - inline string formatting with capitalization
debug!(
    target: &quot;client&quot;,
    &quot;{:?} Received block {} &lt;- {} at {} from {}, requested: {}&quot;,
    self.client.validator_signer.get().map(|vs| vs.validator_id()),
    hash,
    block.header().prev_hash(),
    block.header().height(),
    peer_id,
    was_requested
);
<span class="boring">}
</span></code></pre></pre>
<p><strong>Rationale:</strong> Structured events are the core value proposition of the tracing
ecosystem. They allow for immediately actionable data without post-processing,
especially with advanced subscribers that output JSON or publish to distributed
systems like OpenTelemetry. Structured logging also generally executes faster
when logs are enabled.</p>
<p><strong>Always use the <code>tracing::</code> qualifier</strong> - Never use unqualified logging macros:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// GOOD - explicit qualifier
tracing::error!(target: &quot;client&quot;, ?err, &quot;failed to process&quot;);
tracing::warn!(target: &quot;sync&quot;, height, &quot;state sync started&quot;);

// BAD - unqualified macros
error!(target: &quot;client&quot;, ?err, &quot;failed to process&quot;);
warn!(target: &quot;sync&quot;, height, &quot;state sync started&quot;);
<span class="boring">}
</span></code></pre></pre>
<p><strong>Rationale:</strong> Explicit qualification improves code clarity by making it immediately obvious that tracing infrastructure is being used. It also prevents naming conflicts with other logging libraries or macros, and makes the code easier to search and refactor.</p>
<h3 id="message-format-conventions"><a class="header" href="#message-format-conventions">Message Format Conventions</a></h3>
<p>Follow these conventions for consistent, machine-friendly log messages:</p>
<ol>
<li><strong>Use lowercase</strong> - Start messages with a lowercase letter</li>
<li><strong>No ending punctuation</strong> - Omit periods, ellipsis, or other punctuation</li>
<li><strong>Use commas for continuation</strong> - When a message contains multiple clauses, use commas instead of periods to connect them</li>
</ol>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// GOOD - comma for continuation
tracing::warn!(target: &quot;sync&quot;, &quot;failed to connect, retrying in 200ms&quot;);
tracing::error!(target: &quot;store&quot;, &quot;database locked, waiting for release&quot;);

// BAD - period creates sentence fragment
tracing::warn!(target: &quot;sync&quot;, &quot;failed to connect. retrying in 200ms&quot;);
tracing::error!(target: &quot;store&quot;, &quot;database locked. waiting for release&quot;);
<span class="boring">}
</span></code></pre></pre>
<p><strong>Rationale:</strong> Using commas instead of periods maintains message flow and avoids creating sentence fragments. This keeps messages concise and parsable while still conveying multiple pieces of information.</p>
<ol start="4">
<li><strong>Fields before message</strong> - Place all structured fields before the message string</li>
<li><strong>Remove redundant prefixes</strong> - Don't repeat context from <code>target</code> or log level</li>
</ol>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// GOOD
debug!(target: &quot;sync&quot;, height, &quot;transition to state sync&quot;);
error!(target: &quot;client&quot;, ?err, &quot;failed to process block&quot;);

// BAD
debug!(target: &quot;sync&quot;, &quot;Sync: Transition to State Sync...&quot;);
error!(target: &quot;client&quot;, &quot;Error: failed to process block: {:?}&quot;, err);
<span class="boring">}
</span></code></pre></pre>
<h3 id="field-formatting"><a class="header" href="#field-formatting">Field Formatting</a></h3>
<p>Use the appropriate prefix for each field type:</p>
<ul>
<li><code>field</code> - Include field by name (Debug by default)</li>
<li><code>field = expr</code> - Explicitly compute and assign a value</li>
<li><code>?field</code> - Force Debug formatting (<code>{:?}</code>)</li>
<li><code>%field</code> - Force Display formatting (<code>{}</code>)</li>
</ul>
<p><strong>Recommended field ordering:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>log_macro!(
    target: &quot;target_name&quot;,     // 1. Target (always required)
    field1,                     // 2. Simple field references
    field2 = expr,              // 3. Computed fields
    ?debug_field,               // 4. Debug-formatted fields
    %display_field,             // 5. Display-formatted fields
    &quot;message string&quot;            // 6. Message always last
);
<span class="boring">}
</span></code></pre></pre>
<h3 id="additional-examples"><a class="header" href="#additional-examples">Additional Examples</a></h3>
<p><strong>Complex fields with context:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// GOOD
warn!(
    target: &quot;sync&quot;,
    %peer = peer.peer_info,
    peer_height = peer.highest_block_height,
    &quot;banning peer for insufficient headers&quot;
);

// BAD
warn!(
    target: &quot;sync&quot;,
    &quot;ban a peer: {}, for not providing enough headers. Peer's height: {}&quot;,
    peer.peer_info,
    peer.highest_block_height
);
<span class="boring">}
</span></code></pre></pre>
<p><strong>Error logging with context:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// GOOD
error!(
    target: &quot;runtime&quot;,
    thread_name = &quot;worker&quot;,
    task_id = task.id,
    ?err,
    &quot;failed to spawn thread&quot;
);

// BAD - missing context
error!(target: &quot;runtime&quot;, &quot;failed to spawn the thread: {}&quot;, err);
<span class="boring">}
</span></code></pre></pre>
<p><strong>Rationale for these conventions:</strong></p>
<ul>
<li><strong>Searchability:</strong> Structured fields enable precise querying and filtering</li>
<li><strong>Automation:</strong> Log aggregation tools (Loki, Elasticsearch, OpenTelemetry) can
automatically parse and index structured data</li>
<li><strong>Consistency:</strong> Predictable format improves readability and reduces cognitive load</li>
<li><strong>Machine-friendly:</strong> Lowercase, un-punctuated messages are easier for automated
systems to parse and analyze</li>
</ul>
<h3 id="spans-1"><a class="header" href="#spans-1">Spans</a></h3>
<p>Use the <a href="https://docs.rs/tracing/latest/tracing/#spans">spans</a> to introduce
context and grouping to and between events instead of manually adding such
information as part of the events themselves. Most of the subscribers ingesting
spans also provide a built-in timing facility, so prefer using spans for measuring
the amount of time a section of code needs to execute.</p>
<p>Give spans simple names that make them both easy to trace back to code, and to
find a particular span in logs or other tools ingesting the span data. If a
span begins at the top of a function, prefer giving it a name of that function,
otherwise prefer a <code>snake_case</code> name.</p>
<p>When instrumenting asynchronous functions the <a href="https://docs.rs/tracing-attributes/latest/tracing_attributes/attr.instrument.html"><code>#[tracing::instrument]</code></a> macro or the
<code>Future::instrument</code> is <strong>required</strong>. Using <code>Span::entered</code> or a similar method that is not aware
of yield points will result in incorrect span data and could lead to difficult to troubleshoot
issues such as stack overflows.</p>
<p>Always explicitly specify the <code>level</code>, <code>target</code>, and <code>skip_all</code> options and do not rely on the
default values. <code>skip_all</code> avoids adding all function arguments as span fields which can lead
recording potentially unnecessary and expensive information. Carefully consider which information
needs recording and the cost of recording the information when using the <code>fields</code> option.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[tracing::instrument(
    level = &quot;trace&quot;,
    target = &quot;network&quot;,
    &quot;handle_sync_routing_table&quot;,
    skip_all
)]
async fn handle_sync_routing_table(
    clock: &amp;time::Clock,
    network_state: &amp;Arc&lt;NetworkState&gt;,
    conn: Arc&lt;connection::Connection&gt;,
    rtu: RoutingTableUpdate,
) {
    ...
}
<span class="boring">}
</span></code></pre></pre>
<p>In regular synchronous code it is fine to use the regular span API if you need to instrument
portions of a function without affecting the code structure:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn compile_and_serialize_wasmer(code: &amp;[u8]) -&gt; Result&lt;wasmer::Module&gt; {
    // Some code...
    {
        let _span = tracing::debug_span!(target: &quot;vm&quot;, &quot;compile_wasmer&quot;).entered();
        // ...
        // _span will be dropped when this scope ends, terminating the span created above.
        // You can also `drop` it manually, to end the span early with `drop(_span)`.
    }
    // Some more code...
}
<span class="boring">}
</span></code></pre></pre>
<p><strong>Rationale:</strong> Much as with events, this makes the information provided by spans
structured and contextual. This information can then be output to tooling in an
industry standard format, and can be interpreted by an extensive ecosystem of
<code>tracing</code> subscribers.</p>
<h3 id="event-and-span-levels"><a class="header" href="#event-and-span-levels">Event and span levels</a></h3>
<p>The <code>INFO</code> level is enabled by default, use it for information useful for node
operators. The <code>DEBUG</code> level is enabled on the canary nodes, use it for
information useful in debugging testnet failures. The <code>TRACE</code> level is not
generally enabled, use it for arbitrary debug output.</p>
<h2 id="metrics"><a class="header" href="#metrics">Metrics</a></h2>
<p>Consider adding metrics to new functionality. For example, how often each type
of error was triggered, how often each message type was processed.</p>
<p><strong>Rationale:</strong> Metrics are cheap to increment, and they often provide a significant
insight into operation of the code, almost as much as logging. But unlike logging
metrics don't incur a significant runtime cost.</p>
<h3 id="naming"><a class="header" href="#naming">Naming</a></h3>
<p>Prefix all <code>nearcore</code> metrics with <code>near_</code>. Follow the
<a href="https://prometheus.io/docs/practices/naming/">Prometheus naming convention</a>
for new metrics.</p>
<p><strong>Rationale:</strong> The <code>near_</code> prefix makes it trivial to separate metrics exported
by <code>nearcore</code> from other metrics, such as metrics about the state of the machine
that runs <code>neard</code>.</p>
<h3 id="performance"><a class="header" href="#performance">Performance</a></h3>
<p>In most cases incrementing a metric is cheap enough never to give it a second
thought. However accessing a metric with labels on a hot path needs to be done
carefully.</p>
<p>If a label is based on an integer, use a faster way of converting an integer
to the label, such as the <code>itoa</code> crate.</p>
<p>For hot code paths, re-use results of <code>with_label_values()</code> as much as possible.</p>
<p><strong>Rationale:</strong> We've encountered issues caused by the runtime costs of
incrementing metrics before. Avoid runtime costs of incrementing metrics too
often.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="documentation-1"><a class="header" href="#documentation-1">Documentation</a></h1>
<p>This chapter describes nearcore's approach to documentation. There are three
primary types of documentation to keep in mind:</p>
<ul>
<li><a href="https://nomicon.io"><strong>The NEAR Protocol Specification</strong></a>
(<a href="https://github.com/near/NEPs">source code</a>) is the formal description of
the NEAR protocol. The reference nearcore implementation and any other NEAR
client implementations must follow this specification.</li>
<li><a href="https://docs.near.org"><strong>User docs</strong></a> (<a href="https://github.com/near/docs">source code</a>)
explain what is NEAR and how to participate in the network. In particular,
they contain information pertinent to the users of NEAR: validators and
smart contract developers.</li>
<li><a href="https://near.github.io/nearcore/"><strong>Documentation for nearcore developers</strong></a>
(<a href="https://github.com/near/nearcore/tree/master/docs">source code</a>) is the
book you are reading right now! The target audience here is the contributors
to the main implementation of the NEAR protocol (nearcore).</li>
</ul>
<h2 id="overview-6"><a class="header" href="#overview-6">Overview</a></h2>
<p>The bulk of the internal docs is within this book. If you want to write some
kind of document, add it here! The <a href="practices/../architecture/">architecture</a> and
<a href="practices/../practices/">practices</a> chapters are intended for somewhat up-to-date
normative documents. The <a href="practices/../misc/">misc</a> chapter holds everything else.</p>
<p>This book is not intended for user-facing documentation, so don't worry about
proper English, typos, or beautiful diagrams -- just write stuff! It can easily
be improved over time with pull requests. For docs, we use a lightweight review
process and try to merge any improvement as quickly as possible. Rather than
blocking a PR on some stylistic changes, just merge it and submit a follow-up.</p>
<p>Note the &quot;edit&quot; button at the top-right corner -- super useful for fixing any
typos you spot!</p>
<p>In addition to the book, we also have some &quot;inline&quot; documentation in the code.
For Rust, it is customary to have a per-crate <code>README.md</code> file and include it as
a doc comment via <code>#![doc = include_str!(&quot;../README.md&quot;)]</code> in <code>lib.rs</code>. We don't
<em>require</em> every item to be documented, but we certainly encourage documenting as
much as possible. If you spend some time refactoring or fixing a function,
consider adding a doc comment (<code>///</code>) to it as a drive-by improvement.</p>
<p>We currently don't render <code>rustdoc</code>, see <a href="https://github.com/near/nearcore/issues/7836">#7836</a>.</p>
<h2 id="book-how-to"><a class="header" href="#book-how-to">Book How To</a></h2>
<p>We use mdBook to render a bunch of markdown files as a static website with a table
of contents, search and themes. Full docs are <a href="https://rust-lang.github.io/mdBook/">here</a>,
but the basics are very simple.</p>
<p>To add a new page to the book:</p>
<ol>
<li>Add a <code>.md</code> file somewhere in the
<a href="https://github.com/near/nearcore/tree/master/docs"><code>./docs</code></a> folder.</li>
<li>Add a link to that page to the
<a href="https://github.com/near/nearcore/blob/master/docs/SUMMARY.md"><code>SUMMARY.md</code></a>.</li>
<li>Submit a PR (again, we promise to merge it without much ceremony).</li>
</ol>
<p>The doc itself is in vanilla markdown.</p>
<p>To render documentation locally:</p>
<!-- cspell:ignore mdbook -->
<pre><code class="language-console"># Install mdBook
$ cargo install mdbook
$ mdbook serve --open ./docs
</code></pre>
<p>This will generate the book from the docs folder, open it in a browser and
start a file watcher to rebuild the book every time the source files change.</p>
<p>Note that GitHub's default rendering mostly works just as well, so you don't
need to go out of your way to preview your changes when drafting a page or
reviewing pull requests to this book.</p>
<p>The book is deployed via the
<a href="https://github.com/near/nearcore/blob/master/.github/workflows/book.yml">book GitHub Action workflow</a>.
This workflow runs mdBook and then deploys the result to
<a href="https://docs.github.com/en/pages/getting-started-with-github-pages/about-github-pages">GitHub Pages</a>.</p>
<p>For internal docs, you often want to have pretty pictures. We don't currently
have a recommended workflow, but here are some tips:</p>
<ul>
<li>
<p>Don't add binary media files to Git to avoid inflating repository size.
Rather, upload images as comments to this super-secret issue
<a href="https://github.com/near/nearcore/issues/7821">#7821</a>, and then link to
the images as</p>
<pre><code>![image](https://user-images.githubusercontent.com/1711539/195626792-7697129b-7f9c-4953-b939-0b9bcacaf72c.png)
</code></pre>
<p>Use a single comment per page with multiple images.</p>
</li>
<li>
<p>Google Docs is an OK way to create technical drawings, you can add a link to
the doc with source to that secret issue as well.</p>
</li>
<li>
<p>There's some momentum around using mermaid.js for diagramming, and there's
an appropriate <a href="https://github.com/badboy/mdbook-mermaid">plugin</a> for that.
Consider if that's something you might want to use.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="tracking-issues"><a class="header" href="#tracking-issues">Tracking issues</a></h1>
<p><code>nearcore</code> uses so-called &quot;tracking issues&quot; to coordinate larger pieces of work
(e.g. implementation of new NEPs).  Such issues are tagged with the
<a href="https://github.com/near/nearcore/issues?q=is%3Aopen+is%3Aissue+label%3AC-tracking-issue"><code>C-tracking-issue</code>
label</a>.</p>
<p>The goal of tracking issues is to serve as a coordination point. They can help
new contributors and other interested parties come up to speed with the current
state of projects. As such, they should link to things like design docs,
todo-lists of sub-issues, existing implementation PRs, etc.</p>
<p>One can further use tracking issues to:</p>
<ul>
<li>get a feeling for what's happening in <code>nearcore</code> by looking at the set of
open tracking issues.</li>
<li>find larger efforts to contribute to as tracking issues usually contain
up-for-grab to-do lists.</li>
<li>follow the progress of specific features by subscribing to the issue on GitHub.</li>
</ul>
<p>If you are leading or participating in a larger effort, please create a tracking
issue for your work.</p>
<h2 id="guidelines"><a class="header" href="#guidelines">Guidelines</a></h2>
<ul>
<li>Tracking issues should be maintained in the <code>nearcore</code> repository. If the
projects are security sensitive, then they should be maintained in the
<code>nearcore-private</code> repository.</li>
<li>The issues should be kept up-to-date. At a minimum, all new context
should be added as comments, but preferably the original description should be
edited to reflect the current status.</li>
<li>The issues should contain links to all the relevant design documents
which should also be kept up-to-date.</li>
<li>The issues should link to any relevant NEP if applicable.</li>
<li>The issues should contain a list of to-do tasks that should be kept
up-to-date as new work items are discovered and other items are done. This
helps others gauge progress and helps lower the barrier of entry for others to
participate.</li>
<li>The issues should contain links to relevant Zulip discussions. Prefer
open forums like Zulip for discussions. When necessary, closed forums like
video calls can also be used but care should be taken to document a summary of
the discussions.</li>
<li>For security-sensitive discussions, use the appropriate private Zulip streams.</li>
</ul>
<p><a href="https://github.com/near/nearcore/issues/7670">This issue</a> is a good example of
how tracking issues should be maintained.</p>
<h2 id="background-1"><a class="header" href="#background-1">Background</a></h2>
<p>The idea of tracking issues is also used to track project work in the Rust
language. See <a href="https://internals.rust-lang.org/t/how-the-rust-issue-tracker-works/3951">this
post</a>
for a rough description and
<a href="https://github.com/rust-lang/rust/issues/101840">these</a>
<a href="https://github.com/rust-lang/rust/issues/100717">issues</a> for how they are used
in Rust.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h2 id="security-vulnerabilities"><a class="header" href="#security-vulnerabilities">Security Vulnerabilities</a></h2>
<!-- cspell:ignore rgba -->
<blockquote style="background: rgba(255, 200, 0, 0.1); border: 5px solid rgba(255, 200, 0, 0.4);">
<p>The intended audience of the information presented here is developers working
on the implementation of NEAR.</p>
<p>Are you a security researcher? Please report security vulnerabilities to
<a href="mailto:security@near.org">security@near.org</a>.</p>
</blockquote>
<p>As nearcore is open source, all of its issues and pull requests are also
publicly tracked on GitHub. However, from time to time, if a security-sensitive
issue is discovered, it cannot be tracked publicly on GitHub. However, we
should promote as similar a development process to work on such issues as
possible. To enable this, below is the high-level process for working on
security-sensitive issues.</p>
<ol>
<li>
<p>There is a <a href="https://github.com/near/nearcore-private">private fork of
nearcore</a> on GitHub. Access to
this repository is restricted to the set of people who are trusted to work on
and have knowledge about security-sensitive issues in nearcore.</p>
<p>This repository can be manually synced with the public nearcore repository
using the following commands:</p>
<pre><code class="language-console">git remote add nearcore-public git@github.com:near/nearcore
git remote add nearcore-private git@github.com:near/nearcore-private
git fetch nearcore-public
git push nearcore-private nearcore-public/master:master
</code></pre>
</li>
<li>
<p>All security-sensitive issues must be created on the private nearcore
repository. You must also assign one of the <code>[P-S0, P-S1]</code> labels to the
issue to indicate the severity of the issue. The two criteria to use to help
you judge the severity are the ease of carrying out the attack and the impact
of the attack. An attack that is easy to do or can have a huge impact should
have the <code>P-S0</code> label and <code>P-S1</code> otherwise.</p>
</li>
<li>
<p>All security-sensitive pull requests should also be created on the private
nearcore repository. Note that once a PR has been approved, it should not be
merged into the private repository. Instead, it should be first merged into
the public repository and then the private fork should be updated using the
steps above.</p>
</li>
<li>
<p>Once work on a security issue is finished, it needs to be deployed to all the
impacted networks. Please contact the node team for help with this.</p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="fast-builds"><a class="header" href="#fast-builds">Fast Builds</a></h1>
<p>nearcore is implemented in Rust and is a fairly sizable project, so it takes a
while to build. This chapter collects various tips to make the development
process faster.</p>
<p>Optimizing build times is a bit of a black art, so please do benchmarks on your
machine to verify that the improvements work for you. Changing some configuration
and making a typo, which prevents it from improving build times is an
extremely common failure mode!</p>
<p><a href="https://nnethercote.github.io/perf-book/compile-times.html">Rust Perf Book</a>
contains a section on compilation times as well!</p>
<h2 id="release-builds-and-link-time-optimization"><a class="header" href="#release-builds-and-link-time-optimization">Release Builds and Link Time Optimization</a></h2>
<p><code>cargo build --release</code> is obviously slower than <code>cargo build</code>. We enable full
lto (link-time optimization), so our <code>-r</code> builds are very slow, use a lot of
RAM, and don't utilize the available parallelism fully.</p>
<p>As debug builds are much too slow at runtime for many purposes, we have a custom
profile <code>--profile dev-release</code> which is equivalent to <code>-r</code>, except that the
time-consuming options such as LTO are disabled, and debug assertions are enabled.</p>
<p>Use <code>--profile dev-release</code> for most local development, or when connecting a
locally built node to a network. Use <code>-r</code> for production, or if you want to get
absolute performance numbers.</p>
<h2 id="linker"><a class="header" href="#linker">Linker</a></h2>
<p>By default, <code>rustc</code> uses the default system linker, which tends to be quite
slow. Using <code>lld</code> (LLVM linker) or <code>mold</code> (very new, very fast linker) provides
big wins for many setups.</p>
<p>I don't know what's the official source of truth for using alternative linkers,
I usually refer to <a href="https://github.com/rust-lang/rust/issues/39915#issuecomment-538049306">this
comment</a>.</p>
<p>Usually, adding</p>
<pre><code class="language-toml">[build]
rustflags = [&quot;-C&quot;, &quot;link-arg=-fuse-ld=lld&quot;]
</code></pre>
<p>to <code>~/.cargo/config</code> is the most convenient approach.</p>
<p><code>lld</code> itself can be installed with <code>sudo apt install lld</code> (or the equivalent in
the distro/package manager of your choice).</p>
<h2 id="prebuilt-rocksdb"><a class="header" href="#prebuilt-rocksdb">Prebuilt RocksDB</a></h2>
<p>By default, we compile RocksDB (a C++ project) from source during the neard
build. By linking to a prebuilt copy of RocksDB this work can be avoided
entirely. This is a huge win, especially if you clean the <code>./target</code> directory
frequently.</p>
<p>To use a prebuilt RocksDB, set the <code>ROCKSDB_LIB_DIR</code> environment variable to
a location containing <code>librocksdb.a</code>:</p>
<pre><code class="language-console">export ROCKSDB_LIB_DIR=/usr/lib/x86_64-linux-gnu
cargo build -p neard
</code></pre>
<p>Note, that the system must provide a recent version of the library which,
depending on which operating system youâ€™re using, may require installing packages
from a testing branch. For example, on Debian it requires installing
<code>librocksdb-dev</code> from the <code>experimental</code> repository:</p>
<p><strong>Note:</strong> Based on which distro you are using this process will look different.
Please refer to the documentation of the package manager you are using.</p>
<pre><code class="language-bash">echo 'deb http://ftp.debian.org/debian experimental main contrib non-free' |
    sudo tee -a /etc/apt/sources.list
sudo apt update
sudo apt -t experimental install librocksdb-dev

ROCKSDB_LIB_DIR=/usr/lib/x86_64-linux-gnu
export ROCKSDB_LIB_DIR
</code></pre>
<h2 id="global-compilation-cache"><a class="header" href="#global-compilation-cache">Global Compilation Cache</a></h2>
<!-- cspell:ignore sccache direnv -->
<p>By default, Rust compiles incrementally, with the incremental cache and
intermediate outputs stored in the project-local <code>./target</code> directory.</p>
<p>The <a href="https://github.com/mozilla/sccache"><code>sccache</code></a> utility can be used to share
these artifacts between machines or checkouts within the same machine. <code>sccache</code>
works by intercepting calls to <code>rustc</code> and will fetch the cached outputs from
the global cache whenever possible. This tool can be set up as such:</p>
<pre><code class="language-console">cargo install sccache
export RUSTC_WRAPPER=&quot;sccache&quot;
export SCCACHE_CACHE_SIZE=&quot;30G&quot;
cargo build -p neard
</code></pre>
<p>Refer to the <a href="https://github.com/mozilla/sccache">projectâ€™s README</a> for further
configuration options.</p>
<h2 id="ides-are-bad-for-environment-handling"><a class="header" href="#ides-are-bad-for-environment-handling">IDEs Are Bad For Environment Handling</a></h2>
<p>Generally, the knobs in this section are controlled either via global
configuration in <code>~/.cargo/config</code> or environment variables.</p>
<p>Environment variables are notoriously easy to lose, especially if you are
working both from a command line and a graphical IDE. Double-check that the
environment within which builds are executed is identical to avoid nasty
failure modes such as full cache invalidation when switching from the
CLI to an IDE or vice-versa.</p>
<p><a href="https://direnv.net"><code>direnv</code></a> sometimes can be used to conveniently manage
project-specific environment variables.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="general-principles"><a class="header" href="#general-principles">General principles</a></h1>
<ol>
<li>Every PR needs to have test coverage in place. Sending the code change and
deferring tests for a future change is not acceptable.</li>
<li>Tests need to either be sufficiently simple to follow or have good
documentation to explain why certain actions are made and conditions are
expected.</li>
<li>When implementing a PR, <strong>make sure to run the new tests with the change
disabled and confirm that they fail</strong>! It is extremely common to have tests
that pass without the change that is being tested.</li>
<li>The general rule of thumb for a reviewer is to first review the tests, and
ensure that they can convince themselves that the code change that passes the
tests must be correct. Only then the code should be reviewed.</li>
<li>Have the assertions in the tests as specific as possible,
however do not make the tests change-detectors of the concrete implementation.
(assert only properties which are required for correctness).
For example, do not do <code>assert!(result.is_err())</code>, expect the specific error instead.</li>
</ol>
<h1 id="tests-hierarchy"><a class="header" href="#tests-hierarchy">Tests hierarchy</a></h1>
<p>In the NEAR Reference Client we largely split tests into three categories:</p>
<ol>
<li><strong>Relatively cheap sanity or fast fuzz tests:</strong> It includes all the <code>#[test]</code>
Rust tests not decorated by features. Our repo is configured in such a way
that all such tests are run on every PR and failing at least one of them is
blocking the PR from being merged.</li>
</ol>
<p>To run such tests locally run <code>cargo nextest run --all</code>.
It requires nextest harness which can be installed by running <code>cargo install cargo-nextest</code> first.</p>
<ol start="2">
<li><strong>Expensive tests:</strong> This includes all the fuzzy tests that run many iterations,
as well as tests that spin up multiple nodes and run them until they reach a
certain condition. Such tests are decorated with
<code>#[cfg(feature=&quot;expensive-tests&quot;)]</code>. It is not trivial to enable features
that are not declared in the top-level crate, and thus the easiest way to run
such tests is to enable all the features by passing <code>--all-features</code> to
<code>cargo nextest run</code>, e.g:</li>
</ol>
<p><code>cargo nextest run --package near-client -E 'test(=tests::cross_shard_tx::test_cross_shard_tx)' --all-features</code></p>
<ol start="3">
<li><strong>Python tests:</strong> We have an infrastructure to spin up nodes, both locally and
remotely, in python, and interact with them using RPC. The infrastructure and
the tests are located in the <code>pytest</code> folder. The infrastructure is relatively
straightforward, see for example <code>block_production.py</code>
<a href="https://github.com/near/nearcore/blob/master/pytest/tests/sanity/block_production.py">here</a>.
See the <code>Test infrastructure</code> section below for details.</li>
</ol>
<p>Expensive and python tests are not part of CI, and are run by a custom nightly
runner. The results of the latest runs are available
<a href="https://nayduck.nearone.org/#/">here</a>. Today, test runs launch approximately
every 5-6 hours. For the latest results look at the <strong>second</strong> run, since the
first one has some tests still scheduled to run.</p>
<h1 id="test-infrastructure"><a class="header" href="#test-infrastructure">Test infrastructure</a></h1>
<p>Different levels of the reference implementation have different infrastructures
available to test them.</p>
<h2 id="client"><a class="header" href="#client">Client</a></h2>
<p>The Client is separated from the runtime via a <code>RuntimeAdapter</code> trait for historical reasons.
In production, it uses <code>NightshadeRuntime</code> which uses real runtime and epoch managers.
The same should be used in tests.</p>
<p>Most of the tests in the client work by setting up either a single node (via
<code>setup_mock()</code>) or multiple nodes (via <code>setup_mock_all_validators()</code>) and then
launching the nodes and waiting for a particular message to occur, with a
predefined timeout.</p>
<p>For the most basic example of using this infrastructure see <code>produce_two_blocks</code>
in
<a href="https://github.com/near/nearcore/blob/master/integration-tests/src/tests/client/process_blocks.rs"><code>tests/process_blocks.rs</code></a>.</p>
<ol>
<li>The callback (<code>Box::new(move |msg, _ctx, _| { ...</code>) is what is executed
whenever the client sends a message. The return value of the callback is sent
back to the client, which allows for testing relatively complex scenarios. The
tests generally expect a particular message to occur, in this case, the tests
expect two blocks to be produced. <code>near_async::shutdown_all_actors();</code> is the way to
stop the test and mark it as passed.</li>
<li>See <code>near_network::test_utils::wait_or_timeout</code> for how to wait for some condition
to be true or panic if it doesn't within a certain time.</li>
</ol>
<p>For an example of a test that launches multiple nodes, see
<code>chunks_produced_and_distributed_common</code> in
<a href="https://github.com/near/nearcore/blob/master/integration-tests/src/tests/client/chunks_management.rs">integration-tests/src/tests/client/chunks_management.rs | Network chunk management test</a>.
The <code>setup_mock_all_validators</code> function is the key piece of infrastructure here.</p>
<h2 id="runtime-1"><a class="header" href="#runtime-1">Runtime</a></h2>
<p>Tests for Runtime are listed in
<a href="https://github.com/near/nearcore/blob/master/integration-tests/src/tests/standard_cases/runtime.rs">tests/test_cases_runtime.rs</a>.</p>
<p>To run a test, usually, a mock <code>RuntimeNode</code> is created via <code>create_runtime_node()</code>.
In its constructor, the <code>Runtime</code> is created in the
<code>get_runtime_and_trie_from_genesis</code> function.</p>
<p>Inside a test, an abstracted <code>User</code> is used for sending specific actions to the
runtime client. The helper functions <code>function_call</code>, <code>deploy_contract</code>, etc.
eventually lead to the <code>Runtime.apply</code> method call.</p>
<p>For setting usernames during playing with transactions, use default names
<code>alice_account</code>, <code>bob_account</code>, <code>eve_dot_alice_account</code>, etc.</p>
<h2 id="network-1"><a class="header" href="#network-1">Network</a></h2>
<!-- TODO: Explain the `runner` here -->
<h2 id="chain-epoch-manager-runtime-and-other-low-level-changes"><a class="header" href="#chain-epoch-manager-runtime-and-other-low-level-changes">Chain, Epoch Manager, Runtime and other low-level changes</a></h2>
<p>When building new features in the <code>chain</code>, <code>epoch_manager</code> and <code>network</code> crates,
make sure to build new components sufficiently abstract so that they can be tested
without relying on other components.</p>
<p>For example, see tests for doomslug
<a href="https://github.com/near/nearcore/blob/master/chain/chain/src/tests/doomslug.rs">here</a>,
for network cache
<a href="https://github.com/near/nearcore/blob/master/chain/network/src/routing/edge_cache/tests.rs">here</a>,
or for promises in runtime
<a href="https://github.com/near/nearcore/blob/master/runtime/near-vm-runner/src/logic/tests/promises.rs">here</a>.</p>
<h2 id="python-tests"><a class="header" href="#python-tests">Python tests</a></h2>
<p>See
<a href="practices/testing/python_tests.html">this page</a>
for detailed coverage of how to write a python test.</p>
<p>We have a python library that allows one to create and run python tests.</p>
<p>To run python tests, from the <code>nearcore</code> repo the first time, do the following:</p>
<pre><code class="language-shell">cd pytest
virtualenv . --python=python3
. .env/bin/activate
pip install -r requirements.txt
python tests/sanity/block_production.py
</code></pre>
<p>This will create a python virtual environment, activate the environment, install
all the required packages specified in the <code>requirements.txt</code> file and run the
<code>tests/sanity/block_production.py</code> file. After the first time, we only need to
activate the environment and can then run the tests:</p>
<pre><code class="language-shell">cd pytest
. .env/bin/activate
python tests/sanity/block_production.py
</code></pre>
<p>Use <code>pytest/tests/sanity/block_production.py</code> as the basic example of starting a
cluster with multiple nodes, and doing RPC calls.</p>
<p>See <code>pytest/tests/sanity/deploy_call_smart_contract.py</code> to see how contracts can
be deployed, or transactions called.</p>
<p>See <code>pytest/tests/sanity/staking1.py</code> to see how staking transactions can be
issued.</p>
<p>See <code>pytest/tests/sanity/state_sync.py</code> to see how to delay the launch of the
whole cluster by using <code>init_cluster</code> instead of <code>start_cluster</code>, and then
launching nodes manually.</p>
<h3 id="enabling-adversarial-behavior"><a class="header" href="#enabling-adversarial-behavior">Enabling adversarial behavior</a></h3>
<p>To allow testing adversarial behavior, or generally, behaviors that a node should
not normally exercise, we have certain features in the code decorated with
<code>#[cfg(feature=&quot;adversarial&quot;)]</code>. The binary normally is compiled with the
feature disabled, and when compiled with the feature enabled, it traces a
warning on launch.</p>
<p>The nightly runner runs all the python tests against the binary compiled with
the feature enabled, and thus the python tests can make the binary perform
actions that it normally would not perform.</p>
<p>The actions can include lying about the known chain height, producing multiple
blocks for the same height, or disabling doomslug.</p>
<p>See all the tests under <code>pytest/tests/adversarial</code> for some examples.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="python-tests-1"><a class="header" href="#python-tests-1">Python Tests</a></h1>
<p>To simplify writing integration tests for nearcore we have a python
infrastructure that allows writing a large variety of tests that run small local
clusters, remove clusters, or run against full-scale live deployments.</p>
<p>Such tests are written in python and not in Rust (in which the nearcore itself,
and most of the sanity and fuzz tests, are written) due to the availability of
libraries to easily connect to, remove nodes and orchestrate cloud instances.</p>
<p>Nearcore itself has several features guarded by a
<a href="https://doc.rust-lang.org/1.29.0/book/first-edition/conditional-compilation.html">feature flag</a>
that allows the python tests to invoke behaviors otherwise impossible to be
exercised by an honest actor.</p>
<h1 id="basics-1"><a class="header" href="#basics-1">Basics</a></h1>
<p>The infrastructure is located in <code>{nearcore}/pytest/lib</code> and the tests themselves
are in subdirectories of <code>{nearcore}/pytest/tests</code>. To prepare the local machine to
run the tests you'd need python3 (python 3.7), and have several dependencies
installed, for which we recommend using virtualenv:</p>
<pre><code>cd pytest
virtualenv .env --python=python3
. .env/bin/activate
pip install -r requirements.txt
</code></pre>
<p>The tests are expected to be ran from the <code>pytest</code> dir itself. For example, once
the virtualenv is configured:</p>
<pre><code>cd pytest
. .env/bin/activate
python tests/sanity/block_production.py
</code></pre>
<p>This will run the most basic tests that spin up a small cluster locally and wait
until it produces several blocks.</p>
<h2 id="compiling-the-client-for-tests"><a class="header" href="#compiling-the-client-for-tests">Compiling the client for tests</a></h2>
<p>The local tests by default expect the binary to be in the default location for a
debug build (<code>{nearcore}/target/debug</code>). Some tests might also expect
test-specific features guarded by a feature flag to be available. To compile the
binary with such features run:</p>
<pre><code>cargo build -p neard --features=adversarial
</code></pre>
<p>The feature is called <code>adversarial</code> to highlight that the many functions it enables,
outside of tests, would constitute malicious behavior. The node compiled with
such a flag will not start unless an environment variable <code>ADVERSARY_CONSENT=1</code>
is set and prints a noticeable warning when it starts, thus minimizing the chance
that an honest participant accidentally launches a node compiled with such
functionality.</p>
<p>You can change the way the tests run (locally or using Google Cloud), and where
the local tests look for the binary by supplying a config file. For example, if you
want to run tests against a release build, you can create a file with the
following config:</p>
<pre><code class="language-json">{&quot;local&quot;: true, &quot;near_root&quot;: &quot;../target/release/&quot;}
</code></pre>
<p>and run the test with the following command:</p>
<pre><code class="language-shell">NEAR_PYTEST_CONFIG=&lt;path to config&gt; python tests/sanity/block_production.py
</code></pre>
<h1 id="writing-tests"><a class="header" href="#writing-tests">Writing tests</a></h1>
<p>We differentiate between &quot;regular&quot; tests, or tests that spin up their cluster,
either local or on the cloud, and &quot;mocknet&quot; tests, or tests that run against
an existing live deployment of NEAR.</p>
<p>In both cases, the test starts by importing the infrastructure and starting or
connecting to a cluster</p>
<h2 id="starting-a-cluster"><a class="header" href="#starting-a-cluster">Starting a cluster</a></h2>
<p>In the simplest case a regular test starts by starting a cluster. The cluster
will run locally by default but can be spun up on the cloud by supplying the
corresponding config.</p>
<pre><code class="language-python">import sys
sys.path.append('lib')
from cluster import start_cluster

nodes = start_cluster(4, 0, 4, None, [[&quot;epoch_length&quot;, 10], [&quot;block_producer_kickout_threshold&quot;, 80]], {})
</code></pre>
<p>In the example above the first three parameters are <code>num_validating_nodes</code>,
<code>num_observers</code> and <code>num_shards</code>. The third parameter is a config, which generally
should be <code>None</code>, in which case the config is picked up from the environment
variable as shown above.</p>
<p><code>start_cluster</code> will spin up <code>num_validating_nodes</code> nodes that are block
producers (with pre-staked tokens), <code>num_observers</code> non-validating nodes and
will configure the system to have <code>num_shards</code> shards. The fifth argument
changes the genesis config. Each element is a list of some length <code>n</code> where the
first <code>n-1</code> elements are a path in the genesis JSON file, and the last element
is the value. You'd often want to significantly reduce the epoch length, so that
your test triggers epoch switches, and reduce the kick-out threshold since with
shorter epochs it is easier for a block producer to get kicked out.</p>
<p>The last parameter is a dictionary from the node ordinal to changes to their
local config.</p>
<p>Note that <code>start_cluster</code> spins up all the nodes right away. Some tests (e.g.
tests that test syncing) might want to configure the nodes but delay their
start. In such a case you will initialize the cluster by calling
<code>init_cluster</code> and will run the nodes manually, for example, see
<a href="https://github.com/near/nearcore/blob/master/pytest/tests/sanity/state_sync.py"><code>state_sync.py</code></a></p>
<h2 id="connecting-to-a-mocknet"><a class="header" href="#connecting-to-a-mocknet">Connecting to a mocknet</a></h2>
<p>Nodes that run against a mocknet would connect to an existing cluster instead of
running their own.</p>
<pre><code class="language-python">import sys
sys.path.append('lib')
from cluster import connect_to_mocknet

nodes, accounts = connect_to_mocknet(None)
</code></pre>
<p>The only parameter is a config, with <code>None</code> meaning to use the config from the
environment variable. The config should have the following format:</p>
<pre><code class="language-json">{
    &quot;nodes&quot;: [
        {&quot;ip&quot;: &quot;(some_ip)&quot;, &quot;port&quot;: 3030},
        {&quot;ip&quot;: &quot;(some_ip)&quot;, &quot;port&quot;: 3030},
        {&quot;ip&quot;: &quot;(some_ip)&quot;, &quot;port&quot;: 3030},
        {&quot;ip&quot;: &quot;(some_ip)&quot;, &quot;port&quot;: 3030}
    ],
    &quot;accounts&quot;: [
        {&quot;account_id&quot;: &quot;node1&quot;, &quot;pk&quot;: &quot;ed25519:&lt;public key&gt;&quot;, &quot;sk&quot;: &quot;edd25519:&lt;secret key&gt;&quot;},
        {&quot;account_id&quot;: &quot;node2&quot;, &quot;pk&quot;: &quot;ed25519:&lt;public key&gt;&quot;, &quot;sk&quot;: &quot;edd25519:&lt;secret key&gt;&quot;}
    ]
}
</code></pre>
<h2 id="manipulating-nodes"><a class="header" href="#manipulating-nodes">Manipulating nodes</a></h2>
<p>The nodes returned by <code>start_cluster</code> and <code>init_cluster</code> have certain
convenience functions. You can see the full interface in
<code>{nearcore}/pytest/lib/cluster.py</code>.</p>
<p><code>start(boot_public_key, (boot_ip, boot_port))</code> starts the node. If both
arguments are <code>None</code>, the node will start as a boot node (note that the concept
of a &quot;boot node&quot; is relatively vague in a decentralized system, and from the
perspective of the tests the only requirement is that the graph of &quot;node A
booted from node B&quot; is connected).</p>
<p>The particular way to get the <code>boot_ip</code> and <code>boot_port</code> when launching <code>node1</code>
with <code>node2</code> being its boot node is the following:</p>
<pre><code class="language-python">node1.start(node2.node_key.pk, node2.addr())
</code></pre>
<p><code>kill()</code> shuts down the node by sending it <code>SIGKILL</code></p>
<p><code>reset_data()</code> cleans up the data dir, which could be handy between the calls to
<code>kill</code> and <code>start</code> to see if a node can start from a clean state.</p>
<p>Nodes on the mocknet do not expose <code>start</code>, <code>kill</code> and <code>reset_data</code>.</p>
<h2 id="issuing-rpc-calls"><a class="header" href="#issuing-rpc-calls">Issuing RPC calls</a></h2>
<p>Nodes in both regular and mocknet tests expose an interface to issue RPC calls.
In the most generic case, one can just issue raw JSON RPC calls by calling the
<code>json_rpc</code> method:</p>
<pre><code class="language-python">validator_info = nodes[0].json_rpc('validators', [&lt;some block_hash&gt;])
</code></pre>
<p>For the most popular calls, there are convenience functions:</p>
<ul>
<li><code>send_tx</code> sends a signed transaction asynchronously</li>
<li><code>send_tx_and_wait</code> sends a signed transaction synchronously</li>
<li><code>get_status</code> returns the current status (the output of the <code>/status/endpoint</code>),
which contains e.g. last block hash and height</li>
<li><code>get_tx</code> returns a transaction by the transaction hash and the recipient ID.</li>
</ul>
<p>See all the methods in <code>{nearcore}/pytest/lib/cluster.rs</code> after the definition
of the <code>json_rpc</code> method.</p>
<h3 id="signing-and-sending-transactions"><a class="header" href="#signing-and-sending-transactions">Signing and sending transactions</a></h3>
<p>There are two ways to send a transaction. A synchronous way (<code>send_tx_and_wait</code>)
sends a tx and blocks the test execution until either the TX is finished, or the
timeout is hit. An asynchronous way (<code>send_tx</code> + <code>get_tx</code>) sends a TX and then
verifies its result later. Here's an end-to-end example of sending a
transaction:</p>
<pre><code class="language-python"># the tx needs to include one of the recent hashes
last_block_hash = nodes[0].get_status()['sync_info']['latest_block_hash']
last_block_hash_decoded = base58.b58decode(last_block_hash.encode('utf8'))

# sign the actual transaction
# `fr` and `to` in this case are instances of class `Key`.
# In mocknet tests the list `Key`s for all the accounts are returned by `connect_to_mocknet`
# In regular tests each node is associated with a single account, and its key is stored in the
# `signer_key` field (e.g. `nodes[0].signer_key`)
# `15` in the example below is the nonce. Nonces needs to increase for consecutive transactions
# for the same sender account.
tx = sign_payment_tx(fr, to.account_id, 100, 15, last_block_hash_decoded)

# Sending the transaction synchronously. `10` is the timeout in seconds. If after 10 seconds the
# outcome is not ready, throws an exception
if want_sync:
    outcome = nodes[0].send_tx_and_wait(tx, 10)

# Sending the transaction asynchronously.
if want_async:
    tx_hash = nodes[from_ordinal % len(nodes)].send_tx(tx)['result']

    # and then sometime later fetch the result...
    resp = nodes[0].get_tx(tx_hash, to.account_id, timeout=1)
    # and see if the tx has finished
    finished = 'result' in resp and 'receipts_outcome' in resp['result'] and len(resp['result']['receipts_outcome']) &gt; 0
</code></pre>
<p>See
<a href="https://github.com/near/nearcore/blob/master/pytest/tests/sanity/rpc_tx_forwarding.py">rpc_tx_forwarding.py</a>
for an example of signing and submitting a transaction.</p>
<h2 id="adversarial-behavior"><a class="header" href="#adversarial-behavior">Adversarial behavior</a></h2>
<p>Some tests need certain nodes in the cluster to exercise behavior that is
impossible to be invoked by an honest node. For such tests, we provide
functionality that is protected by an &quot;adversarial&quot; feature flag.</p>
<p>It's an advanced feature, and more thorough documentation is a TODO. Most of the
tests that depend on the feature flag enabled are under
<code>{nearcore}/pytest/tests/adversarial</code>, refer to them for how such features can
be used. Search for code in the <code>nearcore</code> codebase guarded by the &quot;adversarial&quot;
feature flag for an example of how such features are added and exposed.</p>
<h2 id="interfering-with-the-network"><a class="header" href="#interfering-with-the-network">Interfering with the network</a></h2>
<p>We have a library that allows running a proxy in front of each node that would
intercept all the messages between nodes, deserialize them in python and run a
handler on each one. The handler can then either let the message pass (<code>return True</code>), drop it (<code>return False</code>) or replace it (<code>return &lt;new message&gt;</code>).</p>
<p>This technique can be used to both interfere with the network (by dropping or
replacing messages), and to inspect messages that flow through the network
without interfering with them. For the latter, note that the handler for each node
runs in a separate <code>Process</code>, and thus you need to use <code>multiprocessing</code>
primitives if you want the handlers to exchange information with the main test
process, or between each other.</p>
<p>See the tests that match <code>tests/sanity/proxy_*.py</code> for examples.</p>
<h1 id="contributing-tests"><a class="header" href="#contributing-tests">Contributing tests</a></h1>
<p>We always welcome new tests, especially python tests that use the above
infrastructure. We have a list of test requests
<a href="https://github.com/nearprotocol/nearcore/issues?q=is%3Aissue+is%3Aopen+label%3A%22A-testing%22">here</a>,
but also welcome any other tests that test aspects of the network we haven't
thought about.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="cheat-sheetoverview-of-testing-utils"><a class="header" href="#cheat-sheetoverview-of-testing-utils">Cheat sheet/overview of testing utils</a></h1>
<p>This page covers the different testing utils/libraries that we have for easier
unit testing in Rust.</p>
<h2 id="basics-2"><a class="header" href="#basics-2">Basics</a></h2>
<h3 id="cryptohash-1"><a class="header" href="#cryptohash-1">CryptoHash</a></h3>
<p>To create a new crypto hash:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>&quot;ADns6sqVyFLRZbSMCGdzUiUPaDDtjTmKCWzR8HxWsfDU&quot;.parse().unwrap();
<span class="boring">}
</span></code></pre></pre>
<h3 id="account-3"><a class="header" href="#account-3">Account</a></h3>
<p>Also, prefer doing parse + unwrap:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let alice: AccountId = &quot;alice.near&quot;.parse().unwrap();
<span class="boring">}
</span></code></pre></pre>
<h3 id="signatures"><a class="header" href="#signatures">Signatures</a></h3>
<p>In memory signer (generates the key based on a seed). There is a slight preference
to use the seed that is matching the account name.</p>
<p>This will create a signer for account 'test' using 'test' as a seed.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let signer: InMemoryValidatorSigner = create_test_signer(&quot;test&quot;);
<span class="boring">}
</span></code></pre></pre>
<h3 id="block"><a class="header" href="#block">Block</a></h3>
<p>Use <code>TestBlockBuilder</code> to create the block that you need. This class allows you to set custom values for most of the fields.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let test_block = test_utils::TestBlockBuilder::new(prev, signer).height(33).build();
<span class="boring">}
</span></code></pre></pre>
<h2 id="store"><a class="header" href="#store">Store</a></h2>
<p>Use the in-memory test store in tests:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let store = create_test_store();
<span class="boring">}
</span></code></pre></pre>
<h2 id="epochmanager-1"><a class="header" href="#epochmanager-1">EpochManager</a></h2>
<p>Use EpochManager itself.</p>
<h2 id="runtime-2"><a class="header" href="#runtime-2">Runtime</a></h2>
<p>Use Nightshade runtime.</p>
<h2 id="chain"><a class="header" href="#chain">Chain</a></h2>
<p>No fakes or mocks.</p>
<h2 id="client-1"><a class="header" href="#client-1">Client</a></h2>
<p>TestEnv - for testing multiple clients (without network):</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>TestEnvBuilder::new(genesis).client(vec![&quot;aa&quot;]).validators(..).epoch_managers(..).build();
<span class="boring">}
</span></code></pre></pre>
<h2 id="network-2"><a class="header" href="#network-2">Network</a></h2>
<h3 id="peermanager"><a class="header" href="#peermanager">PeerManager</a></h3>
<p>To create a PeerManager handler:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let pm = peer_manager::testonly::start(...).await;
<span class="boring">}
</span></code></pre></pre>
<p>To connect to others:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pm.connect_to(&amp;pm2.peer_info).await;
<span class="boring">}
</span></code></pre></pre>
<h3 id="events-handling"><a class="header" href="#events-handling">Events handling</a></h3>
<p>To wait/handle a given event (as a lot of network code is running in an async fashion):</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pm.events.recv_util(|event| match event {...}).await;
<span class="boring">}
</span></code></pre></pre>
<h2 id="end-to-end"><a class="header" href="#end-to-end">End to End</a></h2>
<h3 id="chain-runtime-signer"><a class="header" href="#chain-runtime-signer">chain, runtime, signer</a></h3>
<p>In chain/chain/src/test_utils.rs:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Creates 1-validator (test):  chain, KVRuntime and a signer
let (chain, runtime, signer) = setup();
<span class="boring">}
</span></code></pre></pre>
<h3 id="block-client-actor-view-client"><a class="header" href="#block-client-actor-view-client">block, client actor, view client</a></h3>
<p>In chain/client/src/test_utils.rs</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let (block, client, view_client) = setup(MANY_FIELDS);
<span class="boring">}
</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="test-coverage"><a class="header" href="#test-coverage">Test Coverage</a></h1>
<p>In order to focus the testing effort where it is most needed, we have a few
ways we track test coverage.</p>
<h2 id="codecov"><a class="header" href="#codecov">Codecov</a></h2>
<p>The main one is Codecov. Coverage is visible <a href="https://app.codecov.io/gh/near/nearcore">on this
webpage</a>, and displays the total
coverage, including unit and integration tests. Codecov is especially
interesting for <a href="https://github.com/near/nearcore/pull/10731#issuecomment-1985356880">its PR
comments</a>.
The PR comments, in particular, can easily show which diff lines are being
tested and which are not.</p>
<p>However, sometimes Codecov gives too rough estimates, and this is where
artifact results come in.</p>
<h2 id="artifact-results"><a class="header" href="#artifact-results">Artifact Results</a></h2>
<p>We also push artifacts, as a result of each CI run. You can access them here:</p>
<ol>
<li>Click &quot;Details&quot; on one of the CI actions run on your PR (literally any one
of the actions is fine, you can also access CI actions runs on any CI)</li>
<li>Click &quot;Summary&quot; on the top left of the opening page</li>
<li>Scroll to the bottom of the page</li>
<li>In the &quot;Artifacts&quot; section, just above the &quot;Summary&quot; section, there is a
<code>coverage-html</code> link (there is also <code>coverage-lcov</code> for people who use eg.
the coverage gutters vscode integration)</li>
<li>Downloading it will give you a zip file with the interesting files.</li>
</ol>
<p>In there, you can find:</p>
<ul>
<li>Two <code>-diff</code> files, that contain code coverage for the diff of your PR, to
easily see exactly which lines are covered and which are not</li>
<li>Two <code>-full</code> folders, that contain code coverage for the whole repository</li>
<li>Each of these exists in one <code>unit-</code> variant, that only contains the unit
tests, and one <code>integration-</code> variant, that contains all the tests we
currently have</li>
</ul>
<p><strong>To check that your PR is properly tested</strong>, if you want better quality
coverage than what codecov &quot;requires,&quot; you can have a look at <code>unit-diff</code>,
because we agreed that we want unit tests to be able to detect most bugs
due to the troubles of debugging failing integration tests.</p>
<p><strong>To find a place that would deserve adding more tests</strong>, look at one of the
<code>-full</code> directories on master, pick one not-well-tested file, and add (ideally
unit) tests for the lines that are missing.</p>
<p>The presentation is unfortunately less easy to access than codecov, and less
eye-catchy. On the other hand, it should be more precise. In particular, the
<code>-full</code> variants show region-based coverage. It can tell you that eg. the <code>?</code>
branch is not covered properly by highlighting it red.</p>
<p>One caveat to be aware of: the <code>-full</code> variants do not highlight covered lines
in green, they just highlight non-covered lines in red.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h2 id="protocol-upgrade-1"><a class="header" href="#protocol-upgrade-1">Protocol Upgrade</a></h2>
<p>This document describes the entire cycle of how a protocol upgrade is done, from
the initial PR to the final release. It is important for everyone who
contributes to the development of the protocol and its client(s) to understand
this process.</p>
<h3 id="background-2"><a class="header" href="#background-2">Background</a></h3>
<p>At NEAR, we use the term protocol version to mean the version of the blockchain
protocol and is separate from the version of some specific client (such as nearcore),
since the protocol version defines the protocol rather than some specific
implementation of the protocol. More concretely, for each epoch, there is a
corresponding protocol version that is agreed upon by validators through
<a href="https://github.com/near/NEPs/blob/master/specs/ChainSpec/Upgradability.md">a voting mechanism</a>.
Our upgrade scheme dictates that protocol version X is backward compatible with
protocol version X-1 so that nodes in the network can seamlessly upgrade to
the new protocol. However, there is <strong>no guarantee</strong> that protocol version X is
backward compatible with protocol version X-2.</p>
<p>Despite the upgrade mechanism, rolling out a protocol change can be scary,
especially if the change is invasive. For those changes, we may want to have
several months of testing before we are confident that the change itself works
and that it doesn't break other parts of the system.</p>
<h3 id="protocol-version-voting-and-upgrade"><a class="header" href="#protocol-version-voting-and-upgrade">Protocol version voting and upgrade</a></h3>
<p>When a new neard version, containing a new protocol version, is released, all node maintainers need
to upgrade their binary. That typically means stopping neard, downloading or compiling the new neard
binary and restarting neard. However the protocol version of the whole network is not immediately
bumped to the new protocol version. Instead a process called voting takes place and determines if and
when the protocol version upgrade will take place.</p>
<p>Voting is a fully automated process in which all block producers across the network vote in support
or against upgrading the protocol version. The voting happens in the last block every epoch. Upgraded
nodes will begin voting in favour of the new protocol version after a predetermined date. The voting
date is configured by the release owner <a href="https://github.com/near/nearcore/commit/9b0275de057a01f87c259580f93e58f746da75aa">like this</a>.
Once at least 80% of the stake votes in favour of the protocol change in the last block of epoch X, the
protocol version will be upgraded in the first block of epoch X+2.</p>
<p>For mainnet releases, the release on github typically happens on a Monday or Tuesday, the voting
typically happens a week later and the protocol version upgrade happens 1-2 epochs after the voting. This
gives the node maintainers enough time to upgrade their neard nodes. The node maintainers can upgrade
their nodes at any time between the release and the voting but it is recommended to upgrade soon after the
release. This is to accommodate for any database migrations or miscellaneous delays.</p>
<p>Starting a neard node with protocol version voting in the future in a network that is already operating
at that protocol version is supported as well. This is useful in the scenario where there is a mainnet
security release where mainnet has not yet voted or upgraded to the new version. That same binary with
protocol voting date in the future can be released in testnet even though it has already upgraded to
the new protocol version.</p>
<h3 id="nightly-protocol-features"><a class="header" href="#nightly-protocol-features">Nightly Protocol features</a></h3>
<p>To make protocol upgrades more robust, we introduce the concept of a nightly
protocol version together with the protocol feature flags to allow easy testing
of the cutting-edge protocol changes without jeopardizing the stability of the
codebase overall. The use of the <code>nightly</code> feature for new protocol features
is mandatory while the use of dedicated rust features for new protocol features
is optional and only recommended when necessary. Adding rust features leads to
conditional compilation which is generally not developer friendly. In <code>Cargo.toml</code>
file of the crates we have in nearcore, we introduce the rust compile-time feature
<code>nightly</code>:</p>
<pre><code class="language-toml">nightly = [
    ...
]
</code></pre>
<p>where <code>nightly</code> is a collection of new protocol features that indicates we are using
the nightly protocol version.</p>
<p>When it is not necessary to use a rust feature for the new protocol feature
the Cargo.toml file will remain unchanged.</p>
<p>When it is necessary to use a rust feature for the new protocol feature, it
can be added to the Cargo.toml, to the nightly features. For example, when
we introduce EVM as a new protocol change, suppose the current protocol
version is 40, then we would do the following change in Cargo.toml:</p>
<pre><code class="language-toml">nightly = [
    &quot;protocol_features_evm&quot;,
    ...
]
</code></pre>
<p>In <a href="https://github.com/near/nearcore/blob/master/core/primitives-core/src/version.rs">core/primitives-core/src/version.rs</a>, we would
change the protocol version by:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub const PROTOCOL_VERSION: ProtocolVersion = 
    if cfg!(feature = &quot;nightly&quot;) { NIGHTLY_PROTOCOL_VERSION } else { STABLE_PROTOCOL_VERSION };
<span class="boring">}
</span></code></pre></pre>
<p>This way the stable versions remain unaffected after the change. Note that
nightly protocol version intentionally starts at a much higher number to make
the distinction between the stable protocol and nightly protocol clearer.</p>
<p>To determine whether a protocol feature is enabled, we do the following:</p>
<ul>
<li>We maintain a <code>ProtocolFeature</code> enum where each variant corresponds to some
protocol feature. For nightly protocol features, the variant may optionally
be gated by the corresponding rust compile-time feature.</li>
<li>We implement a function <code>protocol_version</code> to return, for each variant, the
corresponding protocol version in which the feature is enabled.</li>
<li>When we need to decide whether to use the new feature based on the protocol
version of the current network, we can simply compare it to the protocol
version of the feature. To make this simpler, we also introduced a macro
<code>checked_feature</code></li>
</ul>
<p>For more details, please refer to
<a href="https://github.com/near/nearcore/blob/master/core/primitives/src/version.rs">core/primitives/src/version.rs</a>.</p>
<h3 id="feature-gating"><a class="header" href="#feature-gating">Feature Gating</a></h3>
<p>It is worth mentioning that there are two types of checks related to protocol features:</p>
<ul>
<li>Runtime checks that compare the protocol version of the current epoch and
the protocol version of the feature. Those runtime checks must be used for
both stable and nightly features.</li>
<li>Compile time checks that check if the rust feature corresponding with the
protocol feature is enabled. This check is optional and can only be used for
nightly features.</li>
</ul>
<h3 id="testing-1"><a class="header" href="#testing-1">Testing</a></h3>
<p>Nightly protocol features allow us to enable the most bleeding-edge code in some
testing environments. We can choose to enable all nightly protocol features by</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>cargo build -p neard --release --features nightly
<span class="boring">}
</span></code></pre></pre>
<p>or enable some specific protocol feature by</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>cargo build -p neard --release --features nightly,&lt;protocol_feature&gt;
<span class="boring">}
</span></code></pre></pre>
<p>In practice, we have all nightly protocol features enabled for Nayduck tests and
on betanet, which is updated daily.</p>
<h3 id="feature-stabilization"><a class="header" href="#feature-stabilization">Feature Stabilization</a></h3>
<p>New protocol features are introduced first as nightly features and when the
author of the feature thinks that the feature is ready to be stabilized, they
should submit a pull request to stabilize the feature using
<a href="practices/../../.github/PULL_REQUEST_TEMPLATE/feature_stabilization.html">this template</a>.
In this pull request, they should do the feature gating, increase the
<code>PROTOCOL_VERSION</code> constant (if it hasn't been increased since the last
release), and change the <code>protocol_version</code> implementation to map the
stabilized features to the new protocol version.</p>
<p>A feature stabilization request must be approved by at least <strong>two</strong>
<a href="https://github.com/orgs/near/teams/nearcore-codeowners">nearcore code owners</a>.
Unless it is a security-related fix, a protocol feature cannot be included in
any release until at least <strong>one</strong> week after its stabilization. This is to ensure
that feature implementation and stabilization are not rushed.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<p>This document describes the advanced network options that you can configure
by modifying the &quot;network&quot; section of your &quot;config.json&quot; file:</p>
<pre><code>{
  // ...
  &quot;network&quot;: {
    // ...
    &quot;public_addrs&quot;: [],
    &quot;allow_private_ip_in_public_addrs&quot;: false,
    &quot;experimental&quot;: {
      &quot;inbound_disabled&quot;: false,
      &quot;connect_only_to_boot_nodes&quot;: false,
      &quot;skip_sending_tombstones_seconds&quot;: 0,
      &quot;tier1_enable_inbound&quot;: true,
      &quot;tier1_enable_outbound&quot;: false,
      &quot;tier1_connect_interval&quot;: {
        &quot;secs&quot;: 60,
        &quot;nanos&quot;: 0
      },
      &quot;tier1_new_connections_per_attempt&quot;: 50
    }
  },
  // ...
}
</code></pre>
<h3 id="tier1-network"><a class="header" href="#tier1-network">TIER1 network</a></h3>
<p>Participants of the BFT consensus (block &amp; chunk producers) now can establish
direct (aka TIER1) connections between each other, which will optimize the
communication latency and minimize the number of dropped chunks. If you are a
validator, you can enable TIER1 connections by setting the following fields in the config:</p>
<ul>
<li><a href="https://github.com/near/nearcore/blob/d95a5f58d998c69cb8d4e965ad6b0a440cf3f233/chain/network/src/config_json.rs#L154">public_addrs</a>
<ul>
<li>this is a list of the public addresses (in the format <code>&quot;&lt;node public key&gt;@&lt;IP&gt;:&lt;port&gt;&quot;</code>)
of trusted nodes, which are willing to route messages to your node</li>
<li>this list will be broadcasted to the network so that other validator nodes can connect
to your node.</li>
<li>if your node has a static public IP, set <code>public_addrs</code> to a list with a single entry
with the public key and address of your node, for example:
<code>&quot;public_addrs&quot;: [&quot;ed25519:86EtEy7epneKyrcJwSWP7zsisTkfDRH5CFVszt4qiQYw@31.192.22.209:24567&quot;]</code>.</li>
<li>if your node doesn't have a public IP (for example, it is hidden behind a NAT), set
<code>public_addrs</code> to a list (&lt;=10 entries) of proxy nodes that you trust (arbitrary nodes
with static public IPs).</li>
<li>support for nodes with dynamic public IPs is not implemented yet.</li>
</ul>
</li>
<li><a href="https://github.com/near/nearcore/blob/d95a5f58d998c69cb8d4e965ad6b0a440cf3f233/chain/network/src/config_json.rs#L213">experimental.tier1_enable_outbound</a>
<ul>
<li>makes your node actively try to establish outbound TIER1 connections (recommended)
once it learns about the public addresses of other validator nodes. If disabled, your
node won't try to establish outbound TIER1 connections, but it still may accept
incoming TIER1 connections from other nodes.</li>
<li>currently <code>false</code> by default, but will be changed to <code>true</code> by default in the future</li>
</ul>
</li>
<li><a href="https://github.com/near/nearcore/blob/d95a5f58d998c69cb8d4e965ad6b0a440cf3f233/chain/network/src/config_json.rs#L209">experimental.tier1_enable_inbound</a>
<ul>
<li>makes your node accept inbound TIER1 connections from other validator nodes.</li>
<li>disable both <code>tier1_enable_inbound</code> and <code>tier1_enable_outbound</code> if you want to opt-out
from the TIER1 communication entirely</li>
<li>disable <code>tier1_enable_inbound</code> if you are not a validator AND you don't want your
node to act as a proxy for validators.</li>
<li><code>true</code> by default</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="starting-a-test-chain-from-state-taken-from-mainnet-or-testnet"><a class="header" href="#starting-a-test-chain-from-state-taken-from-mainnet-or-testnet">Starting a test chain from state taken from mainnet or testnet</a></h1>
<h2 id="purpose"><a class="header" href="#purpose">Purpose</a></h2>
<p>For testing purposes, it is often desirable to start a test chain with
a starting state that looks like mainnet or testnet. This is usually
done for the purpose of testing changes to neard itself, but it's also
possible to do this if you're a contract developer and want to see
what a change to your contract would look like on top of the current
mainnet state. At the end of the process described here, you'll have
a set of genesis records that can be used to start your own test chain,
that'll be like any other test chain like the ones generated by the
<code>neard localnet</code> command, except with account balances and data taken
from mainnet</p>
<h2 id="how-to"><a class="header" href="#how-to">How-to</a></h2>
<p>The first step is to obtain an RPC node home directory for the chain
you'd like to spoon. So if you want to use mainnet state, you can
follow the instructions
<a href="https://near-nodes.io/rpc/run-rpc-node-without-nearup#5-get-data-backup-1">here</a>
to obtain a recent snapshot of a mainnet node's home directory. Once
you have your node's home directory set up, run the following
<code>state-viewer</code> command to generate a dump of the chain's state:</p>
<pre><code class="language-shell">neard --home $NEAR_HOME_DIRECTORY view-state dump-state --stream
</code></pre>
<p>This command will take a while (possibly many hours) to run. But at the
end you should have <code>genesis.json</code> and <code>records.json</code> files in
<code>$NEAR_HOME_DIRECTORY/output</code>. This records file represents all of the
chain's current state, and is what we'll use to start our chain.</p>
<p>From here, we need to make some changes to the <code>genesis.json</code> that was
generated in <code>$NEAR_HOME_DIRECTORY/output</code>. To see why, note that the
validators field of this genesis file lists all the current mainnet
validators and their keys. So that means if we were to try and start a
test chain from the generated genesis and records files as-is, it
would work, but our node would expect the current mainnet validators
to be producing blocks and chunks (which they definitely won't be!
Because we're the only ones who know or care about this new test
chain).</p>
<p>So we need to select a new list of validators to start off our
chain. Suppose that we want our chain to have two validators,
<code>validator0.near</code> and <code>validator1.near</code>. Let's make a new directory
where we'll be storing intermediate files during this process:</p>
<pre><code class="language-shell">mkdir ~/test-chain-scratch
</code></pre>
<p>then using your favorite editor, lay out the validators you want in
the test chain as a JSON list in the same format as the <code>validators</code>
field in <code>genesis.json</code>, maybe in the file
<code>~/test-chain-scratch/validators.json</code></p>
<pre><code class="language-json">[
  {
    &quot;account_id&quot;: &quot;validator0.near&quot;,
    &quot;public_key&quot;: &quot;ed25519:GRAFkrqEkJAbdbWUgc6fDnNpCTE83C3pzdJpjAHkMEhq&quot;,
    &quot;amount&quot;: &quot;100000000000000000000000000000000&quot;
  },
  {
    &quot;account_id&quot;: &quot;validator1.near&quot;,
    &quot;public_key&quot;: &quot;ed25519:5FxQQTC9mk5kLAhTF9ffDMTXiyYrDXyGYskgz46kHMdd&quot;,
    &quot;amount&quot;: &quot;100000000000000000000000000000000&quot;
  }
]
</code></pre>
<p>These validator keys should be keys you've already generated. So for
the rest of this document, we'll assume you've run:</p>
<pre><code class="language-shell">neard --home ~/near-test-chain/validator0 init --account-id validator0.near
neard --home ~/near-test-chain/validator1 init --account-id validator1.near
</code></pre>
<p>This is also a good time to think about what extra accounts you might
want in your test chain. Since all accounts in the test chain will
have the same keys as they do on mainnet, you'll only have access to
the accounts that you have access to on mainnet. If you want to add an
account with a large balance to properly test things out, you can
write them out in a file as a JSON list of state records (in the same
format as they appear in <code>records.json</code>). For example, you could put
the following in <code>~/test-chain-scratch/extra-records.json</code>:</p>
<pre><code class="language-json">[
  {
    &quot;Account&quot;: {
      &quot;account_id&quot;: &quot;my-test-account.near&quot;,
      &quot;account&quot;: {
        &quot;amount&quot;: &quot;10000000000000000000000000000000000&quot;,
        &quot;locked&quot;: &quot;0&quot;,
        &quot;code_hash&quot;: &quot;11111111111111111111111111111111&quot;,
        &quot;storage_usage&quot;: 182,
        &quot;version&quot;: &quot;V1&quot;
      }
    }
  },
  {
    &quot;AccessKey&quot;: {
      &quot;account_id&quot;: &quot;my-test-account.near&quot;,
      &quot;public_key&quot;: &quot;ed25519:Eo9W44tRMwcYcoua11yM7Xfr1DjgR4EWQFM3RU27MEX8&quot;,
      &quot;access_key&quot;: {
        &quot;nonce&quot;: 0,
        &quot;permission&quot;: &quot;FullAccess&quot;
      }
    }
  }
]
</code></pre>
<p>You'll want to include an access key here, otherwise you won't be able
to do anything with the account. Note that here you can also add
access keys for any mainnet account you want, so you'll be able to
control it in the test chain.</p>
<p>Now to make these changes to the genesis and records files, you can
use the <code>neard amend-genesis</code> command like so:</p>
<pre><code class="language-shell"># mkdir ~/near-test-chain/
$ neard amend-genesis --genesis-file-in $NEAR_HOME_DIRECTORY/output/genesis.json --records-file-in $NEAR_HOME_DIRECTORY/output/records.json --validators ~/test-chain-scratch/validators.json --extra-records ~/test-chain-scratch/extra-records.json --chain-id $TEST_CHAIN_ID --records-file-out ~/near-test-chain/records.json --genesis-file-out ~/near-test-chain/genesis.json
</code></pre>
<h2 id="starting-the-network"><a class="header" href="#starting-the-network">Starting the network</a></h2>
<p>After running the previous steps you should have the files
<code>genesis.json</code> and <code>records.json</code> in <code>~/near-test-chain/</code>. Assuming
you've started it with the two validators <code>validator0.near</code> and
<code>validator1.near</code> as described above, you'll want to run at least two
nodes, one for each of these validator accounts. If you're working
with multiple computers or VMs that can connect to each other over the
internet, you'll be able to run your test network over the internet as
is done with the &quot;real&quot; networks (mainnet, testnet, etc.). But for now
let's assume that you want to run this on only one machine.</p>
<p>So assuming you've initialized home directories for each of the
validators with the <code>init</code> command described above, you'll want to
copy the records and genesis files generated in the previous step to
each of these:</p>
<pre><code class="language-shell">cp ~/near-test-chain/records.json ~/near-test-chain/validator0
cp ~/near-test-chain/genesis.json ~/near-test-chain/validator0
cp ~/near-test-chain/records.json ~/near-test-chain/validator1
cp ~/near-test-chain/genesis.json ~/near-test-chain/validator1
</code></pre>
<p>Now we'll need to make a few config changes to each of
<code>~/near-test-chain/validator0/config.json</code> and
<code>~/near-test-chain/validator1/config.json</code>:</p>
<p>changes to <code>~/near-test-chain/validator0/config.json</code>:</p>
<pre><code class="language-json">{
  &quot;genesis_records_file&quot;: &quot;records.json&quot;,
  &quot;rpc&quot;: {
    &quot;addr&quot;: &quot;0.0.0.0:3030&quot;
  },
  &quot;network&quot;: {
    &quot;addr&quot;: &quot;0.0.0.0:24567&quot;,
    &quot;boot_nodes&quot;: &quot;ed25519:Dk4A7NPBYFPwKWouiSUoyZ15igbLSrcPEJqUqDX4grb7@127.0.0.1:24568&quot;,
    &quot;skip_sync_wait&quot;: false,
  },
  &quot;consensus&quot;: {
    &quot;min_num_peers&quot;: 1
  },
  &quot;tracked_shards_config&quot;: &quot;AllShards&quot;,
}
</code></pre>
<p>changes to <code>~/near-test-chain/validator1/config.json</code>:</p>
<pre><code class="language-json">{
  &quot;genesis_records_file&quot;: &quot;records.json&quot;,
  &quot;rpc&quot;: {
    &quot;addr&quot;: &quot;0.0.0.0:3031&quot;
  },
  &quot;network&quot;: {
    &quot;addr&quot;: &quot;0.0.0.0:24568&quot;,
    &quot;boot_nodes&quot;: &quot;ed25519:6aR4xVQedQ7Z9URrASgwBY8bedpaYzgH8u5NqEHp2hBv@127.0.0.1:24567&quot;,
    &quot;skip_sync_wait&quot;: false,
  },
  &quot;consensus&quot;: {
    &quot;min_num_peers&quot;: 1
  },
  &quot;tracked_shards_config&quot;: &quot;AllShards&quot;,
}
</code></pre>
<p>Here we make sure to have each node listen on different ports, while
telling each about the other via <code>network.boot_nodes</code>. In this
<code>boot_nodes</code> string, we set the public key not to the validator key,
but to whatever key is present in the <code>node_key.json</code> file you got
when you initialized the home directory. So for <code>validator0</code>'s config,
we set its boot node to <code>validator1</code>'s node key, followed by the
address of the socket it should be listening on. We also want to drop
the minimum required number of peers, since we're just running a small
test network locally. We set <code>skip_sync_wait</code> to <code>false</code>, because
otherwise we get strange behavior that will often make your network
stall.</p>
<p>After making these changes, you can try running one neard process for
each of your validators:</p>
<pre><code class="language-shell">neard --home ~/near-test-chain/validator0 run
neard --home ~/near-test-chain/validator1 run
</code></pre>
<p>Now these nodes will begin by taking the records laid out in
<code>records.json</code> and turning them into a genesis state. At the time of
this writing, using the latest nearcore version from the master
branch, this will take a couple hours. But your validators should
begin producing blocks after that's done.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="overview-7"><a class="header" href="#overview-7">Overview</a></h1>
<p>This chapter holds various assorted bits of docs. If you want to document
something, but don't know where to put it, put it here!</p>
<h2 id="crate-versioning-and-publishing"><a class="header" href="#crate-versioning-and-publishing">Crate Versioning and Publishing</a></h2>
<p>While all the crates in the workspace are directly unversioned (<code>v0.0.0</code>), they
all share a unified variable version in the <a href="misc/../../Cargo.toml">workspace manifest</a>.
This keeps versions consistent across the workspace and informs their versions
at the moment of publishing.</p>
<p>We also have CI infrastructure set up to automate the publishing process to
crates.io. So, on every merge to master, if there's a version change, it is
automatically applied to all the crates in the workspace and it attempts to
publish the new versions of all non-private crates. All crates that should be
exempt from this process should be marked <code>private</code>. That is, they should have
the <code>publish = false</code> specification in their package manifest.</p>
<p>This process is managed by
<a href="https://github.com/pksunkara/cargo-workspaces">cargo-workspaces</a>, with a
<a href="https://github.com/pksunkara/cargo-workspaces/compare/master...miraclx:grouping-and-exclusion#files_bucket">bit of magic</a>
sprinkled on top.</p>
<h2 id="issue-labels"><a class="header" href="#issue-labels">Issue Labels</a></h2>
<p>Issue labels are of the following format <code>&lt;type&gt;-&lt;content&gt;</code> where <code>&lt;type&gt;</code> is a
capital letter indicating the type of the label and <code>&lt;content&gt;</code> is a hyphened
phrase indicating what this label is about. For example, in the label <code>C-bug</code>,
<code>C</code> means category and <code>bug</code> means that the label is about bugs. Common types
include <code>C</code>, which means category, <code>A</code>, which means area and <code>T</code>, which means team.</p>
<p>An issue can have multiple labels including which area it touches, which team
should be responsible for the issue, and so on. Each issue should have at least
one label attached to it after it is triaged and the label could be a general
one, such as <code>C-enhancement</code> or <code>C-bug</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="experimental-dump-state-to-external-storage"><a class="header" href="#experimental-dump-state-to-external-storage">Experimental: Dump State to External Storage</a></h1>
<h2 id="purpose-1"><a class="header" href="#purpose-1">Purpose</a></h2>
<p><a href="misc/../architecture/how/sync.html#step-2-state-sync-normal-node">State Sync</a> is being
reworked.</p>
<p>A new version is available for experimental use. This version gets state parts
from external storage. The following kinds of external storage are supported:</p>
<ul>
<li>Local filesystem</li>
<li>Google Cloud Storage</li>
<li>Amazon S3</li>
</ul>
<p>A new version of decentralized state sync is work in progress.</p>
<h2 id="how-to-1"><a class="header" href="#how-to-1">How-to</a></h2>
<p>neard release <code>1.36.0-rc.1</code> adds an experimental option to sync state from
external storage.</p>
<p>See <a href="misc/state_sync_from_external_storage.html">how-to</a> how to configure your node to
State Sync from External Storage.</p>
<p>In case you would like to manage your own dumps of State, keep reading.</p>
<h3 id="google-cloud-storage"><a class="header" href="#google-cloud-storage">Google Cloud Storage</a></h3>
<p>To enable Google Cloud Storage as your external storage, add this to your
<code>config.json</code> file:</p>
<pre><code class="language-json">&quot;state_sync&quot;: {
  &quot;dump&quot;: {
    &quot;location&quot;: {
      &quot;GCS&quot;: {
        &quot;bucket&quot;: &quot;my-gcs-bucket&quot;,
      }
    }
  }
}
</code></pre>
<p>And run your node with an environment variable <code>SERVICE_ACCOUNT</code> or
<code>GOOGLE_APPLICATION_CREDENTIALS</code> pointing to the credentials json file</p>
<pre><code class="language-shell">SERVICE_ACCOUNT=/path/to/file ./neard run
</code></pre>
<h3 id="amazon-s3"><a class="header" href="#amazon-s3">Amazon S3</a></h3>
<p>To enable Amazon S3 as your external storage, add this to your <code>config.json</code>
file:</p>
<pre><code class="language-json">&quot;state_sync&quot;: {
  &quot;dump&quot;: {
    &quot;location&quot;: {
      &quot;S3&quot;: {
        &quot;bucket&quot;: &quot;my-aws-bucket&quot;,
        &quot;region&quot;: &quot;my-aws-region&quot;
      }
    }    
  }
}
</code></pre>
<p>And run your node with environment variables <code>AWS_ACCESS_KEY_ID</code> and
<code>AWS_SECRET_ACCESS_KEY</code>:</p>
<pre><code class="language-shell">AWS_ACCESS_KEY_ID=&quot;MY_ACCESS_KEY&quot; AWS_SECRET_ACCESS_KEY=&quot;MY_AWS_SECRET_ACCESS_KEY&quot; ./neard run
</code></pre>
<h2 id="dump-to-a-local-filesystem"><a class="header" href="#dump-to-a-local-filesystem">Dump to a local filesystem</a></h2>
<p>Add this to your <code>config.json</code> file to dump state of every epoch to local
filesystem:</p>
<pre><code class="language-json">&quot;state_sync&quot;: {
  &quot;dump&quot;: {
    &quot;location&quot;: {
      &quot;Filesystem&quot;: {
        &quot;root_dir&quot;: &quot;/tmp/state-dump&quot;
      }
    }    
  }
}
</code></pre>
<p>In this case you don't need any extra environment variables. Simply run your
node:</p>
<pre><code class="language-shell">./neard run
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="archival-node---recovery-of-missing-data"><a class="header" href="#archival-node---recovery-of-missing-data">Archival node - Recovery of missing data</a></h1>
<h1 id="incident-description"><a class="header" href="#incident-description">Incident description</a></h1>
<p>In early 2024 there have been a few incidents on archival node storage. As result of these incidents archival node might have lost some data from January to March.</p>
<p>The practical effect of this issue is that requests querying the state of an account may fail, returning instead an internal server error.</p>
<h1 id="check-if-my-node-has-been-impacted"><a class="header" href="#check-if-my-node-has-been-impacted">Check if my node has been impacted</a></h1>
<p>The simplest way to check whether or not a node has suffered data loss is to run one of the following queries:</p>
<p><em>replace &lt;RPC_URL&gt; with the correct URL (example: <a href="http://localhost:3030">http://localhost:3030</a>)</em></p>
<pre><code class="language-bash">curl -X POST &lt;RPC_URL&gt; \
        -H &quot;Content-Type: application/json&quot; \
        -d '
        { &quot;id&quot;: &quot;dontcare&quot;, &quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;method&quot;: &quot;query&quot;, &quot;params&quot;: { &quot;account_id&quot;: &quot;b001b461c65aca5968a0afab3302a5387d128178c99ff5b2592796963407560a&quot;, &quot;block_id&quot;: 109913260, &quot;request_type&quot;: &quot;view_account&quot; } }'
</code></pre>
<pre><code class="language-bash">curl -X POST &lt;RPC_URL&gt; \
        -H &quot;Content-Type: application/json&quot; \
        -d '
        { &quot;id&quot;: &quot;dontcare&quot;, &quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;method&quot;: &quot;query&quot;, &quot;params&quot;: { &quot;account_id&quot;: &quot;token2.near&quot;, &quot;block_id&quot;: 114580308, &quot;request_type&quot;: &quot;view_account&quot; } }'
</code></pre>
<!-- cspell:ignore timpanic -->
<pre><code class="language-bash">curl -X POST &lt;RPC_URL&gt; \
        -H &quot;Content-Type: application/json&quot; \
        -d '
        { &quot;id&quot;: &quot;dontcare&quot;, &quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;method&quot;: &quot;query&quot;, &quot;params&quot;: { &quot;account_id&quot;: &quot;timpanic.tg&quot;, &quot;block_id&quot;: 115185110, &quot;request_type&quot;: &quot;view_account&quot; } }'
</code></pre>
<pre><code class="language-bash">curl -X POST &lt;RPC_URL&gt; \
        -H &quot;Content-Type: application/json&quot; \
        -d '
        { &quot;id&quot;: &quot;dontcare&quot;, &quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;method&quot;: &quot;query&quot;, &quot;params&quot;: { &quot;account_id&quot;: &quot;01.near&quot;, &quot;block_id&quot;: 115514400, &quot;request_type&quot;: &quot;view_account&quot; } }'
</code></pre>
<p>If for any of the above requests you get an error of the kind <code>MissingTrieValue</code> it means that the node presents the issue.</p>
<h1 id="remediation-steps"><a class="header" href="#remediation-steps">Remediation steps</a></h1>
<h2 id="option-a-recommended-download-a-new-db-snapshot"><a class="header" href="#option-a-recommended-download-a-new-db-snapshot">Option A (recommended): download a new DB snapshot</a></h2>
<ol>
<li>
<p>Stop <code>neard</code></p>
</li>
<li>
<p>Delete the existing <code>hot</code> and <code>cold</code> databases. Example assuming default configuration:</p>
<pre><code class="language-bash">rm -rf ~/.near/hot-data &amp;&amp; rm -rf ~/.near/cold-data
</code></pre>
</li>
<li>
<p>Download an up-to-date snapshot, following this guide: <a href="https://near-nodes.io/archival/split-storage-archival#S3%20migration">Storage snapshots</a></p>
</li>
</ol>
<h2 id="option-b-manually-run-recovery-commands"><a class="header" href="#option-b-manually-run-recovery-commands">Option B: manually run recovery commands</a></h2>
<p>Follow the instructions below if, for any reason, you prefer to perform the manual recovery steps on your node instead of downloading a new snapshot.</p>
<p><strong>Requirements:</strong></p>
<ul>
<li><code>neard</code> must be stopped while recovering data</li>
<li><code>cold</code> storage must be mounted on an SSD disk or better</li>
<li>The config <code>resharding_config.batch_delay</code> must be set to 0.</li>
</ul>
<p>After the recovery is finished the configuration changes can be undone and a hard disk drive can be used to mount the <code>cold</code> storage.</p>
<p><strong>Important considerations:</strong></p>
<ul>
<li>The recovery procedure will, most likely, take more than one week
<ul>
<li>Since <code>neard</code> must be stopped in order to execute the commands, the node won't be functional during this period of time</li>
</ul>
</li>
<li>The node must catch up to the chain's head after completing the data recovery, this could take days as well
<ul>
<li>During catch up the node can answer RPC queries. However, the chain head is still at the point where the node was stopped; for this reason recent blocks won't be available immediately</li>
</ul>
</li>
</ul>
<p>We published a <a href="https://github.com/near/nearcore/blob/master/scripts/recover_missing_archival_data.sh">reference recovery script</a> in the <code>nearcore</code> repository. Your <code>neard</code> setup might be different, so the advice is to thoroughly check the script before running it. For completeness, here we include the set of commands to run:</p>
<pre><code class="language-bash">neard view-state -t cold --readwrite apply-range --start-index 109913254 --end-index 110050000 --shard-id 2 --storage trie-free --save-state cold sequential
</code></pre>
<pre><code class="language-bash">RUST_LOG=debug neard database resharding --height 114580307 --shard-id 0 --restore
</code></pre>
<pre><code class="language-bash">RUST_LOG=debug neard database resharding --height 114580307 --shard-id 1 --restore
</code></pre>
<pre><code class="language-bash">RUST_LOG=debug neard database resharding --height 114580307 --shard-id 2 --restore
</code></pre>
<pre><code class="language-bash">RUST_LOG=debug neard database resharding --height 114580307 --shard-id 3 --restore
</code></pre>
<pre><code class="language-bash">RUST_LOG=debug neard database resharding --height 115185107 --shard-id 0 --restore
</code></pre>
<pre><code class="language-bash">RUST_LOG=debug neard database resharding --height 115185107 --shard-id 1 --restore
</code></pre>
<pre><code class="language-bash">RUST_LOG=debug neard database resharding --height 115185107 --shard-id 2 --restore
</code></pre>
<pre><code class="language-bash">RUST_LOG=debug neard database resharding --height 115185107 --shard-id 3 --restore
</code></pre>
<pre><code class="language-bash">RUST_LOG=debug neard database resharding --height 115185107 --shard-id 4 --restore
</code></pre>
<h2 id="verify-if-remediation-has-been-successful"><a class="header" href="#verify-if-remediation-has-been-successful">Verify if remediation has been successful</a></h2>
<p>Run the queries specified in the section: <a href="https://docs.nearone.org/doc/archival-node-recovery-of-missing-data-speQFTJc0L#h-check-if-my-node-has-been-impacted">Check if my node has been impacted</a>. All of them should return a successful response now.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
            </nav>

        </div>

        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
    </body>
</html>
